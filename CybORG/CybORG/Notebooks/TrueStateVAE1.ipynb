{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True State VAE\n",
    "\n",
    "Creating a simple VAE model to learn how to encode-decode true states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.8/dist-packages (0.19.0)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (1.3.0)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (0.1.8)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (5.1.1)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (2.2.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from tensorflow-probability) (1.14.0)\n",
      "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (1.23.4)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-probability\n",
    "from IPython import display\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import time\n",
    "\n",
    "from ray.rllib.offline.json_reader import JsonReader\n",
    "import numpy_indexed as npi\n",
    "import pandas as pd\n",
    "from true_state_viewer import TrueStateTreeGraphViz, display_tree_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from https://www.tensorflow.org/tutorials/generative/cvae\n",
    "class TrueStateVAE(tf.keras.Model):\n",
    "  \"\"\"Convolutional variational autoencoder.\"\"\"\n",
    "\n",
    "  def __init__(self, latent_dim):\n",
    "    super(TrueStateVAE, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(78)),\n",
    "#             tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(8192, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(16384, activation=\"relu\"),\n",
    "#             RUN 7\n",
    "#             tf.keras.layers.Dense(10000, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(6000, activation=\"relu\"),\n",
    "#               RUN 8 (bs32) RUN 9 (BS64)\n",
    "#             tf.keras.layers.Dense(15000, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(10000, activation=\"relu\"),\n",
    "#             RUN 10 (bs64, L8)\n",
    "            tf.keras.layers.Dense(12288, activation=\"relu\"),\n",
    "            tf.keras.layers.Reshape([64,64,3]),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=128, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "#             tf.keras.layers.Conv2D(\n",
    "#                 filters=128, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "#             tf.keras.layers.Dense(8192, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(4096, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(2048, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(latent_dim)\n",
    "            # No activation\n",
    "            tf.keras.layers.Dense(latent_dim + latent_dim)\n",
    "        ]\n",
    "    )\n",
    "#     self.dist_fc = tf.keras.Sequential(\n",
    "#         [\n",
    "#             tf.keras.layers.Dense(latent_dim + latent_dim)\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "    self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "#             tf.keras.layers.Dense(2048, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(4096, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(8192, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(6000, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(10000, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(10000, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(15000, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(units=28800, activation=tf.nn.relu),\n",
    "#             tf.keras.layers.Dense(units=4608, activation=tf.nn.relu),\n",
    "#             tf.keras.layers.Reshape(target_shape=(6, 6, 128)),\n",
    "            tf.keras.layers.Reshape(target_shape=(15, 15, 128)),\n",
    "#             tf.keras.layers.Conv2DTranspose(\n",
    "#                 filters=128, kernel_size=3, strides=2, padding='same',\n",
    "#                 activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=128, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            # No activation\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=1, kernel_size=3, strides=1, padding='same'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "#             tf.keras.layers.Dense(16384, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(8192, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(78)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "#   @tf.function\n",
    "#   def get_dist(self, x):\n",
    "#     mean, logvar = tf.split(self.dist_fc(x), num_or_size_splits=2, axis=1)\n",
    "#     return mean, logvar\n",
    "\n",
    "  @tf.function\n",
    "  def sample(self, eps=None):\n",
    "    if eps is None:\n",
    "      eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "    return self.decode(eps, apply_sigmoid=True)\n",
    "  \n",
    "  @tf.function\n",
    "  def encode(self, x):\n",
    "    return tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "\n",
    "  @tf.function\n",
    "  def reparameterize(self, mean, logvar):\n",
    "#     eps = tf.random.normal(shape=mean.shape)\n",
    "    eps = tf.random.normal(shape=tf.shape(mean))\n",
    "    \n",
    "    return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "  @tf.function\n",
    "  def decode(self, z, apply_sigmoid=False):\n",
    "    logits = self.decoder(z)\n",
    "    if apply_sigmoid:\n",
    "      probs = tf.sigmoid(logits)\n",
    "      return probs\n",
    "    return logits\n",
    "\n",
    "  @tf.function\n",
    "  def get_oh_output(self, predictions):\n",
    "    pred_oh = tf.one_hot(tf.argmax(tf.nn.softmax(tf.reshape(predictions,(-1,2,3))),axis=2),depth=3)\n",
    "    return pred_oh\n",
    "    \n",
    "  def call(self, inputs, training):\n",
    "    mean, logvar = self.encode(inputs)\n",
    "    z = self.reparameterize(mean, logvar)\n",
    "    x_logit = self.decode(z)\n",
    "    return x_logit\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "  log2pi = tf.math.log(2. * np.pi)\n",
    "  return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis)\n",
    "\n",
    "\n",
    "# TODO: make this a combination of cat cross entropy\n",
    "def compute_loss(model, x):\n",
    "  mean, logvar = model.encode(x)\n",
    "  z = model.reparameterize(mean, logvar)\n",
    "  x_logit = model.decode(z)\n",
    "  \n",
    "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "  logpx_z = -tf.reduce_sum(cross_ent, axis=[1])\n",
    "\n",
    "#   THIS SHOULD WORK BETTER....\n",
    "#   as suggested in https://medium.com/p/53eefdfdbcc7\n",
    "#   acc = 0\n",
    "#   for i in range(26):\n",
    "#     cross_ent = tf.nn.softmax_cross_entropy_with_logits(logits=x_logit[:,i*3:(i*3)+3], labels=x[:,i*3:(i*3)+3])\n",
    "#     acc += cross_ent#tf.reduce_sum(cross_ent, axis=[1])\n",
    "#   logpx_z = -acc\n",
    "\n",
    "#   logpx_z = logpx_z/26\n",
    "\n",
    "\n",
    "  logpz = log_normal_pdf(z, 0., 0.)\n",
    "  logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "  \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "  This function computes the loss and gradients, and uses the latter to\n",
    "  update the model's parameters.\n",
    "  \"\"\"\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss = compute_loss(model, x)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "latent_dim = 8\n",
    "# latent_dim = 5\n",
    "# num_examples_to_generate = 16\n",
    "\n",
    "# # keeping the random vector constant for generation (prediction) so\n",
    "# # it will be easier to see the improvement.\n",
    "# random_vector_for_generation = tf.random.normal(\n",
    "#     shape=[num_examples_to_generate, latent_dim])\n",
    "true_state_model = TrueStateVAE(latent_dim)\n",
    "\n",
    "# train_size = 4445\n",
    "train_test_split = 0.98\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_45 (Dense)            (None, 12288)             970752    \n",
      "                                                                 \n",
      " reshape_19 (Reshape)        (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 31, 31, 64)        1792      \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 15, 15, 128)       73856     \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 28800)             0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 16)                460816    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,507,216\n",
      "Trainable params: 1,507,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "true_state_model.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows = 4445\n",
      "number of rows = 305\n",
      "number of rows = 7972\n",
      "number of rows = 12716\n"
     ]
    }
   ],
   "source": [
    "meander = pd.read_csv('csv_data/TrueStates_200_4000_Meander.csv')\n",
    "bline = pd.read_csv('csv_data/TrueStates_1221_4000_B_Line.csv')\n",
    "badbluemeander = pd.read_csv('csv_data/TrueStates_200_4000_Meander_badblue.csv')\n",
    "\n",
    "dataset = pd.concat([meander, bline, badbluemeander], ignore_index=True)\n",
    "dataset = dataset.drop_duplicates()\n",
    "\n",
    "print(f\"number of rows = {meander.shape[0]}\")\n",
    "print(f\"number of rows = {bline.shape[0]}\")\n",
    "print(f\"number of rows = {badbluemeander.shape[0]}\")\n",
    "print(f\"number of rows = {dataset.shape[0]}\")\n",
    "# dataset=bline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "train_df=dataset.sample(frac=train_test_split,random_state=200)\n",
    "test_df=dataset.drop(train_df.index)\n",
    "\n",
    "train_size = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (tf.data.Dataset.from_tensor_slices((train_df.iloc[:,1:].values)).shuffle(train_size).batch(batch_size))\n",
    "test_dataset = (tf.data.Dataset.from_tensor_slices((test_df.iloc[:,1:].values)).shuffle(train_size).batch(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 300, Test set ELBO: -11.290464401245117, time elapse for current epoch: 1.8965139389038086\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "  start_time = time.time()\n",
    "  for train_x in train_dataset:\n",
    "    train_x = tf.cast(train_x,tf.float32)\n",
    "    train_step(true_state_model, train_x, optimizer)\n",
    "  end_time = time.time()\n",
    "\n",
    "  loss = tf.keras.metrics.Mean()\n",
    "  for test_x in test_dataset:\n",
    "    test_x = tf.cast(test_x,tf.float32)\n",
    "    loss(compute_loss(true_state_model, test_x))\n",
    "  elbo = -loss.result()\n",
    "  display.clear_output(wait=False)\n",
    "  print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "        .format(epoch, elbo, end_time - start_time))\n",
    "#   generate_and_save_images(model, epoch, test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_pred_pair(model, state):\n",
    "  state = tf.cast(state, tf.float32)\n",
    "  mean, logvar = model.encode(state)\n",
    "  z = model.reparameterize(mean, logvar)\n",
    "  predictions = model.sample(z)\n",
    "    \n",
    "  state_oh = tf.reshape(state,(-1,2,3)) #tf.one_hot(tf.argmax(tf.reshape(state,(-1,3)),axis=1),depth=3)\n",
    "  pred_oh = model.get_oh_output(predictions)#tf.one_hot(tf.argmax(tf.nn.softmax(tf.reshape(predictions,(-1,2,3))),axis=2),depth=3)\n",
    "#   print(f\"{state_oh.shape}, {pred_oh.shape}\")\n",
    "  return state_oh, pred_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 163/254 = 0.6417322834645669, \n",
      "mean of squared diffs = 224.0/19812=0.011306279022814456\n",
      "percentage wrong = (224.0/2)/(19812/3)=0.016959418534221685\n",
      "254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipywidgets/widgets/widget.py:443: DeprecationWarning: Passing unrecognized arguments to super(IntSlider).__init__(name='Index').\n",
      "object.__init__() takes exactly one argument (the instance to initialize)\n",
      "This is deprecated in traitlets 4.2.This error will be raised in a future release of traitlets.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a7e64599af451e8304a218b7aa9ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='<<', style=ButtonStyle()), Button(description='>>', style=ButtonStyle()), I…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c2f927da164543bd28cdb670012d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\xfa\\x00\\x00\\x01[\\x08\\x02\\x00\\x00\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test_dataset = (tf.data.Dataset.from_tensor_slices((dataset.iloc[:200,1:].values)).shuffle(train_size).batch(batch_size))\n",
    "train_dataset2 = (tf.data.Dataset.from_tensor_slices((train_df.iloc[:,1:].values)).shuffle(train_size).batch(1))\n",
    "\n",
    "total_matches = 0\n",
    "total = 0\n",
    "nodes = 0\n",
    "sum_diffs_sqrd = 0\n",
    "state_pred_pairs = []\n",
    "state_pred_pair_tree_vis = []\n",
    "for test_x in test_dataset:\n",
    "    total +=1\n",
    "    state_oh, pred_oh = get_state_pred_pair(true_state_model, test_x)\n",
    "    \n",
    "    state_pred_pairs.append([state_oh, pred_oh])\n",
    "    state_pred_pair_tree_vis.append([TrueStateTreeGraphViz(state_oh), TrueStateTreeGraphViz(pred_oh)])\n",
    "    \n",
    "    diffs = np.rint(state_oh.numpy()) - np.rint(pred_oh.numpy())\n",
    "#     diffs = get_state_diff(true_state_model,test_x)\n",
    "    nodes += len(diffs.flatten())\n",
    "    diffs_sqrd = np.sum(diffs*diffs)\n",
    "    sum_diffs_sqrd += diffs_sqrd\n",
    "    if not diffs_sqrd >0:\n",
    "#       print(diffs)\n",
    "#     else:\n",
    "      total_matches += 1\n",
    "#       print(\"Match\")\n",
    "#       print(diffs)\n",
    "\n",
    "print(f\"accuracy = {total_matches}/{total} = {total_matches/total}, \\nmean of squared diffs = {sum_diffs_sqrd}/{nodes}={sum_diffs_sqrd/nodes}\\npercentage wrong = ({sum_diffs_sqrd}/{2})/({nodes}/{3})={(sum_diffs_sqrd/2)/(nodes/3)}\")\n",
    "display_tree_pairs(state_pred_pair_tree_vis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# true_state_model.build((1,78))\n",
    "true_state_model(np.ones((1,78)))\n",
    "true_state_model.save('models/trueStateVAE_11_L8',overwrite=True)# best one is L8 3 or 4 or 6 or 7 (78%).. need to check\n",
    "# m2 = Tr\n",
    "# # true_state_model.save('models/trueStateVAE_1')\n",
    "# true_state_model.compile()\n",
    "# # true_state_model._set_inputs(test_x)\n",
    "# true_state_model.fit(dataset, epochs=1)\n",
    "# tf.keras.models.save_model(\n",
    "#     true_state_model,\n",
    "#     'models/trueStateVAE_1',\n",
    "#     overwrite=False,\n",
    "#     include_optimizer=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "m2 = tf.keras.models.load_model(\n",
    "    'models/trueStateVAE_7_L8',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 194/254 = 0.7637795275590551, \n",
      "mean of squared diffs = 134.0/19812=0.006763577629719362\n",
      "percentage wrong = (134.0/2)/(19812/3)=0.010145366444579043\n",
      "254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipywidgets/widgets/widget.py:443: DeprecationWarning: Passing unrecognized arguments to super(IntSlider).__init__(name='Index').\n",
      "object.__init__() takes exactly one argument (the instance to initialize)\n",
      "This is deprecated in traitlets 4.2.This error will be raised in a future release of traitlets.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8336e965744af897d70b59f308e6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='<<', style=ButtonStyle()), Button(description='>>', style=ButtonStyle()), I…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87444ab909ae4cca98d259e2f89e680d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\xfa\\x00\\x00\\x01[\\x08\\x02\\x00\\x00\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# m2.sample()\n",
    "total_matches = 0\n",
    "total = 0\n",
    "nodes = 0\n",
    "sum_diffs_sqrd = 0\n",
    "state_pred_pairs = []\n",
    "state_pred_pair_tree_vis = []\n",
    "for test_x in test_dataset:\n",
    "    total +=1\n",
    "    state_oh, pred_oh = get_state_pred_pair(m2, test_x)\n",
    "    \n",
    "    state_pred_pairs.append([state_oh, pred_oh])\n",
    "    state_pred_pair_tree_vis.append([TrueStateTreeGraphViz(state_oh), TrueStateTreeGraphViz(pred_oh)])\n",
    "    \n",
    "    diffs = np.rint(state_oh.numpy()) - np.rint(pred_oh.numpy())\n",
    "#     diffs = get_state_diff(true_state_model,test_x)\n",
    "    nodes += len(diffs.flatten())\n",
    "    diffs_sqrd = np.sum(diffs*diffs)\n",
    "    sum_diffs_sqrd += diffs_sqrd\n",
    "    if not diffs_sqrd >0:\n",
    "#       print(diffs)\n",
    "#     else:\n",
    "      total_matches += 1\n",
    "#       print(\"Match\")\n",
    "#       print(diffs)\n",
    "\n",
    "print(f\"accuracy = {total_matches}/{total} = {total_matches/total}, \\nmean of squared diffs = {sum_diffs_sqrd}/{nodes}={sum_diffs_sqrd/nodes}\\npercentage wrong = ({sum_diffs_sqrd}/{2})/({nodes}/{3})={(sum_diffs_sqrd/2)/(nodes/3)}\")\n",
    "display_tree_pairs(state_pred_pair_tree_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 10000)             790000    \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 6000)              60006000  \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 16)                96016     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60,892,016\n",
      "Trainable params: 60,892,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m2.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
