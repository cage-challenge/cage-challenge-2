{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True State VAE\n",
    "\n",
    "Creating a simple VAE model to learn how to encode-decode true states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.8/dist-packages (0.19.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (5.1.1)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (0.1.8)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (1.3.0)\n",
      "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (0.4.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from tensorflow-probability) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (1.23.4)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (2.2.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 23.0 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-probability\n",
    "from IPython import display\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import time\n",
    "\n",
    "from ray.rllib.offline.json_reader import JsonReader\n",
    "import numpy_indexed as npi\n",
    "import pandas as pd\n",
    "from true_state_viewer import TrueStateTreeGraphViz, display_tree_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from https://www.tensorflow.org/tutorials/generative/cvae\n",
    "class TrueStateVAE(tf.keras.Model):\n",
    "  \"\"\"Convolutional variational autoencoder.\"\"\"\n",
    "\n",
    "  def __init__(self, latent_dim):\n",
    "    super(TrueStateVAE, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(78)),\n",
    "#             tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(8192, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(16384, activation=\"relu\"),\n",
    "#             RUN 7\n",
    "#             tf.keras.layers.Dense(10000, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(6000, activation=\"relu\"),\n",
    "#               RUN 8 (bs32) RUN 9 (BS64)\n",
    "#             tf.keras.layers.Dense(15000, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(10000, activation=\"relu\"),\n",
    "#             RUN 10 (bs64, L8)\n",
    "            tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(latent_dim + latent_dim)\n",
    "        ]\n",
    "    )\n",
    "#     self.dist_fc = tf.keras.Sequential(\n",
    "#         [\n",
    "#             tf.keras.layers.Dense(latent_dim + latent_dim)\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "    self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "\n",
    "        \n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(78)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "#   @tf.function\n",
    "#   def get_dist(self, x):\n",
    "#     mean, logvar = tf.split(self.dist_fc(x), num_or_size_splits=2, axis=1)\n",
    "#     return mean, logvar\n",
    "\n",
    "  @tf.function\n",
    "  def sample(self, eps=None):\n",
    "    if eps is None:\n",
    "      eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "    return self.decode(eps, apply_sigmoid=True)\n",
    "  \n",
    "  @tf.function\n",
    "  def encode(self, x):\n",
    "    return tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "\n",
    "  @tf.function\n",
    "  def reparameterize(self, mean, logvar):\n",
    "#     eps = tf.random.normal(shape=mean.shape)\n",
    "    eps = tf.random.normal(shape=tf.shape(mean))\n",
    "    \n",
    "    return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "  @tf.function\n",
    "  def decode(self, z, apply_sigmoid=False):\n",
    "    logits = self.decoder(z)\n",
    "    if apply_sigmoid:\n",
    "      probs = tf.sigmoid(logits)\n",
    "      return probs\n",
    "    return logits\n",
    "\n",
    "  @tf.function\n",
    "  def get_oh_output(self, predictions):\n",
    "    pred_oh = tf.one_hot(tf.argmax(tf.nn.softmax(tf.reshape(predictions,(-1,2,3))),axis=2),depth=3)\n",
    "    return pred_oh\n",
    "    \n",
    "  def call(self, inputs, training):\n",
    "    mean, logvar = self.encode(inputs)\n",
    "    z = self.reparameterize(mean, logvar)\n",
    "    x_logit = self.decode(z)\n",
    "    return x_logit\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(.25e-4)\n",
    "\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "  log2pi = tf.math.log(2. * np.pi)\n",
    "  return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis)\n",
    "\n",
    "\n",
    "# TODO: make this a combination of cat cross entropy\n",
    "def compute_loss(model, x):\n",
    "  mean, logvar = model.encode(x)\n",
    "  z = model.reparameterize(mean, logvar)\n",
    "  x_logit = model.decode(z)\n",
    "  \n",
    "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "  logpx_z = -tf.reduce_sum(cross_ent, axis=[1])\n",
    "\n",
    "#   THIS SHOULD WORK BETTER....\n",
    "#   as suggested in https://medium.com/p/53eefdfdbcc7\n",
    "#   acc = 0\n",
    "#   for i in range(26):\n",
    "#     cross_ent = tf.nn.softmax_cross_entropy_with_logits(logits=x_logit[:,i*3:(i*3)+3], labels=x[:,i*3:(i*3)+3])\n",
    "#     acc += cross_ent#tf.reduce_sum(cross_ent, axis=[1])\n",
    "#   logpx_z = -acc\n",
    "\n",
    "#   logpx_z = logpx_z/26\n",
    "\n",
    "\n",
    "  logpz = log_normal_pdf(z, 0., 0.)\n",
    "  logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "  \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "  This function computes the loss and gradients, and uses the latter to\n",
    "  update the model's parameters.\n",
    "  \"\"\"\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss = compute_loss(model, x)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "latent_dim = 16\n",
    "# latent_dim = 5\n",
    "# num_examples_to_generate = 16\n",
    "\n",
    "# # keeping the random vector constant for generation (prediction) so\n",
    "# # it will be easier to see the improvement.\n",
    "# random_vector_for_generation = tf.random.normal(\n",
    "#     shape=[num_examples_to_generate, latent_dim])\n",
    "true_state_model = TrueStateVAE(latent_dim)\n",
    "\n",
    "# train_size = 4445\n",
    "train_test_split = 0.95\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_138 (Dense)           (None, 512)               40448     \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_140 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 32)                4128      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 553,760\n",
      "Trainable params: 553,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "true_state_model.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows = 4515\n"
     ]
    }
   ],
   "source": [
    "meander = pd.read_csv('csv_data/all_true_states.csv')\n",
    "#bline = pd.read_csv('csv_data/TrueStates_1221_4000_B_Line.csv')\n",
    "#badbluemeander = pd.read_csv('csv_data/TrueStates_200_4000_Meander_badblue.csv')\n",
    "\n",
    "#dataset = pd.concat([meander, bline, badbluemeander], ignore_index=True)\n",
    "#dataset = dataset.drop_duplicates()\n",
    "\n",
    "dataset = meander\n",
    "\n",
    "print(f\"number of rows = {meander.shape[0]}\")\n",
    "#print(f\"number of rows = {bline.shape[0]}\")\n",
    "#print(f\"number of rows = {badbluemeander.shape[0]}\")\n",
    "#print(f\"number of rows = {dataset.shape[0]}\")\n",
    "# dataset=bline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>0_unknown</th>\n",
       "      <th>0_known</th>\n",
       "      <th>0_scanned</th>\n",
       "      <th>0_none</th>\n",
       "      <th>0_user</th>\n",
       "      <th>0_privileged</th>\n",
       "      <th>1_unknown</th>\n",
       "      <th>1_known</th>\n",
       "      <th>1_scanned</th>\n",
       "      <th>...</th>\n",
       "      <th>11_scanned</th>\n",
       "      <th>11_none</th>\n",
       "      <th>11_user</th>\n",
       "      <th>11_privileged</th>\n",
       "      <th>12_unknown</th>\n",
       "      <th>12_known</th>\n",
       "      <th>12_scanned</th>\n",
       "      <th>12_none</th>\n",
       "      <th>12_user</th>\n",
       "      <th>12_privileged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4510</th>\n",
       "      <td>4510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4511</th>\n",
       "      <td>4511</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4512</th>\n",
       "      <td>4512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4513</th>\n",
       "      <td>4513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4514</th>\n",
       "      <td>4514</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4515 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.1  0_unknown  0_known  0_scanned  0_none  0_user  \\\n",
       "0                0          1        0          0       1       0   \n",
       "1                1          1        0          0       1       0   \n",
       "2                2          1        0          0       1       0   \n",
       "3                3          1        0          0       1       0   \n",
       "4                4          1        0          0       1       0   \n",
       "...            ...        ...      ...        ...     ...     ...   \n",
       "4510          4510          0        0          1       1       0   \n",
       "4511          4511          0        0          1       1       0   \n",
       "4512          4512          0        0          1       1       0   \n",
       "4513          4513          0        0          1       1       0   \n",
       "4514          4514          0        0          1       1       0   \n",
       "\n",
       "      0_privileged  1_unknown  1_known  1_scanned  ...  11_scanned  11_none  \\\n",
       "0                0          1        0          0  ...           0        1   \n",
       "1                0          1        0          0  ...           0        1   \n",
       "2                0          1        0          0  ...           1        1   \n",
       "3                0          1        0          0  ...           1        1   \n",
       "4                0          1        0          0  ...           1        1   \n",
       "...            ...        ...      ...        ...  ...         ...      ...   \n",
       "4510             0          0        0          1  ...           1        0   \n",
       "4511             0          0        0          1  ...           1        0   \n",
       "4512             0          0        0          1  ...           1        1   \n",
       "4513             0          0        0          1  ...           1        0   \n",
       "4514             0          0        0          1  ...           1        0   \n",
       "\n",
       "      11_user  11_privileged  12_unknown  12_known  12_scanned  12_none  \\\n",
       "0           0              0           1         0           0        1   \n",
       "1           0              0           0         1           0        1   \n",
       "2           0              0           0         1           0        1   \n",
       "3           0              0           0         1           0        1   \n",
       "4           0              0           0         0           1        1   \n",
       "...       ...            ...         ...       ...         ...      ...   \n",
       "4510        0              1           0         0           1        0   \n",
       "4511        0              1           0         0           1        0   \n",
       "4512        0              0           0         0           1        1   \n",
       "4513        1              0           0         0           1        1   \n",
       "4514        0              1           0         0           1        0   \n",
       "\n",
       "      12_user  12_privileged  \n",
       "0           0              0  \n",
       "1           0              0  \n",
       "2           0              0  \n",
       "3           0              0  \n",
       "4           0              0  \n",
       "...       ...            ...  \n",
       "4510        0              1  \n",
       "4511        0              1  \n",
       "4512        0              0  \n",
       "4513        0              0  \n",
       "4514        0              1  \n",
       "\n",
       "[4515 rows x 79 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.drop('Unnamed: 0', axis=1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "train_df=dataset.sample(frac=train_test_split,random_state=200)\n",
    "test_df=dataset.drop(train_df.index)\n",
    "\n",
    "train_size = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (tf.data.Dataset.from_tensor_slices((train_df.iloc[:,1:].values)).shuffle(train_size).batch(batch_size))\n",
    "test_dataset = (tf.data.Dataset.from_tensor_slices((test_df.iloc[:,1:].values)).shuffle(train_size).batch(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 300, Test set ELBO: -16.70627212524414, time elapse for current epoch: 0.39061713218688965\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "  start_time = time.time()\n",
    "  for train_x in train_dataset:\n",
    "    train_x = tf.cast(train_x,tf.float32)\n",
    "    train_step(true_state_model, train_x, optimizer)\n",
    "  end_time = time.time()\n",
    "\n",
    "  loss = tf.keras.metrics.Mean()\n",
    "  for test_x in test_dataset:\n",
    "    test_x = tf.cast(test_x,tf.float32)\n",
    "    loss(compute_loss(true_state_model, test_x))\n",
    "  elbo = -loss.result()\n",
    "  display.clear_output(wait=False)\n",
    "  print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "        .format(epoch, elbo, end_time - start_time))\n",
    "#   generate_and_save_images(model, epoch, test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def get_state_pred_pair(model, state):\n",
    "  state = tf.cast(state, tf.float32)\n",
    "  mean, logvar = model.encode(state)\n",
    "  z = model.reparameterize(mean, logvar)\n",
    "  predictions = model.sample(z)\n",
    "    \n",
    "  state_oh = tf.reshape(state,(-1,2,3)) #tf.one_hot(tf.argmax(tf.reshape(state,(-1,3)),axis=1),depth=3)\n",
    "  pred_oh = model.get_oh_output(predictions)#tf.one_hot(tf.argmax(tf.nn.softmax(tf.reshape(predictions,(-1,2,3))),axis=2),depth=3)\n",
    "#   print(f\"{state_oh.shape}, {pred_oh.shape}\")\n",
    "  return state_oh, pred_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0/226 = 0.0, \n",
      "mean of squared diffs = 6662.0/17628=0.3779214885409576\n",
      "percentage wrong = (6662.0/2)/(17628/3)=0.5668822328114363\n",
      "226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipywidgets/widgets/widget.py:443: DeprecationWarning: Passing unrecognized arguments to super(IntSlider).__init__(name='Index').\n",
      "object.__init__() takes exactly one argument (the instance to initialize)\n",
      "This is deprecated in traitlets 4.2.This error will be raised in a future release of traitlets.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf2a73cd76949d1a6e7cc5c83b09a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='<<', style=ButtonStyle()), Button(description='>>', style=ButtonStyle()), I…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b30b76c165456dbc50e795adcc6dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\xfa\\x00\\x00\\x01[\\x08\\x02\\x00\\x00\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test_dataset = (tf.data.Dataset.from_tensor_slices((dataset.iloc[:200,1:].values)).shuffle(train_size).batch(batch_size))\n",
    "#train_dataset2 = (tf.data.Dataset.from_tensor_slices((train_df.iloc[:,1:].values)).shuffle(train_size).batch(1))\n",
    "\n",
    "total_matches = 0\n",
    "total = 0\n",
    "nodes = 0\n",
    "sum_diffs_sqrd = 0\n",
    "state_pred_pairs = []\n",
    "state_pred_pair_tree_vis = []\n",
    "for test_x in test_dataset:\n",
    "    total +=1\n",
    "    state_oh, pred_oh = get_state_pred_pair(true_state_model, test_x)\n",
    "    \n",
    "    state_pred_pairs.append([state_oh, pred_oh])\n",
    "    state_pred_pair_tree_vis.append([TrueStateTreeGraphViz(state_oh), TrueStateTreeGraphViz(pred_oh)])\n",
    "    \n",
    "    diffs = np.rint(state_oh.numpy()) - np.rint(pred_oh.numpy())\n",
    "#     diffs = get_state_diff(true_state_model,test_x)\n",
    "    nodes += len(diffs.flatten())\n",
    "    diffs_sqrd = np.sum(diffs*diffs)\n",
    "    sum_diffs_sqrd += diffs_sqrd\n",
    "    if not diffs_sqrd >0:\n",
    "#       print(diffs)\n",
    "#     else:\n",
    "      total_matches += 1\n",
    "#       print(\"Match\")\n",
    "#       print(diffs)\n",
    "\n",
    "print(f\"accuracy = {total_matches}/{total} = {total_matches/total}, \\nmean of squared diffs = {sum_diffs_sqrd}/{nodes}={sum_diffs_sqrd/nodes}\\npercentage wrong = ({sum_diffs_sqrd}/{2})/({nodes}/{3})={(sum_diffs_sqrd/2)/(nodes/3)}\")\n",
    "display_tree_pairs(state_pred_pair_tree_vis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# true_state_model.build((1,78))\n",
    "true_state_model(np.ones((1,78)))\n",
    "true_state_model.save('models/trueStateVAE_11_L8',overwrite=True)# best one is L8 3 or 4 or 6 or 7 (78%).. need to check\n",
    "# m2 = Tr\n",
    "# # true_state_model.save('models/trueStateVAE_1')\n",
    "# true_state_model.compile()\n",
    "# # true_state_model._set_inputs(test_x)\n",
    "# true_state_model.fit(dataset, epochs=1)\n",
    "# tf.keras.models.save_model(\n",
    "#     true_state_model,\n",
    "#     'models/trueStateVAE_1',\n",
    "#     overwrite=False,\n",
    "#     include_optimizer=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "m2 = tf.keras.models.load_model(\n",
    "    'models/trueStateVAE_11_L8',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0/226 = 0.0, \n",
      "mean of squared diffs = 1840.0/17628=0.10437939641479464\n",
      "percentage wrong = (1840.0/2)/(17628/3)=0.15656909462219196\n",
      "226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipywidgets/widgets/widget.py:443: DeprecationWarning: Passing unrecognized arguments to super(IntSlider).__init__(name='Index').\n",
      "object.__init__() takes exactly one argument (the instance to initialize)\n",
      "This is deprecated in traitlets 4.2.This error will be raised in a future release of traitlets.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c072c924f11488a88e741b07d46524a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='<<', style=ButtonStyle()), Button(description='>>', style=ButtonStyle()), I…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f3cfdace6f4ea283b31e3142e15686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\xfa\\x00\\x00\\x01[\\x08\\x02\\x00\\x00\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# m2.sample()\n",
    "total_matches = 0\n",
    "total = 0\n",
    "nodes = 0\n",
    "sum_diffs_sqrd = 0\n",
    "state_pred_pairs = []\n",
    "state_pred_pair_tree_vis = []\n",
    "for test_x in test_dataset:\n",
    "    total +=1\n",
    "    state_oh, pred_oh = get_state_pred_pair(m2, test_x)\n",
    "    \n",
    "    state_pred_pairs.append([state_oh, pred_oh])\n",
    "    state_pred_pair_tree_vis.append([TrueStateTreeGraphViz(state_oh), TrueStateTreeGraphViz(pred_oh)])\n",
    "    \n",
    "    diffs = np.rint(state_oh.numpy()) - np.rint(pred_oh.numpy())\n",
    "#     diffs = get_state_diff(true_state_model,test_x)\n",
    "    nodes += len(diffs.flatten())\n",
    "    diffs_sqrd = np.sum(diffs*diffs)\n",
    "    sum_diffs_sqrd += diffs_sqrd\n",
    "    if not diffs_sqrd >0:\n",
    "#       print(diffs)\n",
    "#     else:\n",
    "      total_matches += 1\n",
    "#       print(\"Match\")\n",
    "#       print(diffs)\n",
    "\n",
    "print(f\"accuracy = {total_matches}/{total} = {total_matches/total}, \\nmean of squared diffs = {sum_diffs_sqrd}/{nodes}={sum_diffs_sqrd/nodes}\\npercentage wrong = ({sum_diffs_sqrd}/{2})/({nodes}/{3})={(sum_diffs_sqrd/2)/(nodes/3)}\")\n",
    "display_tree_pairs(state_pred_pair_tree_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 10000)             790000    \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 6000)              60006000  \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 16)                96016     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60,892,016\n",
      "Trainable params: 60,892,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m2.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
