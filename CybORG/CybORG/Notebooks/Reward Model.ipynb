{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.offline.json_reader import JsonReader\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-03 11:29:04,952\tWARNING json_reader.py:238 -- Treating input directory as glob patterns: ['/tf/Cage/Notebooks/logs/APPO/RE3/*.json', '/tf/Cage/Notebooks/logs/APPO/RE3/*.zip']\n"
     ]
    }
   ],
   "source": [
    "input_reader = JsonReader(\"logs/APPO/RE3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [03:19<00:00, 50.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "970000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length=3\n",
    "num_episodes = 10000\n",
    "windows_per_episode = 100-sequence_length\n",
    "state_len = 52\n",
    "num_action = 1\n",
    "encoding_len = state_len + num_action\n",
    "state_to_index = {}\n",
    "index_to_state = {}\n",
    "state_index = 0\n",
    "\n",
    "data_points = num_episodes * windows_per_episode\n",
    "\n",
    "X = np.zeros((data_points,sequence_length,encoding_len))\n",
    "Y = np.zeros(data_points)\n",
    "\n",
    "index = 0\n",
    "for e in trange(num_episodes):\n",
    "    data = input_reader.next()\n",
    "    data['obs'].shape\n",
    "    for i in range(0, windows_per_episode):\n",
    "        if not data['obs'][i+1].tobytes() in state_to_index:\n",
    "            state_to_index[data['obs'][i+1].tobytes()] = state_index\n",
    "            index_to_state[state_index] = data['obs'][i+1].tobytes()\n",
    "            state_index += 1\n",
    "        r = data['rewards'][i]\n",
    "        if i < sequence_length:\n",
    "            s = np.zeros((sequence_length, encoding_len))\n",
    "            for k in range(0,i):\n",
    "                s[k,:] = np.concatenate([data['obs'][k], np.zeros(num_action)])\n",
    "        else:\n",
    "            #vec = np.zeros((sequence_length, num_action))\n",
    "            #vec[np.arange(sequence_length),data['actions'][i-sequence_length:i]] = 1\n",
    "            vec = np.array(data['actions'][i-sequence_length:i]) / 145\n",
    "            vec = vec.reshape(sequence_length,1)\n",
    "            s = np.concatenate([data['obs'][i-sequence_length:i], vec], axis=1)\n",
    "            \n",
    "        X[index,:,:] = s\n",
    "        Y[index] = r\n",
    "        index += 1\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_2 (Bidirectio  (None, 3, 512)           634880    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1536)              0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 256)               393472    \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,061,377\n",
      "Trainable params: 1,061,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 873000 samples, validate on 97000 samples\n",
      "Epoch 1/250\n",
      "873000/873000 [==============================] - 19s 22us/sample - loss: 0.1673 - val_loss: 0.3716\n",
      "Epoch 2/250\n",
      "873000/873000 [==============================] - 19s 22us/sample - loss: 0.1394 - val_loss: 0.4187\n",
      "Epoch 3/250\n",
      "873000/873000 [==============================] - 18s 21us/sample - loss: 0.1291 - val_loss: 0.3563\n",
      "Epoch 4/250\n",
      "873000/873000 [==============================] - 18s 21us/sample - loss: 0.1240 - val_loss: 0.3450\n",
      "Epoch 5/250\n",
      "873000/873000 [==============================] - 19s 22us/sample - loss: 0.1187 - val_loss: 0.4213\n",
      "Epoch 6/250\n",
      "873000/873000 [==============================] - 19s 22us/sample - loss: 0.1136 - val_loss: 0.3627\n",
      "Epoch 7/250\n",
      "873000/873000 [==============================] - 19s 22us/sample - loss: 0.1101 - val_loss: 0.3875\n",
      "Epoch 8/250\n",
      "873000/873000 [==============================] - 20s 23us/sample - loss: 0.1051 - val_loss: 0.4424\n",
      "Epoch 9/250\n",
      "873000/873000 [==============================] - 21s 23us/sample - loss: 0.1020 - val_loss: 0.3836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f80da444d60>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Bidirectional, Input\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(256, activation='relu', return_sequences=True), input_shape=(sequence_length, encoding_len)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X, Y, epochs=250, validation_split=0.1, verbose=1, callbacks=[callback], batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 9900/10000 [02:41<00:01, 61.38it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 990000 is out of bounds for axis 0 with size 990000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m r \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrewards\u001b[39m\u001b[38;5;124m'\u001b[39m][i]\n\u001b[1;32m     16\u001b[0m s \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobs\u001b[39m\u001b[38;5;124m'\u001b[39m][i]\n\u001b[0;32m---> 18\u001b[0m X[index,:] \u001b[38;5;241m=\u001b[39m s\n\u001b[1;32m     19\u001b[0m Y[index] \u001b[38;5;241m=\u001b[39m r\n\u001b[1;32m     20\u001b[0m index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 990000 is out of bounds for axis 0 with size 990000"
     ]
    }
   ],
   "source": [
    "sequence_length=1\n",
    "num_episodes = 10000\n",
    "windows_per_episode = 100-sequence_length\n",
    "state_len = 52\n",
    "\n",
    "data_points = num_episodes * windows_per_episode\n",
    "\n",
    "X = np.zeros((data_points,state_len))\n",
    "Y = np.zeros(data_points)\n",
    "\n",
    "index = 0\n",
    "for e in trange(num_episodes):\n",
    "    data = input_reader.next()\n",
    "    for i in range(0, 100):\n",
    "        r = data['rewards'][i]\n",
    "        s = data['obs'][i]\n",
    "            \n",
    "        X[index,:] = s\n",
    "        Y[index] = r\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(990000, 52)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 52)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_reader.next()['obs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val loss = 0.054"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_39 (Dense)            (None, 256)               13568     \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 243,969\n",
      "Trainable params: 243,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 891000 samples, validate on 99000 samples\n",
      "Epoch 1/250\n",
      "891000/891000 [==============================] - 8s 9us/sample - loss: 0.1091 - val_loss: 0.0566\n",
      "Epoch 2/250\n",
      "891000/891000 [==============================] - 8s 9us/sample - loss: 0.0938 - val_loss: 0.0549\n",
      "Epoch 3/250\n",
      "891000/891000 [==============================] - 9s 10us/sample - loss: 0.0907 - val_loss: 0.0540\n",
      "Epoch 4/250\n",
      "891000/891000 [==============================] - 7s 8us/sample - loss: 0.0898 - val_loss: 0.0546\n",
      "Epoch 5/250\n",
      "891000/891000 [==============================] - 7s 8us/sample - loss: 0.0877 - val_loss: 0.0549\n",
      "Epoch 6/250\n",
      "891000/891000 [==============================] - 8s 10us/sample - loss: 0.0871 - val_loss: 0.0547\n",
      "Epoch 7/250\n",
      "891000/891000 [==============================] - 8s 9us/sample - loss: 0.0862 - val_loss: 0.0546\n",
      "Epoch 8/250\n",
      "891000/891000 [==============================] - 7s 7us/sample - loss: 0.0862 - val_loss: 0.0547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f80db17c9d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Bidirectional, Input\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Bidirectional(LSTM(256, activation='relu', return_sequences=True), input_shape=(sequence_length, state_len)))\n",
    "#model.add(Flatten())\n",
    "model.add(Input(52))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X, Y, epochs=250, validation_split=0.1, verbose=1, callbacks=[callback], batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.15961137] : 0.0\n",
      "[-0.11099818] : 0.0\n",
      "[-0.10148653] : -0.10000000149011612\n",
      "[-0.1171312] : -0.10000000149011612\n",
      "[-0.23810643] : -0.10000000149011612\n",
      "[-0.18244702] : -0.10000000149011612\n",
      "[-0.22355002] : -0.10000000149011612\n",
      "[-0.12669125] : -0.10000000149011612\n",
      "[-0.46990216] : -0.10000000149011612\n",
      "[-0.36177063] : -0.10000000149011612\n",
      "[-0.6104989] : -0.10000000149011612\n",
      "[-0.12052961] : -0.10000000149011612\n",
      "[-0.21812779] : -0.10000000149011612\n",
      "[-0.17876002] : -0.10000000149011612\n",
      "[-0.21812779] : -0.10000000149011612\n",
      "[-0.12052961] : -0.10000000149011612\n",
      "[-0.23810643] : -0.10000000149011612\n",
      "[-0.21812779] : -0.10000000149011612\n",
      "[-1.3654217] : -0.10000000149011612\n",
      "[-0.1171312] : -0.10000000149011612\n",
      "[-0.19984646] : -0.10000000149011612\n",
      "[-0.21812779] : -0.10000000149011612\n",
      "[-0.2226271] : -0.10000000149011612\n",
      "[-0.12827392] : -0.10000000149011612\n",
      "[-0.44063365] : -0.10000000149011612\n",
      "[-0.354869] : -0.10000000149011612\n",
      "[-0.23865794] : -0.10000000149011612\n",
      "[-0.88061064] : -0.10000000149011612\n",
      "[-0.4950834] : -0.10000000149011612\n",
      "[-0.354869] : -0.10000000149011612\n",
      "[-0.22355002] : -0.10000000149011612\n",
      "[-0.12827392] : -0.10000000149011612\n",
      "[-0.45741808] : -0.10000000149011612\n",
      "[-0.354869] : -0.10000000149011612\n",
      "[-0.354869] : -0.10000000149011612\n",
      "[-0.11698582] : -0.10000000149011612\n",
      "[-0.2638464] : -0.10000000149011612\n",
      "[-0.21812779] : -0.10000000149011612\n",
      "[-0.2226271] : -0.10000000149011612\n",
      "[-0.12044748] : -0.10000000149011612\n",
      "[-0.2466141] : -0.10000000149011612\n",
      "[-0.17907622] : -0.10000000149011612\n",
      "[-0.1760475] : -0.10000000149011612\n",
      "[-0.12095609] : -0.10000000149011612\n",
      "[-0.21812779] : -0.10000000149011612\n",
      "[-0.2226271] : -0.10000000149011612\n",
      "[-0.23704335] : -0.10000000149011612\n",
      "[-0.3193692] : -0.10000000149011612\n",
      "[-0.46990216] : -0.10000000149011612\n",
      "[-0.24992603] : -0.10000000149011612\n",
      "[-0.354869] : -0.10000000149011612\n",
      "[-0.12867145] : -0.10000000149011612\n",
      "[-0.23810643] : -0.10000000149011612\n",
      "[-0.21812779] : -0.10000000149011612\n",
      "[-0.17876002] : -0.10000000149011612\n",
      "[-0.12076694] : -0.10000000149011612\n",
      "[-0.23810643] : -0.10000000149011612\n",
      "[-0.21812779] : -0.10000000149011612\n",
      "[-0.21812779] : -0.10000000149011612\n",
      "[-0.1171312] : -0.10000000149011612\n",
      "[-0.21812779] : -0.10000000149011612\n",
      "[-0.18244702] : -0.10000000149011612\n",
      "[-0.21812779] : -0.10000000149011612\n",
      "[-0.12052961] : -0.10000000149011612\n",
      "[-0.2466141] : -0.10000000149011612\n",
      "[-0.2226271] : -0.10000000149011612\n",
      "[-1.0995809] : -1.100000023841858\n",
      "[-0.23810643] : -0.10000000149011612\n",
      "[-1.0941055] : -1.100000023841858\n",
      "[-0.23911846] : -0.10000000149011612\n",
      "[-0.23810643] : -0.10000000149011612\n",
      "[-0.12052961] : -0.10000000149011612\n",
      "[-0.23810643] : -0.10000000149011612\n",
      "[-0.21812779] : -0.10000000149011612\n",
      "[-0.23810643] : -0.10000000149011612\n",
      "[-0.12052961] : -0.10000000149011612\n",
      "[-0.23810643] : -0.10000000149011612\n",
      "[-0.17907622] : -0.10000000149011612\n",
      "[-1.3654217] : -0.10000000149011612\n",
      "[-0.11883696] : -0.10000000149011612\n",
      "[-0.22415067] : -0.10000000149011612\n",
      "[-0.21812779] : -0.10000000149011612\n",
      "[-0.43816274] : -0.10000000149011612\n",
      "[-0.12052961] : -0.10000000149011612\n",
      "[-0.23810643] : -0.10000000149011612\n",
      "[-0.21812779] : -0.10000000149011612\n",
      "[-0.23810643] : -0.10000000149011612\n",
      "[-0.11883696] : -0.10000000149011612\n",
      "[-0.23810643] : -0.10000000149011612\n",
      "[-0.1760475] : -0.10000000149011612\n",
      "[-0.36586198] : -0.10000000149011612\n",
      "[-0.1171312] : -0.10000000149011612\n",
      "[-0.30992156] : -0.10000000149011612\n",
      "[-0.17907622] : -0.10000000149011612\n",
      "[-1.0941055] : -1.100000023841858\n",
      "[-0.23810643] : -0.10000000149011612\n",
      "[-0.28052765] : -0.10000000149011612\n",
      "[-0.12397487] : -0.10000000149011612\n",
      "[-0.23810643] : -0.10000000149011612\n",
      "[-0.21812777] : -0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X[0:100])\n",
    "count = 0\n",
    "for i in range(100):\n",
    "    print(str(predictions[i]) + ' : ' + str(Y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('RewardModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1508883]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.zeros((1,52)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
