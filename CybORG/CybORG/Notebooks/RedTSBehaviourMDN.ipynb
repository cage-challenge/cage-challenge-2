{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDN References:\n",
    "\n",
    "[useful pytorch reference](https://github.com/tonyduan/mixture-density-network)\n",
    "\n",
    "[keras version](https://github.com/cpmpercussion/keras-mdn-layer)\n",
    "\n",
    "[another keras version](https://github.com/omimo/Keras-MDN/blob/master/kmdn/mdn.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import MDN\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import pandas as pd\n",
    "from ProcessTrueStateActionData import read_df_in_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess the data \n",
    "(produce tf train+test datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_test_split = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_for_training():\n",
    "    true_states = [\"pre\",\"blue\",\"red\"]\n",
    "    ts_columns = {}\n",
    "    for true_state in true_states:\n",
    "        ts_columns[true_state] = []\n",
    "        for node in range(13):\n",
    "            ts_columns[true_state].append(f\"{node}_ts_{true_state}_known_status\")\n",
    "            ts_columns[true_state].append(f\"{node}_ts_{true_state}_access_status\")\n",
    "    return ts_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_dict = get_columns_for_training()\n",
    "pre_cols, blue_cols, red_cols = cols_dict[\"pre\"], cols_dict[\"blue\"], cols_dict[\"red\"]\n",
    "all_cols = pre_cols + blue_cols + red_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_parquet(\"csv_data/TrueStatesObsActsRwds_1221_4000_B_Line.parquet\")\n",
    "df = df[all_cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index                      39072000\n",
       "0_ts_pre_known_status       4884124\n",
       "0_ts_pre_access_status      4884116\n",
       "1_ts_pre_known_status       4884132\n",
       "1_ts_pre_access_status      4884132\n",
       "                             ...   \n",
       "10_ts_red_access_status     4884132\n",
       "11_ts_red_known_status      4884124\n",
       "11_ts_red_access_status     4884132\n",
       "12_ts_red_known_status      4884124\n",
       "12_ts_red_access_status     4884132\n",
       "Length: 79, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "train_df=df.sample(frac=train_test_split,random_state=42)\n",
    "train_pre_df = train_df[pre_cols]\n",
    "train_blue_df = train_df[blue_cols]\n",
    "train_red_df = train_df[red_cols]\n",
    "\n",
    "test_df=df.drop(train_df.index)\n",
    "test_pre_df = test_df[pre_cols]\n",
    "test_blue_df = test_df[blue_cols]\n",
    "test_red_df = test_df[red_cols]\n",
    "\n",
    "train_size = train_df.shape[0]\n",
    "test_size = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3907200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "print(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (tf.data.Dataset.from_tensor_slices(((train_pre_df.values,train_blue_df.values),train_red_df.values)).batch(batch_size))\n",
    "test_dataset = (tf.data.Dataset.from_tensor_slices(((test_pre_df.values,test_blue_df.values),test_red_df.values)).shuffle(test_size).batch(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((<tf.Tensor: shape=(64, 26), dtype=int64, numpy=\n",
      "array([[0, 0, 0, ..., 0, 1, 0],\n",
      "       [0, 0, 2, ..., 0, 2, 2],\n",
      "       [0, 0, 0, ..., 0, 1, 0],\n",
      "       ...,\n",
      "       [0, 0, 2, ..., 2, 1, 0],\n",
      "       [0, 0, 2, ..., 2, 1, 0],\n",
      "       [1, 0, 2, ..., 0, 2, 2]])>, <tf.Tensor: shape=(64, 26), dtype=int64, numpy=\n",
      "array([[0, 0, 0, ..., 0, 1, 0],\n",
      "       [0, 0, 2, ..., 0, 2, 2],\n",
      "       [0, 0, 0, ..., 0, 1, 0],\n",
      "       ...,\n",
      "       [0, 0, 2, ..., 2, 1, 0],\n",
      "       [0, 0, 2, ..., 2, 1, 0],\n",
      "       [1, 0, 2, ..., 0, 2, 2]])>), <tf.Tensor: shape=(64, 26), dtype=int64, numpy=\n",
      "array([[0, 0, 0, ..., 0, 1, 0],\n",
      "       [0, 0, 2, ..., 0, 2, 2],\n",
      "       [0, 0, 0, ..., 0, 1, 0],\n",
      "       ...,\n",
      "       [0, 0, 2, ..., 2, 1, 0],\n",
      "       [0, 0, 2, ..., 2, 1, 0],\n",
      "       [1, 0, 2, ..., 0, 2, 2]])>)\n"
     ]
    }
   ],
   "source": [
    "for row in train_dataset.take(1):\n",
    "  print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an MDN based model with pretrained encoder/decoder layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedTSPrediction(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, vae_path, latent_size, num_mixtures):\n",
    "        super().__init__()\n",
    "        self.ts_vae = tf.keras.models.load_model(vae_path)\n",
    "        self.ts_vae.trainable = False\n",
    "        self.encoder = self.ts_vae.encoder\n",
    "        self.decoder = self.ts_vae.decoder\n",
    "\n",
    "        self.ts_dense = tf.keras.layers.Dense(128, activation=tf.nn.relu)\n",
    "        self.cross_dense = tf.keras.layers.Dense(2048, activation=tf.nn.relu)\n",
    "\n",
    "        self.mdn = MDN.MDN(output_dimension=latent_size, num_mixtures=num_mixtures)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        pre_ts = inputs[0]\n",
    "        blue_ts = inputs[1]\n",
    "        \n",
    "        pre_ts_oh = tf.reshape(tf.one_hot(pre_ts,3),(-1,78))\n",
    "#         pre_ts_access = tf.reshape(tf.one_hot(pre_ts[:,13:],3),(-1,39))\n",
    "        \n",
    "        blue_ts_oh = tf.reshape(tf.one_hot(blue_ts,3),(-1,78))\n",
    "#         blue_ts_access = tf.reshape(tf.one_hot(blue_ts[:,13:],3),(-1,39))\n",
    "        \n",
    "        print(pre_ts[:,:])\n",
    "        print(pre_ts_oh)\n",
    "#         print(blue_ts)\n",
    "#         blue_ts_kn = K.print_tensor(blue_ts[:,:13], message='blue known = ')\n",
    "#         blue_ts_known = K.print_tensor(blue_ts_known[:,:13], message='blue known OH = ')\n",
    "#         print(blue_ts_known.shape)\n",
    "\n",
    "        pre_ts = self.ts_dense(self.encoder(pre_ts_oh))\n",
    "        blue_ts = self.ts_dense(self.encoder(blue_oh))\n",
    "\n",
    "        combined = tf.layers.concatenate([pre_ts, blue_ts])\n",
    "\n",
    "        combined_hidden = self.cross_dense(combined)\n",
    "\n",
    "        mdn_out = self.mdn(combined_hidden)\n",
    "\n",
    "        return mdn_out\n",
    "\n",
    "    def decode(self, latent_pred):\n",
    "        return self.decoder(latent_pred)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "red_ts_predictor = RedTSPrediction('models/trueStateVAE_7_L8', latent_size=8, num_mixtures=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in test_dataset.take(1):\n",
    "#   print(row)\n",
    "  out = red_ts_predictor(row[0])\n",
    "  print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
