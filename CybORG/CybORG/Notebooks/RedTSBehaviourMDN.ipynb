{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDN References:\n",
    "\n",
    "[useful pytorch reference](https://github.com/tonyduan/mixture-density-network)\n",
    "\n",
    "[keras version](https://github.com/cpmpercussion/keras-mdn-layer)\n",
    "\n",
    "[another keras version](https://github.com/omimo/Keras-MDN/blob/master/kmdn/mdn.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-probability\n",
      "  Downloading tensorflow_probability-0.19.0-py2.py3-none-any.whl (6.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.7 MB 20.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (1.23.4)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (0.1.8)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (2.2.1)\n",
      "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (0.4.0)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (1.3.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (5.1.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from tensorflow-probability) (1.14.0)\n",
      "Installing collected packages: tensorflow-probability\n",
      "Successfully installed tensorflow-probability-0.19.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.8/dist-packages (0.20.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-probability\n",
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import MDN\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import pandas as pd\n",
    "from ProcessTrueStateActionData import read_df_in_chunks\n",
    "\n",
    "from true_state_viewer import TrueStateTreeGraphViz, display_tree_pairs\n",
    "\n",
    "import time\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess the data \n",
    "(produce tf train+test datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "train_test_split = 0.99\n",
    "\n",
    "LATENT_SIZE = 8 # (mdn output_dimension)\n",
    "NUMBER_MIXTURES = 5\n",
    "\n",
    "EPOCHS = 30\n",
    "\n",
    "DATA_CAP = 2_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_for_training():\n",
    "    true_states = [\"pre\",\"blue\",\"red\"]\n",
    "    ts_columns = {}\n",
    "    for true_state in true_states:\n",
    "        ts_columns[true_state] = []\n",
    "        for node in range(13):\n",
    "            ts_columns[true_state].append(f\"{node}_ts_{true_state}_known_status\")\n",
    "            ts_columns[true_state].append(f\"{node}_ts_{true_state}_access_status\")\n",
    "    return ts_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_dict = get_columns_for_training()\n",
    "pre_cols, blue_cols, red_cols = cols_dict[\"pre\"], cols_dict[\"blue\"], cols_dict[\"red\"]\n",
    "all_cols = pre_cols + blue_cols + red_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_parquet(\"csv_data/TrueStatesObsActsRwds_1221_4000_B_Line.parquet\").iloc[:DATA_CAP]\n",
    "df = df[all_cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index                      16000000\n",
       "0_ts_pre_known_status       2000124\n",
       "0_ts_pre_access_status      2000116\n",
       "1_ts_pre_known_status       2000132\n",
       "1_ts_pre_access_status      2000132\n",
       "                             ...   \n",
       "10_ts_red_access_status     2000132\n",
       "11_ts_red_known_status      2000124\n",
       "11_ts_red_access_status     2000132\n",
       "12_ts_red_known_status      2000124\n",
       "12_ts_red_access_status     2000132\n",
       "Length: 79, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "train_df=df.sample(frac=train_test_split,random_state=42)\n",
    "train_pre_df = train_df[pre_cols]\n",
    "train_blue_df = train_df[blue_cols]\n",
    "train_red_df = train_df[red_cols]\n",
    "\n",
    "test_df=df.drop(train_df.index)\n",
    "test_pre_df = test_df[pre_cols]\n",
    "test_blue_df = test_df[blue_cols]\n",
    "test_red_df = test_df[red_cols]\n",
    "\n",
    "train_size = train_df.shape[0]\n",
    "test_size = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "print(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (tf.data.Dataset.from_tensor_slices(((train_pre_df.values,train_blue_df.values),train_red_df.values)).batch(batch_size))\n",
    "test_dataset = (tf.data.Dataset.from_tensor_slices(((test_pre_df.values,test_blue_df.values),test_red_df.values)).shuffle(test_size).batch(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((<tf.Tensor: shape=(128, 26), dtype=int64, numpy=\n",
      "array([[0, 0, 0, ..., 0, 1, 0],\n",
      "       [1, 0, 1, ..., 0, 1, 0],\n",
      "       [0, 0, 2, ..., 2, 1, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 1, 0],\n",
      "       [0, 0, 2, ..., 0, 2, 2],\n",
      "       [0, 0, 2, ..., 0, 2, 2]])>, <tf.Tensor: shape=(128, 26), dtype=int64, numpy=\n",
      "array([[0, 0, 0, ..., 0, 1, 0],\n",
      "       [1, 0, 1, ..., 0, 1, 0],\n",
      "       [0, 0, 2, ..., 2, 1, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 1, 0],\n",
      "       [0, 0, 2, ..., 0, 2, 2],\n",
      "       [0, 0, 2, ..., 0, 2, 2]])>), <tf.Tensor: shape=(128, 26), dtype=int64, numpy=\n",
      "array([[0, 0, 0, ..., 0, 1, 0],\n",
      "       [1, 0, 1, ..., 0, 1, 0],\n",
      "       [0, 0, 2, ..., 2, 1, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 1, 0],\n",
      "       [0, 0, 2, ..., 0, 2, 2],\n",
      "       [0, 0, 2, ..., 0, 2, 2]])>)\n"
     ]
    }
   ],
   "source": [
    "for row in train_dataset.take(1):\n",
    "  print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an MDN based model with pretrained encoder/decoder layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedTSPrediction(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, vae_path, latent_size, num_mixtures):\n",
    "        super().__init__()\n",
    "        self.ts_vae = tf.keras.models.load_model(vae_path)\n",
    "        self.ts_vae.trainable = False\n",
    "        self.encoder = self.ts_vae.encoder\n",
    "        self.decoder = self.ts_vae.decoder\n",
    "\n",
    "        self.ts_dense = tf.keras.layers.Dense(1024, activation=tf.nn.relu)\n",
    "        self.cross_dense = tf.keras.layers.Dense(4096, activation=tf.nn.relu)\n",
    "        \n",
    "        self.fc_1 = tf.keras.layers.Dense(4096, activation=tf.nn.relu)\n",
    "\n",
    "        self.mdn = MDN.MDN(output_dimension=latent_size, num_mixtures=num_mixtures)\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None,78], dtype=tf.float32)])\n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        return z\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None,LATENT_SIZE], dtype=tf.float32),tf.TensorSpec(shape=[None,LATENT_SIZE], dtype=tf.float32)])\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        #     eps = tf.random.normal(shape=mean.shape)\n",
    "        eps = tf.random.normal(shape=tf.shape(mean))\n",
    "\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    " \n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None,LATENT_SIZE], dtype=tf.float32)])\n",
    "    def decode(self, latent, apply_sigmoid=False):\n",
    "        logits = self.decoder(latent)\n",
    "        if apply_sigmoid:\n",
    "          probs = tf.sigmoid(logits)\n",
    "        return logits #self.decoder(latent_pred)\n",
    "\n",
    "    @tf.function#(input_signature=[tf.TensorSpec(shape=[None,26], dtype=tf.uint8),tf.TensorSpec(shape=[None,26], dtype=tf.uint8)])\n",
    "    def call(self, inputs):\n",
    "        pre_ts = inputs[0]\n",
    "        blue_ts = inputs[1]\n",
    "        \n",
    "        pre_ts_oh = tf.cast(tf.reshape(tf.one_hot(pre_ts,3),(-1,78)),tf.float32)\n",
    "#         pre_ts_access = tf.reshape(tf.one_hot(pre_ts[:,13:],3),(-1,39))\n",
    "        \n",
    "        blue_ts_oh = tf.cast(tf.reshape(tf.one_hot(blue_ts,3),(-1,78)),tf.float32)\n",
    "#         blue_ts_access = tf.reshape(tf.one_hot(blue_ts[:,13:],3),(-1,39))\n",
    "        \n",
    "#         print(pre_ts[:,:])\n",
    "#         print(pre_ts_oh)\n",
    "#         print(blue_ts)\n",
    "#         blue_ts_kn = K.print_tensor(blue_ts[:,:13], message='blue known = ')\n",
    "#         blue_ts_known = K.print_tensor(blue_ts_known[:,:13], message='blue known OH = ')\n",
    "#         print(blue_ts_known.shape)\n",
    "\n",
    "        pre_ts_encoded = self.encode(pre_ts_oh)\n",
    "#         mean, logvar = self.ts_vae.encode(pre_ts_oh)\n",
    "#         mean, logvar = tf.split(self.encoder(pre_ts_oh), num_or_size_splits=2, axis=1)\n",
    "#         pre_ts_encoded = self.reparameterize(mean, logvar)\n",
    "        pre_ts_encoded = self.ts_dense(pre_ts_encoded)\n",
    "        \n",
    "        blue_ts_encoded = self.encode(blue_ts_oh)\n",
    "        blue_ts_encoded = self.ts_dense(blue_ts_encoded)\n",
    "\n",
    "        combined = tf.keras.layers.concatenate([pre_ts_encoded, blue_ts_encoded])\n",
    "\n",
    "        combined_hidden = self.cross_dense(combined)\n",
    "        \n",
    "        fc = self.fc_1(combined_hidden)\n",
    "\n",
    "        mdn_out = self.mdn(fc)\n",
    "\n",
    "        return mdn_out\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def forward_pass(model, x, y):\n",
    "    out = model(x)\n",
    "    \n",
    "    y_oh = tf.reshape(tf.one_hot(y,3),(-1,78))\n",
    "    y_encoded = model.encode(y_oh)\n",
    "    \n",
    "    return out, y_encoded\n",
    "\n",
    "@tf.function\n",
    "def decode_z(model, x):\n",
    "    x_oh = model.ts_vae.get_oh_output(model.decode(tf.cast(x,tf.float32)))\n",
    "#     y_oh = model.ts_vae.get_oh_output(model.decode(tf.cast(y,tf.float32)))\n",
    "    \n",
    "    return x_oh\n",
    "    \n",
    "\n",
    "@tf.function\n",
    "def compute_loss(model, x, y, loss_func):\n",
    "    out, y_encoded = forward_pass(model, x, y)\n",
    "    \n",
    "    loss = loss_func(y_encoded, out)\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x, y, optimizer, loss_func):\n",
    "    \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "    This function computes the loss and gradients, and uses the latter to\n",
    "    update the model's parameters.\n",
    "    \"\"\"\n",
    "#     y_encoded = model.encode(y)\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(model, x, y, loss_func)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "red_ts_predictor = RedTSPrediction('models/trueStateVAE_7_L8', latent_size=LATENT_SIZE, num_mixtures=NUMBER_MIXTURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-2.1179868e-03  3.6244500e-02 -1.7986381e-01  3.3291462e-01\n",
      "   3.0949807e-02 -3.3571877e-02 -1.5058097e-01 -2.4488902e-01\n",
      "  -1.3672502e-01  5.6034032e-02 -1.4086106e-01  4.6781264e-03\n",
      "  -1.3754016e-01 -1.0134836e-01  2.5119722e-01 -4.0824196e-01\n",
      "   1.9067058e-01  7.3767856e-02 -1.7701218e-01  2.1799131e-01\n",
      "  -1.9003060e-03  1.9926766e-01 -2.8401411e-01 -2.5834475e-02\n",
      "  -2.3582147e-01 -4.6198051e-02  8.6594693e-02  2.3850985e-04\n",
      "   3.1222925e-01 -1.2751795e-01  7.4389786e-02  8.7453082e-02\n",
      "  -1.3483889e-01 -1.9408233e-02  1.2227374e-01 -2.5353983e-01\n",
      "   1.1041008e-01 -5.3749159e-03 -4.4944596e-02 -1.0472686e-01\n",
      "   8.9145577e-01  9.4130999e-01  1.1497808e+00  1.1018574e+00\n",
      "   1.0397984e+00  1.0513984e+00  9.2240608e-01  1.1383569e+00\n",
      "   1.0527142e+00  1.0940250e+00  1.0025165e+00  9.6285552e-01\n",
      "   9.5457250e-01  7.6767647e-01  7.9955494e-01  1.3214015e+00\n",
      "   1.0597596e+00  8.7119871e-01  1.0375562e+00  1.0713509e+00\n",
      "   8.8040894e-01  9.4466883e-01  8.5019118e-01  1.0719435e+00\n",
      "   1.0083954e+00  1.0224159e+00  1.1384671e+00  8.7299943e-01\n",
      "   1.0775391e+00  1.1334666e+00  1.3705747e+00  9.3001103e-01\n",
      "   1.1887988e+00  9.6712321e-01  9.8184228e-01  8.8231373e-01\n",
      "   8.1236541e-01  9.9464279e-01  9.6136612e-01  8.6094433e-01\n",
      "  -1.2044176e-01 -5.5629048e-02  1.5041440e-02  2.0069392e-02\n",
      "  -2.8448138e-02]], shape=(1, 85), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for row in test_dataset.take(1):\n",
    "#   print(row)\n",
    "  out = red_ts_predictor(row[0])\n",
    "  print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"red_ts_prediction\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " true_state_vae_4 (TrueState  multiple                 121736094 \n",
      " VAE)                                                            \n",
      "                                                                 \n",
      " sequential_8 (Sequential)   (None, 16)                60892016  \n",
      "                                                                 \n",
      " sequential_9 (Sequential)   (None, 78)                60844078  \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  1152      \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  526336    \n",
      "                                                                 \n",
      " mdn (MDN)                   multiple                  174165    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,437,747\n",
      "Trainable params: 701,653\n",
      "Non-trainable params: 121,736,094\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# red_ts_predictor.compile(loss=get_mixture_loss_func(LATENT_SIZE,NUMBER_MIXTURES,red_ts_predictor.encode), optimizer=tf.keras.optimizers.Adam(),metrics=['mean_squared_error'])\n",
    "# red_ts_predictor.build(((1,78),(1,78)))\n",
    "red_ts_predictor.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = MDN.get_mixture_loss_func(LATENT_SIZE,NUMBER_MIXTURES)\n",
    "optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Test set loss: 4.099617958068848, time elapse for current epoch: 90.83968353271484\n"
     ]
    }
   ],
   "source": [
    "# train_dataset=test_dataset.take(10)\n",
    "\n",
    "# EPOCHS = 500\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    for train_x, train_y in train_dataset:\n",
    "        if (count %1000) == 0:\n",
    "            print(f\"{count}={count*batch_size} samples\")\n",
    "        train_step(red_ts_predictor, train_x, train_y, optimizer, loss_func)\n",
    "        count += 1\n",
    "    end_time = time.time()\n",
    "\n",
    "    \n",
    "    total_matches = 0\n",
    "    total = 0\n",
    "    nodes = 0\n",
    "    sum_diffs_sqrd = 0\n",
    "    state_pred_pairs = []\n",
    "    state_pred_pair_tree_vis = []\n",
    "    loss = tf.keras.metrics.Mean()\n",
    "    for test_x, test_y in test_dataset.take(1000):#.take(10):#test_dataset:\n",
    "        total += 1\n",
    "        if (total %100) == 0:\n",
    "            print(f\"{total}={total*1} samples\")\n",
    "        out, y_encoded = forward_pass(red_ts_predictor, test_x, test_y)\n",
    "        loss_val = loss_func(y_encoded, out)\n",
    "        loss(loss_val)\n",
    "        \n",
    "#         sampled_out = MDN.sample_from_output(out[0].numpy(), output_dim=LATENT_SIZE, num_mixes=NUMBER_MIXTURES)\n",
    "#         pred_oh, y_oh = decode_zs(red_ts_predictor, sampled_out, y_encoded)\n",
    "        \n",
    "        \n",
    "#         state_pred_pairs.append([y_oh, pred_oh])\n",
    "# #         state_pred_pair_tree_vis.append([TrueStateTreeGraphViz(y_oh), TrueStateTreeGraphViz(pred_oh)])\n",
    "# #         loss(compute_loss(red_ts_predictor, test_x, test_y, loss_func))\n",
    "#         diffs = np.rint(y_oh.numpy()) - np.rint(pred_oh.numpy())\n",
    "#     #     diffs = get_state_diff(true_state_model,test_x)\n",
    "#         nodes += len(diffs.flatten())\n",
    "#         diffs_sqrd = np.sum(diffs*diffs)\n",
    "#         sum_diffs_sqrd += diffs_sqrd\n",
    "#         if not diffs_sqrd >0:\n",
    "#     #       print(diffs)\n",
    "#     #     else:\n",
    "#           total_matches += 1\n",
    "#     #       print(\"Match\")\n",
    "    #       print(diffs)\n",
    "\n",
    "    loss = loss.result()\n",
    "    display.clear_output(wait=False)\n",
    "#     print(f\"accuracy = {total_matches}/{total} = {total_matches/total}, \\nmean of squared diffs = {sum_diffs_sqrd}/{nodes}={sum_diffs_sqrd/nodes}\\npercentage wrong = ({sum_diffs_sqrd}/{2})/({nodes}/{3})={(sum_diffs_sqrd/2)/(nodes/3)}\")\n",
    "    print('Epoch: {}, Test set loss: {}, time elapse for current epoch: {}'\n",
    "        .format(epoch, loss, end_time - start_time))\n",
    "#     display_tree_pairs(state_pred_pair_tree_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pre_ts_encoded = red_ts_predictor.ts_vae.encode(np.zeros((1,78),dtype=np.float32))\n",
    "# red_ts_predictor.ts_dense(pre_ts_encoded)\n",
    "\n",
    "red_ts_predictor((np.zeros((1,26),dtype=np.uint8),np.zeros((1,26),dtype=np.uint8)))\n",
    "\n",
    "red_ts_predictor.save('models/RedTSPredictionMDN_1',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "m2 = tf.keras.models.load_model(\n",
    "    'models/RedTSPredictionMDN_1',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 5470/10000 = 0.547, \n",
      "mean of squared diffs = 12136.0/780000=0.015558974358974359\n",
      "percentage wrong = (12136.0/2)/(780000/3)=0.023338461538461537\n"
     ]
    }
   ],
   "source": [
    "total_matches = 0\n",
    "total = 0\n",
    "nodes = 0\n",
    "sum_diffs_sqrd = 0\n",
    "state_pred_pairs = []\n",
    "state_pred_pair_tree_vis = []\n",
    "state_pred_samples_correct = []\n",
    "\n",
    "red_change_test_indices = []\n",
    "no_change_indices = []\n",
    "\n",
    "loss = tf.keras.metrics.Mean()\n",
    "\n",
    "num_eval_samples = 10\n",
    "\n",
    "for i, (test_x, test_y) in enumerate(test_dataset.take(1000)):#.take(10):#test_dataset:\n",
    "    pre_ts = tf.reshape(tf.one_hot(test_x[0],3),(-1,2,3))\n",
    "    blue_ts = tf.reshape(tf.one_hot(test_x[1],3),(-1,2,3))\n",
    "    \n",
    "    out, y_encoded = forward_pass(m2, test_x, test_y)\n",
    "    y_oh = decode_z(m2, y_encoded)\n",
    "    \n",
    "#     if not ONLY_MEASURE_CHANGES or np.any(blue_ts != y_oh):\n",
    "    if np.any(blue_ts != y_oh):\n",
    "        red_change_test_indices.append(i)\n",
    "    else:\n",
    "        no_change_indices.append(i)\n",
    "        \n",
    "    loss_val = loss_func(y_encoded, out)\n",
    "    loss(loss_val)\n",
    "\n",
    "    y_tree_vis = TrueStateTreeGraphViz(y_oh)\n",
    "\n",
    "    predictions = []\n",
    "    pred_tree_vis = []\n",
    "    pred_corrects = []\n",
    "    for i in range(num_eval_samples):\n",
    "        total += 1\n",
    "        sampled_out = MDN.sample_from_output(out[0].numpy(), output_dim=LATENT_SIZE, num_mixes=NUMBER_MIXTURES)\n",
    "        pred_oh = decode_z(m2, sampled_out)\n",
    "\n",
    "        predictions.append(pred_oh)\n",
    "        pred_tree_vis.append(TrueStateTreeGraphViz(pred_oh))\n",
    "\n",
    "        diffs = np.rint(y_oh.numpy()) - np.rint(pred_oh.numpy())\n",
    "        diffs_sqrd = np.sum(diffs*diffs)\n",
    "        sum_diffs_sqrd += diffs_sqrd\n",
    "\n",
    "        nodes += len(diffs.flatten())\n",
    "        pred_correct = not diffs_sqrd >0\n",
    "        if pred_correct:\n",
    "            total_matches += 1\n",
    "        pred_corrects.append(pred_correct)\n",
    "\n",
    "\n",
    "\n",
    "    state_pred_pairs.append([y_oh, predictions])\n",
    "\n",
    "    state_pred_pair_tree_vis.append([TrueStateTreeGraphViz(pre_ts),\n",
    "                                     TrueStateTreeGraphViz(blue_ts),\n",
    "                                     y_tree_vis,\n",
    "                                     pred_tree_vis])\n",
    "\n",
    "    state_pred_samples_correct.append(pred_corrects)\n",
    "\n",
    "state_pred_samples_correct = np.array(state_pred_samples_correct)\n",
    "\n",
    "#         state_pred_pairs.append([y_oh, pred_oh])\n",
    "#     state_pred_pair_tree_vis.append([TrueStateTreeGraphViz(y_oh), TrueStateTreeGraphViz(pred_oh)])\n",
    "#         loss(compute_loss(m2, test_x, test_y, loss_func))\n",
    "#     diffs = np.rint(y_oh.numpy()) - np.rint(pred_oh.numpy())\n",
    "#     diffs = get_state_diff(true_state_model,test_x)\n",
    "#     nodes += len(diffs.flatten())\n",
    "#     diffs_sqrd = np.sum(diffs*diffs)\n",
    "#     sum_diffs_sqrd += diffs_sqrd\n",
    "#     if not diffs_sqrd >0:\n",
    "# #       print(diffs)\n",
    "# #     else:\n",
    "#       total_matches += 1\n",
    "#       print(\"Match\")\n",
    "#       print(diffs)\n",
    "\n",
    "loss = loss.result()\n",
    "display.clear_output(wait=False)\n",
    "print(f\"accuracy = {total_matches}/{total} = {total_matches/total}, \\nmean of squared diffs = {sum_diffs_sqrd}/{nodes}={sum_diffs_sqrd/nodes}\\npercentage wrong = ({sum_diffs_sqrd}/{2})/({nodes}/{3})={(sum_diffs_sqrd/2)/(nodes/3)}\")\n",
    "# print('Epoch: {}, Test set loss: {}, time elapse for current epoch: {}'\n",
    "#     .format(epoch, loss, end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAArNUlEQVR4nO3df3DU9Z3H8Vc2mA1IsgiRLMFgQDgRgQTzYw16omXHoIx3OXM2UDxiZKDtBAT26kE4SEJtm1QgzVkpOTqCzpwplBnFil5mYhQ8j0AwIccBQpUTg8AG0GMXwpBAdu8Px/W2hB8bQ5Z8eD5mvtPs5/v+fr7v/U5lX/Pd736/EX6/3y8AAIBezhLuBgAAALoDoQYAABiBUAMAAIxAqAEAAEYg1AAAACMQagAAgBEINQAAwAiEGgAAYIQ+4W6gp/h8Ph07dkwxMTGKiIgIdzsAAOAa+P1+nTlzRgkJCbJYrnwu5qYJNceOHVNiYmK42wAAAF1w5MgR3XHHHVesuWlCTUxMjKRvDkpsbGyYuwEAANfC6/UqMTEx8Dl+JTdNqPn2K6fY2FhCDQAAvcy1XDrChcIAAMAIhBoAAGAEQg0AADACoQYAABiBUAMAAIxAqAEAAEYg1AAAACMQagAAgBEINQAAwAiEGgAAYARCDQAAMAKhBgAAGIFQAwAAjECoAQAARugT7gYAAIYrsYW7g6sr8YS7A3QDztQAAAAjEGoAAIARCDUAAMAIhBoAAGAEQg0AADACoQYAABiBUAMAAIxAqAEAAEYg1AAAACMQagAAgBEINQAAwAiEGgAAYARCDQAAMAKhBgAAGIFQAwAAjECoAQAARuhSqFm9erWSkpIUHR0th8Oh+vr6y9bu27dPOTk5SkpKUkREhCoqKi6p+XbdXy4FBQWBmocffviS9T/5yU+60j4AADBQyKFm48aNcrlcKi4uVmNjo5KTk5WVlaUTJ050Wn/u3DmNGDFCZWVlstvtndbs2rVLx48fDyw1NTWSpKeeeiqobvbs2UF1L774YqjtAwAAQ4UcasrLyzV79mzl5+drzJgxqqysVL9+/bRu3bpO69PT07VixQpNmzZNVqu105rbb79ddrs9sGzZskV33XWXJk2aFFTXr1+/oLrY2NhQ2wcAAIYKKdS0t7eroaFBTqfzuwksFjmdTtXV1XVLQ+3t7fq3f/s3Pfvss4qIiAha9/rrrysuLk5jx45VYWGhzp07d9l52tra5PV6gxYAAGCuPqEUnzp1Sh0dHYqPjw8aj4+P14EDB7qloc2bN+v06dN65plngsZ/9KMf6c4771RCQoL27NmjRYsW6eDBg3rjjTc6nae0tFTLly/vlp4AAMCNL6RQ0xNeeeUVPfbYY0pISAganzNnTuDvcePGaciQIZo8ebIOHTqku+6665J5CgsL5XK5Aq+9Xq8SExOvX+MAACCsQgo1cXFxioyMVEtLS9B4S0vLZS8CDsUXX3yh995777JnX/4/h8MhSfrss886DTVWq/Wy1/AAAADzhHRNTVRUlFJTU1VbWxsY8/l8qq2tVWZm5vduZv369Ro8eLCmTp161dqmpiZJ0pAhQ773fgEAQO8X8tdPLpdLeXl5SktLU0ZGhioqKtTa2qr8/HxJ0syZMzV06FCVlpZK+ubC3/379wf+Pnr0qJqamtS/f3+NHDkyMK/P59P69euVl5enPn2C2zp06JCqqqr0+OOPa9CgQdqzZ48WLlyohx56SOPHj+/ymwcAAOYIOdTk5ubq5MmTKioqktvtVkpKiqqrqwMXDzc3N8ti+e4E0LFjxzRhwoTA65UrV2rlypWaNGmStm7dGhh/77331NzcrGefffaSfUZFRem9994LBKjExETl5ORo6dKlobYPAAAMFeH3+/3hbqIneL1e2Ww2eTwe7m8DAD0oafE74W7hqg6XXf2yB4RHKJ/fPPsJAAAYgVADAACMQKgBAABGINQAAAAjEGoAAIARCDUAAMAIhBoAAGAEQg0AADDCDfeUbgBACEps4e7gGlSFuwHcJDhTAwAAjECoAQAARiDUAAAAIxBqAACAEQg1AADACPz6qbv0hl8glHjC3QEAANcNZ2oAAIARCDUAAMAIhBoAAGAEQg0AADACoQYAABiBUAMAAIxAqAEAAEYg1AAAACMQagAAgBEINQAAwAiEGgAAYARCDQAAMAKhBgAAGIFQAwAAjECoAQAARiDUAAAAI/QJdwMAAIRdiS3cHVxdiSfcHdzwOFMDAACMQKgBAABGINQAAAAjEGoAAIARuhRqVq9eraSkJEVHR8vhcKi+vv6ytfv27VNOTo6SkpIUERGhioqKS2pKSkoUERERtIwePTqo5vz58yooKNCgQYPUv39/5eTkqKWlpSvtAwAAA4UcajZu3CiXy6Xi4mI1NjYqOTlZWVlZOnHiRKf1586d04gRI1RWVia73X7Zee+9914dP348sHz00UdB6xcuXKi3335bmzZt0rZt23Ts2DE9+eSTobYPAAAMFXKoKS8v1+zZs5Wfn68xY8aosrJS/fr107p16zqtT09P14oVKzRt2jRZrdbLztunTx/Z7fbAEhcXF1jn8Xj0yiuvqLy8XD/4wQ+Umpqq9evXa/v27dqxY0eobwEAABgopFDT3t6uhoYGOZ3O7yawWOR0OlVXV/e9Gvn000+VkJCgESNGaMaMGWpubg6sa2ho0IULF4L2O3r0aA0bNuyy+21ra5PX6w1aAACAuUIKNadOnVJHR4fi4+ODxuPj4+V2u7vchMPh0Kuvvqrq6mqtWbNGn3/+uf76r/9aZ86ckSS53W5FRUVpwIAB17zf0tJS2Wy2wJKYmNjl/gAAwI3vhvj102OPPaannnpK48ePV1ZWlt59912dPn1af/zjH7s8Z2FhoTweT2A5cuRIN3YMAABuNCE9JiEuLk6RkZGX/OqopaXlihcBh2rAgAH6q7/6K3322WeSJLvdrvb2dp0+fTrobM2V9mu1Wq94DQ8AADBLSGdqoqKilJqaqtra2sCYz+dTbW2tMjMzu62ps2fP6tChQxoyZIgkKTU1VbfcckvQfg8ePKjm5uZu3S8AAOi9Qn6gpcvlUl5entLS0pSRkaGKigq1trYqPz9fkjRz5kwNHTpUpaWlkr65uHj//v2Bv48ePaqmpib1799fI0eOlCT97Gc/0xNPPKE777xTx44dU3FxsSIjIzV9+nRJks1m06xZs+RyuTRw4EDFxsZq3rx5yszM1P33398tBwIAAPRuIYea3NxcnTx5UkVFRXK73UpJSVF1dXXg4uHm5mZZLN+dADp27JgmTJgQeL1y5UqtXLlSkyZN0tatWyVJX375paZPn66vvvpKt99+ux588EHt2LFDt99+e2C73/zmN7JYLMrJyVFbW5uysrL0u9/9rqvvGwAAGCbC7/f7w91ET/B6vbLZbPJ4PIqNje3+HfDYegDh0Av+7Uk6XxXuFq7qcPSPwt3C1d2k/4aH8vkd8pkaAMCNozcEBqCn3BA/6QYAAPi+CDUAAMAIhBoAAGAEQg0AADACoQYAABiBUAMAAIxAqAEAAEYg1AAAACNw8z0AwE2vN9zE8HC4G+gFOFMDAACMQKgBAABGINQAAAAjEGoAAIARCDUAAMAIhBoAAGAEQg0AADACoQYAABiBUAMAAIxAqAEAAEYg1AAAACMQagAAgBEINQAAwAiEGgAAYARCDQAAMAKhBgAAGIFQAwAAjECoAQAARiDUAAAAIxBqAACAEQg1AADACIQaAABgBEINAAAwAqEGAAAYgVADAACMQKgBAABG6FKoWb16tZKSkhQdHS2Hw6H6+vrL1u7bt085OTlKSkpSRESEKioqLqkpLS1Venq6YmJiNHjwYGVnZ+vgwYNBNQ8//LAiIiKClp/85CddaR8AABgo5FCzceNGuVwuFRcXq7GxUcnJycrKytKJEyc6rT937pxGjBihsrIy2e32Tmu2bdumgoIC7dixQzU1Nbpw4YIeffRRtba2BtXNnj1bx48fDywvvvhiqO0DAABD9Ql1g/Lycs2ePVv5+fmSpMrKSr3zzjtat26dFi9efEl9enq60tPTJanT9ZJUXV0d9PrVV1/V4MGD1dDQoIceeigw3q9fv8sGIwAAcHML6UxNe3u7Ghoa5HQ6v5vAYpHT6VRdXV23NeXxeCRJAwcODBp//fXXFRcXp7Fjx6qwsFDnzp3rtn0CAIDeLaQzNadOnVJHR4fi4+ODxuPj43XgwIFuacjn82nBggV64IEHNHbs2MD4j370I915551KSEjQnj17tGjRIh08eFBvvPFGp/O0tbWpra0t8Nrr9XZLfwAA4MYU8tdP11tBQYH27t2rjz76KGh8zpw5gb/HjRunIUOGaPLkyTp06JDuuuuuS+YpLS3V8uXLr3u/AADgxhDS109xcXGKjIxUS0tL0HhLS0u3XOsyd+5cbdmyRR988IHuuOOOK9Y6HA5J0meffdbp+sLCQnk8nsBy5MiR790fAAC4cYUUaqKiopSamqra2trAmM/nU21trTIzM7vchN/v19y5c/Xmm2/q/fff1/Dhw6+6TVNTkyRpyJAhna63Wq2KjY0NWgAAgLlC/vrJ5XIpLy9PaWlpysjIUEVFhVpbWwO/hpo5c6aGDh2q0tJSSd9cXLx///7A30ePHlVTU5P69++vkSNHSvrmK6eqqiq99dZbiomJkdvtliTZbDb17dtXhw4dUlVVlR5//HENGjRIe/bs0cKFC/XQQw9p/Pjx3XIgAABA7xZyqMnNzdXJkydVVFQkt9utlJQUVVdXBy4ebm5ulsXy3QmgY8eOacKECYHXK1eu1MqVKzVp0iRt3bpVkrRmzRpJ39xg7/9bv369nnnmGUVFRem9994LBKjExETl5ORo6dKlobYPAAAMFeH3+/3hbqIneL1e2Ww2eTye6/NVVImt++fsbiWecHcAoJslLX4n3C2ghxwumxruFsIilM9vnv0EAACMQKgBAABGINQAAAAjEGoAAIARCDUAAMAIhBoAAGAEQg0AADACoQYAABiBUAMAAIxAqAEAAEYg1AAAACMQagAAgBEINQAAwAiEGgAAYARCDQAAMAKhBgAAGIFQAwAAjECoAQAARiDUAAAAIxBqAACAEfqEuwEAuGGV2MLdwTWoCncDwA2DMzUAAMAIhBoAAGAEQg0AADACoQYAABiBUAMAAIxAqAEAAEYg1AAAACMQagAAgBEINQAAwAiEGgAAYARCDQAAMAKhBgAAGIFQAwAAjECoAQAARiDUAAAAIxBqAACAEboUalavXq2kpCRFR0fL4XCovr7+srX79u1TTk6OkpKSFBERoYqKii7Nef78eRUUFGjQoEHq37+/cnJy1NLS0pX2AQCAgUIONRs3bpTL5VJxcbEaGxuVnJysrKwsnThxotP6c+fOacSIESorK5Pdbu/ynAsXLtTbb7+tTZs2adu2bTp27JiefPLJUNsHAACGCjnUlJeXa/bs2crPz9eYMWNUWVmpfv36ad26dZ3Wp6ena8WKFZo2bZqsVmuX5vR4PHrllVdUXl6uH/zgB0pNTdX69eu1fft27dixI9S3AAAADBRSqGlvb1dDQ4OcTud3E1gscjqdqqur61ID1zJnQ0ODLly4EFQzevRoDRs27LL7bWtrk9frDVoAAIC5Qgo1p06dUkdHh+Lj44PG4+Pj5Xa7u9TAtczpdrsVFRWlAQMGXPN+S0tLZbPZAktiYmKX+gMAAL2Dsb9+KiwslMfjCSxHjhwJd0sAAOA66hNKcVxcnCIjIy/51VFLS8tlLwLujjntdrva29t1+vTpoLM1V9qv1Wq97DU8AADAPCGdqYmKilJqaqpqa2sDYz6fT7W1tcrMzOxSA9cyZ2pqqm655ZagmoMHD6q5ubnL+wUAAGYJ6UyNJLlcLuXl5SktLU0ZGRmqqKhQa2ur8vPzJUkzZ87U0KFDVVpaKumbC4H3798f+Pvo0aNqampS//79NXLkyGua02azadasWXK5XBo4cKBiY2M1b948ZWZm6v777++WAwEAAHq3kENNbm6uTp48qaKiIrndbqWkpKi6ujpwoW9zc7Mslu9OAB07dkwTJkwIvF65cqVWrlypSZMmaevWrdc0pyT95je/kcViUU5Ojtra2pSVlaXf/e53XX3fAADAMBF+v98f7iZ6gtfrlc1mk8fjUWxsbPfvoMTW/XN2txJPuDsAepde8N910vmqcLeAHnK4bGq4WwiLUD6/jf31EwAAuLkQagAAgBEINQAAwAiEGgAAYARCDQAAMAKhBgAAGIFQAwAAjECoAQAARiDUAAAAIxBqAACAEQg1AADACCE/0BIAbhY8VwnoXThTAwAAjECoAQAARuDrp5tJiS3cHVxdiSfcHQAAeinO1AAAACMQagAAgBEINQAAwAiEGgAAYARCDQAAMAKhBgAAGIFQAwAAjECoAQAARiDUAAAAIxBqAACAEQg1AADACIQaAABgBEINAAAwAqEGAAAYgVADAACMQKgBAABGINQAAAAjEGoAAIARCDUAAMAIhBoAAGAEQg0AADBCl0LN6tWrlZSUpOjoaDkcDtXX11+xftOmTRo9erSio6M1btw4vfvuu0HrIyIiOl1WrFgRqElKSrpkfVlZWVfaBwAABgo51GzcuFEul0vFxcVqbGxUcnKysrKydOLEiU7rt2/frunTp2vWrFnavXu3srOzlZ2drb179wZqjh8/HrSsW7dOERERysnJCZrr5z//eVDdvHnzQm0fAAAYKuRQU15ertmzZys/P19jxoxRZWWl+vXrp3Xr1nVa/y//8i+aMmWKnn/+ed1zzz164YUXdN999+nll18O1Njt9qDlrbfe0iOPPKIRI0YEzRUTExNUd+utt4baPgAAMFRIoaa9vV0NDQ1yOp3fTWCxyOl0qq6urtNt6urqguolKSsr67L1LS0teueddzRr1qxL1pWVlWnQoEGaMGGCVqxYoYsXL16217a2Nnm93qAFAACYq08oxadOnVJHR4fi4+ODxuPj43XgwIFOt3G73Z3Wu93uTutfe+01xcTE6Mknnwwaf+6553Tfffdp4MCB2r59uwoLC3X8+HGVl5d3Ok9paamWL19+rW8NAAD0ciGFmp6wbt06zZgxQ9HR0UHjLpcr8Pf48eMVFRWlH//4xyotLZXVar1knsLCwqBtvF6vEhMTr1/jAAAgrEIKNXFxcYqMjFRLS0vQeEtLi+x2e6fb2O32a67/j//4Dx08eFAbN268ai8Oh0MXL17U4cOHdffdd1+y3mq1dhp2AACAmUK6piYqKkqpqamqra0NjPl8PtXW1iozM7PTbTIzM4PqJammpqbT+ldeeUWpqalKTk6+ai9NTU2yWCwaPHhwKG8BAAAYKuSvn1wul/Ly8pSWlqaMjAxVVFSotbVV+fn5kqSZM2dq6NChKi0tlSTNnz9fkyZN0qpVqzR16lRt2LBBH3/8sdauXRs0r9fr1aZNm7Rq1apL9llXV6edO3fqkUceUUxMjOrq6rRw4UI9/fTTuu2227ryvgEAgGFCDjW5ubk6efKkioqK5Ha7lZKSourq6sDFwM3NzbJYvjsBNHHiRFVVVWnp0qVasmSJRo0apc2bN2vs2LFB827YsEF+v1/Tp0+/ZJ9Wq1UbNmxQSUmJ2traNHz4cC1cuDDomhkAAHBzi/D7/f5wN9ETvF6vbDabPB6PYmNju38HJbbun/NmVOIJdwdAQNLid8LdAhBwuGxquFsIi1A+v3n2EwAAMAKhBgAAGIFQAwAAjECoAQAARiDUAAAAIxBqAACAEQg1AADACIQaAABgBEINAAAwAqEGAAAYgVADAACMQKgBAABGINQAAAAjEGoAAIARCDUAAMAIhBoAAGAEQg0AADACoQYAABiBUAMAAIxAqAEAAEYg1AAAACP0CXcDAG5SJbZwd3ANqsLdAIAQcKYGAAAYgVADAACMQKgBAABG4JoaAAB6g95wHVqJJ6y750wNAAAwAqEGAAAYgVADAACMQKgBAABGINQAAAAjEGoAAIARCDUAAMAI3KcGQFgknee5SgC6F2dqAACAEQg1AADACF0KNatXr1ZSUpKio6PlcDhUX19/xfpNmzZp9OjRio6O1rhx4/Tuu+8GrX/mmWcUERERtEyZMiWo5uuvv9aMGTMUGxurAQMGaNasWTp79mxX2gcAAAYKOdRs3LhRLpdLxcXFamxsVHJysrKysnTixIlO67dv367p06dr1qxZ2r17t7Kzs5Wdna29e/cG1U2ZMkXHjx8PLH/4wx+C1s+YMUP79u1TTU2NtmzZog8//FBz5swJtX0AAGCoCL/f7w9lA4fDofT0dL388suSJJ/Pp8TERM2bN0+LFy++pD43N1etra3asmVLYOz+++9XSkqKKisrJX1zpub06dPavHlzp/v85JNPNGbMGO3atUtpaWmSpOrqaj3++OP68ssvlZCQcNW+vV6vbDabPB6PYmNjQ3nL16Y3PGisNwjzw9DQc5IWvxPuFoBe5XD0j8LdwtVdh3/DQ/n8DulMTXt7uxoaGuR0Or+bwGKR0+lUXV1dp9vU1dUF1UtSVlbWJfVbt27V4MGDdffdd+unP/2pvvrqq6A5BgwYEAg0kuR0OmWxWLRz585Q3gIAADBUSD/pPnXqlDo6OhQfHx80Hh8frwMHDnS6jdvt7rTe7XYHXk+ZMkVPPvmkhg8frkOHDmnJkiV67LHHVFdXp8jISLndbg0ePDi48T59NHDgwKB5/r+2tja1tbUFXnu93lDeKgAA6GVuiPvUTJs2LfD3uHHjNH78eN11113aunWrJk+e3KU5S0tLtXz58u5qEQAA3OBC+vopLi5OkZGRamlpCRpvaWmR3W7vdBu73R5SvSSNGDFCcXFx+uyzzwJz/OWFyBcvXtTXX3992XkKCwvl8XgCy5EjR676/gAAQO8VUqiJiopSamqqamtrA2M+n0+1tbXKzMzsdJvMzMygekmqqam5bL0kffnll/rqq680ZMiQwBynT59WQ0NDoOb999+Xz+eTw+HodA6r1arY2NigBQAAmCvkn3S7XC79/ve/12uvvaZPPvlEP/3pT9Xa2qr8/HxJ0syZM1VYWBionz9/vqqrq7Vq1SodOHBAJSUl+vjjjzV37lxJ0tmzZ/X8889rx44dOnz4sGpra/W3f/u3GjlypLKysiRJ99xzj6ZMmaLZs2ervr5e//mf/6m5c+dq2rRp1/TLJwAAYL6Qr6nJzc3VyZMnVVRUJLfbrZSUFFVXVwcuBm5ubpbF8l1WmjhxoqqqqrR06VItWbJEo0aN0ubNmzV27FhJUmRkpPbs2aPXXntNp0+fVkJCgh599FG98MILslqtgXlef/11zZ07V5MnT5bFYlFOTo5eeuml7/v+AQCAIUK+T01vxX1qegnuU3PT4D41QGi4T00336cGAADgRnVD/KQbAABcWdL5qnC3cFWHw7x/ztQAAAAjEGoAAIARCDUAAMAIhBoAAGAEQg0AADACoQYAABiBUAMAAIxAqAEAAEYg1AAAACMQagAAgBEINQAAwAiEGgAAYARCDQAAMAJP6caNpcQW7g6ursQT7g4AAJ3gTA0AADACoQYAABiBUAMAAIxAqAEAAEbgQmEgVFzMDAA3JM7UAAAAIxBqAACAEQg1AADACFxTA5ioN1z3o6pwNwDAMJypAQAARiDUAAAAIxBqAACAEQg1AADACIQaAABgBEINAAAwAqEGAAAYgVADAACMQKgBAABGINQAAAAjEGoAAIARCDUAAMAIXQo1q1evVlJSkqKjo+VwOFRfX3/F+k2bNmn06NGKjo7WuHHj9O677wbWXbhwQYsWLdK4ceN06623KiEhQTNnztSxY8eC5khKSlJERETQUlZW1pX2AQCAgUIONRs3bpTL5VJxcbEaGxuVnJysrKwsnThxotP67du3a/r06Zo1a5Z2796t7OxsZWdna+/evZKkc+fOqbGxUcuWLVNjY6PeeOMNHTx4UH/zN39zyVw///nPdfz48cAyb968UNsHAACGivD7/f5QNnA4HEpPT9fLL78sSfL5fEpMTNS8efO0ePHiS+pzc3PV2tqqLVu2BMbuv/9+paSkqLKystN97Nq1SxkZGfriiy80bNgwSd+cqVmwYIEWLFgQSrsBXq9XNptNHo9HsbGxXZrjikps3T8nYLCk81XhbgFANztcNrXb5wzl8zukMzXt7e1qaGiQ0+n8bgKLRU6nU3V1dZ1uU1dXF1QvSVlZWZetlySPx6OIiAgNGDAgaLysrEyDBg3ShAkTtGLFCl28ePGyc7S1tcnr9QYtAADAXH1CKT516pQ6OjoUHx8fNB4fH68DBw50uo3b7e603u12d1p//vx5LVq0SNOnTw9KZM8995zuu+8+DRw4UNu3b1dhYaGOHz+u8vLyTucpLS3V8uXLQ3l7AACgFwsp1FxvFy5c0A9/+EP5/X6tWbMmaJ3L5Qr8PX78eEVFRenHP/6xSktLZbVaL5mrsLAwaBuv16vExMTr1zwAAAirkEJNXFycIiMj1dLSEjTe0tIiu93e6TZ2u/2a6r8NNF988YXef//9q35v5nA4dPHiRR0+fFh33333JeutVmunYQcAAJgppGtqoqKilJqaqtra2sCYz+dTbW2tMjMzO90mMzMzqF6Sampqguq/DTSffvqp3nvvPQ0aNOiqvTQ1NclisWjw4MGhvAUAAGCokL9+crlcysvLU1pamjIyMlRRUaHW1lbl5+dLkmbOnKmhQ4eqtLRUkjR//nxNmjRJq1at0tSpU7VhwwZ9/PHHWrt2raRvAs3f//3fq7GxUVu2bFFHR0fgepuBAwcqKipKdXV12rlzpx555BHFxMSorq5OCxcu1NNPP63bbrutu44FYAx+WQTgZhRyqMnNzdXJkydVVFQkt9utlJQUVVdXBy4Gbm5ulsXy3QmgiRMnqqqqSkuXLtWSJUs0atQobd68WWPHjpUkHT16VH/6058kSSkpKUH7+uCDD/Twww/LarVqw4YNKikpUVtbm4YPH66FCxcGXTMDAABubiHfp6a34j41uJlwpgZAOPSq+9QAAADcqAg1AADACIQaAABgBEINAAAwAqEGAAAYgVADAACMQKgBAABGINQAAAAjEGoAAIARQn5MAnCz4269AHBj4kwNAAAwAqEGAAAYgVADAACMQKgBAABGINQAAAAjEGoAAIARCDUAAMAI3KcGNxTuAQMA6CrO1AAAACMQagAAgBEINQAAwAiEGgAAYARCDQAAMAKhBgAAGIFQAwAAjECoAQAARiDUAAAAIxBqAACAEXhMwk2ERxAAAEzGmRoAAGAEQg0AADACoQYAABiBUAMAAIxAqAEAAEYg1AAAACMQagAAgBG6FGpWr16tpKQkRUdHy+FwqL6+/or1mzZt0ujRoxUdHa1x48bp3XffDVrv9/tVVFSkIUOGqG/fvnI6nfr000+Dar7++mvNmDFDsbGxGjBggGbNmqWzZ892pX0AAGCgkEPNxo0b5XK5VFxcrMbGRiUnJysrK0snTpzotH779u2aPn26Zs2apd27dys7O1vZ2dnau3dvoObFF1/USy+9pMrKSu3cuVO33nqrsrKydP78+UDNjBkztG/fPtXU1GjLli368MMPNWfOnC68ZQAAYKIIv9/vD2UDh8Oh9PR0vfzyy5Ikn8+nxMREzZs3T4sXL76kPjc3V62trdqyZUtg7P7771dKSooqKyvl9/uVkJCgf/zHf9TPfvYzSZLH41F8fLxeffVVTZs2TZ988onGjBmjXbt2KS0tTZJUXV2txx9/XF9++aUSEhKu2rfX65XNZpPH41FsbGwob/maJC1+p9vnBACgNzlcNrXb5wzl8zukxyS0t7eroaFBhYWFgTGLxSKn06m6urpOt6mrq5PL5Qoay8rK0ubNmyVJn3/+udxut5xOZ2C9zWaTw+FQXV2dpk2bprq6Og0YMCAQaCTJ6XTKYrFo586d+ru/+7tL9tvW1qa2trbAa4/HI+mbg3M9+NrOXZd5AQDoLa7HZ+y3c17LOZiQQs2pU6fU0dGh+Pj4oPH4+HgdOHCg023cbnen9W63O7D+27Er1QwePDi48T59NHDgwEDNXyotLdXy5csvGU9MTLzc2wMAAN+DreL6zX3mzBnZbLYr1hj7QMvCwsKgM0Q+n09ff/21Bg0apIiIiG7dl9frVWJioo4cOXJdvtrCNzjOPYPj3DM4zj2D49xzrtex9vv9OnPmzDVdahJSqImLi1NkZKRaWlqCxltaWmS32zvdxm63X7H+2/9taWnRkCFDgmpSUlICNX95IfLFixf19ddfX3a/VqtVVqs1aGzAgAFXfoPfU2xsLP/R9ACOc8/gOPcMjnPP4Dj3nOtxrK92huZbIf36KSoqSqmpqaqtrQ2M+Xw+1dbWKjMzs9NtMjMzg+olqaamJlA/fPhw2e32oBqv16udO3cGajIzM3X69Gk1NDQEat5//335fD45HI5Q3gIAADBUyF8/uVwu5eXlKS0tTRkZGaqoqFBra6vy8/MlSTNnztTQoUNVWloqSZo/f74mTZqkVatWaerUqdqwYYM+/vhjrV27VpIUERGhBQsW6Be/+IVGjRql4cOHa9myZUpISFB2drYk6Z577tGUKVM0e/ZsVVZW6sKFC5o7d66mTZt2TaejAACA+UIONbm5uTp58qSKiorkdruVkpKi6urqwIW+zc3Nsli+OwE0ceJEVVVVaenSpVqyZIlGjRqlzZs3a+zYsYGaf/qnf1Jra6vmzJmj06dP68EHH1R1dbWio6MDNa+//rrmzp2ryZMny2KxKCcnRy+99NL3ee/dxmq1qri4+JKvu9C9OM49g+PcMzjOPYPj3HNuhGMd8n1qAAAAbkQ8+wkAABiBUAMAAIxAqAEAAEYg1AAAACMQar6n1atXKykpSdHR0XI4HKqvrw93S8YpLS1Venq6YmJiNHjwYGVnZ+vgwYPhbstoZWVlgdstoPsdPXpUTz/9tAYNGqS+fftq3Lhx+vjjj8PdllE6Ojq0bNkyDR8+XH379tVdd92lF1544ZqeH4TL+/DDD/XEE08oISFBERERgec4fsvv96uoqEhDhgxR37595XQ69emnn/ZYf4Sa72Hjxo1yuVwqLi5WY2OjkpOTlZWVdcndj/H9bNu2TQUFBdqxY4dqamp04cIFPfroo2ptbQ13a0batWuX/vVf/1Xjx48PdytG+t///V898MADuuWWW/Tv//7v2r9/v1atWqXbbrst3K0Z5de//rXWrFmjl19+WZ988ol+/etf68UXX9Rvf/vbcLfWq7W2tio5OVmrV6/udP2LL76ol156SZWVldq5c6duvfVWZWVl6fz58z3ToB9dlpGR4S8oKAi87ujo8CckJPhLS0vD2JX5Tpw44Zfk37ZtW7hbMc6ZM2f8o0aN8tfU1PgnTZrknz9/frhbMs6iRYv8Dz74YLjbMN7UqVP9zz77bNDYk08+6Z8xY0aYOjKPJP+bb74ZeO3z+fx2u92/YsWKwNjp06f9VqvV/4c//KFHeuJMTRe1t7eroaFBTqczMGaxWOR0OlVXVxfGzszn8XgkSQMHDgxzJ+YpKCjQ1KlTg/5/je71pz/9SWlpaXrqqac0ePBgTZgwQb///e/D3ZZxJk6cqNraWv35z3+WJP3Xf/2XPvroIz322GNh7sxcn3/+udxud9C/HzabTQ6Ho8c+F419Svf1durUKXV0dATupPyt+Ph4HThwIExdmc/n82nBggV64IEHgu5Kje9vw4YNamxs1K5du8LditH+53/+R2vWrJHL5dKSJUu0a9cuPffcc4qKilJeXl642zPG4sWL5fV6NXr0aEVGRqqjo0O//OUvNWPGjHC3Ziy32y1JnX4ufrvueiPUoFcpKCjQ3r179dFHH4W7FaMcOXJE8+fPV01NTdDjSdD9fD6f0tLS9Ktf/UqSNGHCBO3du1eVlZWEmm70xz/+Ua+//rqqqqp07733qqmpSQsWLFBCQgLH2WB8/dRFcXFxioyMVEtLS9B4S0uL7HZ7mLoy29y5c7VlyxZ98MEHuuOOO8LdjlEaGhp04sQJ3XffferTp4/69Omjbdu26aWXXlKfPn3U0dER7haNMWTIEI0ZMyZo7J577lFzc3OYOjLT888/r8WLF2vatGkaN26c/uEf/kELFy4MPGwZ3e/bz75wfi4SarooKipKqampqq2tDYz5fD7V1tYqMzMzjJ2Zx+/3a+7cuXrzzTf1/vvva/jw4eFuyTiTJ0/Wf//3f6upqSmwpKWlacaMGWpqalJkZGS4WzTGAw88cMktCf785z/rzjvvDFNHZjp37lzQw5UlKTIyUj6fL0wdmW/48OGy2+1Bn4ter1c7d+7ssc9Fvn76Hlwul/Ly8pSWlqaMjAxVVFSotbVV+fn54W7NKAUFBaqqqtJbb72lmJiYwHezNptNffv2DXN3ZoiJibnkGqVbb71VgwYN4tqlbrZw4UJNnDhRv/rVr/TDH/5Q9fX1Wrt2rdauXRvu1ozyxBNP6Je//KWGDRume++9V7t371Z5ebmeffbZcLfWq509e1afffZZ4PXnn3+upqYmDRw4UMOGDdOCBQv0i1/8QqNGjdLw4cO1bNkyJSQkKDs7u2ca7JHfWBnst7/9rX/YsGH+qKgof0ZGhn/Hjh3hbsk4kjpd1q9fH+7WjMZPuq+ft99+2z927Fi/1Wr1jx492r927dpwt2Qcr9frnz9/vn/YsGH+6Oho/4gRI/z//M//7G9rawt3a73aBx980Om/x3l5eX6//5ufdS9btswfHx/vt1qt/smTJ/sPHjzYY/1F+P3cXhEAAPR+XFMDAACMQKgBAABGINQAAAAjEGoAAIARCDUAAMAIhBoAAGAEQg0AADACoQYAABiBUAMAAIxAqAEAAEYg1AAAACMQagAAgBH+D9TJp+WhzbHVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "correct_pred_counts = np.sum(state_pred_samples_correct[no_change_indices],axis=1)\n",
    "\n",
    "correct_pred_counts_change_only = np.sum(state_pred_samples_correct[red_change_test_indices], axis=1)\n",
    "\n",
    "# print(f\"Correct prediction frequencies: {correct_pred_counts}\")\n",
    "\n",
    "plt.hist([correct_pred_counts,correct_pred_counts_change_only],num_eval_samples+1,density=True, stacked=True, label=[\"ALL\", \"ONLY CHANGES\"])\n",
    "# plt.hist(correct_pred_counts_change_only,num_eval_samples+1,density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/usr/local/lib/python3.8/dist-packages/ipywidgets/widgets/widget.py:443: DeprecationWarning: Passing unrecognized arguments to super(IntSlider).__init__(name='Index').\n",
      "object.__init__() takes exactly one argument (the instance to initialize)\n",
      "This is deprecated in traitlets 4.2.This error will be raised in a future release of traitlets.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa710a9e13e43a7ae8db959a35185eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='<<', style=ButtonStyle()), Button(description='>>', style=ButtonStyle()), I…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f00d7e9c5a478bba764f23cd6cff24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\xfa\\x00\\x00\\x01[\\x08\\x02\\x00\\x00\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_tree_pairs(state_pred_pair_tree_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
