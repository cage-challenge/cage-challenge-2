{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "import ray\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "from keras.layers import Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM, Input\n",
    "from keras.layers import Bidirectional\n",
    "from ray import tune\n",
    "from ray.tune.registry import register_env\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length=3\n",
    "state_len = 91\n",
    "num_actions = 41\n",
    "encoding_len = state_len + num_actions\n",
    "NUM_NODES = 13\n",
    "NODE_CLASSES = [3, 4]\n",
    "\n",
    "class WorldMovelEnv(gym.Env):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=(state_len,))\n",
    "        self.action_space = gym.spaces.Discrete(num_actions)\n",
    "        \n",
    "        self.step_count = 0\n",
    "\n",
    "        #Reward Model\n",
    "        self.r_model = Sequential()\n",
    "        self.r_model.add(Input(shape=(state_len*2 + 2,)))\n",
    "        self.r_model.add(Dense(512, activation='relu'))\n",
    "        self.r_model.add(Dense(512, activation='relu'))\n",
    "        self.r_model.add(Dense(512, activation='relu'))\n",
    "        self.r_model.add(Dense(11, activation='softmax'))\n",
    "        #self.r_model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "        self.r_model.load_weights('RewardModel')\n",
    "        \n",
    "        \n",
    "        input_ = Input(shape=(state_len+num_actions+1,))\n",
    "        #x = Dense(512, activation='relu')(input_)\n",
    "        #x = Dense(512, activation='relu')(x)\n",
    "        outs = []\n",
    "        for i in range(NUM_NODES):\n",
    "            for n in NODE_CLASSES:\n",
    "                x_ = Dense(128, activation='relu')(input_)\n",
    "                outs.append(Dense(n, activation='softmax', name=str(i)+str(n))(x_))\n",
    "\n",
    "        self.ns_model_multi_model = Model(input_, outs)\n",
    "        self.ns_model_multi_model.load_weights('NextStateModel_MulitLabel')\n",
    "     \n",
    "        '''\n",
    "        input_ = Input(shape=(10,42+20,))\n",
    "        x = Bidirectional(LSTM(256))(input_)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(512, activation='relu')(x)\n",
    "\n",
    "        outs = []\n",
    "        for i in range(NUM_NODES):\n",
    "            for n in NODE_CLASSES:\n",
    "                x_ = Dense(256, activation='relu')(x)\n",
    "                outs.append(Dense(n, activation='softmax', name=str(i)+str(n))(x_))\n",
    "        #x_ = Dense(256, activation='relu')(x)\n",
    "        #outs.append(Dense(6, activation='softmax', name='reward')(x_))\n",
    "        self.ns_model_multi_model = Model(input_, outs)\n",
    "        self.ns_model_multi_model.load_weights('NextStateModel_MulitLabel_rnn')\n",
    "        '''\n",
    "        self.reward_map = np.load('reward_map.npy', allow_pickle=True).item()\n",
    "        #self.state = np.zeros((10, 42))\n",
    "        self.init_state = np.array([0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
    "         0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
    "         1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
    "         1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.])\n",
    "        self.state = self.init_state\n",
    "        #self.action = np.zeros((10, 20))\n",
    "\n",
    "    def step(self, action):\n",
    "        self.step_count += 1\n",
    "        \n",
    "        #self.state_action[0,52] = action / 145\n",
    "        #obs_index_probs = self.st_model.predict(np.array([self.state_action]))\n",
    "        #obs_index = np.argmax(obs_index_probs)\n",
    "        #obs_index = np.random.choice(np.arange(9674), p=obs_index_probs[0])\n",
    "        #new_state = self.index_to_state[obs_index]\n",
    "        #new_state = np.frombuffer(new_state)\n",
    "        \n",
    "        action_vec = np.zeros(num_actions)\n",
    "        action_vec[action] = 1\n",
    "        #self.action[-1,:] = action_vec\n",
    "        \n",
    "        state_action = np.concatenate([self.state, [self.step_count/100], action_vec], axis=-1)\n",
    "        #afterstate_probs = self.as_model.predict(np.array([state_action]), verbose=0)\n",
    "        #afterstate = np.array(np.random.rand(1, 42) < afterstate_probs, dtype=np.int8)\n",
    "        \n",
    "        #while True:\n",
    "        #    new_state_probs = self.ns_model.predict(np.array([state_action]), verbose=0)\n",
    "        #    new_state = np.array(np.random.rand(1, 42) < new_state_probs, dtype=np.int8)\n",
    "        #    if int(np.sum(self.state-new_state)) == 0:\n",
    "        #        break\n",
    "        #self.state = new_state[0]\n",
    "        probs = self.ns_model_multi_model.predict(np.array([state_action]), verbose=0)\n",
    "        next_state = np.zeros(state_len)\n",
    "        index_state = 0; index = 0\n",
    "        for i in range(NUM_NODES):\n",
    "            for n in NODE_CLASSES:\n",
    "                next_state[index_state+np.random.choice(np.arange(n), p=probs[index][0])] = 1\n",
    "                index_state += n; index += 1\n",
    "        \n",
    "       # reward_probs = self.r_model.predict(np.array([self.state]), verbose=0)\n",
    "        #reward = np.random.choice(np.arange(6), p=reward_probs[0])\n",
    "        #reward = self.reward_map[reward]\n",
    "        \n",
    "        #for i in range(1,3):\n",
    "        #    self.state_action[i,:] = self.state_action[i-1,:]\n",
    "        #\n",
    "        #self.state_action[0,:] = np.concatenate([new_state, [0]])\n",
    "        \n",
    "        reward_probs = self.r_model.predict(np.array([np.concatenate([self.state, [self.step_count/100], next_state, [self.step_count/100]])]))\n",
    "        reward_index = np.random.choice(np.arange(11), p=reward_probs[0])\n",
    "        reward = self.reward_map[reward_index]\n",
    "        \n",
    "        #for i in range(0,9):\n",
    "        #    self.state[i,:] = self.state[i+1,:]\n",
    "        #    self.action[i,:] = self.action[i+1,:]\n",
    "            \n",
    "        #self.state[-1,:] = state\n",
    "        \n",
    "        self.state = next_state\n",
    "        \n",
    "        done = self.step_count == 99\n",
    "        if done:\n",
    "            self.step_count = 0\n",
    "        return self.state, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        step_count = 0\n",
    "        \n",
    "        #self.state_action = np.zeros((sequence_length,encoding_len))\n",
    "        #self.state = np.zeros((sequence_length,state_len))\n",
    "        \n",
    "        #obs_index_probs = self.st_model.predict(np.array([self.state_action]))\n",
    "        #obs_index = np.argmax(obs_index_probs)\n",
    "        #obs_index = np.random.choice(np.arange(9674), p=obs_index_probs[0])\n",
    "        #new_state = self.index_to_state[obs_index]\n",
    "        #new_state = np.frombuffer(new_state)\n",
    "       \n",
    "        #self.state = np.zeros((10, 42))\n",
    "        #self.state[0,:] = init_state\n",
    "        self.state = self.init_state\n",
    "      \n",
    "        return self.init_state\n",
    "    \n",
    "\n",
    "    def render(self, mode='human', close=False):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "    \n",
    "def env_creator(config):\n",
    "    return WorldMovelEnv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
      "       0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "       1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "       0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "       0., 1., 0., 0., 0., 1.]), 0.0, False, {})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    }
   ],
   "source": [
    "test = WorldMovelEnv()\n",
    "test.reset()\n",
    "for i in range(1):\n",
    "    print(test.step(np.random.randint(20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "register_env(name=\"DreamCybORG\", env_creator=env_creator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results_dict):\n",
    "    train_iter = results_dict[\"training_iteration\"]\n",
    "    r_mean = results_dict[\"episode_reward_mean\"]\n",
    "    r_max = results_dict[\"episode_reward_max\"]\n",
    "    r_min = results_dict[\"episode_reward_min\"]\n",
    "    print(f\"{train_iter:4d} \\tr_mean: {r_mean:.1f} \\tr_max: {r_max:.1f} \\tr_min: {r_min: .1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=37866)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=37866)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=37863)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=37863)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=37870)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=37870)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=38162)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=38162)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=37879)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=37879)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=37868)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=37868)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=37864)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=37864)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=37874)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=37874)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=37871)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=37871)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=37859)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=37859)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37866)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(pid=37875)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=37875)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=37877)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=37877)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=37860)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=37860)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=37862)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=37862)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=37861)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=37861)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=38424)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=38424)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=38384)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=38384)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=38425)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=38425)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=38466)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=38466)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=38340)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=38340)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37879)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37863)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37870)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=38162)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37874)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37871)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37868)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37864)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37859)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37875)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37860)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37877)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37862)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=37861)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=38424)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=38384)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=38425)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=38466)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=38340)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "2023-02-13 17:30:41,742\tINFO trainable.py:172 -- Trainable.setup took 15.606 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.policy.policy import PolicySpec\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    #Each rollout worker uses a single cpu\n",
    "    .rollouts(num_rollout_workers=20, num_envs_per_worker=1, horizon=100)\\\n",
    "    .training(sgd_minibatch_size = 100, train_batch_size=2000, gamma=0.99, lr=0.00005, \n",
    "              model={\"fcnet_hiddens\": [256, 256], \"fcnet_activation\": \"tanh\",})\\\n",
    "    .environment(disable_env_checking=True, env = 'DreamCybORG')\\\n",
    "    .resources(num_gpus=1)\\\n",
    "    .framework('torch')\\\n",
    "    #.exploration(explore=True, exploration_config={\"type\": \"RE3\", \"embeds_dim\": 128, \"beta_schedule\": \"constant\", \"sub_exploration\": {\"type\": \"StochasticSampling\",},})\\\n",
    ")\n",
    "trainer = config.build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 221 \tr_mean: -36.1 \tr_max: -17.8 \tr_min: -128.8\n",
      " 222 \tr_mean: -36.5 \tr_max: -17.8 \tr_min: -128.8\n",
      " 223 \tr_mean: -36.5 \tr_max: -19.6 \tr_min: -128.8\n",
      " 224 \tr_mean: -36.4 \tr_max: -19.6 \tr_min: -128.8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m500\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     print_results(\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/tune/trainable/trainable.py:364\u001b[0m, in \u001b[0;36mTrainable.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    366\u001b[0m     skipped \u001b[38;5;241m=\u001b[39m skip_exceptions(e)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/algorithms/algorithm.py:749\u001b[0m, in \u001b[0;36mAlgorithm.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    741\u001b[0m     (\n\u001b[1;32m    742\u001b[0m         results,\n\u001b[1;32m    743\u001b[0m         train_iter_ctx,\n\u001b[1;32m    744\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_one_training_iteration_and_evaluation_in_parallel()\n\u001b[1;32m    745\u001b[0m \u001b[38;5;66;03m# - No evaluation necessary, just run the next training iteration.\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;66;03m# - We have to evaluate in this training iteration, but no parallelism ->\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m#   evaluate after the training iteration is entirely done.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 749\u001b[0m     results, train_iter_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_one_training_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;66;03m# Sequential: Train (already done above), then evaluate.\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluate_this_iter \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation_parallel_to_training\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/algorithms/algorithm.py:2623\u001b[0m, in \u001b[0;36mAlgorithm._run_one_training_iteration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2621\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timers[TRAINING_ITERATION_TIMER]:\n\u001b[1;32m   2622\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_disable_execution_plan_api:\n\u001b[0;32m-> 2623\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2624\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2625\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_exec_impl)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/algorithms/ppo/ppo.py:331\u001b[0m, in \u001b[0;36mPPO.training_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m     train_results \u001b[38;5;241m=\u001b[39m train_one_step(\u001b[38;5;28mself\u001b[39m, train_batch)\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     train_results \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_gpu_train_one_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m policies_to_update \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(train_results\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m    335\u001b[0m global_vars \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestep\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_counters[NUM_AGENT_STEPS_SAMPLED],\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_grad_updates_per_policy\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m     },\n\u001b[1;32m    341\u001b[0m }\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/execution/train_ops.py:163\u001b[0m, in \u001b[0;36mmulti_gpu_train_one_step\u001b[0;34m(algorithm, train_batch)\u001b[0m\n\u001b[1;32m    158\u001b[0m         permutation \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(num_batches)\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m batch_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m    160\u001b[0m             \u001b[38;5;66;03m# Learn on the pre-loaded data in the buffer.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m             \u001b[38;5;66;03m# Note: For minibatch SGD, the data is an offset into\u001b[39;00m\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;66;03m# the pre-loaded entire train batch.\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m             results \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn_on_loaded_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpermutation\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mper_device_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m             learner_info_builder\u001b[38;5;241m.\u001b[39madd_learn_on_batch_results(results, policy_id)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# Tower reduce and finalize results.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/policy/torch_policy_v2.py:756\u001b[0m, in \u001b[0;36mTorchPolicyV2.learn_on_loaded_batch\u001b[0;34m(self, offset, buffer_index)\u001b[0m\n\u001b[1;32m    753\u001b[0m     batch_fetches[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtower_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom_metrics\u001b[39m\u001b[38;5;124m\"\u001b[39m: custom_metrics}\n\u001b[1;32m    755\u001b[0m \u001b[38;5;66;03m# Do the (maybe parallelized) gradient calculation step.\u001b[39;00m\n\u001b[0;32m--> 756\u001b[0m tower_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_multi_gpu_parallel_grad_calc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;66;03m# Mean-reduce gradients over GPU-towers (do this on CPU: self.device).\u001b[39;00m\n\u001b[1;32m    759\u001b[0m all_grads \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/policy/torch_policy_v2.py:1208\u001b[0m, in \u001b[0;36mTorchPolicyV2._multi_gpu_parallel_grad_calc\u001b[0;34m(self, sample_batches)\u001b[0m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevices) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_fake_gpus\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1205\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m shard_idx, (model, sample_batch, device) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m   1206\u001b[0m         \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_gpu_towers, sample_batches, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevices)\n\u001b[1;32m   1207\u001b[0m     ):\n\u001b[0;32m-> 1208\u001b[0m         \u001b[43m_worker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1209\u001b[0m         \u001b[38;5;66;03m# Raise errors right away for better debugging.\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m         last_result \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;28mlen\u001b[39m(results) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/policy/torch_policy_v2.py:1150\u001b[0m, in \u001b[0;36mTorchPolicyV2._multi_gpu_parallel_grad_calc.<locals>._worker\u001b[0;34m(shard_idx, model, sample_batch, device)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         param\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mzero_()\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;66;03m# Recompute gradients of loss over all variables.\u001b[39;00m\n\u001b[0;32m-> 1150\u001b[0m \u001b[43mloss_out\u001b[49m\u001b[43m[\u001b[49m\u001b[43mopt_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1151\u001b[0m grad_info\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextra_grad_process(opt, loss_out[opt_idx])\n\u001b[1;32m   1153\u001b[0m )\n\u001b[1;32m   1155\u001b[0m grads \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "    print_results(trainer.train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/root/ray_results/PPO_CybORG_2023-02-13_18-39-51n6m9jq1i/checkpoint_000016'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for FullyConnectedNetwork:\n\tsize mismatch for _logits._model.0.weight: copying a param with shape torch.Size([20, 256]) from checkpoint, the shape in current model is torch.Size([41, 256]).\n\tsize mismatch for _logits._model.0.bias: copying a param with shape torch.Size([20]) from checkpoint, the shape in current model is torch.Size([41]).\n\tsize mismatch for _hidden_layers.0._model.0.weight: copying a param with shape torch.Size([256, 42]) from checkpoint, the shape in current model is torch.Size([256, 91]).\n\tsize mismatch for _value_branch_separate.0._model.0.weight: copying a param with shape torch.Size([256, 42]) from checkpoint, the shape in current model is torch.Size([256, 91]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresults/checkpoint_000268\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/algorithms/algorithm.py:2010\u001b[0m, in \u001b[0;36mAlgorithm.load_checkpoint\u001b[0;34m(self, checkpoint)\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[38;5;66;03m# Checkpoint is a checkpoint-as-dict -> Restore state from it as-is.\u001b[39;00m\n\u001b[1;32m   2008\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2009\u001b[0m     checkpoint_data \u001b[38;5;241m=\u001b[39m checkpoint\n\u001b[0;32m-> 2010\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__setstate__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/algorithms/algorithm.py:2412\u001b[0m, in \u001b[0;36mAlgorithm.__setstate__\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m   2406\u001b[0m \u001b[38;5;66;03m# TODO (sven): Validate that our config and the config in state are compatible.\u001b[39;00m\n\u001b[1;32m   2407\u001b[0m \u001b[38;5;66;03m#  For example, the model architectures may differ.\u001b[39;00m\n\u001b[1;32m   2408\u001b[0m \u001b[38;5;66;03m#  Also, what should the behavior be if e.g. some training parameter\u001b[39;00m\n\u001b[1;32m   2409\u001b[0m \u001b[38;5;66;03m#  (e.g. lr) changed?\u001b[39;00m\n\u001b[1;32m   2411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkers\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworker\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m state:\n\u001b[0;32m-> 2412\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_worker\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mworker\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2413\u001b[0m     remote_state \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mput(state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworker\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   2414\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers\u001b[38;5;241m.\u001b[39mforeach_worker(\n\u001b[1;32m   2415\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m w: w\u001b[38;5;241m.\u001b[39mset_state(ray\u001b[38;5;241m.\u001b[39mget(remote_state)),\n\u001b[1;32m   2416\u001b[0m         local_worker\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   2417\u001b[0m         healthy_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   2418\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/rollout_worker.py:1679\u001b[0m, in \u001b[0;36mRolloutWorker.set_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m   1671\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_policy(\n\u001b[1;32m   1672\u001b[0m                 policy_id\u001b[38;5;241m=\u001b[39mpid,\n\u001b[1;32m   1673\u001b[0m                 policy_cls\u001b[38;5;241m=\u001b[39mpolicy_spec\u001b[38;5;241m.\u001b[39mpolicy_class,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1676\u001b[0m                 config\u001b[38;5;241m=\u001b[39mpolicy_spec\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m   1677\u001b[0m             )\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_map:\n\u001b[0;32m-> 1679\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1681\u001b[0m \u001b[38;5;66;03m# Also restore mapping fn and which policies to train.\u001b[39;00m\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolicy_mapping_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m state:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/policy/torch_mixins.py:108\u001b[0m, in \u001b[0;36mKLCoeffMixin.set_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkl_coeff \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent_kl_coeff\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkl_coeff\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Call super's set_state with rest of the state dict.\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/policy/torch_policy_v2.py:936\u001b[0m, in \u001b[0;36mTorchPolicyV2.set_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_timestep \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal_timestep\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    935\u001b[0m \u001b[38;5;66;03m# Then the Policy's (NN) weights and connectors.\u001b[39;00m\n\u001b[0;32m--> 936\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/policy/policy.py:968\u001b[0m, in \u001b[0;36mPolicy.set_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;129m@DeveloperAPI\u001b[39m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;129m@OverrideToImplementCustomLogic_CallToSuperRecommended\u001b[39m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_state\u001b[39m(\u001b[38;5;28mself\u001b[39m, state: PolicyState) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Restores the entire current state of this Policy from `state`.\u001b[39;00m\n\u001b[1;32m    963\u001b[0m \n\u001b[1;32m    964\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;124;03m        state: The new state to set this policy to. Can be\u001b[39;00m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;124;03m            obtained by calling `self.get_state()`.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 968\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweights\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    969\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore_connectors(state)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/policy/torch_policy_v2.py:885\u001b[0m, in \u001b[0;36mTorchPolicyV2.set_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;129m@override\u001b[39m(Policy)\n\u001b[1;32m    882\u001b[0m \u001b[38;5;129m@DeveloperAPI\u001b[39m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m, weights: ModelWeights) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     weights \u001b[38;5;241m=\u001b[39m convert_to_torch_tensor(weights, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 885\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1671\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1667\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1668\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1671\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1672\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for FullyConnectedNetwork:\n\tsize mismatch for _logits._model.0.weight: copying a param with shape torch.Size([20, 256]) from checkpoint, the shape in current model is torch.Size([41, 256]).\n\tsize mismatch for _logits._model.0.bias: copying a param with shape torch.Size([20]) from checkpoint, the shape in current model is torch.Size([41]).\n\tsize mismatch for _hidden_layers.0._model.0.weight: copying a param with shape torch.Size([256, 42]) from checkpoint, the shape in current model is torch.Size([256, 91]).\n\tsize mismatch for _value_branch_separate.0._model.0.weight: copying a param with shape torch.Size([256, 42]) from checkpoint, the shape in current model is torch.Size([256, 91])."
     ]
    }
   ],
   "source": [
    "trainer.load_checkpoint('results/checkpoint_000268')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'CybORG' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     cyborg \u001b[38;5;241m=\u001b[39m \u001b[43mCybORG\u001b[49m(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msim\u001b[39m\u001b[38;5;124m'\u001b[39m, agents\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRed\u001b[39m\u001b[38;5;124m'\u001b[39m: B_lineAgent})\n\u001b[1;32m      4\u001b[0m     wrapped_cyborg \u001b[38;5;241m=\u001b[39m wrap(cyborg)\n\u001b[1;32m      6\u001b[0m     observation \u001b[38;5;241m=\u001b[39m wrapped_cyborg\u001b[38;5;241m.\u001b[39mreset()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CybORG' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "\n",
    "    cyborg = CybORG(path, 'sim', agents={'Red': B_lineAgent})\n",
    "    wrapped_cyborg = wrap(cyborg)\n",
    "\n",
    "    observation = wrapped_cyborg.reset()\n",
    "    print(wrapped_cyborg.reset())\n",
    "    obs = wrapped_cyborg.step(5)[3]['observation']\n",
    "    print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0213 15:06:02.796053617   39484 backup_poller.cc:136]       Run client channel backup poller: UNKNOWN:pollset_work {created_time:\"2023-02-13T15:06:02.795903359+00:00\", children:[UNKNOWN:Bad file descriptor {syscall:\"epoll_wait\", os_error:\"Bad file descriptor\", errno:9, created_time:\"2023-02-13T15:06:02.795795923+00:00\"}]}\n",
      "Collecting tdqm\n",
      "  Downloading tdqm-0.0.1.tar.gz (1.4 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     || 78 kB 3.6 MB/s eta 0:00:011\n",
      "\u001b[?25hBuilding wheels for collected packages: tdqm\n",
      "  Building wheel for tdqm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tdqm: filename=tdqm-0.0.1-py3-none-any.whl size=1321 sha256=532c668caa6999b215925d5953c295f7a5e1eb4482762ce6287cf4b107a9e93b\n",
      "  Stored in directory: /root/.cache/pip/wheels/86/cd/38/f96ed05dd8049e95d8fbeaa0587664eb001a1848979636b771\n",
      "Successfully built tdqm\n",
      "Installing collected packages: tqdm, tdqm\n",
      "Successfully installed tdqm-0.0.1 tqdm-4.64.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 23.0 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tdqm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m      2\u001b[0m obs2, r, d, i \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      3\u001b[0m obs \u001b[38;5;241m-\u001b[39m obs2\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "test.reset()\n",
    "obs2, r, d, i = test.step(5)\n",
    "obs - obs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if (distutils.version.LooseVersion(tf.__version__) <\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 66\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# observation = cyborg.reset().observation\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# cyborg.env.env.tracker.render()\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m---> 66\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mcompute_single_action(observation, explore\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m#action_vec = np.zeros(145)\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m#action_vec[int(action)] = 1\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m#action = agent.get_action(observation, action_space)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     observation, rew, done, info \u001b[38;5;241m=\u001b[39m wrapped_cyborg\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import time\n",
    "from statistics import mean, stdev\n",
    "from CybORG import CybORG\n",
    "from CybORG.Agents import B_lineAgent, SleepAgent, GreenAgent\n",
    "from CybORG.Agents.SimpleAgents.BaseAgent import BaseAgent\n",
    "from CybORG.Agents.SimpleAgents.BlueReactAgent import BlueReactRemoveAgent\n",
    "from CybORG.Agents.SimpleAgents.Meander import RedMeanderAgent\n",
    "from CybORG.Agents.Wrappers.EnumActionWrapper import EnumActionWrapper\n",
    "from CybORG.Agents.Wrappers.rllib_wrapper import RLlibWrapper\n",
    "from CybORG.Agents.Wrappers.FixedFlatWrapper import FixedFlatWrapper\n",
    "from CybORG.Agents.Wrappers.OpenAIGymWrapper import OpenAIGymWrapper\n",
    "from CybORG.Agents.Wrappers.ReduceActionSpaceWrapper import ReduceActionSpaceWrapper\n",
    "from CybORG.Agents.Wrappers import ChallengeWrapper\n",
    "import os\n",
    "from tqdm import trange\n",
    "\n",
    "MAX_EPS = 5\n",
    "agent_name = 'Blue'\n",
    "\n",
    "def wrap(env):\n",
    "    return RLlibWrapper(agent_name=\"Blue\", env=env)\n",
    "\n",
    "def env_creator(env_config: dict):\n",
    "    path = str(inspect.getfile(CybORG))\n",
    "    path = path[:-10] + '/Shared/Scenarios/Scenario2_No_Decoy.yaml'\n",
    "    agents = {\"Red\": RedMeanderAgent, \"Green\": GreenAgent}\n",
    "    cyborg = CybORG(scenario_file=path, environment='sim', agents=agents)\n",
    "    env = RLlibWrapper(env=cyborg, agent_name=\"Blue\", max_steps=100)\n",
    "    return env\n",
    "\n",
    "register_env(name=\"CybORG\", env_creator=env_creator)\n",
    "\n",
    "\n",
    "path = str(inspect.getfile(CybORG))\n",
    "path = path[:-10] + '/Shared/Scenarios/Scenario2_No_Decoy.yaml'\n",
    "obs = []\n",
    "#print(f'using CybORG v{cyborg_version}, {scenario}\\n')\n",
    "for red_agent in [B_lineAgent]:#, RedMeanderAgent]:\n",
    "\n",
    "    cyborg = CybORG(path, 'sim', agents={'Red': red_agent})\n",
    "    wrapped_cyborg = wrap(cyborg)\n",
    "\n",
    "    observation = wrapped_cyborg.reset()\n",
    "    obs.append(observation)\n",
    "    # observation = cyborg.reset().observation\n",
    "\n",
    "    action_space = wrapped_cyborg.get_action_space(agent_name)\n",
    "    # action_space = cyborg.get_action_space(agent_name)\n",
    "    total_reward = []\n",
    "    actions = []\n",
    "    for i in trange(MAX_EPS):\n",
    "        r = []\n",
    "        #a = []\n",
    "        cyborg = CybORG(path, 'sim', agents={'Red': red_agent})\n",
    "        wrapped_cyborg = wrap(cyborg)\n",
    "\n",
    "        observation = wrapped_cyborg.reset()\n",
    "        obs.append(observation)\n",
    "        # observation = cyborg.reset().observation\n",
    "\n",
    "        # cyborg.env.env.tracker.render()\n",
    "        for j in range(100):\n",
    "            \n",
    "            \n",
    "            action = trainer.compute_single_action(observation, explore=False)\n",
    "            #action_vec = np.zeros(145)\n",
    "            #action_vec[int(action)] = 1\n",
    "            #action = agent.get_action(observation, action_space)\n",
    "            observation, rew, done, info = wrapped_cyborg.step(action)\n",
    "            obs.append(observation)\n",
    "            #actions.append(action_vec)\n",
    "            # result = cyborg.step(agent_name, action)\n",
    "            r.append(rew)\n",
    "            # r.append(result.reward)\n",
    "           # a.append((str(cyborg.get_last_action('Blue')), str(cyborg.get_last_action('Red'))))\n",
    "        total_reward.append(sum(r))\n",
    "        print(sum(r))\n",
    "        # observation = cyborg.reset().observation\n",
    "        observation = wrapped_cyborg.reset()\n",
    "    print(f'Average reward for red agent {red_agent.__name__} and steps {100} is: {mean(total_reward):.1f} with a standard deviation of {stdev(total_reward):.1f}')\n",
    "    #return mean(total_reward), np.mean(np.array(obs), axis=0),  np.mean(np.array(actions), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "\u001b[2m\u001b[36m(pid=25909)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=25909)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=25826)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=25826)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=25829)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=25829)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=25824)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=25824)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=25822)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=25822)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=25828)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=25828)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=25820)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=25820)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=25911)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=25911)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=25819)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=25819)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=25818)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=25818)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25909)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25826)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25829)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25824)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25822)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25828)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25911)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25820)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25818)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25819)\u001b[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "2023-02-08 12:36:23,387\tINFO trainable.py:172 -- Trainable.setup took 12.251 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25826)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25826)\u001b[0m   updates=self.state_updates,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25824)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25824)\u001b[0m   updates=self.state_updates,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25822)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25822)\u001b[0m   updates=self.state_updates,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25820)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25820)\u001b[0m   updates=self.state_updates,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25819)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25819)\u001b[0m   updates=self.state_updates,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25818)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25818)\u001b[0m   updates=self.state_updates,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25909)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25909)\u001b[0m   updates=self.state_updates,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25829)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25829)\u001b[0m   updates=self.state_updates,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25828)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25828)\u001b[0m   updates=self.state_updates,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25911)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25911)\u001b[0m   updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 12:36:23,787\tWARNING multi_agent_prioritized_replay_buffer.py:215 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n",
      "2023-02-08 12:36:26,890\tWARNING deprecation.py:47 -- DeprecationWarning: `concat_samples` has been deprecated. Use `concat_samples() from rllib.policy.sample_batch` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1 \tr_mean: -81.2 \tr_max: -67.7 \tr_min: -97.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ray/rllib/algorithms/algorithm.py:1716: DeprecationWarning: invalid escape sequence \\|\n",
      "  \"\"\"Adds a new policy to this Algorithm.\n",
      "/usr/local/lib/python3.8/dist-packages/ray/rllib/algorithms/dqn/dqn.py:54: DeprecationWarning: invalid escape sequence \\ \n",
      "  \"\"\"Defines a configuration class from which a DQN Algorithm can be built.\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.dqn import DQNConfig\n",
    "from ray.rllib.policy.policy import PolicySpec\n",
    "\n",
    "config = (\n",
    "    DQNConfig()\n",
    "    #Each rollout worker uses a single cpu\n",
    "    .rollouts(num_rollout_workers=10, num_envs_per_worker=1, horizon=100)\\\n",
    "    .training(gamma=0.99, lr=0.005, \n",
    "              model={\"fcnet_hiddens\": [256, 256], \"fcnet_activation\": \"tanh\",})\\\n",
    "    .environment(disable_env_checking=True, env = 'DreamCybORG')\\\n",
    "    .resources(num_gpus=1)\\\n",
    "    .framework('torch')\\\n",
    "    #.exploration(explore=True, exploration_config={\"type\": \"RE3\", \"embeds_dim\": 128, \"beta_schedule\": \"constant\", \"sub_exploration\": {\"type\": \"StochasticSampling\",},})\\\n",
    ")\n",
    "trainer = config.build()\n",
    "for i in range(500):\n",
    "    print_results(trainer.train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = WorldMovelEnv()\n",
    "import time \n",
    "\n",
    "t = time.time()\n",
    "print(test.reset())\n",
    "for i in range(100):\n",
    "    print(test.step(55))\n",
    "print(t-time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=22797)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=22797)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=22790)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead./usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=22790)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=22787)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=22787)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'results/checkpoint_000119'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=22786)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=22786)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=22795)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=22795)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=22800)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=22800)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=22793)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=22793)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=22794)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=22794)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=22792)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=22792)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=22796)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=22796)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=22788)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=22788)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=22789)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=22789)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=22805)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=22805)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=22802)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=22802)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=22798)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=22798)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=22803)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=22803)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=22791)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=22791)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=22807)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=22807)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=22784)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=22784)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n"
     ]
    }
   ],
   "source": [
    "trainer.save('results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     || 78 kB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.64.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 23.0 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = np.arange(10)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._iterations\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._iterations\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.89\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.90\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.91\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.92\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.93\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.94\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.95\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.96\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.97\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.98\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.99\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.100\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.101\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.102\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.103\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.104\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.105\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.106\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.107\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.108\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.109\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.110\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.111\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.112\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._iterations\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._iterations\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.89\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.90\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.91\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.92\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.93\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.94\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.95\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.96\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.97\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.98\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.99\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.100\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.101\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.102\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.103\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.104\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.105\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.106\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.107\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.108\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.109\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.110\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.111\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.112\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,9):\n",
    "    count[i] = count[i+1]\n",
    "count[-1] = 10\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "2023-02-14 12:40:28,248\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[2m\u001b[36m(pid=3800)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=3800)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=3804)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=3804)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=3810)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=3810)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=3811)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=3811)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=3798)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=3798)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=3801)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=3801)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=3813)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=3813)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=3802)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=3802)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=3824)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=3824)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=3806)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=3806)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=3817)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=3817)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=3826)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=3826)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=3821)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=3821)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=3803)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=3803)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=3868)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=3868)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=3815)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=3815)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=3805)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=3805)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=3822)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=3822)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=3818)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=3818)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=3799)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=3799)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "2023-02-14 12:40:48,985\tINFO trainable.py:172 -- Trainable.setup took 23.613 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1 \tr_mean: -136.8 \tr_max: -80.8 \tr_min: -324.8\n",
      "   2 \tr_mean: -127.2 \tr_max: -73.7 \tr_min: -324.8\n",
      "   3 \tr_mean: -142.3 \tr_max: -71.7 \tr_min: -646.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ray/rllib/algorithms/algorithm.py:1716: DeprecationWarning: invalid escape sequence \\|\n",
      "  \"\"\"Adds a new policy to this Algorithm.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m trainer\u001b[38;5;241m.\u001b[39mload_checkpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/root/ray_results/PPO_CybORG_2023-02-13_18-39-51n6m9jq1i/checkpoint_000016\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m500\u001b[39m):\n\u001b[0;32m---> 60\u001b[0m     print_results(\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/tune/trainable/trainable.py:364\u001b[0m, in \u001b[0;36mTrainable.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    366\u001b[0m     skipped \u001b[38;5;241m=\u001b[39m skip_exceptions(e)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/algorithms/algorithm.py:749\u001b[0m, in \u001b[0;36mAlgorithm.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    741\u001b[0m     (\n\u001b[1;32m    742\u001b[0m         results,\n\u001b[1;32m    743\u001b[0m         train_iter_ctx,\n\u001b[1;32m    744\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_one_training_iteration_and_evaluation_in_parallel()\n\u001b[1;32m    745\u001b[0m \u001b[38;5;66;03m# - No evaluation necessary, just run the next training iteration.\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;66;03m# - We have to evaluate in this training iteration, but no parallelism ->\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m#   evaluate after the training iteration is entirely done.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 749\u001b[0m     results, train_iter_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_one_training_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;66;03m# Sequential: Train (already done above), then evaluate.\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluate_this_iter \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation_parallel_to_training\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/algorithms/algorithm.py:2623\u001b[0m, in \u001b[0;36mAlgorithm._run_one_training_iteration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2621\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timers[TRAINING_ITERATION_TIMER]:\n\u001b[1;32m   2622\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_disable_execution_plan_api:\n\u001b[0;32m-> 2623\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2624\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2625\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_exec_impl)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/algorithms/ppo/ppo.py:318\u001b[0m, in \u001b[0;36mPPO.training_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m     train_batch \u001b[38;5;241m=\u001b[39m synchronous_parallel_sample(\n\u001b[1;32m    315\u001b[0m         worker_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers, max_agent_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtrain_batch_size\n\u001b[1;32m    316\u001b[0m     )\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     train_batch \u001b[38;5;241m=\u001b[39m \u001b[43msynchronous_parallel_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworker_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_env_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_batch_size\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m train_batch \u001b[38;5;241m=\u001b[39m train_batch\u001b[38;5;241m.\u001b[39mas_multi_agent()\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_counters[NUM_AGENT_STEPS_SAMPLED] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m train_batch\u001b[38;5;241m.\u001b[39magent_steps()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/execution/rollout_ops.py:85\u001b[0m, in \u001b[0;36msynchronous_parallel_sample\u001b[0;34m(worker_set, max_agent_steps, max_env_steps, concat)\u001b[0m\n\u001b[1;32m     82\u001b[0m     sample_batches \u001b[38;5;241m=\u001b[39m [worker_set\u001b[38;5;241m.\u001b[39mlocal_worker()\u001b[38;5;241m.\u001b[39msample()]\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Loop over remote workers' `sample()` method in parallel.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     sample_batches \u001b[38;5;241m=\u001b[39m \u001b[43mworker_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforeach_worker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhealthy_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m worker_set\u001b[38;5;241m.\u001b[39mnum_healthy_remote_workers() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;66;03m# There is no point staying in this loop, since we will not be able to\u001b[39;00m\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;66;03m# get any new samples if we don't have any healthy remote workers left.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/worker_set.py:688\u001b[0m, in \u001b[0;36mWorkerSet.foreach_worker\u001b[0;34m(self, func, local_worker, healthy_only, remote_worker_ids, timeout_seconds, return_obj_refs)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_worker \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_worker() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    686\u001b[0m     local_result \u001b[38;5;241m=\u001b[39m [func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_worker())]\n\u001b[0;32m--> 688\u001b[0m remote_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__worker_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforeach_actor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhealthy_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhealthy_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_actor_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_worker_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m handle_remote_call_result_errors(remote_results, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore_worker_failures)\n\u001b[1;32m    698\u001b[0m \u001b[38;5;66;03m# With application errors handled, return good results.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/utils/actor_manager.py:574\u001b[0m, in \u001b[0;36mFaultTolerantActorManager.foreach_actor\u001b[0;34m(self, func, healthy_only, remote_actor_ids, timeout_seconds, return_obj_refs)\u001b[0m\n\u001b[1;32m    565\u001b[0m     func, remote_actor_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter_func_and_remote_actor_id_by_state(\n\u001b[1;32m    566\u001b[0m         func, remote_actor_ids\n\u001b[1;32m    567\u001b[0m     )\n\u001b[1;32m    569\u001b[0m remote_calls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_actors(\n\u001b[1;32m    570\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m    571\u001b[0m     remote_actor_ids\u001b[38;5;241m=\u001b[39mremote_actor_ids,\n\u001b[1;32m    572\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m _, remote_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__fetch_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_actor_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_actor_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m remote_results\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/utils/actor_manager.py:453\u001b[0m, in \u001b[0;36mFaultTolerantActorManager.__fetch_result\u001b[0;34m(self, remote_actor_ids, remote_calls, timeout_seconds, return_obj_refs)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;66;03m# Notice that we do not return the refs to any unfinished calls to the\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# user, since it is not safe to handle such remote actor calls outside the\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# context of this actor manager. These requests are simply dropped.\u001b[39;00m\n\u001b[1;32m    452\u001b[0m timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(timeout_seconds) \u001b[38;5;28;01mif\u001b[39;00m timeout_seconds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 453\u001b[0m ready, _ \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Make sure remote results are fetched locally in parallel.\u001b[39;49;00m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;66;03m# Remote data should already be fetched to local object store at this point.\u001b[39;00m\n\u001b[1;32m    462\u001b[0m remote_results \u001b[38;5;241m=\u001b[39m RemoteCallResults()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/_private/client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py:2496\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_refs, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[1;32m   2494\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeout \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m\n\u001b[1;32m   2495\u001b[0m timeout_milliseconds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m-> 2496\u001b[0m ready_ids, remaining_ids \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobject_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_milliseconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_task_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2502\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ready_ids, remaining_ids\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:1759\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:195\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RED_AGENT = \"B_Line\"\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.policy.policy import PolicySpec\n",
    "import inspect\n",
    "import time\n",
    "from statistics import mean, stdev\n",
    "from CybORG import CybORG\n",
    "from CybORG.Agents import B_lineAgent, SleepAgent, GreenAgent\n",
    "from CybORG.Agents.SimpleAgents.BaseAgent import BaseAgent\n",
    "from CybORG.Agents.SimpleAgents.BlueReactAgent import BlueReactRemoveAgent\n",
    "from CybORG.Agents.SimpleAgents.Meander import RedMeanderAgent\n",
    "from CybORG.Agents.Wrappers.EnumActionWrapper import EnumActionWrapper\n",
    "from CybORG.Agents.Wrappers.rllib_wrapper import RLlibWrapper\n",
    "from CybORG.Agents.Wrappers.FixedFlatWrapper import FixedFlatWrapper\n",
    "from CybORG.Agents.Wrappers.OpenAIGymWrapper import OpenAIGymWrapper\n",
    "from CybORG.Agents.Wrappers.ReduceActionSpaceWrapper import ReduceActionSpaceWrapper\n",
    "from CybORG.Agents.Wrappers import ChallengeWrapper\n",
    "import os\n",
    "from ray.tune.registry import register_env\n",
    "from tqdm import trange\n",
    "\n",
    "def print_results(results_dict):\n",
    "    train_iter = results_dict[\"training_iteration\"]\n",
    "    r_mean = results_dict[\"episode_reward_mean\"]\n",
    "    r_max = results_dict[\"episode_reward_max\"]\n",
    "    r_min = results_dict[\"episode_reward_min\"]\n",
    "    print(f\"{train_iter:4d} \\tr_mean: {r_mean:.1f} \\tr_max: {r_max:.1f} \\tr_min: {r_min: .1f}\")\n",
    "\n",
    "def env_creator(env_config: dict):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    path = str(inspect.getfile(CybORG))\n",
    "    path = path[:-10] + '/Shared/Scenarios/Scenario2_No_Decoy.yaml'\n",
    "    if RED_AGENT == \"B_Line\":\n",
    "        agents = {\"Red\": B_lineAgent, \"Green\": GreenAgent}\n",
    "    else:\n",
    "        agents = {\"Red\": RedMeanderAgent, \"Green\": GreenAgent}\n",
    "\n",
    "    cyborg = CybORG(scenario_file=path, environment='sim', agents=agents)\n",
    "    env = RLlibWrapper(env=cyborg, agent_name=\"Blue\", max_steps=100)\n",
    "    return env\n",
    "\n",
    "\n",
    "register_env(name=\"CybORG\", env_creator=env_creator)\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    #Each rollout worker uses a single cpu\n",
    "    .rollouts(num_rollout_workers=20, num_envs_per_worker=1, horizon=100)\\\n",
    "    .training(sgd_minibatch_size = 100, train_batch_size=2000, gamma=0.99, lr=0.0001, \n",
    "              model={\"fcnet_hiddens\": [256, 256], \"fcnet_activation\": \"tanh\",})\\\n",
    "    .environment(disable_env_checking=True, env = 'CybORG')\\\n",
    "    .resources(num_gpus=1)\\\n",
    "    .framework('torch')\\\n",
    "    #.exploration(explore=True, exploration_config={\"type\": \"RE3\", \"embeds_dim\": 128, \"beta_schedule\": \"constant\", \"sub_exploration\": {\"type\": \"StochasticSampling\",},})\\\n",
    ")\n",
    "trainer = config.build()\n",
    "\n",
    "trainer.load_checkpoint('/root/ray_results/PPO_CybORG_2023-02-13_18-39-51n6m9jq1i/checkpoint_000016')\n",
    "\n",
    "for i in range(500):\n",
    "    print_results(trainer.train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/root/ray_results/PPO_CybORG_2023-02-14_12-40-25931iq2wl/checkpoint_000003'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = trainer.save()\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79200, 92)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "LOGS_PATH = 'logs/APPO/Insomnia0'\n",
    "states_t = np.load(LOGS_PATH + '/data/states_t.npy')\n",
    "states_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
