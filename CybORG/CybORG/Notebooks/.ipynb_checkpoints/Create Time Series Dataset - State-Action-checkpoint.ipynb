{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.offline.json_reader import JsonReader\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 17:48:32,388\tWARNING json_reader.py:238 -- Treating input directory as glob patterns: ['/tf/Cage/Notebooks/logs/APPO/RE3/*.json', '/tf/Cage/Notebooks/logs/APPO/RE3/*.zip']\n"
     ]
    }
   ],
   "source": [
    "input_reader = JsonReader(\"logs/APPO/RE3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "882000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length=2\n",
    "num_episodes = 9000\n",
    "windows_per_episode = 100-sequence_length\n",
    "state_len = 52\n",
    "num_action = 145\n",
    "encoding_len = state_len + num_action\n",
    "\n",
    "data_points = num_episodes * windows_per_episode\n",
    "\n",
    "X = np.zeros((data_points,sequence_length,encoding_len))\n",
    "Y = np.zeros((data_points,state_len))\n",
    "\n",
    "index = 0\n",
    "for e in range(num_episodes):\n",
    "    data = input_reader.next()\n",
    "    data['obs'].shape\n",
    "    for i in range(0, windows_per_episode):\n",
    "        ns = data['obs'][i+1]\n",
    "        if i < sequence_length:\n",
    "            s = np.zeros((sequence_length, encoding_len))\n",
    "            for k in range(0,i):\n",
    "                s[k,:] = np.concatenate([data['obs'][k], np.zeros(num_action)])\n",
    "        else:\n",
    "            vec = np.zeros((sequence_length, num_action))\n",
    "            vec[np.arange(sequence_length),data['actions'][i-sequence_length:i]] = 1\n",
    "            s = np.concatenate([data['obs'][i-sequence_length:i], vec], axis=1)\n",
    "            \n",
    "        X[index,:,:] = s\n",
    "        Y[index,:] = ns\n",
    "        index += 1\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "new_state = {}\n",
    "\n",
    "for i, matrix in enumerate(X):\n",
    "    if (X[10]==matrix).all():\n",
    "        if not Y[i].tobytes() in new_state:\n",
    "            new_state[Y.tobytes()] = 1\n",
    "        else:\n",
    "            new_state[Y.tobytes()] += 1\n",
    "            \n",
    "for s in new_state.keys():\n",
    "    print(new_state[s])\n",
    "    print(np.frombuffer(s))\n",
    "\n",
    "print(len(new_state.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_6 (Bidirectio  (None, 2, 512)           929792    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 2, 256)           656384    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 52)                26676     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,612,852\n",
      "Trainable params: 1,612,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 882000 samples\n",
      "Epoch 1/100\n",
      "882000/882000 [==============================] - 144s 164us/sample - loss: 0.0719\n",
      "Epoch 2/100\n",
      "882000/882000 [==============================] - 142s 161us/sample - loss: 0.0670\n",
      "Epoch 3/100\n",
      "882000/882000 [==============================] - 142s 161us/sample - loss: 0.0657\n",
      "Epoch 4/100\n",
      "882000/882000 [==============================] - 143s 162us/sample - loss: 0.0642\n",
      "Epoch 5/100\n",
      "882000/882000 [==============================] - 141s 160us/sample - loss: 0.0625\n",
      "Epoch 6/100\n",
      "882000/882000 [==============================] - 142s 161us/sample - loss: 0.0606\n",
      "Epoch 7/100\n",
      "882000/882000 [==============================] - 142s 161us/sample - loss: 0.0586\n",
      "Epoch 8/100\n",
      "882000/882000 [==============================] - 141s 160us/sample - loss: 0.0566\n",
      "Epoch 9/100\n",
      "882000/882000 [==============================] - 140s 159us/sample - loss: 0.0547\n",
      "Epoch 10/100\n",
      "882000/882000 [==============================] - 141s 160us/sample - loss: 0.0528\n",
      "Epoch 11/100\n",
      "882000/882000 [==============================] - 142s 161us/sample - loss: 0.0510\n",
      "Epoch 12/100\n",
      "882000/882000 [==============================] - 142s 161us/sample - loss: 0.0494\n",
      "Epoch 13/100\n",
      "882000/882000 [==============================] - 142s 161us/sample - loss: 0.0479\n",
      "Epoch 14/100\n",
      "882000/882000 [==============================] - 143s 162us/sample - loss: 0.0466\n",
      "Epoch 15/100\n",
      "882000/882000 [==============================] - 142s 161us/sample - loss: 0.0453\n",
      "Epoch 16/100\n",
      "882000/882000 [==============================] - 142s 161us/sample - loss: 0.0442\n",
      "Epoch 17/100\n",
      "882000/882000 [==============================] - 143s 162us/sample - loss: 0.0432\n",
      "Epoch 18/100\n",
      "882000/882000 [==============================] - 142s 161us/sample - loss: 0.0422\n",
      "Epoch 19/100\n",
      "882000/882000 [==============================] - 142s 161us/sample - loss: 0.0414\n",
      "Epoch 20/100\n",
      "882000/882000 [==============================] - 142s 161us/sample - loss: 0.0406\n",
      "Epoch 21/100\n",
      "882000/882000 [==============================] - 142s 161us/sample - loss: 0.0398\n",
      "Epoch 22/100\n",
      "882000/882000 [==============================] - 142s 161us/sample - loss: 0.0392\n",
      "Epoch 23/100\n",
      "882000/882000 [==============================] - 142s 161us/sample - loss: 0.0386\n",
      "Epoch 24/100\n",
      "882000/882000 [==============================] - 141s 160us/sample - loss: 0.0380\n",
      "Epoch 25/100\n",
      "882000/882000 [==============================] - 143s 162us/sample - loss: 0.0375\n",
      "Epoch 26/100\n",
      "882000/882000 [==============================] - 138s 157us/sample - loss: 0.0370\n",
      "Epoch 27/100\n",
      "882000/882000 [==============================] - 140s 159us/sample - loss: 0.0366\n",
      "Epoch 28/100\n",
      "882000/882000 [==============================] - 143s 162us/sample - loss: 0.0357\n",
      "Epoch 30/100\n",
      "604608/882000 [===================>..........] - ETA: 45s - loss: 0.0350"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "882000/882000 [==============================] - 144s 163us/sample - loss: 0.0354\n",
      "Epoch 31/100\n",
      "882000/882000 [==============================] - 143s 162us/sample - loss: 0.0351\n",
      "Epoch 32/100\n",
      "882000/882000 [==============================] - 144s 164us/sample - loss: 0.0347\n",
      "Epoch 33/100\n",
      "882000/882000 [==============================] - 141s 160us/sample - loss: 0.0345\n",
      "Epoch 34/100\n",
      "882000/882000 [==============================] - 141s 159us/sample - loss: 0.0342\n",
      "Epoch 35/100\n",
      "882000/882000 [==============================] - 140s 159us/sample - loss: 0.0339\n",
      "Epoch 36/100\n",
      "882000/882000 [==============================] - 140s 159us/sample - loss: 0.0337\n",
      "Epoch 37/100\n",
      "882000/882000 [==============================] - 140s 159us/sample - loss: 0.0334\n",
      "Epoch 38/100\n",
      "882000/882000 [==============================] - 142s 162us/sample - loss: 0.0332\n",
      "Epoch 39/100\n",
      "882000/882000 [==============================] - 145s 164us/sample - loss: 0.0330\n",
      "Epoch 40/100\n",
      "882000/882000 [==============================] - 145s 164us/sample - loss: 0.0328\n",
      "Epoch 41/100\n",
      "882000/882000 [==============================] - 144s 164us/sample - loss: 0.0326\n",
      "Epoch 42/100\n",
      "882000/882000 [==============================] - 143s 163us/sample - loss: 0.0324\n",
      "Epoch 43/100\n",
      "882000/882000 [==============================] - 144s 163us/sample - loss: 0.0322\n",
      "Epoch 44/100\n",
      "882000/882000 [==============================] - 144s 163us/sample - loss: 0.0321\n",
      "Epoch 45/100\n",
      "882000/882000 [==============================] - 142s 162us/sample - loss: 0.0319\n",
      "Epoch 46/100\n",
      "882000/882000 [==============================] - 145s 164us/sample - loss: 0.0318\n",
      "Epoch 47/100\n",
      "882000/882000 [==============================] - 145s 164us/sample - loss: 0.0316\n",
      "Epoch 48/100\n",
      "882000/882000 [==============================] - 144s 164us/sample - loss: 0.0315\n",
      "Epoch 49/100\n",
      "882000/882000 [==============================] - 143s 163us/sample - loss: 0.0313\n",
      "Epoch 50/100\n",
      "882000/882000 [==============================] - 141s 160us/sample - loss: 0.0312\n",
      "Epoch 51/100\n",
      "882000/882000 [==============================] - 143s 162us/sample - loss: 0.0311\n",
      "Epoch 52/100\n",
      "882000/882000 [==============================] - 144s 163us/sample - loss: 0.0310\n",
      "Epoch 53/100\n",
      "882000/882000 [==============================] - 144s 164us/sample - loss: 0.0309\n",
      "Epoch 54/100\n",
      "882000/882000 [==============================] - 142s 160us/sample - loss: 0.0308\n",
      "Epoch 55/100\n",
      "882000/882000 [==============================] - 142s 161us/sample - loss: 0.0307\n",
      "Epoch 56/100\n",
      "882000/882000 [==============================] - 142s 161us/sample - loss: 0.0305\n",
      "Epoch 57/100\n",
      "882000/882000 [==============================] - 140s 159us/sample - loss: 0.0305\n",
      "Epoch 58/100\n",
      "882000/882000 [==============================] - 141s 160us/sample - loss: 0.0304\n",
      "Epoch 59/100\n",
      "882000/882000 [==============================] - 141s 159us/sample - loss: 0.0303\n",
      "Epoch 60/100\n",
      "882000/882000 [==============================] - 140s 159us/sample - loss: 0.0302\n",
      "Epoch 61/100\n",
      "882000/882000 [==============================] - 140s 159us/sample - loss: 0.0301\n",
      "Epoch 62/100\n",
      "882000/882000 [==============================] - 140s 159us/sample - loss: 0.0300\n",
      "Epoch 63/100\n",
      "882000/882000 [==============================] - 140s 159us/sample - loss: 0.0299\n",
      "Epoch 64/100\n",
      "882000/882000 [==============================] - 140s 159us/sample - loss: 0.0298\n",
      "Epoch 65/100\n",
      "882000/882000 [==============================] - 140s 159us/sample - loss: 0.0298\n",
      "Epoch 66/100\n",
      "882000/882000 [==============================] - 141s 160us/sample - loss: 0.0297\n",
      "Epoch 67/100\n",
      "882000/882000 [==============================] - 139s 158us/sample - loss: 0.0296\n",
      "Epoch 68/100\n",
      "882000/882000 [==============================] - 141s 160us/sample - loss: 0.0296\n",
      "Epoch 69/100\n",
      "882000/882000 [==============================] - 141s 160us/sample - loss: 0.0295\n",
      "Epoch 70/100\n",
      "882000/882000 [==============================] - 141s 160us/sample - loss: 0.0294\n",
      "Epoch 71/100\n",
      "882000/882000 [==============================] - 140s 159us/sample - loss: 0.0294\n",
      "Epoch 72/100\n",
      "882000/882000 [==============================] - 141s 160us/sample - loss: 0.0293\n",
      "Epoch 73/100\n",
      "882000/882000 [==============================] - 140s 159us/sample - loss: 0.0293\n",
      "Epoch 74/100\n",
      "882000/882000 [==============================] - 140s 159us/sample - loss: 0.0292\n",
      "Epoch 75/100\n",
      "882000/882000 [==============================] - 140s 159us/sample - loss: 0.0291\n",
      "Epoch 76/100\n",
      "882000/882000 [==============================] - 139s 157us/sample - loss: 0.0291\n",
      "Epoch 77/100\n",
      "882000/882000 [==============================] - 140s 158us/sample - loss: 0.0290\n",
      "Epoch 78/100\n",
      "882000/882000 [==============================] - 138s 156us/sample - loss: 0.0290\n",
      "Epoch 79/100\n",
      "882000/882000 [==============================] - 139s 157us/sample - loss: 0.0289\n",
      "Epoch 80/100\n",
      "882000/882000 [==============================] - 140s 159us/sample - loss: 0.0289\n",
      "Epoch 81/100\n",
      "882000/882000 [==============================] - 140s 159us/sample - loss: 0.0289\n",
      "Epoch 82/100\n",
      "882000/882000 [==============================] - 140s 159us/sample - loss: 0.0288\n",
      "Epoch 83/100\n",
      "882000/882000 [==============================] - 136s 154us/sample - loss: 0.0288\n",
      "Epoch 84/100\n",
      "882000/882000 [==============================] - 140s 159us/sample - loss: 0.0287\n",
      "Epoch 85/100\n",
      "882000/882000 [==============================] - 139s 158us/sample - loss: 0.0287\n",
      "Epoch 86/100\n",
      "882000/882000 [==============================] - 141s 159us/sample - loss: 0.0286\n",
      "Epoch 87/100\n",
      "882000/882000 [==============================] - 141s 160us/sample - loss: 0.0286\n",
      "Epoch 88/100\n",
      "882000/882000 [==============================] - 140s 159us/sample - loss: 0.0285\n",
      "Epoch 89/100\n",
      "882000/882000 [==============================] - 141s 159us/sample - loss: 0.0284\n",
      "Epoch 90/100\n",
      "882000/882000 [==============================] - 140s 158us/sample - loss: 0.0285\n",
      "Epoch 91/100\n",
      "882000/882000 [==============================] - 141s 159us/sample - loss: 0.0284\n",
      "Epoch 92/100\n",
      "882000/882000 [==============================] - 140s 159us/sample - loss: 0.0284\n",
      "Epoch 93/100\n",
      "882000/882000 [==============================] - 141s 160us/sample - loss: 0.0283\n",
      "Epoch 94/100\n",
      "882000/882000 [==============================] - 141s 160us/sample - loss: 0.0283\n",
      "Epoch 95/100\n",
      "882000/882000 [==============================] - 141s 160us/sample - loss: 0.0283\n",
      "Epoch 96/100\n",
      "882000/882000 [==============================] - 140s 159us/sample - loss: 0.0282\n",
      "Epoch 97/100\n",
      "882000/882000 [==============================] - 139s 158us/sample - loss: 0.0282\n",
      "Epoch 98/100\n",
      "882000/882000 [==============================] - 140s 158us/sample - loss: 0.0282\n",
      "Epoch 99/100\n",
      "882000/882000 [==============================] - 140s 158us/sample - loss: 0.0281\n",
      "Epoch 100/100\n",
      "882000/882000 [==============================] - 141s 159us/sample - loss: 0.0281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fed790652b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(256, activation='relu', return_sequences=True), input_shape=(sequence_length, encoding_len)))\n",
    "model.add(Bidirectional(LSTM(128, activation='relu', return_sequences=True)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(state_len, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=False))\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X, Y, epochs=100, validation_split=0.0, verbose=1, callbacks=[callback], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.23324515e-02 2.05429770e-12 1.61281817e-12 2.85958345e-12\n",
      "  4.19264793e-01 6.07901451e-10 6.11944595e-27 4.06044087e-10\n",
      "  1.82830710e-02 3.36369021e-06 4.98381880e-13 4.39934665e-05\n",
      "  1.47922440e-02 2.04250318e-05 2.21504749e-07 4.82953219e-05\n",
      "  1.21356488e-05 2.74417641e-12 2.64239325e-12 1.62799960e-12\n",
      "  3.95372888e-04 2.60698993e-12 1.37654634e-12 2.35609080e-12\n",
      "  2.99566006e-03 3.27045292e-12 2.23720847e-12 2.13610705e-12\n",
      "  1.68652902e-03 1.97436338e-12 1.63646465e-23 1.94517691e-09\n",
      "  7.10008740e-01 1.26343814e-12 2.06809700e-12 1.64374070e-12\n",
      "  1.64869688e-02 5.45419288e-22 7.14699016e-35 3.73892604e-22\n",
      "  9.43715334e-01 9.03491497e-01 3.91993535e-06 1.00000000e+00\n",
      "  6.68908358e-02 7.15321075e-12 6.23393882e-17 1.35554189e-11\n",
      "  3.45146080e-04 2.14116116e-12 3.77680781e-32 6.34294104e-13]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(np.array([X[10]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(model.predict(np.array([X[10]])))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(Y[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05682293, 0.878325  , 0.7105613 , 0.9999546 ], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = model.predict(np.array([X[10]]))[0]\n",
    "p[np.where(Y[10]==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i, matrix in enumerate(X):\n",
    "    if (X[10]==matrix).all():\n",
    "        if not Y[i].tobytes() in new_state:\n",
    "            new_state[Y.tobytes()] = 1\n",
    "        else:\n",
    "            new_state[Y.tobytes()] += 1\n",
    "            \n",
    "for s in new_state.keys():\n",
    "    print(new_state[s])\n",
    "    print(np.frombuffer(s))\n",
    "\n",
    "print(len(new_state.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('target.npy',X[10])\n",
    "np.save('prediction.npy',p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
