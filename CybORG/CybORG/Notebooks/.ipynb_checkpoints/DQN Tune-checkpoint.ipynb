{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import time\n",
    "from statistics import mean, stdev\n",
    "from CybORG import CybORG\n",
    "from CybORG.Agents import B_lineAgent, SleepAgent, GreenAgent\n",
    "from CybORG.Agents.SimpleAgents.BaseAgent import BaseAgent\n",
    "from CybORG.Agents.SimpleAgents.BlueReactAgent import BlueReactRemoveAgent\n",
    "from CybORG.Agents.SimpleAgents.Meander import RedMeanderAgent\n",
    "from CybORG.Agents.Wrappers.EnumActionWrapper import EnumActionWrapper\n",
    "from CybORG.Agents.Wrappers.FixedFlatWrapper import FixedFlatWrapper\n",
    "from CybORG.Agents.Wrappers.OpenAIGymWrapper import OpenAIGymWrapper\n",
    "from CybORG.Agents.Wrappers.ReduceActionSpaceWrapper import ReduceActionSpaceWrapper\n",
    "from CybORG.Agents.Wrappers import ChallengeWrapper\n",
    "import os\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "from CybORG.Agents.Wrappers.rllib_wrapper import RLlibWrapper\n",
    "import warnings\n",
    "import numpy as np\n",
    "from ray import air, tune\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_creator(env_config: dict):\n",
    "    path = str(inspect.getfile(CybORG))\n",
    "    path = path[:-10] + '/Shared/Scenarios/Scenario2.yaml'\n",
    "    agents = {\"Red\": B_lineAgent, \"Green\": GreenAgent}\n",
    "    cyborg = CybORG(scenario_file=path, environment='sim', agents=agents)\n",
    "    env = RLlibWrapper(env=cyborg, agent_name=\"Blue\", max_steps=100)\n",
    "    return env\n",
    "\n",
    "def print_results(results_dict):\n",
    "    train_iter = results_dict[\"training_iteration\"]\n",
    "    r_mean = results_dict[\"episode_reward_mean\"]\n",
    "    r_max = results_dict[\"episode_reward_max\"]\n",
    "    r_min = results_dict[\"episode_reward_min\"]\n",
    "    print(f\"{train_iter:4d} \\tr_mean: {r_mean:.1f} \\tr_max: {r_max:.1f} \\tr_min: {r_min: .1f}\")\n",
    "\n",
    "register_env(name=\"CybORG\", env_creator=env_creator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.agents.callbacks import RE3UpdateCallbacks\n",
    "\n",
    "class RE3Callbacks(RE3UpdateCallbacks, config[\"callbacks\"]):\n",
    "            pass\n",
    "\n",
    "\"callbacks\": = RE3Callbacks\n",
    "\"exploration_config\": = {\n",
    "    \"type\": \"RE3\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 23:26:05,857\tINFO worker.py:1528 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2022-12-02 11:10:01</td></tr>\n",
       "<tr><td>Running for: </td><td>11:43:53.81        </td></tr>\n",
       "<tr><td>Memory:      </td><td>79.0/125.8 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 31.0/40 CPUs, 1.0/1 GPUs, 0.0/77.87 GiB heap, 0.0/37.36 GiB objects (0.0/1.0 accelerator_type:V100)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  ... 4 more trials not shown (3 TERMINATED)\n",
       "  \n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status    </th><th>loc             </th><th style=\"text-align: right;\">  gamma</th><th style=\"text-align: right;\">    lr</th><th>model/fcnet_activati\n",
       "on     </th><th>model/fcnet_hiddens  </th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  num_recreated_worker\n",
       "s</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CybORG_886ac_00013</td><td>RUNNING   </td><td>172.28.0.2:25182</td><td style=\"text-align: right;\">   0.97</td><td style=\"text-align: right;\">0.0001</td><td>relu</td><td>[256, 256]           </td><td style=\"text-align: right;\">              4000</td><td style=\"text-align: right;\">   286</td><td style=\"text-align: right;\">         2311.51</td><td style=\"text-align: right;\">1149720</td><td style=\"text-align: right;\"> -46.454</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">                -9.8</td><td style=\"text-align: right;\">              -156.8</td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00014</td><td>PENDING   </td><td>                </td><td style=\"text-align: right;\">   0.97</td><td style=\"text-align: right;\">0.0005</td><td>tanh</td><td>[256, 256]           </td><td style=\"text-align: right;\">              4000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00015</td><td>PENDING   </td><td>                </td><td style=\"text-align: right;\">   0.97</td><td style=\"text-align: right;\">0.0001</td><td>tanh</td><td>[256, 256]           </td><td style=\"text-align: right;\">              4000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00016</td><td>PENDING   </td><td>                </td><td style=\"text-align: right;\">   0.97</td><td style=\"text-align: right;\">0.0005</td><td>relu</td><td>[512, 512]           </td><td style=\"text-align: right;\">              2000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00017</td><td>PENDING   </td><td>                </td><td style=\"text-align: right;\">   0.97</td><td style=\"text-align: right;\">0.0001</td><td>relu</td><td>[512, 512]           </td><td style=\"text-align: right;\">              2000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00018</td><td>PENDING   </td><td>                </td><td style=\"text-align: right;\">   0.97</td><td style=\"text-align: right;\">0.0005</td><td>tanh</td><td>[512, 512]           </td><td style=\"text-align: right;\">              2000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00019</td><td>PENDING   </td><td>                </td><td style=\"text-align: right;\">   0.97</td><td style=\"text-align: right;\">0.0001</td><td>tanh</td><td>[512, 512]           </td><td style=\"text-align: right;\">              2000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00020</td><td>PENDING   </td><td>                </td><td style=\"text-align: right;\">   0.97</td><td style=\"text-align: right;\">0.0005</td><td>relu</td><td>[256, 256]           </td><td style=\"text-align: right;\">              2000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00021</td><td>PENDING   </td><td>                </td><td style=\"text-align: right;\">   0.97</td><td style=\"text-align: right;\">0.0001</td><td>relu</td><td>[256, 256]           </td><td style=\"text-align: right;\">              2000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00022</td><td>PENDING   </td><td>                </td><td style=\"text-align: right;\">   0.97</td><td style=\"text-align: right;\">0.0005</td><td>tanh</td><td>[256, 256]           </td><td style=\"text-align: right;\">              2000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00023</td><td>PENDING   </td><td>                </td><td style=\"text-align: right;\">   0.97</td><td style=\"text-align: right;\">0.0001</td><td>tanh</td><td>[256, 256]           </td><td style=\"text-align: right;\">              2000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00000</td><td>TERMINATED</td><td>172.28.0.2:40917</td><td style=\"text-align: right;\">   0.97</td><td style=\"text-align: right;\">0.0005</td><td>relu</td><td>[512, 512]           </td><td style=\"text-align: right;\">              6000</td><td style=\"text-align: right;\">   250</td><td style=\"text-align: right;\">         2959.57</td><td style=\"text-align: right;\">1500000</td><td style=\"text-align: right;\"> -83.894</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">                -9.4</td><td style=\"text-align: right;\">              -942.8</td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00001</td><td>TERMINATED</td><td>172.28.0.2:2114 </td><td style=\"text-align: right;\">   0.97</td><td style=\"text-align: right;\">0.0001</td><td>relu</td><td>[512, 512]           </td><td style=\"text-align: right;\">              6000</td><td style=\"text-align: right;\">   250</td><td style=\"text-align: right;\">         3003.97</td><td style=\"text-align: right;\">1500000</td><td style=\"text-align: right;\"> -66.647</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">               -11.4</td><td style=\"text-align: right;\">              -550.5</td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00002</td><td>TERMINATED</td><td>172.28.0.2:4024 </td><td style=\"text-align: right;\">   0.97</td><td style=\"text-align: right;\">0.0005</td><td>tanh</td><td>[512, 512]           </td><td style=\"text-align: right;\">              6000</td><td style=\"text-align: right;\">   250</td><td style=\"text-align: right;\">         2995.58</td><td style=\"text-align: right;\">1500000</td><td style=\"text-align: right;\"> -80.869</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">               -10.7</td><td style=\"text-align: right;\">              -611.8</td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00003</td><td>TERMINATED</td><td>172.28.0.2:6051 </td><td style=\"text-align: right;\">   0.97</td><td style=\"text-align: right;\">0.0001</td><td>tanh</td><td>[512, 512]           </td><td style=\"text-align: right;\">              6000</td><td style=\"text-align: right;\">   250</td><td style=\"text-align: right;\">         3001.87</td><td style=\"text-align: right;\">1500000</td><td style=\"text-align: right;\"> -61.795</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">               -11.3</td><td style=\"text-align: right;\">              -261.8</td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00004</td><td>TERMINATED</td><td>172.28.0.2:7948 </td><td style=\"text-align: right;\">   0.97</td><td style=\"text-align: right;\">0.0005</td><td>relu</td><td>[256, 256]           </td><td style=\"text-align: right;\">              6000</td><td style=\"text-align: right;\">   250</td><td style=\"text-align: right;\">         2978.82</td><td style=\"text-align: right;\">1500000</td><td style=\"text-align: right;\"> -65.735</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">               -10.9</td><td style=\"text-align: right;\">              -453.8</td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00005</td><td>TERMINATED</td><td>172.28.0.2:9835 </td><td style=\"text-align: right;\">   0.97</td><td style=\"text-align: right;\">0.0001</td><td>relu</td><td>[256, 256]           </td><td style=\"text-align: right;\">              6000</td><td style=\"text-align: right;\">   250</td><td style=\"text-align: right;\">         2931.14</td><td style=\"text-align: right;\">1500000</td><td style=\"text-align: right;\"> -55.252</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">               -10.2</td><td style=\"text-align: right;\">             -1057.7</td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00006</td><td>TERMINATED</td><td>172.28.0.2:11727</td><td style=\"text-align: right;\">   0.97</td><td style=\"text-align: right;\">0.0005</td><td>tanh</td><td>[256, 256]           </td><td style=\"text-align: right;\">              6000</td><td style=\"text-align: right;\">   250</td><td style=\"text-align: right;\">         2994.3 </td><td style=\"text-align: right;\">1500000</td><td style=\"text-align: right;\"> -49.97 </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">               -11.5</td><td style=\"text-align: right;\">              -179.2</td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00007</td><td>TERMINATED</td><td>172.28.0.2:13636</td><td style=\"text-align: right;\">   0.97</td><td style=\"text-align: right;\">0.0001</td><td>tanh</td><td>[256, 256]           </td><td style=\"text-align: right;\">              6000</td><td style=\"text-align: right;\">   250</td><td style=\"text-align: right;\">         2982.9 </td><td style=\"text-align: right;\">1500000</td><td style=\"text-align: right;\"> -36.572</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">               -11.8</td><td style=\"text-align: right;\">              -136.2</td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00008</td><td>TERMINATED</td><td>172.28.0.2:15530</td><td style=\"text-align: right;\">   0.97</td><td style=\"text-align: right;\">0.0005</td><td>relu</td><td>[512, 512]           </td><td style=\"text-align: right;\">              4000</td><td style=\"text-align: right;\">   374</td><td style=\"text-align: right;\">         3095.54</td><td style=\"text-align: right;\">1503480</td><td style=\"text-align: right;\"> -80.106</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">               -12.2</td><td style=\"text-align: right;\">              -666.7</td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00009</td><td>TERMINATED</td><td>172.28.0.2:17507</td><td style=\"text-align: right;\">   0.97</td><td style=\"text-align: right;\">0.0001</td><td>relu</td><td>[512, 512]           </td><td style=\"text-align: right;\">              4000</td><td style=\"text-align: right;\">   374</td><td style=\"text-align: right;\">         3083.63</td><td style=\"text-align: right;\">1503480</td><td style=\"text-align: right;\"> -36.164</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">               -10.7</td><td style=\"text-align: right;\">              -152.7</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPO pid=40917)\u001b[0m 2022-12-01 23:26:15,314\tINFO algorithm.py:2303 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPO pid=40917)\u001b[0m 2022-12-01 23:26:15,314\tWARNING ppo.py:351 -- `train_batch_size` (6000) cannot be achieved with your other settings (num_workers=30 num_envs_per_worker=2 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 100.\n",
      "\u001b[2m\u001b[36m(PPO pid=40917)\u001b[0m 2022-12-01 23:26:15,314\tINFO ppo.py:379 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(PPO pid=40917)\u001b[0m 2022-12-01 23:26:15,316\tINFO algorithm.py:457 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=40948)\u001b[0m 2022-12-01 23:26:26,201\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=40917)\u001b[0m 2022-12-01 23:26:33,721\tINFO trainable.py:164 -- Trainable.setup took 18.409 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(PPO pid=40917)\u001b[0m 2022-12-01 23:26:33,723\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>counters                                                                                                                                    </th><th>custom_metrics  </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th style=\"text-align: right;\">  episodes_total</th><th>experiment_id                   </th><th>hostname    </th><th>info                                                                                                                                                                                                                                                                                                                                                                                                                                                                          </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip   </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_recreated_workers</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                                           </th><th style=\"text-align: right;\">  pid</th><th>policy_reward_max  </th><th>policy_reward_mean  </th><th>policy_reward_min  </th><th>sampler_perf                                                                                                                                                                                                   </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th>timers                                                                                                                                                                                   </th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th style=\"text-align: right;\">  timesteps_total</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CybORG_886ac_00000</td><td style=\"text-align: right;\">                1500000</td><td>{&#x27;num_env_steps_sampled&#x27;: 1500000, &#x27;num_env_steps_trained&#x27;: 1500000, &#x27;num_agent_steps_sampled&#x27;: 1500000, &#x27;num_agent_steps_trained&#x27;: 1500000}</td><td>{}              </td><td>2022-12-02_00-16-05</td><td>True  </td><td style=\"text-align: right;\">               100</td><td>{}             </td><td style=\"text-align: right;\">                -9.4</td><td style=\"text-align: right;\">              -83.894</td><td style=\"text-align: right;\">              -942.8</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">           15000</td><td>b5e399f05eaf4fa3bf5cab998ee1c0c1</td><td>01589170c3ff</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;cur_kl_coeff&#x27;: 0.20000000298023224, &#x27;cur_lr&#x27;: 0.0005000000237487257, &#x27;total_loss&#x27;: 6.145261, &#x27;policy_loss&#x27;: -0.072524495, &#x27;vf_loss&#x27;: 6.214124, &#x27;vf_explained_var&#x27;: -0.4529026, &#x27;kl&#x27;: 0.018305715, &#x27;entropy&#x27;: 1.9857411, &#x27;entropy_coeff&#x27;: 0.0, &#x27;model&#x27;: {}}, &#x27;train&#x27;: None}}, &#x27;num_env_steps_sampled&#x27;: 1500000, &#x27;num_env_steps_trained&#x27;: 1500000, &#x27;num_agent_steps_sampled&#x27;: 1500000, &#x27;num_agent_steps_trained&#x27;: 1500000}   </td><td style=\"text-align: right;\">                       250</td><td>172.28.0.2</td><td style=\"text-align: right;\">                  1500000</td><td style=\"text-align: right;\">                  1500000</td><td style=\"text-align: right;\">                1500000</td><td style=\"text-align: right;\">                             6000</td><td style=\"text-align: right;\">                1500000</td><td style=\"text-align: right;\">                             6000</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                   30</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                         6000</td><td>{&#x27;cpu_util_percent&#x27;: 34.099999999999994, &#x27;ram_util_percent&#x27;: 63.2}             </td><td style=\"text-align: right;\">40917</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 3.824441979991765, &#x27;mean_inference_ms&#x27;: 2.0151192474298023, &#x27;mean_action_processing_ms&#x27;: 0.20327077246115244, &#x27;mean_env_wait_ms&#x27;: 23.244759228610484, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: -9.39999999999999, &#x27;episode_reward_min&#x27;: -942.8000000000012, &#x27;episode_reward_mean&#x27;: -83.89399999999996, &#x27;episode_len_mean&#x27;: 100.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 60, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-11.999999999999988, -93.2, -109.69999999999989, -112.79999999999986, -100.8, -81.59999999999981, -14.399999999999993, -13.399999999999988, -120.19999999999999, -102.69999999999969, -71.79999999999987, -108.9, -12.89999999999998, -11.399999999999993, -30.70000000000006, -15.099999999999984, -111.79999999999981, -12.89999999999998, -123.79999999999983, -12.099999999999987, -12.49999999999998, -11.699999999999983, -17.599999999999984, -99.7999999999999, -126.7999999999997, -80.69999999999999, -105.7, -165.29999999999995, -430.6, -29.800000000000107, -30.700000000000088, -105.4, -114.4, -30.40000000000005, -84.1, -98.6, -54.700000000000095, -40.80000000000005, -115.79999999999978, -165.9, -124.19999999999978, -104.79999999999984, -168.79999999999956, -123.79999999999978, -64.80000000000007, -20.700000000000017, -104.2, -121.69999999999975, -24.800000000000036, -144.2, -104.1, -14.799999999999986, -15.299999999999978, -45.79999999999999, -117.79999999999978, -104.40000000000005, -111.2, -135.9, -16.499999999999996, -13.79999999999999, -9.39999999999999, -13.799999999999994, -942.8000000000012, -111.2, -96.79999999999988, -155.29999999999998, -24.800000000000022, -84.10000000000001, -68.10000000000004, -105.79999999999986, -102.2, -93.7999999999999, -21.800000000000022, -101.2, -14.199999999999985, -99.4, -109.79999999999981, -12.799999999999983, -115.59999999999975, -13.499999999999975, -76.79999999999998, -19.8, -101.8, -55.80000000000006, -122.79999999999981, -22.20000000000005, -108.4, -15.999999999999984, -14.599999999999985, -76.69999999999996, -86.79999999999995, -14.299999999999992, -15.699999999999982, -96.9, -16.799999999999986, -100.69999999999986, -20.800000000000043, -101.79999999999987, -16.39999999999999, -132.79999999999978], &#x27;episode_lengths&#x27;: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 3.824441979991765, &#x27;mean_inference_ms&#x27;: 2.0151192474298023, &#x27;mean_action_processing_ms&#x27;: 0.20327077246115244, &#x27;mean_env_wait_ms&#x27;: 23.244759228610484, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}                                                                                                                                                                                                                                                                             </td><td style=\"text-align: right;\">             2959.57</td><td style=\"text-align: right;\">          11.799  </td><td style=\"text-align: right;\">       2959.57</td><td>{&#x27;training_iteration_time_ms&#x27;: 11794.659, &#x27;load_time_ms&#x27;: 2.856, &#x27;load_throughput&#x27;: 2100530.353, &#x27;learn_time_ms&#x27;: 8558.128, &#x27;learn_throughput&#x27;: 701.088, &#x27;synch_weights_time_ms&#x27;: 12.22} </td><td style=\"text-align: right;\"> 1669940165</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">          1500000</td><td style=\"text-align: right;\">                 250</td><td>886ac_00000</td><td style=\"text-align: right;\">      18.4293</td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00001</td><td style=\"text-align: right;\">                1500000</td><td>{&#x27;num_env_steps_sampled&#x27;: 1500000, &#x27;num_env_steps_trained&#x27;: 1500000, &#x27;num_agent_steps_sampled&#x27;: 1500000, &#x27;num_agent_steps_trained&#x27;: 1500000}</td><td>{}              </td><td>2022-12-02_01-06-51</td><td>True  </td><td style=\"text-align: right;\">               100</td><td>{}             </td><td style=\"text-align: right;\">               -11.4</td><td style=\"text-align: right;\">              -66.647</td><td style=\"text-align: right;\">              -550.5</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">           15000</td><td>440e92abfd344946842008ea29b0e9af</td><td>01589170c3ff</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;cur_kl_coeff&#x27;: 0.20000000298023224, &#x27;cur_lr&#x27;: 9.999999747378752e-05, &#x27;total_loss&#x27;: 6.248784, &#x27;policy_loss&#x27;: -0.05048617, &#x27;vf_loss&#x27;: 6.2960596, &#x27;vf_explained_var&#x27;: -0.2688931, &#x27;kl&#x27;: 0.016049987, &#x27;entropy&#x27;: 1.1900938, &#x27;entropy_coeff&#x27;: 0.0, &#x27;model&#x27;: {}}, &#x27;train&#x27;: None}}, &#x27;num_env_steps_sampled&#x27;: 1500000, &#x27;num_env_steps_trained&#x27;: 1500000, &#x27;num_agent_steps_sampled&#x27;: 1500000, &#x27;num_agent_steps_trained&#x27;: 1500000}   </td><td style=\"text-align: right;\">                       250</td><td>172.28.0.2</td><td style=\"text-align: right;\">                  1500000</td><td style=\"text-align: right;\">                  1500000</td><td style=\"text-align: right;\">                1500000</td><td style=\"text-align: right;\">                             6000</td><td style=\"text-align: right;\">                1500000</td><td style=\"text-align: right;\">                             6000</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                   30</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                         6000</td><td>{&#x27;cpu_util_percent&#x27;: 33.699999999999996, &#x27;ram_util_percent&#x27;: 63.2}             </td><td style=\"text-align: right;\"> 2114</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 3.9504583420140955, &#x27;mean_inference_ms&#x27;: 2.408198222572037, &#x27;mean_action_processing_ms&#x27;: 0.2074477807769207, &#x27;mean_env_wait_ms&#x27;: 25.51555596637362, &#x27;mean_env_render_ms&#x27;: 0.0}  </td><td>{&#x27;episode_reward_max&#x27;: -11.399999999999983, &#x27;episode_reward_min&#x27;: -550.5, &#x27;episode_reward_mean&#x27;: -66.647, &#x27;episode_len_mean&#x27;: 100.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 60, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-77.8, -23.599999999999994, -178.6999999999997, -17.300000000000004, -70.30000000000003, -50.8000000000001, -51.80000000000007, -69.5, -56.8000000000001, -84.4, -11.399999999999983, -17.7, -86.4, -58.5, -72.0, -58.4, -41.10000000000004, -30.200000000000053, -33.60000000000002, -22.900000000000013, -68.80000000000003, -42.800000000000075, -51.800000000000104, -69.5, -54.70000000000008, -65.7, -26.700000000000077, -46.70000000000009, -77.19999999999996, -13.999999999999975, -26.100000000000065, -86.79999999999991, -75.79999999999998, -11.899999999999984, -264.79999999999984, -85.79999999999994, -48.80000000000008, -59.30000000000006, -51.80000000000008, -542.2, -35.80000000000005, -148.39999999999995, -17.800000000000008, -26.100000000000072, -63.9, -63.4, -46.20000000000003, -52.40000000000001, -15.299999999999985, -43.40000000000003, -47.80000000000008, -44.80000000000009, -36.10000000000005, -95.79999999999994, -71.9, -13.199999999999983, -85.79999999999995, -70.80000000000001, -52.8000000000001, -48.800000000000075, -56.80000000000008, -69.20000000000006, -11.799999999999992, -109.60000000000002, -15.699999999999976, -15.399999999999977, -227.00000000000003, -24.100000000000044, -26.200000000000063, -38.400000000000084, -85.69999999999995, -45.800000000000075, -93.69999999999987, -53.500000000000085, -13.799999999999981, -71.8, -11.499999999999982, -54.80000000000008, -65.5, -133.79999999999976, -53.80000000000009, -51.70000000000009, -168.39999999999998, -550.5, -51.800000000000075, -66.5, -17.499999999999986, -66.4, -83.69999999999997, -27.900000000000098, -34.600000000000065, -66.4, -19.80000000000002, -24.400000000000027, -18.499999999999993, -56.70000000000009, -15.899999999999977, -21.700000000000006, -30.700000000000045, -48.800000000000104], &#x27;episode_lengths&#x27;: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 3.9504583420140955, &#x27;mean_inference_ms&#x27;: 2.408198222572037, &#x27;mean_action_processing_ms&#x27;: 0.2074477807769207, &#x27;mean_env_wait_ms&#x27;: 25.51555596637362, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}                                                                                                                                                                                                                                                                                     </td><td style=\"text-align: right;\">             3003.97</td><td style=\"text-align: right;\">          11.9684 </td><td style=\"text-align: right;\">       3003.97</td><td>{&#x27;training_iteration_time_ms&#x27;: 11988.926, &#x27;load_time_ms&#x27;: 2.598, &#x27;load_throughput&#x27;: 2309448.008, &#x27;learn_time_ms&#x27;: 8211.345, &#x27;learn_throughput&#x27;: 730.696, &#x27;synch_weights_time_ms&#x27;: 11.969}</td><td style=\"text-align: right;\"> 1669943211</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">          1500000</td><td style=\"text-align: right;\">                 250</td><td>886ac_00001</td><td style=\"text-align: right;\">      20.2123</td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00002</td><td style=\"text-align: right;\">                1500000</td><td>{&#x27;num_env_steps_sampled&#x27;: 1500000, &#x27;num_env_steps_trained&#x27;: 1500000, &#x27;num_agent_steps_sampled&#x27;: 1500000, &#x27;num_agent_steps_trained&#x27;: 1500000}</td><td>{}              </td><td>2022-12-02_01-57-30</td><td>True  </td><td style=\"text-align: right;\">               100</td><td>{}             </td><td style=\"text-align: right;\">               -10.7</td><td style=\"text-align: right;\">              -80.869</td><td style=\"text-align: right;\">              -611.8</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">           15000</td><td>a5c2b14e81364c64aeafb5216f836c0f</td><td>01589170c3ff</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;cur_kl_coeff&#x27;: 0.20000000298023224, &#x27;cur_lr&#x27;: 0.0005000000237487257, &#x27;total_loss&#x27;: 6.806364, &#x27;policy_loss&#x27;: -0.06868108, &#x27;vf_loss&#x27;: 6.8607855, &#x27;vf_explained_var&#x27;: -0.24313569, &#x27;kl&#x27;: 0.07129704, &#x27;entropy&#x27;: 1.7946182, &#x27;entropy_coeff&#x27;: 0.0, &#x27;model&#x27;: {}}, &#x27;train&#x27;: None}}, &#x27;num_env_steps_sampled&#x27;: 1500000, &#x27;num_env_steps_trained&#x27;: 1500000, &#x27;num_agent_steps_sampled&#x27;: 1500000, &#x27;num_agent_steps_trained&#x27;: 1500000}   </td><td style=\"text-align: right;\">                       250</td><td>172.28.0.2</td><td style=\"text-align: right;\">                  1500000</td><td style=\"text-align: right;\">                  1500000</td><td style=\"text-align: right;\">                1500000</td><td style=\"text-align: right;\">                             6000</td><td style=\"text-align: right;\">                1500000</td><td style=\"text-align: right;\">                             6000</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                   30</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                         6000</td><td>{&#x27;cpu_util_percent&#x27;: 33.73529411764706, &#x27;ram_util_percent&#x27;: 63.2}              </td><td style=\"text-align: right;\"> 4024</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 4.135767056278162, &#x27;mean_inference_ms&#x27;: 2.6593114237437656, &#x27;mean_action_processing_ms&#x27;: 0.21091466330576647, &#x27;mean_env_wait_ms&#x27;: 26.55626631762311, &#x27;mean_env_render_ms&#x27;: 0.0} </td><td>{&#x27;episode_reward_max&#x27;: -10.699999999999983, &#x27;episode_reward_min&#x27;: -611.8000000000012, &#x27;episode_reward_mean&#x27;: -80.86899999999993, &#x27;episode_len_mean&#x27;: 100.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 60, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-84.69999999999996, -135.7999999999997, -140.79999999999964, -111.79999999999987, -29.600000000000072, -98.7999999999999, -147.79999999999976, -85.69999999999999, -54.800000000000075, -110.69999999999987, -22.800000000000022, -611.8000000000012, -14.599999999999977, -101.7999999999999, -98.79999999999991, -20.7, -15.19999999999998, -16.099999999999973, -92.7999999999999, -19.40000000000002, -120.79999999999984, -15.799999999999972, -47.70000000000003, -107.79999999999991, -18.199999999999996, -49.7000000000001, -154.79999999999973, -73.80000000000004, -43.700000000000045, -21.40000000000001, -27.600000000000076, -19.099999999999998, -45.70000000000008, -159.79999999999973, -35.70000000000008, -22.700000000000003, -15.799999999999978, -28.99999999999999, -26.800000000000054, -29.40000000000009, -151.69999999999973, -23.700000000000056, -96.79999999999984, -151.69999999999976, -92.7999999999999, -104.79999999999983, -13.799999999999978, -62.80000000000008, -139.6999999999998, -151.79999999999976, -12.699999999999978, -130.7999999999998, -150.69999999999976, -135.79999999999978, -16.499999999999982, -27.70000000000006, -20.800000000000026, -128.69999999999982, -144.79999999999976, -19.39999999999999, -158.69999999999973, -151.79999999999976, -66.80000000000007, -199.79999999999964, -143.79999999999978, -12.499999999999982, -113.69999999999986, -30.80000000000006, -14.899999999999977, -121.69999999999985, -131.7999999999998, -26.800000000000043, -106.69999999999985, -156.69999999999973, -33.3, -16.599999999999984, -17.800000000000004, -15.799999999999974, -41.700000000000074, -119.79999999999977, -189.69999999999965, -148.69999999999976, -15.29999999999998, -150.79999999999976, -156.69999999999965, -151.79999999999973, -15.699999999999982, -17.19999999999999, -47.10000000000003, -15.299999999999974, -136.79999999999978, -72.80000000000004, -38.800000000000054, -113.69999999999989, -26.30000000000006, -62.80000000000006, -13.799999999999976, -15.299999999999976, -148.79999999999976, -10.699999999999983], &#x27;episode_lengths&#x27;: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 4.135767056278162, &#x27;mean_inference_ms&#x27;: 2.6593114237437656, &#x27;mean_action_processing_ms&#x27;: 0.21091466330576647, &#x27;mean_env_wait_ms&#x27;: 26.55626631762311, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}</td><td style=\"text-align: right;\">             2995.58</td><td style=\"text-align: right;\">          11.9138 </td><td style=\"text-align: right;\">       2995.58</td><td>{&#x27;training_iteration_time_ms&#x27;: 11934.252, &#x27;load_time_ms&#x27;: 2.513, &#x27;load_throughput&#x27;: 2387309.586, &#x27;learn_time_ms&#x27;: 8098.66, &#x27;learn_throughput&#x27;: 740.863, &#x27;synch_weights_time_ms&#x27;: 11.788} </td><td style=\"text-align: right;\"> 1669946250</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">          1500000</td><td style=\"text-align: right;\">                 250</td><td>886ac_00002</td><td style=\"text-align: right;\">      20.5774</td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00003</td><td style=\"text-align: right;\">                1500000</td><td>{&#x27;num_env_steps_sampled&#x27;: 1500000, &#x27;num_env_steps_trained&#x27;: 1500000, &#x27;num_agent_steps_sampled&#x27;: 1500000, &#x27;num_agent_steps_trained&#x27;: 1500000}</td><td>{}              </td><td>2022-12-02_02-48-18</td><td>True  </td><td style=\"text-align: right;\">               100</td><td>{}             </td><td style=\"text-align: right;\">               -11.3</td><td style=\"text-align: right;\">              -61.795</td><td style=\"text-align: right;\">              -261.8</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">           15000</td><td>a9b5f2e36e1f4eefaa726c33c4231316</td><td>01589170c3ff</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;cur_kl_coeff&#x27;: 0.20000000298023224, &#x27;cur_lr&#x27;: 9.999999747378752e-05, &#x27;total_loss&#x27;: 7.1972218, &#x27;policy_loss&#x27;: -0.07955466, &#x27;vf_loss&#x27;: 7.2709723, &#x27;vf_explained_var&#x27;: -0.29602626, &#x27;kl&#x27;: 0.029018858, &#x27;entropy&#x27;: 1.4417502, &#x27;entropy_coeff&#x27;: 0.0, &#x27;model&#x27;: {}}, &#x27;train&#x27;: None}}, &#x27;num_env_steps_sampled&#x27;: 1500000, &#x27;num_env_steps_trained&#x27;: 1500000, &#x27;num_agent_steps_sampled&#x27;: 1500000, &#x27;num_agent_steps_trained&#x27;: 1500000} </td><td style=\"text-align: right;\">                       250</td><td>172.28.0.2</td><td style=\"text-align: right;\">                  1500000</td><td style=\"text-align: right;\">                  1500000</td><td style=\"text-align: right;\">                1500000</td><td style=\"text-align: right;\">                             6000</td><td style=\"text-align: right;\">                1500000</td><td style=\"text-align: right;\">                             6000</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                   30</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                         6000</td><td>{&#x27;cpu_util_percent&#x27;: 34.7, &#x27;ram_util_percent&#x27;: 63.2}                           </td><td style=\"text-align: right;\"> 6051</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 3.995877067955918, &#x27;mean_inference_ms&#x27;: 2.4634520482085933, &#x27;mean_action_processing_ms&#x27;: 0.2071228713915775, &#x27;mean_env_wait_ms&#x27;: 25.688145526324792, &#x27;mean_env_render_ms&#x27;: 0.0} </td><td>{&#x27;episode_reward_max&#x27;: -11.29999999999998, &#x27;episode_reward_min&#x27;: -261.79999999999995, &#x27;episode_reward_mean&#x27;: -61.795, &#x27;episode_len_mean&#x27;: 100.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 60, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-72.69999999999989, -12.699999999999978, -69.6, -87.79999999999991, -16.59999999999998, -27.80000000000002, -80.19999999999999, -101.79999999999984, -44.40000000000008, -21.300000000000054, -79.59999999999995, -48.80000000000006, -165.4, -45.8, -100.79999999999987, -86.39999999999993, -69.2, -19.69999999999998, -32.80000000000003, -83.79999999999995, -22.700000000000045, -53.00000000000004, -43.8000000000001, -57.900000000000034, -38.800000000000104, -22.200000000000035, -261.79999999999995, -43.20000000000002, -43.300000000000054, -58.80000000000001, -26.800000000000036, -65.8, -24.800000000000008, -72.80000000000001, -63.699999999999996, -55.800000000000104, -48.60000000000007, -27.30000000000006, -38.80000000000009, -40.700000000000095, -52.30000000000006, -54.00000000000008, -51.20000000000004, -73.8, -34.8000000000001, -90.09999999999997, -79.79999999999997, -42.8000000000001, -47.60000000000007, -89.79999999999993, -31.20000000000003, -13.699999999999987, -85.69999999999985, -85.59999999999992, -174.8, -89.79999999999993, -66.1, -102.79999999999986, -40.10000000000002, -94.69999999999989, -83.69999999999987, -62.80000000000007, -73.79999999999998, -27.80000000000006, -63.800000000000104, -20.50000000000002, -52.50000000000009, -22.700000000000024, -47.800000000000026, -103.79999999999986, -98.79999999999987, -29.400000000000045, -63.70000000000004, -95.49999999999989, -106.79999999999988, -40.90000000000007, -79.79999999999997, -90.79999999999984, -16.69999999999999, -91.7, -29.700000000000053, -26.80000000000009, -75.79999999999997, -11.29999999999998, -30.800000000000054, -92.5, -24.70000000000002, -191.6999999999997, -13.499999999999979, -35.20000000000008, -20.499999999999986, -47.80000000000008, -89.59999999999987, -36.700000000000045, -42.400000000000055, -64.80000000000004, -45.800000000000054, -80.79999999999997, -80.69999999999999, -86.59999999999997], &#x27;episode_lengths&#x27;: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 3.995877067955918, &#x27;mean_inference_ms&#x27;: 2.4634520482085933, &#x27;mean_action_processing_ms&#x27;: 0.2071228713915775, &#x27;mean_env_wait_ms&#x27;: 25.688145526324792, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}                                                                                                                                                  </td><td style=\"text-align: right;\">             3001.87</td><td style=\"text-align: right;\">          12.2069 </td><td style=\"text-align: right;\">       3001.87</td><td>{&#x27;training_iteration_time_ms&#x27;: 11925.422, &#x27;load_time_ms&#x27;: 2.469, &#x27;load_throughput&#x27;: 2430189.175, &#x27;learn_time_ms&#x27;: 8187.825, &#x27;learn_throughput&#x27;: 732.795, &#x27;synch_weights_time_ms&#x27;: 11.458}</td><td style=\"text-align: right;\"> 1669949298</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">          1500000</td><td style=\"text-align: right;\">                 250</td><td>886ac_00003</td><td style=\"text-align: right;\">      20.7607</td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00004</td><td style=\"text-align: right;\">                1500000</td><td>{&#x27;num_env_steps_sampled&#x27;: 1500000, &#x27;num_env_steps_trained&#x27;: 1500000, &#x27;num_agent_steps_sampled&#x27;: 1500000, &#x27;num_agent_steps_trained&#x27;: 1500000}</td><td>{}              </td><td>2022-12-02_03-38-43</td><td>True  </td><td style=\"text-align: right;\">               100</td><td>{}             </td><td style=\"text-align: right;\">               -10.9</td><td style=\"text-align: right;\">              -65.735</td><td style=\"text-align: right;\">              -453.8</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">           15000</td><td>a9d13f17000b4d70b14ee27efbcda4c6</td><td>01589170c3ff</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;cur_kl_coeff&#x27;: 0.20000000298023224, &#x27;cur_lr&#x27;: 0.0005000000237487257, &#x27;total_loss&#x27;: 6.241515, &#x27;policy_loss&#x27;: -0.07851871, &#x27;vf_loss&#x27;: 6.3156433, &#x27;vf_explained_var&#x27;: -0.2444029, &#x27;kl&#x27;: 0.021952588, &#x27;entropy&#x27;: 1.7150981, &#x27;entropy_coeff&#x27;: 0.0, &#x27;model&#x27;: {}}, &#x27;train&#x27;: None}}, &#x27;num_env_steps_sampled&#x27;: 1500000, &#x27;num_env_steps_trained&#x27;: 1500000, &#x27;num_agent_steps_sampled&#x27;: 1500000, &#x27;num_agent_steps_trained&#x27;: 1500000}   </td><td style=\"text-align: right;\">                       250</td><td>172.28.0.2</td><td style=\"text-align: right;\">                  1500000</td><td style=\"text-align: right;\">                  1500000</td><td style=\"text-align: right;\">                1500000</td><td style=\"text-align: right;\">                             6000</td><td style=\"text-align: right;\">                1500000</td><td style=\"text-align: right;\">                             6000</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                   30</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                         6000</td><td>{&#x27;cpu_util_percent&#x27;: 33.588235294117645, &#x27;ram_util_percent&#x27;: 62.7}             </td><td style=\"text-align: right;\"> 7948</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 4.030609045823706, &#x27;mean_inference_ms&#x27;: 2.3634809240038535, &#x27;mean_action_processing_ms&#x27;: 0.20744841959197555, &#x27;mean_env_wait_ms&#x27;: 25.890381856778816, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: -10.89999999999998, &#x27;episode_reward_min&#x27;: -453.8000000000014, &#x27;episode_reward_mean&#x27;: -65.73499999999999, &#x27;episode_len_mean&#x27;: 100.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 60, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-13.299999999999997, -18.89999999999998, -14.299999999999976, -17.6, -32.200000000000024, -78.50000000000001, -24.300000000000065, -182.7, -17.299999999999997, -32.700000000000024, -70.0, -22.000000000000018, -86.5, -138.09999999999994, -36.40000000000005, -16.499999999999993, -64.7000000000001, -20.099999999999998, -14.99999999999999, -91.3, -18.9, -23.000000000000032, -175.8, -87.6, -14.899999999999991, -16.599999999999987, -11.29999999999998, -66.80000000000004, -103.29999999999981, -91.89999999999995, -15.499999999999986, -92.79999999999991, -16.599999999999987, -14.899999999999988, -76.89999999999999, -79.79999999999997, -85.10000000000005, -34.00000000000002, -141.7999999999996, -53.10000000000003, -71.80000000000001, -79.5, -33.699999999999996, -14.499999999999986, -15.099999999999978, -16.49999999999999, -16.799999999999997, -36.800000000000075, -24.200000000000035, -54.400000000000055, -15.499999999999979, -74.9, -40.100000000000044, -49.80000000000004, -13.499999999999984, -15.399999999999991, -78.5, -16.29999999999998, -57.80000000000006, -170.79999999999956, -17.99999999999999, -112.7999999999998, -64.3, -69.39999999999993, -118.6, -66.80000000000001, -212.79999999999953, -108.09999999999991, -144.69999999999956, -87.6, -15.799999999999981, -71.3, -85.70000000000002, -14.099999999999985, -11.099999999999989, -182.1, -49.2, -56.80000000000009, -165.79999999999973, -453.8000000000014, -93.50000000000006, -10.89999999999998, -59.800000000000054, -41.60000000000003, -84.2, -58.10000000000008, -16.099999999999998, -15.099999999999993, -113.7999999999998, -257.2, -11.399999999999999, -17.299999999999997, -55.30000000000004, -64.00000000000004, -102.80000000000004, -21.700000000000017, -17.999999999999993, -177.39999999999992, -50.200000000000074, -87.40000000000003], &#x27;episode_lengths&#x27;: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 4.030609045823706, &#x27;mean_inference_ms&#x27;: 2.3634809240038535, &#x27;mean_action_processing_ms&#x27;: 0.20744841959197555, &#x27;mean_env_wait_ms&#x27;: 25.890381856778816, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}                                                                                                                                                                                                                                       </td><td style=\"text-align: right;\">             2978.82</td><td style=\"text-align: right;\">          11.7715 </td><td style=\"text-align: right;\">       2978.82</td><td>{&#x27;training_iteration_time_ms&#x27;: 11791.172, &#x27;load_time_ms&#x27;: 2.531, &#x27;load_throughput&#x27;: 2370846.468, &#x27;learn_time_ms&#x27;: 8137.312, &#x27;learn_throughput&#x27;: 737.344, &#x27;synch_weights_time_ms&#x27;: 10.627}</td><td style=\"text-align: right;\"> 1669952323</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">          1500000</td><td style=\"text-align: right;\">                 250</td><td>886ac_00004</td><td style=\"text-align: right;\">      20.3596</td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00005</td><td style=\"text-align: right;\">                1500000</td><td>{&#x27;num_env_steps_sampled&#x27;: 1500000, &#x27;num_env_steps_trained&#x27;: 1500000, &#x27;num_agent_steps_sampled&#x27;: 1500000, &#x27;num_agent_steps_trained&#x27;: 1500000}</td><td>{}              </td><td>2022-12-02_04-28-22</td><td>True  </td><td style=\"text-align: right;\">               100</td><td>{}             </td><td style=\"text-align: right;\">               -10.2</td><td style=\"text-align: right;\">              -55.252</td><td style=\"text-align: right;\">             -1057.7</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">           15000</td><td>01c77bf9068a42d4b793710beb2af29b</td><td>01589170c3ff</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;cur_kl_coeff&#x27;: 0.20000000298023224, &#x27;cur_lr&#x27;: 9.999999747378752e-05, &#x27;total_loss&#x27;: 5.3005557, &#x27;policy_loss&#x27;: -0.02554541, &#x27;vf_loss&#x27;: 5.323387, &#x27;vf_explained_var&#x27;: -0.054122113, &#x27;kl&#x27;: 0.013567673, &#x27;entropy&#x27;: 0.983912, &#x27;entropy_coeff&#x27;: 0.0, &#x27;model&#x27;: {}}, &#x27;train&#x27;: None}}, &#x27;num_env_steps_sampled&#x27;: 1500000, &#x27;num_env_steps_trained&#x27;: 1500000, &#x27;num_agent_steps_sampled&#x27;: 1500000, &#x27;num_agent_steps_trained&#x27;: 1500000}  </td><td style=\"text-align: right;\">                       250</td><td>172.28.0.2</td><td style=\"text-align: right;\">                  1500000</td><td style=\"text-align: right;\">                  1500000</td><td style=\"text-align: right;\">                1500000</td><td style=\"text-align: right;\">                             6000</td><td style=\"text-align: right;\">                1500000</td><td style=\"text-align: right;\">                             6000</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                   30</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                         6000</td><td>{&#x27;cpu_util_percent&#x27;: 34.4375, &#x27;ram_util_percent&#x27;: 62.5}                        </td><td style=\"text-align: right;\"> 9835</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 3.8870410405586036, &#x27;mean_inference_ms&#x27;: 2.1733209641363285, &#x27;mean_action_processing_ms&#x27;: 0.20771393521309578, &#x27;mean_env_wait_ms&#x27;: 24.73891529200294, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: -10.199999999999998, &#x27;episode_reward_min&#x27;: -1057.7000000000007, &#x27;episode_reward_mean&#x27;: -55.25200000000001, &#x27;episode_len_mean&#x27;: 100.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 60, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-49.800000000000004, -83.80000000000001, -52.2, -149.89999999999984, -18.899999999999984, -79.4, -41.50000000000001, -51.400000000000006, -89.6, -50.7, -55.500000000000014, -10.399999999999979, -60.5, -56.10000000000001, -50.8, -47.7, -48.3, -13.599999999999978, -50.00000000000001, -20.90000000000003, -12.799999999999988, -10.199999999999998, -15.199999999999987, -1057.7000000000007, -68.89999999999999, -45.30000000000001, -15.499999999999984, -49.40000000000004, -43.5, -87.0, -46.80000000000001, -51.00000000000001, -13.599999999999982, -13.099999999999982, -54.3, -13.799999999999981, -49.90000000000003, -26.900000000000034, -13.69999999999998, -50.40000000000002, -20.80000000000002, -51.00000000000001, -84.2, -51.7, -58.6, -13.699999999999985, -141.3, -90.3, -16.399999999999984, -35.70000000000009, -10.499999999999982, -52.70000000000002, -49.90000000000004, -38.800000000000004, -49.900000000000006, -55.7, -97.7, -18.70000000000001, -57.900000000000006, -56.800000000000004, -12.399999999999988, -12.699999999999985, -52.00000000000002, -16.09999999999998, -176.4, -55.10000000000001, -13.699999999999985, -14.099999999999989, -17.299999999999994, -61.80000000000001, -20.80000000000005, -55.6, -15.399999999999974, -13.699999999999989, -60.2, -91.8, -50.800000000000075, -10.999999999999986, -43.8, -53.4, -50.300000000000026, -14.799999999999983, -67.3, -92.2, -11.099999999999977, -12.499999999999991, -57.7, -15.299999999999986, -56.40000000000006, -55.5, -17.20000000000001, -15.99999999999998, -14.39999999999999, -13.299999999999974, -50.900000000000006, -14.599999999999984, -53.50000000000001, -166.2, -12.999999999999977, -12.599999999999985], &#x27;episode_lengths&#x27;: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 3.8870410405586036, &#x27;mean_inference_ms&#x27;: 2.1733209641363285, &#x27;mean_action_processing_ms&#x27;: 0.20771393521309578, &#x27;mean_env_wait_ms&#x27;: 24.73891529200294, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}                                                                                                                                                                                                                                                                                                                                                                            </td><td style=\"text-align: right;\">             2931.14</td><td style=\"text-align: right;\">          11.3208 </td><td style=\"text-align: right;\">       2931.14</td><td>{&#x27;training_iteration_time_ms&#x27;: 11682.761, &#x27;load_time_ms&#x27;: 2.612, &#x27;load_throughput&#x27;: 2297220.787, &#x27;learn_time_ms&#x27;: 8152.034, &#x27;learn_throughput&#x27;: 736.013, &#x27;synch_weights_time_ms&#x27;: 10.749}</td><td style=\"text-align: right;\"> 1669955302</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">          1500000</td><td style=\"text-align: right;\">                 250</td><td>886ac_00005</td><td style=\"text-align: right;\">      20.2023</td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00006</td><td style=\"text-align: right;\">                1500000</td><td>{&#x27;num_env_steps_sampled&#x27;: 1500000, &#x27;num_env_steps_trained&#x27;: 1500000, &#x27;num_agent_steps_sampled&#x27;: 1500000, &#x27;num_agent_steps_trained&#x27;: 1500000}</td><td>{}              </td><td>2022-12-02_05-19-05</td><td>True  </td><td style=\"text-align: right;\">               100</td><td>{}             </td><td style=\"text-align: right;\">               -11.5</td><td style=\"text-align: right;\">              -49.97 </td><td style=\"text-align: right;\">              -179.2</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">           15000</td><td>a76fc66a878f47999882824515549a17</td><td>01589170c3ff</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;cur_kl_coeff&#x27;: 0.20000000298023224, &#x27;cur_lr&#x27;: 0.0005000000237487257, &#x27;total_loss&#x27;: 6.181749, &#x27;policy_loss&#x27;: -0.08044623, &#x27;vf_loss&#x27;: 6.251637, &#x27;vf_explained_var&#x27;: -0.2760126, &#x27;kl&#x27;: 0.052795332, &#x27;entropy&#x27;: 1.1086559, &#x27;entropy_coeff&#x27;: 0.0, &#x27;model&#x27;: {}}, &#x27;train&#x27;: None}}, &#x27;num_env_steps_sampled&#x27;: 1500000, &#x27;num_env_steps_trained&#x27;: 1500000, &#x27;num_agent_steps_sampled&#x27;: 1500000, &#x27;num_agent_steps_trained&#x27;: 1500000}    </td><td style=\"text-align: right;\">                       250</td><td>172.28.0.2</td><td style=\"text-align: right;\">                  1500000</td><td style=\"text-align: right;\">                  1500000</td><td style=\"text-align: right;\">                1500000</td><td style=\"text-align: right;\">                             6000</td><td style=\"text-align: right;\">                1500000</td><td style=\"text-align: right;\">                             6000</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                   30</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                         6000</td><td>{&#x27;cpu_util_percent&#x27;: 32.68333333333333, &#x27;ram_util_percent&#x27;: 62.5}              </td><td style=\"text-align: right;\">11727</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 3.934890117597671, &#x27;mean_inference_ms&#x27;: 2.273445959967289, &#x27;mean_action_processing_ms&#x27;: 0.206069127032127, &#x27;mean_env_wait_ms&#x27;: 25.372305573262896, &#x27;mean_env_render_ms&#x27;: 0.0}   </td><td>{&#x27;episode_reward_max&#x27;: -11.499999999999998, &#x27;episode_reward_min&#x27;: -179.2, &#x27;episode_reward_mean&#x27;: -49.970000000000006, &#x27;episode_len_mean&#x27;: 100.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 60, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-31.20000000000003, -41.000000000000036, -12.299999999999994, -33.00000000000003, -45.60000000000008, -32.40000000000002, -12.899999999999993, -19.500000000000014, -14.69999999999998, -36.90000000000003, -28.100000000000044, -18.50000000000001, -20.70000000000002, -11.799999999999988, -26.200000000000024, -15.499999999999991, -106.30000000000004, -53.70000000000008, -101.7999999999999, -17.999999999999993, -166.8, -21.30000000000002, -73.69999999999985, -52.70000000000007, -15.099999999999984, -12.899999999999991, -16.59999999999998, -19.099999999999987, -58.40000000000006, -13.599999999999982, -56.10000000000007, -20.700000000000003, -15.799999999999994, -24.700000000000014, -18.0, -103.7999999999998, -15.099999999999987, -85.8, -12.599999999999996, -77.69999999999996, -175.29999999999984, -21.700000000000045, -18.099999999999994, -15.89999999999998, -70.20000000000002, -43.300000000000075, -20.200000000000003, -15.29999999999999, -55.5, -16.39999999999999, -20.199999999999992, -146.1, -72.40000000000005, -69.79999999999991, -92.00000000000003, -71.50000000000007, -19.099999999999994, -47.70000000000005, -76.79999999999998, -78.39999999999998, -17.8, -66.9, -40.20000000000007, -53.10000000000003, -30.000000000000018, -63.5, -17.89999999999999, -46.80000000000007, -34.80000000000001, -22.5, -18.399999999999995, -32.10000000000008, -58.50000000000008, -78.5, -67.50000000000004, -40.90000000000007, -132.29999999999973, -47.80000000000005, -17.399999999999988, -24.100000000000033, -179.2, -11.499999999999998, -129.3, -21.900000000000002, -21.80000000000002, -79.79999999999993, -14.599999999999984, -119.90000000000002, -28.90000000000005, -74.3, -159.3, -70.60000000000002, -29.700000000000056, -22.20000000000003, -55.80000000000003, -57.10000000000005, -141.29999999999993, -24.00000000000003, -54.6, -83.69999999999999], &#x27;episode_lengths&#x27;: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 3.934890117597671, &#x27;mean_inference_ms&#x27;: 2.273445959967289, &#x27;mean_action_processing_ms&#x27;: 0.206069127032127, &#x27;mean_env_wait_ms&#x27;: 25.372305573262896, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}                                                                                                                                                                                                        </td><td style=\"text-align: right;\">             2994.3 </td><td style=\"text-align: right;\">          12.0946 </td><td style=\"text-align: right;\">       2994.3 </td><td>{&#x27;training_iteration_time_ms&#x27;: 11928.556, &#x27;load_time_ms&#x27;: 2.457, &#x27;load_throughput&#x27;: 2442382.81, &#x27;learn_time_ms&#x27;: 8236.202, &#x27;learn_throughput&#x27;: 728.491, &#x27;synch_weights_time_ms&#x27;: 10.801} </td><td style=\"text-align: right;\"> 1669958345</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">          1500000</td><td style=\"text-align: right;\">                 250</td><td>886ac_00006</td><td style=\"text-align: right;\">      20.2301</td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00007</td><td style=\"text-align: right;\">                1500000</td><td>{&#x27;num_env_steps_sampled&#x27;: 1500000, &#x27;num_env_steps_trained&#x27;: 1500000, &#x27;num_agent_steps_sampled&#x27;: 1500000, &#x27;num_agent_steps_trained&#x27;: 1500000}</td><td>{}              </td><td>2022-12-02_06-09-38</td><td>True  </td><td style=\"text-align: right;\">               100</td><td>{}             </td><td style=\"text-align: right;\">               -11.8</td><td style=\"text-align: right;\">              -36.572</td><td style=\"text-align: right;\">              -136.2</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">           15000</td><td>312e2e77ae164fd5b3fbb3bbd3c3fc92</td><td>01589170c3ff</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;cur_kl_coeff&#x27;: 0.20000000298023224, &#x27;cur_lr&#x27;: 9.999999747378752e-05, &#x27;total_loss&#x27;: 5.6769614, &#x27;policy_loss&#x27;: -0.061928403, &#x27;vf_loss&#x27;: 5.734837, &#x27;vf_explained_var&#x27;: -0.112468086, &#x27;kl&#x27;: 0.020263676, &#x27;entropy&#x27;: 1.2967395, &#x27;entropy_coeff&#x27;: 0.0, &#x27;model&#x27;: {}}, &#x27;train&#x27;: None}}, &#x27;num_env_steps_sampled&#x27;: 1500000, &#x27;num_env_steps_trained&#x27;: 1500000, &#x27;num_agent_steps_sampled&#x27;: 1500000, &#x27;num_agent_steps_trained&#x27;: 1500000}</td><td style=\"text-align: right;\">                       250</td><td>172.28.0.2</td><td style=\"text-align: right;\">                  1500000</td><td style=\"text-align: right;\">                  1500000</td><td style=\"text-align: right;\">                1500000</td><td style=\"text-align: right;\">                             6000</td><td style=\"text-align: right;\">                1500000</td><td style=\"text-align: right;\">                             6000</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                   30</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                         6000</td><td>{&#x27;cpu_util_percent&#x27;: 34.40555555555556, &#x27;ram_util_percent&#x27;: 62.599999999999994}</td><td style=\"text-align: right;\">13636</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 3.9401970875383334, &#x27;mean_inference_ms&#x27;: 2.252839083287414, &#x27;mean_action_processing_ms&#x27;: 0.20564141877335765, &#x27;mean_env_wait_ms&#x27;: 25.371932567556676, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: -11.799999999999974, &#x27;episode_reward_min&#x27;: -136.2, &#x27;episode_reward_mean&#x27;: -36.572000000000024, &#x27;episode_len_mean&#x27;: 100.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 60, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-13.799999999999978, -29.600000000000072, -30.700000000000063, -20.699999999999996, -38.70000000000009, -16.69999999999998, -38.19999999999999, -15.799999999999974, -12.699999999999978, -80.39999999999996, -40.60000000000005, -49.80000000000009, -23.800000000000008, -27.700000000000045, -26.7, -13.799999999999981, -57.70000000000008, -78.79999999999997, -55.50000000000006, -50.80000000000009, -27.700000000000063, -24.80000000000003, -20.8, -68.80000000000005, -21.6, -96.7999999999997, -37.800000000000026, -52.800000000000075, -25.800000000000075, -69.80000000000004, -22.800000000000022, -20.80000000000001, -17.699999999999992, -42.80000000000005, -14.799999999999972, -15.599999999999975, -99.79999999999978, -24.800000000000058, -23.000000000000007, -30.7000000000001, -32.500000000000085, -23.700000000000053, -49.500000000000085, -53.80000000000008, -33.70000000000009, -63.4, -23.50000000000004, -19.10000000000003, -26.800000000000043, -11.799999999999974, -27.100000000000044, -75.6, -19.499999999999996, -25.800000000000022, -81.69999999999997, -20.70000000000002, -33.70000000000002, -22.20000000000005, -22.800000000000026, -15.799999999999974, -33.70000000000005, -24.40000000000003, -22.900000000000013, -79.8, -22.300000000000033, -23.80000000000004, -52.80000000000008, -21.300000000000026, -63.8000000000001, -22.70000000000002, -15.699999999999978, -15.799999999999972, -136.2, -25.80000000000005, -20.500000000000025, -90.79999999999993, -83.70000000000002, -19.800000000000008, -22.100000000000026, -18.80000000000001, -66.80000000000005, -25.80000000000003, -39.50000000000006, -19.800000000000022, -54.60000000000009, -20.80000000000001, -43.500000000000064, -23.50000000000005, -13.799999999999981, -115.69999999999978, -15.399999999999975, -26.800000000000065, -14.799999999999978, -29.700000000000028, -34.700000000000024, -18.800000000000004, -22.500000000000014, -24.800000000000047, -29.700000000000102, -34.800000000000075], &#x27;episode_lengths&#x27;: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 3.9401970875383334, &#x27;mean_inference_ms&#x27;: 2.252839083287414, &#x27;mean_action_processing_ms&#x27;: 0.20564141877335765, &#x27;mean_env_wait_ms&#x27;: 25.371932567556676, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}                                                                                      </td><td style=\"text-align: right;\">             2982.9 </td><td style=\"text-align: right;\">          12.4133 </td><td style=\"text-align: right;\">       2982.9 </td><td>{&#x27;training_iteration_time_ms&#x27;: 11989.603, &#x27;load_time_ms&#x27;: 3.351, &#x27;load_throughput&#x27;: 1790422.744, &#x27;learn_time_ms&#x27;: 8197.768, &#x27;learn_throughput&#x27;: 731.907, &#x27;synch_weights_time_ms&#x27;: 11.32} </td><td style=\"text-align: right;\"> 1669961378</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">          1500000</td><td style=\"text-align: right;\">                 250</td><td>886ac_00007</td><td style=\"text-align: right;\">      20.121 </td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00008</td><td style=\"text-align: right;\">                1503480</td><td>{&#x27;num_env_steps_sampled&#x27;: 1503480, &#x27;num_env_steps_trained&#x27;: 1503480, &#x27;num_agent_steps_sampled&#x27;: 1503480, &#x27;num_agent_steps_trained&#x27;: 1503480}</td><td>{}              </td><td>2022-12-02_07-02-16</td><td>True  </td><td style=\"text-align: right;\">               100</td><td>{}             </td><td style=\"text-align: right;\">               -12.2</td><td style=\"text-align: right;\">              -80.106</td><td style=\"text-align: right;\">              -666.7</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">           15000</td><td>6911fff9f01e4c13a3f492fe6c49f862</td><td>01589170c3ff</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;cur_kl_coeff&#x27;: 0.20000000298023224, &#x27;cur_lr&#x27;: 0.0005000000237487257, &#x27;total_loss&#x27;: 6.5486336, &#x27;policy_loss&#x27;: -0.10670714, &#x27;vf_loss&#x27;: 6.6501365, &#x27;vf_explained_var&#x27;: -0.3637098, &#x27;kl&#x27;: 0.026020415, &#x27;entropy&#x27;: 2.1058552, &#x27;entropy_coeff&#x27;: 0.0, &#x27;model&#x27;: {}}, &#x27;train&#x27;: None}}, &#x27;num_env_steps_sampled&#x27;: 1503480, &#x27;num_env_steps_trained&#x27;: 1503480, &#x27;num_agent_steps_sampled&#x27;: 1503480, &#x27;num_agent_steps_trained&#x27;: 1503480}  </td><td style=\"text-align: right;\">                       374</td><td>172.28.0.2</td><td style=\"text-align: right;\">                  1503480</td><td style=\"text-align: right;\">                  1503480</td><td style=\"text-align: right;\">                1503480</td><td style=\"text-align: right;\">                             4020</td><td style=\"text-align: right;\">                1503480</td><td style=\"text-align: right;\">                             4020</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                   30</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                         4020</td><td>{&#x27;cpu_util_percent&#x27;: 32.923076923076934, &#x27;ram_util_percent&#x27;: 63.10000000000001}</td><td style=\"text-align: right;\">15530</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 4.468257341586227, &#x27;mean_inference_ms&#x27;: 2.3637653316167064, &#x27;mean_action_processing_ms&#x27;: 0.20539110393858742, &#x27;mean_env_wait_ms&#x27;: 25.48187003944327, &#x27;mean_env_render_ms&#x27;: 0.0} </td><td>{&#x27;episode_reward_max&#x27;: -12.19999999999998, &#x27;episode_reward_min&#x27;: -666.7000000000006, &#x27;episode_reward_mean&#x27;: -80.106, &#x27;episode_len_mean&#x27;: 100.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 60, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-22.700000000000014, -61.80000000000009, -78.79999999999998, -62.8000000000001, -40.800000000000054, -78.79999999999995, -47.500000000000085, -150.79999999999973, -105.7999999999999, -45.700000000000074, -108.69999999999975, -55.700000000000045, -479.70000000000124, -64.80000000000007, -142.79999999999978, -78.80000000000004, -14.799999999999978, -77.39999999999986, -56.800000000000075, -104.89999999999992, -87.69999999999995, -89.69999999999997, -58.80000000000009, -114.79999999999981, -123.79999999999984, -79.70000000000003, -118.79999999999974, -85.69999999999972, -26.60000000000004, -26.800000000000054, -48.70000000000003, -106.79999999999976, -22.300000000000004, -22.800000000000004, -26.800000000000043, -666.7000000000006, -121.79999999999961, -56.700000000000095, -124.10000000000002, -83.79999999999994, -21.70000000000004, -55.4000000000001, -277.7000000000002, -56.80000000000009, -64.80000000000008, -22.800000000000033, -62.30000000000001, -51.50000000000003, -72.80000000000004, -81.7, -75.7, -81.79999999999997, -25.100000000000026, -110.79999999999988, -88.7999999999999, -112.79999999999974, -70.80000000000003, -105.69999999999978, -63.2, -59.80000000000008, -18.700000000000014, -39.800000000000104, -77.69999999999996, -30.700000000000063, -138.7999999999997, -82.7, -22.800000000000058, -28.60000000000004, -94.5, -75.8, -12.19999999999998, -16.799999999999986, -32.80000000000007, -70.70000000000003, -102.79999999999986, -21.800000000000036, -83.69999999999996, -96.79999999999984, -97.6999999999997, -51.80000000000008, -82.79999999999995, -22.800000000000054, -53.60000000000006, -73.80000000000001, -48.80000000000007, -103.79999999999984, -111.79999999999984, -34.70000000000009, -56.80000000000009, -18.4, -59.30000000000009, -21.30000000000001, -30.800000000000058, -57.70000000000012, -126.79999999999983, -19.500000000000036, -28.600000000000076, -112.69999999999985, -19.799999999999994, -194.79999999999967], &#x27;episode_lengths&#x27;: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 4.468257341586227, &#x27;mean_inference_ms&#x27;: 2.3637653316167064, &#x27;mean_action_processing_ms&#x27;: 0.20539110393858742, &#x27;mean_env_wait_ms&#x27;: 25.48187003944327, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}                                                                                                </td><td style=\"text-align: right;\">             3095.54</td><td style=\"text-align: right;\">           8.6838 </td><td style=\"text-align: right;\">       3095.54</td><td>{&#x27;training_iteration_time_ms&#x27;: 8316.995, &#x27;load_time_ms&#x27;: 2.404, &#x27;load_throughput&#x27;: 1671948.802, &#x27;learn_time_ms&#x27;: 5630.176, &#x27;learn_throughput&#x27;: 714.01, &#x27;synch_weights_time_ms&#x27;: 11.325}  </td><td style=\"text-align: right;\"> 1669964536</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">          1503480</td><td style=\"text-align: right;\">                 374</td><td>886ac_00008</td><td style=\"text-align: right;\">      20.083 </td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00009</td><td style=\"text-align: right;\">                1503480</td><td>{&#x27;num_env_steps_sampled&#x27;: 1503480, &#x27;num_env_steps_trained&#x27;: 1503480, &#x27;num_agent_steps_sampled&#x27;: 1503480, &#x27;num_agent_steps_trained&#x27;: 1503480}</td><td>{}              </td><td>2022-12-02_07-54-45</td><td>True  </td><td style=\"text-align: right;\">               100</td><td>{}             </td><td style=\"text-align: right;\">               -10.7</td><td style=\"text-align: right;\">              -36.164</td><td style=\"text-align: right;\">              -152.7</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">           15000</td><td>2ce0ffb7fbed4660b5020ea2db613eaa</td><td>01589170c3ff</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;cur_kl_coeff&#x27;: 0.20000000298023224, &#x27;cur_lr&#x27;: 9.999999747378752e-05, &#x27;total_loss&#x27;: 4.0672407, &#x27;policy_loss&#x27;: -0.08751962, &#x27;vf_loss&#x27;: 4.151053, &#x27;vf_explained_var&#x27;: -0.046604812, &#x27;kl&#x27;: 0.018536897, &#x27;entropy&#x27;: 1.2092108, &#x27;entropy_coeff&#x27;: 0.0, &#x27;model&#x27;: {}}, &#x27;train&#x27;: None}}, &#x27;num_env_steps_sampled&#x27;: 1503480, &#x27;num_env_steps_trained&#x27;: 1503480, &#x27;num_agent_steps_sampled&#x27;: 1503480, &#x27;num_agent_steps_trained&#x27;: 1503480} </td><td style=\"text-align: right;\">                       374</td><td>172.28.0.2</td><td style=\"text-align: right;\">                  1503480</td><td style=\"text-align: right;\">                  1503480</td><td style=\"text-align: right;\">                1503480</td><td style=\"text-align: right;\">                             4020</td><td style=\"text-align: right;\">                1503480</td><td style=\"text-align: right;\">                             4020</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                   30</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                         4020</td><td>{&#x27;cpu_util_percent&#x27;: 33.57692307692307, &#x27;ram_util_percent&#x27;: 63.10000000000001} </td><td style=\"text-align: right;\">17507</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 4.543865397542109, &#x27;mean_inference_ms&#x27;: 2.431681849947735, &#x27;mean_action_processing_ms&#x27;: 0.2068349972305063, &#x27;mean_env_wait_ms&#x27;: 26.652918579319138, &#x27;mean_env_render_ms&#x27;: 0.0}  </td><td>{&#x27;episode_reward_max&#x27;: -10.699999999999978, &#x27;episode_reward_min&#x27;: -152.69999999999973, &#x27;episode_reward_mean&#x27;: -36.16399999999999, &#x27;episode_len_mean&#x27;: 100.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 60, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-20.800000000000008, -12.799999999999974, -132.7999999999998, -16.79999999999999, -85.7999999999999, -11.799999999999978, -18.80000000000001, -25.800000000000058, -13.79999999999997, -111.7999999999998, -14.799999999999976, -10.799999999999978, -15.799999999999972, -14.799999999999972, -24.800000000000104, -12.699999999999973, -57.80000000000004, -12.799999999999969, -42.80000000000002, -47.7000000000001, -18.8, -32.800000000000075, -29.80000000000006, -12.799999999999974, -14.799999999999972, -13.799999999999969, -14.799999999999978, -17.799999999999976, -33.400000000000055, -123.79999999999984, -14.799999999999974, -14.79999999999997, -20.8, -112.20000000000002, -35.70000000000008, -129.4, -22.80000000000003, -17.799999999999983, -15.799999999999978, -19.800000000000004, -24.700000000000053, -31.800000000000047, -16.799999999999986, -68.80000000000004, -107.99999999999987, -87.6999999999999, -18.700000000000003, -13.699999999999982, -17.799999999999986, -10.79999999999998, -14.799999999999974, -152.69999999999973, -10.799999999999981, -13.69999999999998, -35.3000000000001, -12.699999999999978, -140.79999999999978, -19.800000000000015, -14.799999999999974, -32.80000000000003, -11.799999999999974, -15.799999999999976, -11.399999999999979, -81.79999999999998, -67.80000000000004, -16.099999999999973, -30.70000000000007, -15.69999999999998, -95.6999999999999, -10.799999999999978, -22.800000000000043, -12.699999999999978, -12.799999999999974, -15.599999999999975, -41.70000000000008, -12.699999999999978, -12.699999999999978, -33.500000000000064, -14.799999999999978, -73.79999999999995, -45.800000000000026, -34.80000000000008, -26.800000000000036, -10.799999999999978, -10.699999999999978, -20.800000000000022, -19.800000000000015, -16.69999999999999, -17.599999999999994, -28.7, -46.80000000000003, -13.79999999999998, -14.799999999999978, -10.799999999999978, -79.79999999999994, -120.79999999999984, -127.79999999999981, -11.799999999999978, -40.800000000000054, -36.70000000000011], &#x27;episode_lengths&#x27;: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 4.543865397542109, &#x27;mean_inference_ms&#x27;: 2.431681849947735, &#x27;mean_action_processing_ms&#x27;: 0.2068349972305063, &#x27;mean_env_wait_ms&#x27;: 26.652918579319138, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}                          </td><td style=\"text-align: right;\">             3083.63</td><td style=\"text-align: right;\">           8.45096</td><td style=\"text-align: right;\">       3083.63</td><td>{&#x27;training_iteration_time_ms&#x27;: 8298.491, &#x27;load_time_ms&#x27;: 2.353, &#x27;load_throughput&#x27;: 1708162.587, &#x27;learn_time_ms&#x27;: 5525.202, &#x27;learn_throughput&#x27;: 727.575, &#x27;synch_weights_time_ms&#x27;: 11.856} </td><td style=\"text-align: right;\"> 1669967685</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">          1503480</td><td style=\"text-align: right;\">                 374</td><td>886ac_00009</td><td style=\"text-align: right;\">      20.322 </td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00010</td><td style=\"text-align: right;\">                1503480</td><td>{&#x27;num_env_steps_sampled&#x27;: 1503480, &#x27;num_env_steps_trained&#x27;: 1503480, &#x27;num_agent_steps_sampled&#x27;: 1503480, &#x27;num_agent_steps_trained&#x27;: 1503480}</td><td>{}              </td><td>2022-12-02_08-47-43</td><td>True  </td><td style=\"text-align: right;\">               100</td><td>{}             </td><td style=\"text-align: right;\">                -9.7</td><td style=\"text-align: right;\">              -51.779</td><td style=\"text-align: right;\">              -170.6</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">           15000</td><td>1052cf7809d24827823bcaceb76efeb3</td><td>01589170c3ff</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;cur_kl_coeff&#x27;: 0.20000000298023224, &#x27;cur_lr&#x27;: 0.0005000000237487257, &#x27;total_loss&#x27;: 6.344014, &#x27;policy_loss&#x27;: -0.09525535, &#x27;vf_loss&#x27;: 6.4246736, &#x27;vf_explained_var&#x27;: -0.12925522, &#x27;kl&#x27;: 0.0729794, &#x27;entropy&#x27;: 1.8120375, &#x27;entropy_coeff&#x27;: 0.0, &#x27;model&#x27;: {}}, &#x27;train&#x27;: None}}, &#x27;num_env_steps_sampled&#x27;: 1503480, &#x27;num_env_steps_trained&#x27;: 1503480, &#x27;num_agent_steps_sampled&#x27;: 1503480, &#x27;num_agent_steps_trained&#x27;: 1503480}    </td><td style=\"text-align: right;\">                       374</td><td>172.28.0.2</td><td style=\"text-align: right;\">                  1503480</td><td style=\"text-align: right;\">                  1503480</td><td style=\"text-align: right;\">                1503480</td><td style=\"text-align: right;\">                             4020</td><td style=\"text-align: right;\">                1503480</td><td style=\"text-align: right;\">                             4020</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                   30</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                         4020</td><td>{&#x27;cpu_util_percent&#x27;: 33.09166666666667, &#x27;ram_util_percent&#x27;: 63.1}              </td><td style=\"text-align: right;\">19413</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 4.603933585859355, &#x27;mean_inference_ms&#x27;: 2.4729493262570283, &#x27;mean_action_processing_ms&#x27;: 0.20724757006094927, &#x27;mean_env_wait_ms&#x27;: 25.90123954622962, &#x27;mean_env_render_ms&#x27;: 0.0} </td><td>{&#x27;episode_reward_max&#x27;: -9.699999999999982, &#x27;episode_reward_min&#x27;: -170.60000000000002, &#x27;episode_reward_mean&#x27;: -51.77900000000002, &#x27;episode_len_mean&#x27;: 100.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 60, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-65.50000000000009, -55.80000000000003, -65.80000000000008, -60.30000000000001, -15.599999999999977, -164.79999999999959, -63.2, -53.60000000000006, -40.40000000000004, -48.900000000000084, -14.199999999999978, -41.20000000000005, -55.6, -119.7, -46.80000000000009, -33.70000000000009, -44.80000000000007, -61.000000000000014, -63.90000000000003, -98.0, -84.2, -30.200000000000045, -113.7999999999999, -62.50000000000002, -88.6, -68.5, -59.3, -28.00000000000006, -49.300000000000054, -59.100000000000016, -68.80000000000005, -65.10000000000002, -31.10000000000006, -84.70000000000002, -82.10000000000002, -21.700000000000053, -26.500000000000053, -22.70000000000001, -40.50000000000006, -27.800000000000068, -41.400000000000006, -16.699999999999992, -31.1, -93.0, -31.000000000000064, -45.9, -42.600000000000044, -53.7000000000001, -49.70000000000011, -40.100000000000094, -30.600000000000097, -88.7999999999999, -9.699999999999982, -44.80000000000003, -170.60000000000002, -34.800000000000054, -29.400000000000087, -19.500000000000004, -36.80000000000008, -60.5, -21.8, -21.7, -70.10000000000001, -47.80000000000009, -33.80000000000006, -29.400000000000063, -93.1, -78.1, -28.700000000000053, -22.400000000000023, -52.600000000000065, -88.69999999999986, -36.20000000000005, -78.59999999999992, -37.80000000000004, -54.000000000000085, -26.200000000000088, -19.80000000000003, -58.80000000000011, -33.50000000000005, -18.900000000000023, -65.80000000000007, -58.000000000000014, -154.59999999999982, -73.79999999999995, -21.800000000000043, -76.8, -12.699999999999974, -40.40000000000006, -26.800000000000047, -26.700000000000035, -74.10000000000002, -65.9, -30.800000000000036, -14.79999999999997, -21.800000000000043, -34.900000000000084, -18.80000000000002, -31.70000000000004, -77.69999999999996], &#x27;episode_lengths&#x27;: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 4.603933585859355, &#x27;mean_inference_ms&#x27;: 2.4729493262570283, &#x27;mean_action_processing_ms&#x27;: 0.20724757006094927, &#x27;mean_env_wait_ms&#x27;: 25.90123954622962, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}                                                                                                                                                                                                                                        </td><td style=\"text-align: right;\">             3110.65</td><td style=\"text-align: right;\">           8.38059</td><td style=\"text-align: right;\">       3110.65</td><td>{&#x27;training_iteration_time_ms&#x27;: 8211.648, &#x27;load_time_ms&#x27;: 2.328, &#x27;load_throughput&#x27;: 1726881.889, &#x27;learn_time_ms&#x27;: 5643.55, &#x27;learn_throughput&#x27;: 712.318, &#x27;synch_weights_time_ms&#x27;: 11.624}  </td><td style=\"text-align: right;\"> 1669970863</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">          1503480</td><td style=\"text-align: right;\">                 374</td><td>886ac_00010</td><td style=\"text-align: right;\">      20.2753</td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00011</td><td style=\"text-align: right;\">                1503480</td><td>{&#x27;num_env_steps_sampled&#x27;: 1503480, &#x27;num_env_steps_trained&#x27;: 1503480, &#x27;num_agent_steps_sampled&#x27;: 1503480, &#x27;num_agent_steps_trained&#x27;: 1503480}</td><td>{}              </td><td>2022-12-02_09-39-53</td><td>True  </td><td style=\"text-align: right;\">               100</td><td>{}             </td><td style=\"text-align: right;\">               -10.9</td><td style=\"text-align: right;\">              -80.233</td><td style=\"text-align: right;\">              -210.8</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">           15000</td><td>12da045704db4af4b885374bc261f889</td><td>01589170c3ff</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;cur_kl_coeff&#x27;: 0.20000000298023224, &#x27;cur_lr&#x27;: 9.999999747378752e-05, &#x27;total_loss&#x27;: 6.704199, &#x27;policy_loss&#x27;: -0.09738395, &#x27;vf_loss&#x27;: 6.7959943, &#x27;vf_explained_var&#x27;: -0.5005095, &#x27;kl&#x27;: 0.027941223, &#x27;entropy&#x27;: 2.279788, &#x27;entropy_coeff&#x27;: 0.0, &#x27;model&#x27;: {}}, &#x27;train&#x27;: None}}, &#x27;num_env_steps_sampled&#x27;: 1503480, &#x27;num_env_steps_trained&#x27;: 1503480, &#x27;num_agent_steps_sampled&#x27;: 1503480, &#x27;num_agent_steps_trained&#x27;: 1503480}    </td><td style=\"text-align: right;\">                       374</td><td>172.28.0.2</td><td style=\"text-align: right;\">                  1503480</td><td style=\"text-align: right;\">                  1503480</td><td style=\"text-align: right;\">                1503480</td><td style=\"text-align: right;\">                             4020</td><td style=\"text-align: right;\">                1503480</td><td style=\"text-align: right;\">                             4020</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                   30</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                         4020</td><td>{&#x27;cpu_util_percent&#x27;: 32.91538461538462, &#x27;ram_util_percent&#x27;: 63.29999999999998} </td><td style=\"text-align: right;\">21377</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 4.6934664128894505, &#x27;mean_inference_ms&#x27;: 2.5424621935229315, &#x27;mean_action_processing_ms&#x27;: 0.20828285230965882, &#x27;mean_env_wait_ms&#x27;: 26.53148788990586, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: -10.899999999999984, &#x27;episode_reward_min&#x27;: -210.7999999999997, &#x27;episode_reward_mean&#x27;: -80.23299999999992, &#x27;episode_len_mean&#x27;: 100.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 60, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-53.80000000000012, -12.09999999999998, -63.60000000000009, -73.80000000000001, -102.79999999999993, -129.6, -106.69999999999982, -125.69999999999978, -140.79999999999976, -16.099999999999987, -126.79999999999974, -22.800000000000036, -168.79999999999976, -21.800000000000054, -153.79999999999973, -12.499999999999986, -88.80000000000001, -19.500000000000018, -101.69999999999987, -94.79999999999991, -150.69999999999973, -72.3, -23.800000000000047, -88.79999999999993, -102.79999999999988, -17.699999999999985, -108.79999999999981, -26.39999999999999, -46.80000000000007, -33.800000000000026, -154.79999999999973, -37.30000000000005, -133.79999999999976, -17.699999999999985, -183.69999999999968, -152.7999999999997, -47.800000000000054, -16.599999999999984, -24.500000000000025, -77.69999999999999, -19.800000000000008, -72.7999999999999, -34.5, -159.79999999999973, -10.899999999999984, -45.40000000000009, -14.399999999999977, -90.79999999999993, -92.79999999999986, -93.79999999999988, -65.40000000000009, -144.69999999999973, -136.79999999999978, -77.4, -20.50000000000002, -15.89999999999998, -90.40000000000003, -18.599999999999994, -94.7999999999999, -108.69999999999985, -117.39999999999985, -125.79999999999981, -97.7999999999999, -19.60000000000002, -95.7999999999999, -173.79999999999973, -20.599999999999987, -15.199999999999978, -91.69999999999982, -37.400000000000084, -57.80000000000003, -149.0999999999998, -139.9, -23.79999999999999, -210.7999999999997, -67.80000000000001, -69.80000000000001, -16.59999999999998, -156.79999999999973, -51.500000000000085, -128.79999999999978, -71.20000000000005, -154.79999999999973, -21.000000000000004, -93.79999999999987, -71.80000000000004, -47.30000000000005, -142.79999999999976, -19.799999999999997, -36.80000000000009, -147.9, -21.800000000000022, -102.69999999999986, -170.79999999999967, -17.800000000000004, -151.79999999999976, -86.59999999999987, -14.19999999999998, -91.79999999999991, -127.6999999999997], &#x27;episode_lengths&#x27;: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 4.6934664128894505, &#x27;mean_inference_ms&#x27;: 2.5424621935229315, &#x27;mean_action_processing_ms&#x27;: 0.20828285230965882, &#x27;mean_env_wait_ms&#x27;: 26.53148788990586, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}                                                            </td><td style=\"text-align: right;\">             3060.19</td><td style=\"text-align: right;\">           8.44198</td><td style=\"text-align: right;\">       3060.19</td><td>{&#x27;training_iteration_time_ms&#x27;: 8146.519, &#x27;load_time_ms&#x27;: 2.369, &#x27;load_throughput&#x27;: 1696646.382, &#x27;learn_time_ms&#x27;: 5425.705, &#x27;learn_throughput&#x27;: 740.918, &#x27;synch_weights_time_ms&#x27;: 10.66}  </td><td style=\"text-align: right;\"> 1669973993</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">          1503480</td><td style=\"text-align: right;\">                 374</td><td>886ac_00011</td><td style=\"text-align: right;\">      21.4206</td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00012</td><td style=\"text-align: right;\">                1503480</td><td>{&#x27;num_env_steps_sampled&#x27;: 1503480, &#x27;num_env_steps_trained&#x27;: 1503480, &#x27;num_agent_steps_sampled&#x27;: 1503480, &#x27;num_agent_steps_trained&#x27;: 1503480}</td><td>{}              </td><td>2022-12-02_10-30-22</td><td>True  </td><td style=\"text-align: right;\">               100</td><td>{}             </td><td style=\"text-align: right;\">               -11.5</td><td style=\"text-align: right;\">              -74.279</td><td style=\"text-align: right;\">              -240.8</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">           15000</td><td>9f6ac89437e04d43a49ac49568a57376</td><td>01589170c3ff</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;cur_kl_coeff&#x27;: 0.20000000298023224, &#x27;cur_lr&#x27;: 0.0005000000237487257, &#x27;total_loss&#x27;: 6.997576, &#x27;policy_loss&#x27;: -0.117873475, &#x27;vf_loss&#x27;: 7.109816, &#x27;vf_explained_var&#x27;: -0.124295145, &#x27;kl&#x27;: 0.028170416, &#x27;entropy&#x27;: 2.0114453, &#x27;entropy_coeff&#x27;: 0.0, &#x27;model&#x27;: {}}, &#x27;train&#x27;: None}}, &#x27;num_env_steps_sampled&#x27;: 1503480, &#x27;num_env_steps_trained&#x27;: 1503480, &#x27;num_agent_steps_sampled&#x27;: 1503480, &#x27;num_agent_steps_trained&#x27;: 1503480} </td><td style=\"text-align: right;\">                       374</td><td>172.28.0.2</td><td style=\"text-align: right;\">                  1503480</td><td style=\"text-align: right;\">                  1503480</td><td style=\"text-align: right;\">                1503480</td><td style=\"text-align: right;\">                             4020</td><td style=\"text-align: right;\">                1503480</td><td style=\"text-align: right;\">                             4020</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                   30</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                         4020</td><td>{&#x27;cpu_util_percent&#x27;: 34.61666666666667, &#x27;ram_util_percent&#x27;: 63.0}              </td><td style=\"text-align: right;\">23250</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 4.312949430880554, &#x27;mean_inference_ms&#x27;: 2.0279831679897686, &#x27;mean_action_processing_ms&#x27;: 0.20264813577305751, &#x27;mean_env_wait_ms&#x27;: 24.424269211367605, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: -11.499999999999979, &#x27;episode_reward_min&#x27;: -240.79999999999964, &#x27;episode_reward_mean&#x27;: -74.27899999999998, &#x27;episode_len_mean&#x27;: 100.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 60, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-20.300000000000008, -21.80000000000002, -139.2, -59.1, -240.79999999999964, -75.0, -13.699999999999982, -118.79999999999986, -73.19999999999993, -26.700000000000088, -110.79999999999976, -90.90000000000003, -74.9, -114.4, -119.2, -33.700000000000024, -20.80000000000004, -110.29999999999986, -51.70000000000009, -12.799999999999974, -181.19999999999982, -87.29999999999998, -91.5, -59.70000000000009, -15.79999999999997, -58.80000000000006, -27.40000000000008, -144.79999999999973, -19.8, -59.99999999999999, -29.800000000000043, -70.0, -27.70000000000007, -153.69999999999976, -150.0, -110.79999999999988, -116.50000000000003, -48.70000000000007, -126.69999999999975, -154.49999999999977, -118.79999999999976, -35.70000000000009, -27.800000000000043, -35.90000000000009, -108.70000000000003, -66.09999999999998, -102.59999999999997, -33.70000000000005, -48.8000000000001, -66.5, -37.70000000000009, -105.69999999999989, -151.8, -69.80000000000001, -23.700000000000035, -32.800000000000075, -34.8000000000001, -72.80000000000004, -57.90000000000008, -11.499999999999979, -18.50000000000002, -12.499999999999977, -20.800000000000022, -108.1, -23.300000000000022, -87.9, -31.800000000000058, -123.69999999999983, -41.8000000000001, -51.30000000000006, -37.80000000000009, -19.500000000000014, -95.5, -122.09999999999974, -18.400000000000016, -37.9, -21.700000000000006, -99.20000000000002, -69.80000000000005, -129.29999999999995, -77.0, -19.799999999999986, -83.79999999999988, -93.79999999999977, -22.40000000000002, -169.5, -48.100000000000016, -114.80000000000003, -87.09999999999995, -91.10000000000002, -77.3, -88.30000000000004, -99.49999999999993, -145.7, -66.19999999999999, -38.60000000000008, -72.0, -84.79999999999997, -111.59999999999992, -159.69999999999973], &#x27;episode_lengths&#x27;: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 4.312949430880554, &#x27;mean_inference_ms&#x27;: 2.0279831679897686, &#x27;mean_action_processing_ms&#x27;: 0.20264813577305751, &#x27;mean_env_wait_ms&#x27;: 24.424269211367605, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}                                                                                                                                                                                                                                                                    </td><td style=\"text-align: right;\">             2958.78</td><td style=\"text-align: right;\">           8.02255</td><td style=\"text-align: right;\">       2958.78</td><td>{&#x27;training_iteration_time_ms&#x27;: 7870.524, &#x27;load_time_ms&#x27;: 2.2, &#x27;load_throughput&#x27;: 1827325.958, &#x27;learn_time_ms&#x27;: 5378.783, &#x27;learn_throughput&#x27;: 747.381, &#x27;synch_weights_time_ms&#x27;: 9.998}    </td><td style=\"text-align: right;\"> 1669977022</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">          1503480</td><td style=\"text-align: right;\">                 374</td><td>886ac_00012</td><td style=\"text-align: right;\">      19.6144</td></tr>\n",
       "<tr><td>PPO_CybORG_886ac_00013</td><td style=\"text-align: right;\">                1149720</td><td>{&#x27;num_env_steps_sampled&#x27;: 1149720, &#x27;num_env_steps_trained&#x27;: 1149720, &#x27;num_agent_steps_sampled&#x27;: 1149720, &#x27;num_agent_steps_trained&#x27;: 1149720}</td><td>{}              </td><td>2022-12-02_11-09-56</td><td>False </td><td style=\"text-align: right;\">               100</td><td>{}             </td><td style=\"text-align: right;\">                -9.8</td><td style=\"text-align: right;\">              -46.454</td><td style=\"text-align: right;\">              -156.8</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">           11460</td><td>39733ca35f4c49eb87c25e1ab22bb912</td><td>01589170c3ff</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;cur_kl_coeff&#x27;: 0.20000000298023224, &#x27;cur_lr&#x27;: 9.999999747378752e-05, &#x27;total_loss&#x27;: 5.443099, &#x27;policy_loss&#x27;: -0.06584027, &#x27;vf_loss&#x27;: 5.5034738, &#x27;vf_explained_var&#x27;: -0.11525923, &#x27;kl&#x27;: 0.027326914, &#x27;entropy&#x27;: 1.6944562, &#x27;entropy_coeff&#x27;: 0.0, &#x27;model&#x27;: {}}, &#x27;train&#x27;: None}}, &#x27;num_env_steps_sampled&#x27;: 1149720, &#x27;num_env_steps_trained&#x27;: 1149720, &#x27;num_agent_steps_sampled&#x27;: 1149720, &#x27;num_agent_steps_trained&#x27;: 1149720}  </td><td style=\"text-align: right;\">                       286</td><td>172.28.0.2</td><td style=\"text-align: right;\">                  1149720</td><td style=\"text-align: right;\">                  1149720</td><td style=\"text-align: right;\">                1149720</td><td style=\"text-align: right;\">                             4020</td><td style=\"text-align: right;\">                1149720</td><td style=\"text-align: right;\">                             4020</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                   30</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                         4020</td><td>{&#x27;cpu_util_percent&#x27;: 34.82727272727272, &#x27;ram_util_percent&#x27;: 62.79999999999998} </td><td style=\"text-align: right;\">25182</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 4.425170349306674, &#x27;mean_inference_ms&#x27;: 2.1549659764232287, &#x27;mean_action_processing_ms&#x27;: 0.20334906940173042, &#x27;mean_env_wait_ms&#x27;: 25.007475012826664, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: -9.799999999999981, &#x27;episode_reward_min&#x27;: -156.79999999999973, &#x27;episode_reward_mean&#x27;: -46.45399999999999, &#x27;episode_len_mean&#x27;: 100.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 60, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-17.800000000000008, -76.3, -14.29999999999998, -16.699999999999996, -83.1, -156.79999999999973, -57.50000000000003, -34.800000000000075, -54.90000000000005, -16.099999999999973, -21.80000000000001, -105.7999999999999, -39.70000000000003, -24.500000000000032, -10.79999999999998, -18.500000000000007, -109.4, -144.6, -76.8, -19.999999999999993, -93.59999999999994, -24.50000000000007, -29.80000000000001, -29.900000000000027, -25.000000000000057, -24.600000000000055, -38.20000000000007, -11.699999999999976, -41.500000000000064, -26.900000000000002, -88.1, -34.300000000000026, -31.1000000000001, -22.300000000000036, -84.4, -77.70000000000002, -19.40000000000001, -19.400000000000002, -14.199999999999976, -58.40000000000008, -87.7999999999999, -127.79999999999973, -14.999999999999973, -25.40000000000003, -149.69999999999973, -36.10000000000002, -31.900000000000027, -11.399999999999977, -15.29999999999998, -17.800000000000004, -21.800000000000004, -13.799999999999978, -31.40000000000003, -28.500000000000018, -101.60000000000001, -32.70000000000006, -77.49999999999997, -23.900000000000073, -72.10000000000001, -105.5, -28.700000000000017, -145.60000000000002, -23.500000000000018, -88.09999999999994, -51.100000000000016, -17.49999999999999, -13.999999999999977, -14.49999999999998, -62.9, -27.500000000000032, -12.29999999999998, -107.19999999999987, -141.4, -12.799999999999981, -72.59999999999997, -32.70000000000002, -45.500000000000014, -13.099999999999984, -60.10000000000002, -17.099999999999987, -34.50000000000004, -40.800000000000026, -9.799999999999981, -59.7, -17.09999999999999, -37.100000000000044, -110.39999999999985, -15.499999999999979, -21.800000000000026, -40.10000000000004, -41.1, -20.700000000000006, -42.200000000000024, -63.60000000000004, -12.599999999999982, -12.799999999999981, -22.09999999999999, -39.2, -63.800000000000104, -30.100000000000016], &#x27;episode_lengths&#x27;: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 4.425170349306674, &#x27;mean_inference_ms&#x27;: 2.1549659764232287, &#x27;mean_action_processing_ms&#x27;: 0.20334906940173042, &#x27;mean_env_wait_ms&#x27;: 25.007475012826664, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}                                                                                                                                                     </td><td style=\"text-align: right;\">             2311.51</td><td style=\"text-align: right;\">           8.08481</td><td style=\"text-align: right;\">       2311.51</td><td>{&#x27;training_iteration_time_ms&#x27;: 8082.774, &#x27;load_time_ms&#x27;: 2.353, &#x27;load_throughput&#x27;: 1708197.198, &#x27;learn_time_ms&#x27;: 5498.373, &#x27;learn_throughput&#x27;: 731.125, &#x27;synch_weights_time_ms&#x27;: 10.638} </td><td style=\"text-align: right;\"> 1669979396</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">          1149720</td><td style=\"text-align: right;\">                 286</td><td>886ac_00013</td><td style=\"text-align: right;\">      20.1202</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPO pid=2114)\u001b[0m 2022-12-02 00:16:13,675\tINFO algorithm.py:2303 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPO pid=2114)\u001b[0m 2022-12-02 00:16:13,676\tWARNING ppo.py:351 -- `train_batch_size` (6000) cannot be achieved with your other settings (num_workers=30 num_envs_per_worker=2 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 100.\n",
      "\u001b[2m\u001b[36m(PPO pid=2114)\u001b[0m 2022-12-02 00:16:13,676\tINFO ppo.py:379 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(PPO pid=2114)\u001b[0m 2022-12-02 00:16:13,677\tINFO algorithm.py:457 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m 2022-12-02 00:16:25,926\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=2114)\u001b[0m 2022-12-02 00:16:33,864\tINFO trainable.py:164 -- Trainable.setup took 20.191 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(PPO pid=2114)\u001b[0m 2022-12-02 00:16:33,865\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m 2022-12-02 01:06:52,371\tERROR worker.py:763 -- Worker exits with an exit code 1.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1032, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m   File \"python/ray/_raylet.pyx\", line 812, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m   File \"python/ray/_raylet.pyx\", line 852, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m   File \"python/ray/_raylet.pyx\", line 859, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m   File \"python/ray/_raylet.pyx\", line 863, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m   File \"python/ray/_raylet.pyx\", line 810, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1328, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1380, in exit_actor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m     ray._private.worker.disconnect()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 2137, in disconnect\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m     worker.import_thread.join_import_thread()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/import_thread.py\", line 61, in join_import_thread\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m     self.t.join()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m     self._wait_for_tstate_lock()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m     elif lock.acquire(block, timeout):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 760, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2144)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m 2022-12-02 01:06:52,369\tERROR worker.py:763 -- Worker exits with an exit code 1.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1032, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m   File \"python/ray/_raylet.pyx\", line 812, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m   File \"python/ray/_raylet.pyx\", line 852, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m   File \"python/ray/_raylet.pyx\", line 859, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m   File \"python/ray/_raylet.pyx\", line 863, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m   File \"python/ray/_raylet.pyx\", line 810, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1328, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1380, in exit_actor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m     ray._private.worker.disconnect()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 2137, in disconnect\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m     worker.import_thread.join_import_thread()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/import_thread.py\", line 61, in join_import_thread\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m     self.t.join()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m     self._wait_for_tstate_lock()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m     elif lock.acquire(block, timeout):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 760, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2193)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(PPO pid=4024)\u001b[0m 2022-12-02 01:06:59,658\tINFO algorithm.py:2303 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPO pid=4024)\u001b[0m 2022-12-02 01:06:59,659\tWARNING ppo.py:351 -- `train_batch_size` (6000) cannot be achieved with your other settings (num_workers=30 num_envs_per_worker=2 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 100.\n",
      "\u001b[2m\u001b[36m(PPO pid=4024)\u001b[0m 2022-12-02 01:06:59,659\tINFO ppo.py:379 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(PPO pid=4024)\u001b[0m 2022-12-02 01:06:59,660\tINFO algorithm.py:457 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=4054)\u001b[0m 2022-12-02 01:07:11,560\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=4024)\u001b[0m 2022-12-02 01:07:20,210\tINFO trainable.py:164 -- Trainable.setup took 20.553 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(PPO pid=4024)\u001b[0m 2022-12-02 01:07:20,211\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=6051)\u001b[0m 2022-12-02 01:57:39,378\tINFO algorithm.py:2303 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPO pid=6051)\u001b[0m 2022-12-02 01:57:39,379\tWARNING ppo.py:351 -- `train_batch_size` (6000) cannot be achieved with your other settings (num_workers=30 num_envs_per_worker=2 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 100.\n",
      "\u001b[2m\u001b[36m(PPO pid=6051)\u001b[0m 2022-12-02 01:57:39,379\tINFO ppo.py:379 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(PPO pid=6051)\u001b[0m 2022-12-02 01:57:39,380\tINFO algorithm.py:457 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m 2022-12-02 01:57:51,125\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=6051)\u001b[0m 2022-12-02 01:58:00,127\tINFO trainable.py:164 -- Trainable.setup took 20.751 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(PPO pid=6051)\u001b[0m 2022-12-02 01:58:00,128\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m 2022-12-02 02:48:19,231\tERROR worker.py:763 -- Worker exits with an exit code 1.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1032, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m   File \"python/ray/_raylet.pyx\", line 812, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m   File \"python/ray/_raylet.pyx\", line 852, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m   File \"python/ray/_raylet.pyx\", line 859, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m   File \"python/ray/_raylet.pyx\", line 863, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m   File \"python/ray/_raylet.pyx\", line 810, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1328, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1380, in exit_actor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m     ray._private.worker.disconnect()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 2137, in disconnect\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m     worker.import_thread.join_import_thread()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/import_thread.py\", line 61, in join_import_thread\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m     self.t.join()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m     self._wait_for_tstate_lock()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m     elif lock.acquire(block, timeout):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 760, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6081)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m 2022-12-02 02:48:19,308\tERROR worker.py:763 -- Worker exits with an exit code 1.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1032, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m   File \"python/ray/_raylet.pyx\", line 812, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m   File \"python/ray/_raylet.pyx\", line 852, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m   File \"python/ray/_raylet.pyx\", line 859, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m   File \"python/ray/_raylet.pyx\", line 863, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m   File \"python/ray/_raylet.pyx\", line 810, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1328, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1380, in exit_actor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m     ray._private.worker.disconnect()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 2137, in disconnect\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m     worker.import_thread.join_import_thread()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/import_thread.py\", line 61, in join_import_thread\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m     self.t.join()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m     self._wait_for_tstate_lock()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m     elif lock.acquire(block, timeout):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 760, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=6107)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(PPO pid=7948)\u001b[0m 2022-12-02 02:48:26,913\tINFO algorithm.py:2303 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPO pid=7948)\u001b[0m 2022-12-02 02:48:26,913\tWARNING ppo.py:351 -- `train_batch_size` (6000) cannot be achieved with your other settings (num_workers=30 num_envs_per_worker=2 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 100.\n",
      "\u001b[2m\u001b[36m(PPO pid=7948)\u001b[0m 2022-12-02 02:48:26,913\tINFO ppo.py:379 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(PPO pid=7948)\u001b[0m 2022-12-02 02:48:26,915\tINFO algorithm.py:457 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=7978)\u001b[0m 2022-12-02 02:48:40,041\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=7948)\u001b[0m 2022-12-02 02:48:47,241\tINFO trainable.py:164 -- Trainable.setup took 20.330 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(PPO pid=7948)\u001b[0m 2022-12-02 02:48:47,242\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=9835)\u001b[0m 2022-12-02 03:38:52,124\tINFO algorithm.py:2303 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPO pid=9835)\u001b[0m 2022-12-02 03:38:52,125\tWARNING ppo.py:351 -- `train_batch_size` (6000) cannot be achieved with your other settings (num_workers=30 num_envs_per_worker=2 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 100.\n",
      "\u001b[2m\u001b[36m(PPO pid=9835)\u001b[0m 2022-12-02 03:38:52,125\tINFO ppo.py:379 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(PPO pid=9835)\u001b[0m 2022-12-02 03:38:52,126\tINFO algorithm.py:457 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=9866)\u001b[0m 2022-12-02 03:39:04,725\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=9835)\u001b[0m 2022-12-02 03:39:12,299\tINFO trainable.py:164 -- Trainable.setup took 20.177 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(PPO pid=9835)\u001b[0m 2022-12-02 03:39:12,300\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=11727)\u001b[0m 2022-12-02 04:28:30,916\tINFO algorithm.py:2303 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPO pid=11727)\u001b[0m 2022-12-02 04:28:30,916\tWARNING ppo.py:351 -- `train_batch_size` (6000) cannot be achieved with your other settings (num_workers=30 num_envs_per_worker=2 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 100.\n",
      "\u001b[2m\u001b[36m(PPO pid=11727)\u001b[0m 2022-12-02 04:28:30,916\tINFO ppo.py:379 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(PPO pid=11727)\u001b[0m 2022-12-02 04:28:30,918\tINFO algorithm.py:457 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m 2022-12-02 04:28:43,156\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=11727)\u001b[0m 2022-12-02 04:28:51,136\tINFO trainable.py:164 -- Trainable.setup took 20.222 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(PPO pid=11727)\u001b[0m 2022-12-02 04:28:51,137\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m 2022-12-02 05:19:06,523\tERROR worker.py:763 -- Worker exits with an exit code 1.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1032, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m   File \"python/ray/_raylet.pyx\", line 812, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m   File \"python/ray/_raylet.pyx\", line 852, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m   File \"python/ray/_raylet.pyx\", line 859, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m   File \"python/ray/_raylet.pyx\", line 863, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m   File \"python/ray/_raylet.pyx\", line 810, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1328, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1380, in exit_actor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m     ray._private.worker.disconnect()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 2137, in disconnect\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m     worker.import_thread.join_import_thread()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/import_thread.py\", line 61, in join_import_thread\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m     self.t.join()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m     self._wait_for_tstate_lock()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m     elif lock.acquire(block, timeout):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 760, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11776)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m 2022-12-02 05:19:06,527\tERROR worker.py:763 -- Worker exits with an exit code 1.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1032, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m   File \"python/ray/_raylet.pyx\", line 812, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m   File \"python/ray/_raylet.pyx\", line 852, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m   File \"python/ray/_raylet.pyx\", line 859, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m   File \"python/ray/_raylet.pyx\", line 863, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m   File \"python/ray/_raylet.pyx\", line 810, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1328, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1380, in exit_actor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m     ray._private.worker.disconnect()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 2137, in disconnect\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m     worker.import_thread.join_import_thread()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/import_thread.py\", line 61, in join_import_thread\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m     self.t.join()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m     self._wait_for_tstate_lock()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m     elif lock.acquire(block, timeout):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 760, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11783)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m 2022-12-02 05:19:06,533\tERROR worker.py:763 -- Worker exits with an exit code 1.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1032, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m   File \"python/ray/_raylet.pyx\", line 812, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m   File \"python/ray/_raylet.pyx\", line 852, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m   File \"python/ray/_raylet.pyx\", line 859, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m   File \"python/ray/_raylet.pyx\", line 863, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m   File \"python/ray/_raylet.pyx\", line 810, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1328, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1380, in exit_actor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m     ray._private.worker.disconnect()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 2137, in disconnect\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m     worker.import_thread.join_import_thread()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/import_thread.py\", line 61, in join_import_thread\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m     self.t.join()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m     self._wait_for_tstate_lock()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m     elif lock.acquire(block, timeout):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 760, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11808)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m 2022-12-02 05:19:06,563\tERROR worker.py:763 -- Worker exits with an exit code 1.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1032, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m   File \"python/ray/_raylet.pyx\", line 812, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m   File \"python/ray/_raylet.pyx\", line 852, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m   File \"python/ray/_raylet.pyx\", line 859, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m   File \"python/ray/_raylet.pyx\", line 863, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m   File \"python/ray/_raylet.pyx\", line 810, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1328, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1380, in exit_actor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m     ray._private.worker.disconnect()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 2137, in disconnect\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m     worker.import_thread.join_import_thread()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/import_thread.py\", line 61, in join_import_thread\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m     self.t.join()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m     self._wait_for_tstate_lock()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m     elif lock.acquire(block, timeout):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 760, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11803)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m 2022-12-02 05:19:06,547\tERROR worker.py:763 -- Worker exits with an exit code 1.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1032, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m   File \"python/ray/_raylet.pyx\", line 812, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m   File \"python/ray/_raylet.pyx\", line 852, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m   File \"python/ray/_raylet.pyx\", line 859, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m   File \"python/ray/_raylet.pyx\", line 863, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m   File \"python/ray/_raylet.pyx\", line 810, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1328, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1380, in exit_actor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m     ray._private.worker.disconnect()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 2137, in disconnect\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m     worker.import_thread.join_import_thread()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/import_thread.py\", line 61, in join_import_thread\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m     self.t.join()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m     self._wait_for_tstate_lock()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m     elif lock.acquire(block, timeout):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 760, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11812)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m 2022-12-02 05:19:06,563\tERROR worker.py:763 -- Worker exits with an exit code 1.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1032, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m   File \"python/ray/_raylet.pyx\", line 812, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m   File \"python/ray/_raylet.pyx\", line 852, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m   File \"python/ray/_raylet.pyx\", line 859, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m   File \"python/ray/_raylet.pyx\", line 863, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m   File \"python/ray/_raylet.pyx\", line 810, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1328, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1380, in exit_actor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m     ray._private.worker.disconnect()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 2137, in disconnect\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m     worker.import_thread.join_import_thread()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/import_thread.py\", line 61, in join_import_thread\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m     self.t.join()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m     self._wait_for_tstate_lock()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m     elif lock.acquire(block, timeout):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 760, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11773)\u001b[0m SystemExit: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPO pid=13636)\u001b[0m 2022-12-02 05:19:13,711\tINFO algorithm.py:2303 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPO pid=13636)\u001b[0m 2022-12-02 05:19:13,711\tWARNING ppo.py:351 -- `train_batch_size` (6000) cannot be achieved with your other settings (num_workers=30 num_envs_per_worker=2 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 100.\n",
      "\u001b[2m\u001b[36m(PPO pid=13636)\u001b[0m 2022-12-02 05:19:13,711\tINFO ppo.py:379 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(PPO pid=13636)\u001b[0m 2022-12-02 05:19:13,713\tINFO algorithm.py:457 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13666)\u001b[0m 2022-12-02 05:19:26,694\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=13636)\u001b[0m 2022-12-02 05:19:33,796\tINFO trainable.py:164 -- Trainable.setup took 20.087 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(PPO pid=13636)\u001b[0m 2022-12-02 05:19:33,797\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m 2022-12-02 06:09:38,807\tERROR worker.py:763 -- Worker exits with an exit code 1.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1032, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m   File \"python/ray/_raylet.pyx\", line 812, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m   File \"python/ray/_raylet.pyx\", line 852, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m   File \"python/ray/_raylet.pyx\", line 859, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m   File \"python/ray/_raylet.pyx\", line 863, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m   File \"python/ray/_raylet.pyx\", line 810, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1328, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1380, in exit_actor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m     ray._private.worker.disconnect()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 2137, in disconnect\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m     worker.import_thread.join_import_thread()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/import_thread.py\", line 61, in join_import_thread\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m     self.t.join()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m     self._wait_for_tstate_lock()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m     elif lock.acquire(block, timeout):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 760, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13715)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m 2022-12-02 06:09:38,828\tERROR worker.py:763 -- Worker exits with an exit code 1.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1032, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m   File \"python/ray/_raylet.pyx\", line 812, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m   File \"python/ray/_raylet.pyx\", line 852, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m   File \"python/ray/_raylet.pyx\", line 859, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m   File \"python/ray/_raylet.pyx\", line 863, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m   File \"python/ray/_raylet.pyx\", line 810, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1328, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1380, in exit_actor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m     ray._private.worker.disconnect()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 2137, in disconnect\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m     worker.import_thread.join_import_thread()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/import_thread.py\", line 61, in join_import_thread\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m     self.t.join()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m     self._wait_for_tstate_lock()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m     elif lock.acquire(block, timeout):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 760, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13719)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(PPO pid=15530)\u001b[0m 2022-12-02 06:09:46,237\tINFO algorithm.py:2303 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPO pid=15530)\u001b[0m 2022-12-02 06:09:46,237\tWARNING ppo.py:351 -- `train_batch_size` (4000) cannot be achieved with your other settings (num_workers=30 num_envs_per_worker=2 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 67.\n",
      "\u001b[2m\u001b[36m(PPO pid=15530)\u001b[0m 2022-12-02 06:09:46,238\tINFO ppo.py:379 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(PPO pid=15530)\u001b[0m 2022-12-02 06:09:46,239\tINFO algorithm.py:457 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=15561)\u001b[0m 2022-12-02 06:09:58,435\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=15530)\u001b[0m 2022-12-02 06:10:06,292\tINFO trainable.py:164 -- Trainable.setup took 20.056 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(PPO pid=15530)\u001b[0m 2022-12-02 06:10:06,292\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m 2022-12-02 07:02:17,215\tERROR worker.py:763 -- Worker exits with an exit code 1.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1032, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m   File \"python/ray/_raylet.pyx\", line 812, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m   File \"python/ray/_raylet.pyx\", line 852, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m   File \"python/ray/_raylet.pyx\", line 859, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m   File \"python/ray/_raylet.pyx\", line 863, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m   File \"python/ray/_raylet.pyx\", line 810, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1328, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1380, in exit_actor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m     ray._private.worker.disconnect()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 2137, in disconnect\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m     worker.import_thread.join_import_thread()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/import_thread.py\", line 61, in join_import_thread\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m     self.t.join()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m     self._wait_for_tstate_lock()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m     elif lock.acquire(block, timeout):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 760, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15597)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(PPO pid=17507)\u001b[0m 2022-12-02 07:02:24,691\tINFO algorithm.py:2303 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPO pid=17507)\u001b[0m 2022-12-02 07:02:24,692\tWARNING ppo.py:351 -- `train_batch_size` (4000) cannot be achieved with your other settings (num_workers=30 num_envs_per_worker=2 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 67.\n",
      "\u001b[2m\u001b[36m(PPO pid=17507)\u001b[0m 2022-12-02 07:02:24,692\tINFO ppo.py:379 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(PPO pid=17507)\u001b[0m 2022-12-02 07:02:24,694\tINFO algorithm.py:457 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17538)\u001b[0m 2022-12-02 07:02:36,819\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=17507)\u001b[0m 2022-12-02 07:02:45,003\tINFO trainable.py:164 -- Trainable.setup took 20.313 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(PPO pid=17507)\u001b[0m 2022-12-02 07:02:45,004\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m 2022-12-02 07:54:46,083\tERROR worker.py:763 -- Worker exits with an exit code 1.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1032, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m   File \"python/ray/_raylet.pyx\", line 812, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m   File \"python/ray/_raylet.pyx\", line 852, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m   File \"python/ray/_raylet.pyx\", line 859, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m   File \"python/ray/_raylet.pyx\", line 863, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m   File \"python/ray/_raylet.pyx\", line 810, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1328, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1380, in exit_actor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m     ray._private.worker.disconnect()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 2137, in disconnect\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m     worker.import_thread.join_import_thread()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/import_thread.py\", line 61, in join_import_thread\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m     self.t.join()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m     self._wait_for_tstate_lock()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m     elif lock.acquire(block, timeout):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 760, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17564)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m 2022-12-02 07:54:46,134\tERROR worker.py:763 -- Worker exits with an exit code 1.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1032, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m   File \"python/ray/_raylet.pyx\", line 812, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m   File \"python/ray/_raylet.pyx\", line 852, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m   File \"python/ray/_raylet.pyx\", line 859, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m   File \"python/ray/_raylet.pyx\", line 863, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m   File \"python/ray/_raylet.pyx\", line 810, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1328, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1380, in exit_actor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m     ray._private.worker.disconnect()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 2137, in disconnect\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m     worker.import_thread.join_import_thread()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/import_thread.py\", line 61, in join_import_thread\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m     self.t.join()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m     self._wait_for_tstate_lock()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m     elif lock.acquire(block, timeout):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 760, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17576)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m 2022-12-02 07:54:46,160\tERROR worker.py:763 -- Worker exits with an exit code 1.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1032, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m   File \"python/ray/_raylet.pyx\", line 812, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m   File \"python/ray/_raylet.pyx\", line 852, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m   File \"python/ray/_raylet.pyx\", line 859, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m   File \"python/ray/_raylet.pyx\", line 863, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m   File \"python/ray/_raylet.pyx\", line 810, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1328, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1380, in exit_actor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m     ray._private.worker.disconnect()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 2137, in disconnect\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m     worker.import_thread.join_import_thread()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/import_thread.py\", line 61, in join_import_thread\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m     self.t.join()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m     self._wait_for_tstate_lock()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m     elif lock.acquire(block, timeout):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 760, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=17544)\u001b[0m SystemExit: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPO pid=19413)\u001b[0m 2022-12-02 07:54:53,865\tINFO algorithm.py:2303 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPO pid=19413)\u001b[0m 2022-12-02 07:54:53,865\tWARNING ppo.py:351 -- `train_batch_size` (4000) cannot be achieved with your other settings (num_workers=30 num_envs_per_worker=2 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 67.\n",
      "\u001b[2m\u001b[36m(PPO pid=19413)\u001b[0m 2022-12-02 07:54:53,866\tINFO ppo.py:379 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(PPO pid=19413)\u001b[0m 2022-12-02 07:54:53,867\tINFO algorithm.py:457 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19443)\u001b[0m 2022-12-02 07:55:06,134\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=19413)\u001b[0m 2022-12-02 07:55:14,113\tINFO trainable.py:164 -- Trainable.setup took 20.250 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(PPO pid=19413)\u001b[0m 2022-12-02 07:55:14,114\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m 2022-12-02 08:47:43,767\tERROR worker.py:763 -- Worker exits with an exit code 1.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1032, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m   File \"python/ray/_raylet.pyx\", line 812, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m   File \"python/ray/_raylet.pyx\", line 852, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m   File \"python/ray/_raylet.pyx\", line 859, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m   File \"python/ray/_raylet.pyx\", line 863, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m   File \"python/ray/_raylet.pyx\", line 810, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1328, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1380, in exit_actor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m     ray._private.worker.disconnect()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 2137, in disconnect\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m     worker.import_thread.join_import_thread()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/import_thread.py\", line 61, in join_import_thread\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m     self.t.join()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m     self._wait_for_tstate_lock()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m     elif lock.acquire(block, timeout):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 760, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19449)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(PPO pid=21377)\u001b[0m 2022-12-02 08:47:50,930\tINFO algorithm.py:2303 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPO pid=21377)\u001b[0m 2022-12-02 08:47:50,931\tWARNING ppo.py:351 -- `train_batch_size` (4000) cannot be achieved with your other settings (num_workers=30 num_envs_per_worker=2 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 67.\n",
      "\u001b[2m\u001b[36m(PPO pid=21377)\u001b[0m 2022-12-02 08:47:50,931\tINFO ppo.py:379 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(PPO pid=21377)\u001b[0m 2022-12-02 08:47:50,933\tINFO algorithm.py:457 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21407)\u001b[0m 2022-12-02 08:48:03,891\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=21377)\u001b[0m 2022-12-02 08:48:12,326\tINFO trainable.py:164 -- Trainable.setup took 21.398 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(PPO pid=21377)\u001b[0m 2022-12-02 08:48:12,327\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m 2022-12-02 09:39:53,801\tERROR worker.py:763 -- Worker exits with an exit code 1.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1032, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m   File \"python/ray/_raylet.pyx\", line 812, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m   File \"python/ray/_raylet.pyx\", line 852, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m   File \"python/ray/_raylet.pyx\", line 859, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m   File \"python/ray/_raylet.pyx\", line 863, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m   File \"python/ray/_raylet.pyx\", line 810, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1328, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/actor.py\", line 1380, in exit_actor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m     ray._private.worker.disconnect()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 2137, in disconnect\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m     worker.import_thread.join_import_thread()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/import_thread.py\", line 61, in join_import_thread\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m     self.t.join()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m     self._wait_for_tstate_lock()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m   File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m     elif lock.acquire(block, timeout):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m   File \"/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\", line 760, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21459)\u001b[0m SystemExit: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPO pid=23250)\u001b[0m 2022-12-02 09:40:01,520\tINFO algorithm.py:2303 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPO pid=23250)\u001b[0m 2022-12-02 09:40:01,520\tWARNING ppo.py:351 -- `train_batch_size` (4000) cannot be achieved with your other settings (num_workers=30 num_envs_per_worker=2 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 67.\n",
      "\u001b[2m\u001b[36m(PPO pid=23250)\u001b[0m 2022-12-02 09:40:01,521\tINFO ppo.py:379 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(PPO pid=23250)\u001b[0m 2022-12-02 09:40:01,522\tINFO algorithm.py:457 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=23280)\u001b[0m 2022-12-02 09:40:13,592\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=23250)\u001b[0m 2022-12-02 09:40:21,111\tINFO trainable.py:164 -- Trainable.setup took 19.593 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(PPO pid=23250)\u001b[0m 2022-12-02 09:40:21,112\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPO pid=25182)\u001b[0m 2022-12-02 10:30:30,935\tINFO algorithm.py:2303 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPO pid=25182)\u001b[0m 2022-12-02 10:30:30,935\tWARNING ppo.py:351 -- `train_batch_size` (4000) cannot be achieved with your other settings (num_workers=30 num_envs_per_worker=2 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 67.\n",
      "\u001b[2m\u001b[36m(PPO pid=25182)\u001b[0m 2022-12-02 10:30:30,935\tINFO ppo.py:379 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(PPO pid=25182)\u001b[0m 2022-12-02 10:30:30,937\tINFO algorithm.py:457 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=25213)\u001b[0m 2022-12-02 10:30:43,768\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(PPO pid=25182)\u001b[0m 2022-12-02 10:30:51,032\tINFO trainable.py:164 -- Trainable.setup took 20.099 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(PPO pid=25182)\u001b[0m 2022-12-02 10:30:51,033\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "from ray import air, tune\n",
    "\n",
    "tune.Tuner(\n",
    "        \"PPO\",\n",
    "        run_config=air.RunConfig(\n",
    "            stop={\"timesteps_total\": 1.5e6},\n",
    "            local_dir='results/APPO', name=\"tune\",\n",
    "            checkpoint_config=air.CheckpointConfig(\n",
    "                checkpoint_frequency=500, \n",
    "            ),\n",
    "        ),\n",
    "        param_space={\n",
    "            # CC3 specific.\n",
    "            \"env\": \"CybORG\",\n",
    "            # General\n",
    "            \"num_gpus\": 1,\n",
    "            \"num_workers\": 30,\n",
    "            \"horizon\": 100,\n",
    "            \"num_envs_per_worker\": 2,\n",
    "            #algo params\n",
    "            \"train_batch_size\": tune.grid_search([6000, 4000, 2000]),\n",
    "            \"lr\": tune.grid_search([0.0005, 0.0001]),\n",
    "            \"gamma\": tune.grid_search([0.97]),\n",
    "            \"framework\": 'tf',\n",
    "            \"model\": {\n",
    "                    \"fcnet_hiddens\": tune.grid_search([[512, 512],[256, 256]]),\n",
    "                    \"fcnet_activation\": tune.grid_search([\"relu\", \"tanh\"])\n",
    "                },\n",
    "            \n",
    " \n",
    "        },\n",
    "    ).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = str(inspect.getfile(CybORG))\n",
    "path = path[:-10] + '/Shared/Scenarios/Scenario2.yaml'\n",
    "agents = {\"Red\": B_lineAgent, \"Green\": GreenAgent}\n",
    "cyborg = CybORG(scenario_file=path, environment='sim', agents=agents)\n",
    "env = RLlibWrapper(env=cyborg, agent_name=\"Blue\", max_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
