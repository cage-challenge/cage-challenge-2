{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if (distutils.version.LooseVersion(tf.__version__) <\n",
      "2023-02-09 16:55:20,279\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[2m\u001b[36m(pid=12047)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=12047)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=12057)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=12057)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=12048)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=12048)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=12053)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=12053)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=12059)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=12059)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=12049)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=12049)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=12061)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=12061)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=12051)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=12051)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=12055)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=12055)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=12050)\u001b[0m /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=12050)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "2023-02-09 16:55:40,514\tINFO trainable.py:172 -- Trainable.setup took 23.262 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2023-02-09 16:55:40,879\tERROR actor_manager.py:486 -- Ray error, taking actor 1 out of service. \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=12047, ip=192.168.224.2, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f3d43210bb0>)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/utils/actor_manager.py\", line 183, in apply\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/utils/actor_manager.py\", line 174, in apply\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/execution/rollout_ops.py\", line 86, in <lambda>\n",
      "    lambda w: w.sample(), local_worker=False, healthy_only=True\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/rollout_worker.py\", line 900, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 285, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 721, in _env_runner\n",
      "    base_env.send_actions(actions_to_send)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 396, in send_actions\n",
      "    ) = self.vector_env.vector_step(action_vector)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 309, in vector_step\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 302, in vector_step\n",
      "    obs, r, done, info = self.envs[i].step(actions[i])\n",
      "  File \"/app/CybORG/Agents/Wrappers/rllib_wrapper.py\", line 14, in step\n",
      "    obs, reward, done, info = self.env.step(action=action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/OpenAIGymWrapper.py\", line 27, in step\n",
      "    result = self.env.step(self.agent_name, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/EnumActionWrapper.py\", line 20, in step\n",
      "    return super().step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BaseWrapper.py\", line 16, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BlueTableWrapper.py\", line 29, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BaseWrapper.py\", line 16, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/CybORG.py\", line 104, in step\n",
      "    obs_dict = self.environment_controller.step(agent, action, skip_valid_action_check)\n",
      "  File \"/app/CybORG/Shared/EnvironmentController.py\", line 558, in step\n",
      "    self.record_additional_states(true_obs_pre_any_actions, true_obs_post_blue_action, true_obs_post_all_actions, afterstate_vector)\n",
      "  File \"/app/CybORG/Shared/EnvironmentController.py\", line 435, in record_additional_states\n",
      "    assert last_red.shape == (36,)\n",
      "AssertionError\n",
      "2023-02-09 16:55:40,880\tERROR actor_manager.py:486 -- Ray error, taking actor 2 out of service. \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=12048, ip=192.168.224.2, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f21fc506a00>)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/utils/actor_manager.py\", line 183, in apply\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/utils/actor_manager.py\", line 174, in apply\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/execution/rollout_ops.py\", line 86, in <lambda>\n",
      "    lambda w: w.sample(), local_worker=False, healthy_only=True\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/rollout_worker.py\", line 900, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 285, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 721, in _env_runner\n",
      "    base_env.send_actions(actions_to_send)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 396, in send_actions\n",
      "    ) = self.vector_env.vector_step(action_vector)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 309, in vector_step\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 302, in vector_step\n",
      "    obs, r, done, info = self.envs[i].step(actions[i])\n",
      "  File \"/app/CybORG/Agents/Wrappers/rllib_wrapper.py\", line 14, in step\n",
      "    obs, reward, done, info = self.env.step(action=action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/OpenAIGymWrapper.py\", line 27, in step\n",
      "    result = self.env.step(self.agent_name, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/EnumActionWrapper.py\", line 20, in step\n",
      "    return super().step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BaseWrapper.py\", line 16, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BlueTableWrapper.py\", line 29, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BaseWrapper.py\", line 16, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/CybORG.py\", line 104, in step\n",
      "    obs_dict = self.environment_controller.step(agent, action, skip_valid_action_check)\n",
      "  File \"/app/CybORG/Shared/EnvironmentController.py\", line 558, in step\n",
      "    self.record_additional_states(true_obs_pre_any_actions, true_obs_post_blue_action, true_obs_post_all_actions, afterstate_vector)\n",
      "  File \"/app/CybORG/Shared/EnvironmentController.py\", line 435, in record_additional_states\n",
      "    assert last_red.shape == (36,)\n",
      "AssertionError\n",
      "2023-02-09 16:55:40,881\tERROR actor_manager.py:486 -- Ray error, taking actor 3 out of service. \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=12049, ip=192.168.224.2, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fcd8838fa60>)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/utils/actor_manager.py\", line 183, in apply\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/utils/actor_manager.py\", line 174, in apply\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/execution/rollout_ops.py\", line 86, in <lambda>\n",
      "    lambda w: w.sample(), local_worker=False, healthy_only=True\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/rollout_worker.py\", line 900, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 285, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 721, in _env_runner\n",
      "    base_env.send_actions(actions_to_send)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 396, in send_actions\n",
      "    ) = self.vector_env.vector_step(action_vector)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 309, in vector_step\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 302, in vector_step\n",
      "    obs, r, done, info = self.envs[i].step(actions[i])\n",
      "  File \"/app/CybORG/Agents/Wrappers/rllib_wrapper.py\", line 14, in step\n",
      "    obs, reward, done, info = self.env.step(action=action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/OpenAIGymWrapper.py\", line 27, in step\n",
      "    result = self.env.step(self.agent_name, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/EnumActionWrapper.py\", line 20, in step\n",
      "    return super().step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BaseWrapper.py\", line 16, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BlueTableWrapper.py\", line 29, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BaseWrapper.py\", line 16, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/CybORG.py\", line 104, in step\n",
      "    obs_dict = self.environment_controller.step(agent, action, skip_valid_action_check)\n",
      "  File \"/app/CybORG/Shared/EnvironmentController.py\", line 558, in step\n",
      "    self.record_additional_states(true_obs_pre_any_actions, true_obs_post_blue_action, true_obs_post_all_actions, afterstate_vector)\n",
      "  File \"/app/CybORG/Shared/EnvironmentController.py\", line 435, in record_additional_states\n",
      "    assert last_red.shape == (36,)\n",
      "AssertionError\n",
      "2023-02-09 16:55:40,882\tERROR actor_manager.py:486 -- Ray error, taking actor 4 out of service. \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=12050, ip=192.168.224.2, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fbeba112ac0>)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/utils/actor_manager.py\", line 183, in apply\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/utils/actor_manager.py\", line 174, in apply\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/execution/rollout_ops.py\", line 86, in <lambda>\n",
      "    lambda w: w.sample(), local_worker=False, healthy_only=True\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/rollout_worker.py\", line 900, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 285, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 721, in _env_runner\n",
      "    base_env.send_actions(actions_to_send)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 396, in send_actions\n",
      "    ) = self.vector_env.vector_step(action_vector)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 309, in vector_step\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 302, in vector_step\n",
      "    obs, r, done, info = self.envs[i].step(actions[i])\n",
      "  File \"/app/CybORG/Agents/Wrappers/rllib_wrapper.py\", line 14, in step\n",
      "    obs, reward, done, info = self.env.step(action=action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/OpenAIGymWrapper.py\", line 27, in step\n",
      "    result = self.env.step(self.agent_name, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/EnumActionWrapper.py\", line 20, in step\n",
      "    return super().step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BaseWrapper.py\", line 16, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BlueTableWrapper.py\", line 29, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BaseWrapper.py\", line 16, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/CybORG.py\", line 104, in step\n",
      "    obs_dict = self.environment_controller.step(agent, action, skip_valid_action_check)\n",
      "  File \"/app/CybORG/Shared/EnvironmentController.py\", line 558, in step\n",
      "    self.record_additional_states(true_obs_pre_any_actions, true_obs_post_blue_action, true_obs_post_all_actions, afterstate_vector)\n",
      "  File \"/app/CybORG/Shared/EnvironmentController.py\", line 435, in record_additional_states\n",
      "    assert last_red.shape == (36,)\n",
      "AssertionError\n",
      "2023-02-09 16:55:40,882\tERROR actor_manager.py:486 -- Ray error, taking actor 5 out of service. \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=12051, ip=192.168.224.2, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f6f56191be0>)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/utils/actor_manager.py\", line 183, in apply\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/utils/actor_manager.py\", line 174, in apply\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/execution/rollout_ops.py\", line 86, in <lambda>\n",
      "    lambda w: w.sample(), local_worker=False, healthy_only=True\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/rollout_worker.py\", line 900, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 285, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 721, in _env_runner\n",
      "    base_env.send_actions(actions_to_send)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 396, in send_actions\n",
      "    ) = self.vector_env.vector_step(action_vector)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 309, in vector_step\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 302, in vector_step\n",
      "    obs, r, done, info = self.envs[i].step(actions[i])\n",
      "  File \"/app/CybORG/Agents/Wrappers/rllib_wrapper.py\", line 14, in step\n",
      "    obs, reward, done, info = self.env.step(action=action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/OpenAIGymWrapper.py\", line 27, in step\n",
      "    result = self.env.step(self.agent_name, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/EnumActionWrapper.py\", line 20, in step\n",
      "    return super().step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BaseWrapper.py\", line 16, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BlueTableWrapper.py\", line 29, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BaseWrapper.py\", line 16, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/CybORG.py\", line 104, in step\n",
      "    obs_dict = self.environment_controller.step(agent, action, skip_valid_action_check)\n",
      "  File \"/app/CybORG/Shared/EnvironmentController.py\", line 558, in step\n",
      "    self.record_additional_states(true_obs_pre_any_actions, true_obs_post_blue_action, true_obs_post_all_actions, afterstate_vector)\n",
      "  File \"/app/CybORG/Shared/EnvironmentController.py\", line 435, in record_additional_states\n",
      "    assert last_red.shape == (36,)\n",
      "AssertionError\n",
      "2023-02-09 16:55:40,883\tERROR actor_manager.py:486 -- Ray error, taking actor 6 out of service. \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=12053, ip=192.168.224.2, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f1a6d73bb20>)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/utils/actor_manager.py\", line 183, in apply\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/utils/actor_manager.py\", line 174, in apply\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/execution/rollout_ops.py\", line 86, in <lambda>\n",
      "    lambda w: w.sample(), local_worker=False, healthy_only=True\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/rollout_worker.py\", line 900, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 285, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 721, in _env_runner\n",
      "    base_env.send_actions(actions_to_send)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 396, in send_actions\n",
      "    ) = self.vector_env.vector_step(action_vector)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 309, in vector_step\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 302, in vector_step\n",
      "    obs, r, done, info = self.envs[i].step(actions[i])\n",
      "  File \"/app/CybORG/Agents/Wrappers/rllib_wrapper.py\", line 14, in step\n",
      "    obs, reward, done, info = self.env.step(action=action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/OpenAIGymWrapper.py\", line 27, in step\n",
      "    result = self.env.step(self.agent_name, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/EnumActionWrapper.py\", line 20, in step\n",
      "    return super().step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BaseWrapper.py\", line 16, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BlueTableWrapper.py\", line 29, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BaseWrapper.py\", line 16, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/CybORG.py\", line 104, in step\n",
      "    obs_dict = self.environment_controller.step(agent, action, skip_valid_action_check)\n",
      "  File \"/app/CybORG/Shared/EnvironmentController.py\", line 558, in step\n",
      "    self.record_additional_states(true_obs_pre_any_actions, true_obs_post_blue_action, true_obs_post_all_actions, afterstate_vector)\n",
      "  File \"/app/CybORG/Shared/EnvironmentController.py\", line 435, in record_additional_states\n",
      "    assert last_red.shape == (36,)\n",
      "AssertionError\n",
      "2023-02-09 16:55:40,883\tERROR actor_manager.py:486 -- Ray error, taking actor 7 out of service. \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=12055, ip=192.168.224.2, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fb59f9d7a60>)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/utils/actor_manager.py\", line 183, in apply\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/utils/actor_manager.py\", line 174, in apply\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/execution/rollout_ops.py\", line 86, in <lambda>\n",
      "    lambda w: w.sample(), local_worker=False, healthy_only=True\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/rollout_worker.py\", line 900, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 285, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 721, in _env_runner\n",
      "    base_env.send_actions(actions_to_send)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 396, in send_actions\n",
      "    ) = self.vector_env.vector_step(action_vector)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 309, in vector_step\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 302, in vector_step\n",
      "    obs, r, done, info = self.envs[i].step(actions[i])\n",
      "  File \"/app/CybORG/Agents/Wrappers/rllib_wrapper.py\", line 14, in step\n",
      "    obs, reward, done, info = self.env.step(action=action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/OpenAIGymWrapper.py\", line 27, in step\n",
      "    result = self.env.step(self.agent_name, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/EnumActionWrapper.py\", line 20, in step\n",
      "    return super().step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BaseWrapper.py\", line 16, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BlueTableWrapper.py\", line 29, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BaseWrapper.py\", line 16, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/CybORG.py\", line 104, in step\n",
      "    obs_dict = self.environment_controller.step(agent, action, skip_valid_action_check)\n",
      "  File \"/app/CybORG/Shared/EnvironmentController.py\", line 558, in step\n",
      "    self.record_additional_states(true_obs_pre_any_actions, true_obs_post_blue_action, true_obs_post_all_actions, afterstate_vector)\n",
      "  File \"/app/CybORG/Shared/EnvironmentController.py\", line 435, in record_additional_states\n",
      "    assert last_red.shape == (36,)\n",
      "AssertionError\n",
      "2023-02-09 16:55:40,884\tERROR actor_manager.py:486 -- Ray error, taking actor 8 out of service. \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=12057, ip=192.168.224.2, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7efc63911ac0>)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/utils/actor_manager.py\", line 183, in apply\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/utils/actor_manager.py\", line 174, in apply\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/execution/rollout_ops.py\", line 86, in <lambda>\n",
      "    lambda w: w.sample(), local_worker=False, healthy_only=True\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/rollout_worker.py\", line 900, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 285, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 721, in _env_runner\n",
      "    base_env.send_actions(actions_to_send)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 396, in send_actions\n",
      "    ) = self.vector_env.vector_step(action_vector)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 309, in vector_step\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 302, in vector_step\n",
      "    obs, r, done, info = self.envs[i].step(actions[i])\n",
      "  File \"/app/CybORG/Agents/Wrappers/rllib_wrapper.py\", line 14, in step\n",
      "    obs, reward, done, info = self.env.step(action=action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/OpenAIGymWrapper.py\", line 27, in step\n",
      "    result = self.env.step(self.agent_name, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/EnumActionWrapper.py\", line 20, in step\n",
      "    return super().step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BaseWrapper.py\", line 16, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BlueTableWrapper.py\", line 29, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BaseWrapper.py\", line 16, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/CybORG.py\", line 104, in step\n",
      "    obs_dict = self.environment_controller.step(agent, action, skip_valid_action_check)\n",
      "  File \"/app/CybORG/Shared/EnvironmentController.py\", line 558, in step\n",
      "    self.record_additional_states(true_obs_pre_any_actions, true_obs_post_blue_action, true_obs_post_all_actions, afterstate_vector)\n",
      "  File \"/app/CybORG/Shared/EnvironmentController.py\", line 435, in record_additional_states\n",
      "    assert last_red.shape == (36,)\n",
      "AssertionError\n",
      "2023-02-09 16:55:40,884\tERROR actor_manager.py:486 -- Ray error, taking actor 9 out of service. \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=12059, ip=192.168.224.2, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f0f54ed4ac0>)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/utils/actor_manager.py\", line 183, in apply\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/utils/actor_manager.py\", line 174, in apply\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/execution/rollout_ops.py\", line 86, in <lambda>\n",
      "    lambda w: w.sample(), local_worker=False, healthy_only=True\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/rollout_worker.py\", line 900, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 285, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 721, in _env_runner\n",
      "    base_env.send_actions(actions_to_send)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 396, in send_actions\n",
      "    ) = self.vector_env.vector_step(action_vector)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 309, in vector_step\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 302, in vector_step\n",
      "    obs, r, done, info = self.envs[i].step(actions[i])\n",
      "  File \"/app/CybORG/Agents/Wrappers/rllib_wrapper.py\", line 14, in step\n",
      "    obs, reward, done, info = self.env.step(action=action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/OpenAIGymWrapper.py\", line 27, in step\n",
      "    result = self.env.step(self.agent_name, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/EnumActionWrapper.py\", line 20, in step\n",
      "    return super().step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BaseWrapper.py\", line 16, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BlueTableWrapper.py\", line 29, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BaseWrapper.py\", line 16, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/CybORG.py\", line 104, in step\n",
      "    obs_dict = self.environment_controller.step(agent, action, skip_valid_action_check)\n",
      "  File \"/app/CybORG/Shared/EnvironmentController.py\", line 558, in step\n",
      "    self.record_additional_states(true_obs_pre_any_actions, true_obs_post_blue_action, true_obs_post_all_actions, afterstate_vector)\n",
      "  File \"/app/CybORG/Shared/EnvironmentController.py\", line 435, in record_additional_states\n",
      "    assert last_red.shape == (36,)\n",
      "AssertionError\n",
      "2023-02-09 16:55:40,885\tERROR actor_manager.py:486 -- Ray error, taking actor 10 out of service. \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=12061, ip=192.168.224.2, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7ff182781a00>)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/utils/actor_manager.py\", line 183, in apply\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/utils/actor_manager.py\", line 174, in apply\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/execution/rollout_ops.py\", line 86, in <lambda>\n",
      "    lambda w: w.sample(), local_worker=False, healthy_only=True\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/rollout_worker.py\", line 900, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 285, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 721, in _env_runner\n",
      "    base_env.send_actions(actions_to_send)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 396, in send_actions\n",
      "    ) = self.vector_env.vector_step(action_vector)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 309, in vector_step\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 302, in vector_step\n",
      "    obs, r, done, info = self.envs[i].step(actions[i])\n",
      "  File \"/app/CybORG/Agents/Wrappers/rllib_wrapper.py\", line 14, in step\n",
      "    obs, reward, done, info = self.env.step(action=action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/OpenAIGymWrapper.py\", line 27, in step\n",
      "    result = self.env.step(self.agent_name, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/EnumActionWrapper.py\", line 20, in step\n",
      "    return super().step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BaseWrapper.py\", line 16, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BlueTableWrapper.py\", line 29, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BaseWrapper.py\", line 16, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/CybORG.py\", line 104, in step\n",
      "    obs_dict = self.environment_controller.step(agent, action, skip_valid_action_check)\n",
      "  File \"/app/CybORG/Shared/EnvironmentController.py\", line 558, in step\n",
      "    self.record_additional_states(true_obs_pre_any_actions, true_obs_post_blue_action, true_obs_post_all_actions, afterstate_vector)\n",
      "  File \"/app/CybORG/Shared/EnvironmentController.py\", line 435, in record_additional_states\n",
      "    assert last_red.shape == (36,)\n",
      "AssertionError\n",
      "Traceback (most recent call last):\n",
      "  File \"PPO_Database.py\", line 188, in <module>\n",
      "    print_results(trainer.train())\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/tune/trainable/trainable.py\", line 367, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/tune/trainable/trainable.py\", line 364, in train\n",
      "    result = self.step()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/algorithms/algorithm.py\", line 749, in step\n",
      "    results, train_iter_ctx = self._run_one_training_iteration()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/algorithms/algorithm.py\", line 2623, in _run_one_training_iteration\n",
      "    results = self.training_step()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/algorithms/ppo/ppo.py\", line 318, in training_step\n",
      "    train_batch = synchronous_parallel_sample(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/execution/rollout_ops.py\", line 85, in synchronous_parallel_sample\n",
      "    sample_batches = worker_set.foreach_worker(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/worker_set.py\", line 696, in foreach_worker\n",
      "    handle_remote_call_result_errors(remote_results, self._ignore_worker_failures)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/worker_set.py\", line 73, in handle_remote_call_result_errors\n",
      "    raise r.get()\n",
      "ray.exceptions.RayTaskError(AssertionError): \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=12047, ip=192.168.224.2, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f3d43210bb0>)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/utils/actor_manager.py\", line 183, in apply\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/utils/actor_manager.py\", line 174, in apply\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/execution/rollout_ops.py\", line 86, in <lambda>\n",
      "    lambda w: w.sample(), local_worker=False, healthy_only=True\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/rollout_worker.py\", line 900, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 285, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/sampler.py\", line 721, in _env_runner\n",
      "    base_env.send_actions(actions_to_send)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 396, in send_actions\n",
      "    ) = self.vector_env.vector_step(action_vector)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 309, in vector_step\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ray/rllib/env/vector_env.py\", line 302, in vector_step\n",
      "    obs, r, done, info = self.envs[i].step(actions[i])\n",
      "  File \"/app/CybORG/Agents/Wrappers/rllib_wrapper.py\", line 14, in step\n",
      "    obs, reward, done, info = self.env.step(action=action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/OpenAIGymWrapper.py\", line 27, in step\n",
      "    result = self.env.step(self.agent_name, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/EnumActionWrapper.py\", line 20, in step\n",
      "    return super().step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BaseWrapper.py\", line 16, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BlueTableWrapper.py\", line 29, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/Agents/Wrappers/BaseWrapper.py\", line 16, in step\n",
      "    result = self.env.step(agent, action)\n",
      "  File \"/app/CybORG/CybORG.py\", line 104, in step\n",
      "    obs_dict = self.environment_controller.step(agent, action, skip_valid_action_check)\n",
      "  File \"/app/CybORG/Shared/EnvironmentController.py\", line 558, in step\n",
      "    self.record_additional_states(true_obs_pre_any_actions, true_obs_post_blue_action, true_obs_post_all_actions, afterstate_vector)\n",
      "  File \"/app/CybORG/Shared/EnvironmentController.py\", line 435, in record_additional_states\n",
      "    assert last_red.shape == (36,)\n",
      "AssertionError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python PPO_Database.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\" in /usr/local/lib/python3.8/dist-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\" in /usr/local/lib/python3.8/dist-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" in /usr/local/lib/python3.8/dist-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" in /usr/local/lib/python3.8/dist-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\"->torch) (65.5.1)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\"->torch) (0.34.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 23.0 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
