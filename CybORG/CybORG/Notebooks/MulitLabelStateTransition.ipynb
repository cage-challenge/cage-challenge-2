{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 09:38:03.792371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-30 09:38:04.010853: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-30 09:38:04.859930: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/adamprice/miniconda3/envs/u75a/lib/\n",
      "2023-03-30 09:38:04.860035: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/adamprice/miniconda3/envs/u75a/lib/\n",
      "2023-03-30 09:38:04.860047: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import pandas as pd\n",
    "#from ProcessTrueStateActionData import read_df_in_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess the data \n",
    "(produce tf train+test datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'logs/APPO/TrueStates_200_4000_B_Line_nodecoys/data/states.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28941/3057809895.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'logs/APPO/TrueStates_200_4000_B_Line_nodecoys/data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/states.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mstates_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/states_t.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mafterstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/afterstates.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/u75a/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'logs/APPO/TrueStates_200_4000_B_Line_nodecoys/data/states.npy'"
     ]
    }
   ],
   "source": [
    "train_test_split = 0.95\n",
    "\n",
    "data_path = 'logs/PPO/no_decoy_200000/data'\n",
    "states = np.load(data_path + '/states.npy')\n",
    "states_t = np.load(data_path + '/states_t.npy')\n",
    "afterstates = np.load(data_path + '/afterstates.npy')\n",
    "next_states = np.load(data_path + '/next_states.npy')\n",
    "next_states_t = np.load(data_path + '/next_states_t.npy')\n",
    "actions = np.load(data_path + '/actions_onehot.npy')\n",
    "rewards = np.load(data_path + '/rewards.npy')\n",
    "\n",
    "states_actions = np.concatenate([states, actions], axis=1)\n",
    "states_actions_t = np.concatenate([states_t, actions], axis=1)\n",
    "next_states_delta = next_states - states\n",
    "\n",
    "afterstates = np.array(afterstates, dtype=np.float32)\n",
    "next_states = np.array(next_states, dtype=np.float32)\n",
    "states_actions = np.array(states_actions, dtype=np.float32)\n",
    "\n",
    "divide = int(train_test_split * afterstates.shape[0])\n",
    "afterstates_train = afterstates[:divide,:]\n",
    "next_states_train = next_states[:divide,:]\n",
    "afterstates_test = afterstates[divide:,:]\n",
    "next_states_test = next_states[divide:,:]\n",
    "print(afterstates.shape[0] - divide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_LEN = 41\n",
    "STATE_LEN = 91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afterstates.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'logs/APPO/TrueStates_200_4000_B_Line_nodecoys/data/states_seq.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m states_seq \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/states_seq.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m actions_seq \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(data_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/actions_onehot_seq.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m states_actions_seq \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([states_seq, actions_seq], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py:390\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    388\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    391\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'logs/APPO/TrueStates_200_4000_B_Line_nodecoys/data/states_seq.npy'"
     ]
    }
   ],
   "source": [
    "states_seq = np.load(data_path + '/states_seq.npy')\n",
    "actions_seq = np.load(data_path + '/actions_onehot_seq.npy')\n",
    "\n",
    "states_actions_seq = np.concatenate([states_seq, actions_seq], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_seq_10 = np.load(data_path + '/states_seq_10.npy')\n",
    "actions_seq_10 = np.load(data_path + '/actions_onehot_seq_10.npy')\n",
    "\n",
    "states_actions_seq_10 = np.concatenate([states_seq_10, actions_seq_10], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM, Input\n",
    "from keras.layers import Bidirectional\n",
    "from keras.models import Model\n",
    "\n",
    "NUM_NODES = 6\n",
    "NODE_CLASSES = [3, 4]\n",
    "\n",
    "data_map = {}\n",
    "losses = []\n",
    "index = 0\n",
    "for i in range(NUM_NODES):\n",
    "    for n in NODE_CLASSES:\n",
    "        data_map[str(i)+str(n)] = next_states[:,index:index+n]\n",
    "        losses.append(tf.keras.losses.CategoricalCrossentropy())\n",
    "        index += n\n",
    "        \n",
    "input_ = Input(shape=(42+20,))\n",
    "x = Dense(512, activation='relu')(input_)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "\n",
    "outs = []\n",
    "for i in range(NUM_NODES):\n",
    "    for n in NODE_CLASSES:\n",
    "        x_ = Dense(128, activation='relu')(x)\n",
    "        outs.append(Dense(n, activation='softmax', name=str(i)+str(n))(x_))\n",
    "\n",
    "model = Model(input_, outs)\n",
    "model.compile(optimizer='adam', loss=losses, metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='54_categorical_accuracy', patience=7)\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_value(model.optimizer.learning_rate, 0.0005)\n",
    "\n",
    "#model.fit(train_dataset,epochs=250, verbose=1, callbacks=[callback])\n",
    "\n",
    "model.fit(states_actions, data_map, epochs=50, validation_split=0.1, verbose=1, callbacks=[callback], batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 133)]        0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 128)          17152       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " 03 (Dense)                     (None, 3)            387         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " 04 (Dense)                     (None, 4)            516         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " 13 (Dense)                     (None, 3)            387         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " 14 (Dense)                     (None, 4)            516         ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " 23 (Dense)                     (None, 3)            387         ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " 24 (Dense)                     (None, 4)            516         ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " 33 (Dense)                     (None, 3)            387         ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " 34 (Dense)                     (None, 4)            516         ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " 43 (Dense)                     (None, 3)            387         ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " 44 (Dense)                     (None, 4)            516         ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " 53 (Dense)                     (None, 3)            387         ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " 54 (Dense)                     (None, 4)            516         ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " 63 (Dense)                     (None, 3)            387         ['dense_12[0][0]']               \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64 (Dense)                     (None, 4)            516         ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " 73 (Dense)                     (None, 3)            387         ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " 74 (Dense)                     (None, 4)            516         ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " 83 (Dense)                     (None, 3)            387         ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " 84 (Dense)                     (None, 4)            516         ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " 93 (Dense)                     (None, 3)            387         ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " 94 (Dense)                     (None, 4)            516         ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " 103 (Dense)                    (None, 3)            387         ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " 104 (Dense)                    (None, 4)            516         ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " 113 (Dense)                    (None, 3)            387         ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " 114 (Dense)                    (None, 4)            516         ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " 123 (Dense)                    (None, 3)            387         ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " 124 (Dense)                    (None, 4)            516         ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 457,691\n",
      "Trainable params: 457,691\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## from keras.layers import Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM, Input\n",
    "from keras.layers import Bidirectional\n",
    "from keras.models import Model\n",
    "\n",
    "NUM_NODES = 13\n",
    "NODE_CLASSES = [3, 4]\n",
    "\n",
    "data_map = {}\n",
    "losses = []\n",
    "index = 0\n",
    "for i in range(NUM_NODES):\n",
    "    for n in NODE_CLASSES:\n",
    "        #data_map[str(i)+str(n)] = next_states[:,index:index+n]\n",
    "        losses.append(tf.keras.losses.CategoricalCrossentropy())\n",
    "        index += n\n",
    "        \n",
    "input_ = Input(shape=(91+41+1,))\n",
    "#x = Dense(512, activation='relu')(input_)\n",
    "#x = Dense(512, activation='relu')(x)\n",
    "outs = []\n",
    "for i in range(NUM_NODES):\n",
    "    for n in NODE_CLASSES:\n",
    "        x_ = Dense(128, activation='relu')(input_)\n",
    "        outs.append(Dense(n, activation='softmax', name=str(i)+str(n))(x_))\n",
    "\n",
    "model = Model(input_, outs)\n",
    "model.compile(optimizer='adam', loss=losses, metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "model.summary()\n",
    "#callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "#from keras import backend as K\n",
    "#K.set_value(model.optimizer.learning_rate, 0.0005)\n",
    "\n",
    "#model.fit(train_dataset,epochs=250, verbose=1, callbacks=[callback])\n",
    "\n",
    "#model.fit(states_actions_t, data_map, epochs=200, validation_split=0.1, verbose=1, callbacks=[callback], batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.56\n",
    "model.save_weights('AfterStateModel_MulitLabel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "697/697 [==============================] - 58s 47ms/step - loss: 8.1866 - 03_loss: 0.0029 - 04_loss: 0.0035 - 13_loss: 0.3314 - 14_loss: 0.1877 - 23_loss: 0.4319 - 24_loss: 0.5159 - 33_loss: 0.8464 - 34_loss: 1.0939 - 43_loss: 0.0022 - 44_loss: 0.0033 - 53_loss: 0.0023 - 54_loss: 0.0034 - 63_loss: 0.0026 - 64_loss: 0.0031 - 73_loss: 0.2563 - 74_loss: 0.2695 - 83_loss: 0.2401 - 84_loss: 0.0032 - 93_loss: 0.2629 - 94_loss: 0.7452 - 103_loss: 0.2714 - 104_loss: 0.7581 - 113_loss: 0.2622 - 114_loss: 0.7306 - 123_loss: 0.2656 - 124_loss: 0.6913 - 03_categorical_accuracy: 0.9986 - 04_categorical_accuracy: 0.9986 - 13_categorical_accuracy: 0.9149 - 14_categorical_accuracy: 0.9567 - 23_categorical_accuracy: 0.8844 - 24_categorical_accuracy: 0.8692 - 33_categorical_accuracy: 0.6544 - 34_categorical_accuracy: 0.4618 - 43_categorical_accuracy: 0.9998 - 44_categorical_accuracy: 0.9987 - 53_categorical_accuracy: 0.9994 - 54_categorical_accuracy: 0.9986 - 63_categorical_accuracy: 0.9986 - 64_categorical_accuracy: 0.9986 - 73_categorical_accuracy: 0.9394 - 74_categorical_accuracy: 0.9426 - 83_categorical_accuracy: 0.9363 - 84_categorical_accuracy: 0.9989 - 93_categorical_accuracy: 0.9308 - 94_categorical_accuracy: 0.7702 - 103_categorical_accuracy: 0.9286 - 104_categorical_accuracy: 0.7775 - 113_categorical_accuracy: 0.9293 - 114_categorical_accuracy: 0.7747 - 123_categorical_accuracy: 0.9288 - 124_categorical_accuracy: 0.7969 - val_loss: 8.1844 - val_03_loss: 2.0091e-08 - val_04_loss: 1.7701e-08 - val_13_loss: 0.3226 - val_14_loss: 0.1935 - val_23_loss: 0.4181 - val_24_loss: 0.5196 - val_33_loss: 0.8367 - val_34_loss: 1.0979 - val_43_loss: 3.0638e-06 - val_44_loss: 1.3860e-08 - val_53_loss: 4.9129e-08 - val_54_loss: 5.8997e-08 - val_63_loss: 1.4913e-08 - val_64_loss: 2.8345e-08 - val_73_loss: 0.2368 - val_74_loss: 0.3265 - val_83_loss: 0.2257 - val_84_loss: 1.3456e-08 - val_93_loss: 0.2606 - val_94_loss: 0.7855 - val_103_loss: 0.2620 - val_104_loss: 0.7722 - val_113_loss: 0.2556 - val_114_loss: 0.7771 - val_123_loss: 0.2503 - val_124_loss: 0.6436 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9129 - val_14_categorical_accuracy: 0.9554 - val_23_categorical_accuracy: 0.8862 - val_24_categorical_accuracy: 0.8644 - val_33_categorical_accuracy: 0.6565 - val_34_categorical_accuracy: 0.4674 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9439 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9409 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9292 - val_94_categorical_accuracy: 0.7526 - val_103_categorical_accuracy: 0.9299 - val_104_categorical_accuracy: 0.7784 - val_113_categorical_accuracy: 0.9307 - val_114_categorical_accuracy: 0.7704 - val_123_categorical_accuracy: 0.9322 - val_124_categorical_accuracy: 0.8320\n",
      "Epoch 2/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 7.8840 - 03_loss: 1.2133e-08 - 04_loss: 1.0854e-08 - 13_loss: 0.3165 - 14_loss: 0.1728 - 23_loss: 0.4153 - 24_loss: 0.4944 - 33_loss: 0.8251 - 34_loss: 1.0587 - 43_loss: 1.8267e-06 - 44_loss: 8.8390e-09 - 53_loss: 2.2473e-08 - 54_loss: 3.1073e-08 - 63_loss: 9.0016e-09 - 64_loss: 1.6008e-08 - 73_loss: 0.2488 - 74_loss: 0.2579 - 83_loss: 0.2348 - 84_loss: 8.9695e-09 - 93_loss: 0.2546 - 94_loss: 0.7223 - 103_loss: 0.2624 - 104_loss: 0.7332 - 113_loss: 0.2531 - 114_loss: 0.7058 - 123_loss: 0.2558 - 124_loss: 0.6723 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9159 - 14_categorical_accuracy: 0.9578 - 23_categorical_accuracy: 0.8854 - 24_categorical_accuracy: 0.8702 - 33_categorical_accuracy: 0.6569 - 34_categorical_accuracy: 0.4782 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9407 - 74_categorical_accuracy: 0.9431 - 83_categorical_accuracy: 0.9376 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9320 - 94_categorical_accuracy: 0.7704 - 103_categorical_accuracy: 0.9295 - 104_categorical_accuracy: 0.7780 - 113_categorical_accuracy: 0.9305 - 114_categorical_accuracy: 0.7757 - 123_categorical_accuracy: 0.9296 - 124_categorical_accuracy: 0.7974 - val_loss: 8.1681 - val_03_loss: 7.3091e-09 - val_04_loss: 7.0141e-09 - val_13_loss: 0.3149 - val_14_loss: 0.1928 - val_23_loss: 0.4124 - val_24_loss: 0.5193 - val_33_loss: 0.8219 - val_34_loss: 1.0948 - val_43_loss: 1.2982e-06 - val_44_loss: 5.4909e-09 - val_53_loss: 1.4642e-08 - val_54_loss: 1.9290e-08 - val_63_loss: 4.8828e-09 - val_64_loss: 1.0398e-08 - val_73_loss: 0.2350 - val_74_loss: 0.3290 - val_83_loss: 0.2277 - val_84_loss: 5.2681e-09 - val_93_loss: 0.2632 - val_94_loss: 0.7775 - val_103_loss: 0.2633 - val_104_loss: 0.7726 - val_113_loss: 0.2528 - val_114_loss: 0.7957 - val_123_loss: 0.2502 - val_124_loss: 0.6452 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9153 - val_14_categorical_accuracy: 0.9567 - val_23_categorical_accuracy: 0.8862 - val_24_categorical_accuracy: 0.8646 - val_33_categorical_accuracy: 0.6571 - val_34_categorical_accuracy: 0.4709 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9439 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9409 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9292 - val_94_categorical_accuracy: 0.7526 - val_103_categorical_accuracy: 0.9299 - val_104_categorical_accuracy: 0.7691 - val_113_categorical_accuracy: 0.9311 - val_114_categorical_accuracy: 0.7712 - val_123_categorical_accuracy: 0.9316 - val_124_categorical_accuracy: 0.8319\n",
      "Epoch 3/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 7.7846 - 03_loss: 5.0360e-09 - 04_loss: 5.0085e-09 - 13_loss: 0.3144 - 14_loss: 0.1688 - 23_loss: 0.4108 - 24_loss: 0.4875 - 33_loss: 0.8174 - 34_loss: 1.0441 - 43_loss: 1.0863e-06 - 44_loss: 3.8358e-09 - 53_loss: 8.5386e-09 - 54_loss: 1.2901e-08 - 63_loss: 3.8445e-09 - 64_loss: 6.7619e-09 - 73_loss: 0.2476 - 74_loss: 0.2524 - 83_loss: 0.2344 - 84_loss: 3.7669e-09 - 93_loss: 0.2540 - 94_loss: 0.7107 - 103_loss: 0.2621 - 104_loss: 0.7205 - 113_loss: 0.2528 - 114_loss: 0.6918 - 123_loss: 0.2556 - 124_loss: 0.6598 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9162 - 14_categorical_accuracy: 0.9579 - 23_categorical_accuracy: 0.8856 - 24_categorical_accuracy: 0.8700 - 33_categorical_accuracy: 0.6577 - 34_categorical_accuracy: 0.4842 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9407 - 74_categorical_accuracy: 0.9431 - 83_categorical_accuracy: 0.9376 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9321 - 94_categorical_accuracy: 0.7704 - 103_categorical_accuracy: 0.9295 - 104_categorical_accuracy: 0.7780 - 113_categorical_accuracy: 0.9306 - 114_categorical_accuracy: 0.7757 - 123_categorical_accuracy: 0.9295 - 124_categorical_accuracy: 0.7973 - val_loss: 8.2158 - val_03_loss: 1.6196e-09 - val_04_loss: 1.6978e-09 - val_13_loss: 0.3158 - val_14_loss: 0.1959 - val_23_loss: 0.4136 - val_24_loss: 0.5180 - val_33_loss: 0.8170 - val_34_loss: 1.0841 - val_43_loss: 4.2358e-07 - val_44_loss: 1.4931e-09 - val_53_loss: 2.6130e-09 - val_54_loss: 3.8352e-09 - val_63_loss: 1.2342e-09 - val_64_loss: 2.3420e-09 - val_73_loss: 0.2348 - val_74_loss: 0.3315 - val_83_loss: 0.2261 - val_84_loss: 1.3426e-09 - val_93_loss: 0.2603 - val_94_loss: 0.7743 - val_103_loss: 0.2625 - val_104_loss: 0.7876 - val_113_loss: 0.2509 - val_114_loss: 0.8368 - val_123_loss: 0.2486 - val_124_loss: 0.6582 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9151 - val_14_categorical_accuracy: 0.9568 - val_23_categorical_accuracy: 0.8866 - val_24_categorical_accuracy: 0.8646 - val_33_categorical_accuracy: 0.6572 - val_34_categorical_accuracy: 0.4717 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9439 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9409 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9292 - val_94_categorical_accuracy: 0.7526 - val_103_categorical_accuracy: 0.9299 - val_104_categorical_accuracy: 0.7703 - val_113_categorical_accuracy: 0.9311 - val_114_categorical_accuracy: 0.7712 - val_123_categorical_accuracy: 0.9322 - val_124_categorical_accuracy: 0.8306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 7.7047 - 03_loss: 4.2733e-09 - 04_loss: 4.2800e-09 - 13_loss: 0.3133 - 14_loss: 0.1654 - 23_loss: 0.4084 - 24_loss: 0.4827 - 33_loss: 0.8128 - 34_loss: 1.0347 - 43_loss: 7.4587e-07 - 44_loss: 3.2177e-09 - 53_loss: 6.7539e-09 - 54_loss: 9.7548e-09 - 63_loss: 3.4539e-09 - 64_loss: 5.3002e-09 - 73_loss: 0.2469 - 74_loss: 0.2467 - 83_loss: 0.2344 - 84_loss: 2.9535e-09 - 93_loss: 0.2534 - 94_loss: 0.7007 - 103_loss: 0.2613 - 104_loss: 0.7081 - 113_loss: 0.2527 - 114_loss: 0.6796 - 123_loss: 0.2552 - 124_loss: 0.6483 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9162 - 14_categorical_accuracy: 0.9581 - 23_categorical_accuracy: 0.8858 - 24_categorical_accuracy: 0.8704 - 33_categorical_accuracy: 0.6579 - 34_categorical_accuracy: 0.4888 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9407 - 74_categorical_accuracy: 0.9431 - 83_categorical_accuracy: 0.9376 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9320 - 94_categorical_accuracy: 0.7704 - 103_categorical_accuracy: 0.9295 - 104_categorical_accuracy: 0.7779 - 113_categorical_accuracy: 0.9306 - 114_categorical_accuracy: 0.7757 - 123_categorical_accuracy: 0.9296 - 124_categorical_accuracy: 0.7976 - val_loss: 8.3569 - val_03_loss: 8.4289e-11 - val_04_loss: 8.4289e-11 - val_13_loss: 0.3146 - val_14_loss: 0.2064 - val_23_loss: 0.4136 - val_24_loss: 0.5200 - val_33_loss: 0.8145 - val_34_loss: 1.0789 - val_43_loss: 2.2057e-07 - val_44_loss: 1.2041e-10 - val_53_loss: 1.3245e-10 - val_54_loss: 2.0470e-10 - val_63_loss: 6.0207e-11 - val_64_loss: 1.3245e-10 - val_73_loss: 0.2347 - val_74_loss: 0.3413 - val_83_loss: 0.2259 - val_84_loss: 9.6331e-11 - val_93_loss: 0.2602 - val_94_loss: 0.7941 - val_103_loss: 0.2608 - val_104_loss: 0.8278 - val_113_loss: 0.2530 - val_114_loss: 0.8546 - val_123_loss: 0.2490 - val_124_loss: 0.7075 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9153 - val_14_categorical_accuracy: 0.9568 - val_23_categorical_accuracy: 0.8867 - val_24_categorical_accuracy: 0.8646 - val_33_categorical_accuracy: 0.6584 - val_34_categorical_accuracy: 0.4770 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9439 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9409 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9292 - val_94_categorical_accuracy: 0.7517 - val_103_categorical_accuracy: 0.9299 - val_104_categorical_accuracy: 0.7674 - val_113_categorical_accuracy: 0.9311 - val_114_categorical_accuracy: 0.7712 - val_123_categorical_accuracy: 0.9322 - val_124_categorical_accuracy: 0.8313\n",
      "Epoch 5/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 7.6322 - 03_loss: 2.7555e-09 - 04_loss: 2.9361e-09 - 13_loss: 0.3126 - 14_loss: 0.1627 - 23_loss: 0.4060 - 24_loss: 0.4780 - 33_loss: 0.8087 - 34_loss: 1.0273 - 43_loss: 5.1265e-07 - 44_loss: 2.3728e-09 - 53_loss: 4.1717e-09 - 54_loss: 5.6982e-09 - 63_loss: 2.4671e-09 - 64_loss: 3.3722e-09 - 73_loss: 0.2453 - 74_loss: 0.2419 - 83_loss: 0.2341 - 84_loss: 2.2123e-09 - 93_loss: 0.2532 - 94_loss: 0.6920 - 103_loss: 0.2610 - 104_loss: 0.6965 - 113_loss: 0.2523 - 114_loss: 0.6693 - 123_loss: 0.2548 - 124_loss: 0.6365 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9164 - 14_categorical_accuracy: 0.9582 - 23_categorical_accuracy: 0.8860 - 24_categorical_accuracy: 0.8702 - 33_categorical_accuracy: 0.6584 - 34_categorical_accuracy: 0.4918 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9407 - 74_categorical_accuracy: 0.9431 - 83_categorical_accuracy: 0.9376 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9321 - 94_categorical_accuracy: 0.7702 - 103_categorical_accuracy: 0.9295 - 104_categorical_accuracy: 0.7781 - 113_categorical_accuracy: 0.9305 - 114_categorical_accuracy: 0.7756 - 123_categorical_accuracy: 0.9296 - 124_categorical_accuracy: 0.7976 - val_loss: 8.5457 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3160 - val_14_loss: 0.2139 - val_23_loss: 0.4120 - val_24_loss: 0.5236 - val_33_loss: 0.8136 - val_34_loss: 1.0772 - val_43_loss: 2.7617e-08 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 6.0207e-12 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2331 - val_74_loss: 0.3681 - val_83_loss: 0.2254 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2606 - val_94_loss: 0.8343 - val_103_loss: 0.2618 - val_104_loss: 0.8363 - val_113_loss: 0.2522 - val_114_loss: 0.9327 - val_123_loss: 0.2491 - val_124_loss: 0.7357 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9154 - val_14_categorical_accuracy: 0.9570 - val_23_categorical_accuracy: 0.8865 - val_24_categorical_accuracy: 0.8637 - val_33_categorical_accuracy: 0.6569 - val_34_categorical_accuracy: 0.4785 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9439 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9409 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9292 - val_94_categorical_accuracy: 0.7501 - val_103_categorical_accuracy: 0.9298 - val_104_categorical_accuracy: 0.7672 - val_113_categorical_accuracy: 0.9311 - val_114_categorical_accuracy: 0.7697 - val_123_categorical_accuracy: 0.9322 - val_124_categorical_accuracy: 0.8275\n",
      "Epoch 6/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 7.5634 - 03_loss: 5.9136e-10 - 04_loss: 7.2248e-10 - 13_loss: 0.3119 - 14_loss: 0.1609 - 23_loss: 0.4036 - 24_loss: 0.4734 - 33_loss: 0.8051 - 34_loss: 1.0202 - 43_loss: 2.7746e-07 - 44_loss: 5.4922e-10 - 53_loss: 8.9039e-10 - 54_loss: 1.6430e-09 - 63_loss: 4.7296e-10 - 64_loss: 9.2451e-10 - 73_loss: 0.2441 - 74_loss: 0.2369 - 83_loss: 0.2337 - 84_loss: 5.6929e-10 - 93_loss: 0.2529 - 94_loss: 0.6825 - 103_loss: 0.2610 - 104_loss: 0.6849 - 113_loss: 0.2518 - 114_loss: 0.6600 - 123_loss: 0.2549 - 124_loss: 0.6255 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9165 - 14_categorical_accuracy: 0.9584 - 23_categorical_accuracy: 0.8863 - 24_categorical_accuracy: 0.8705 - 33_categorical_accuracy: 0.6589 - 34_categorical_accuracy: 0.4951 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9407 - 74_categorical_accuracy: 0.9431 - 83_categorical_accuracy: 0.9376 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9320 - 94_categorical_accuracy: 0.7703 - 103_categorical_accuracy: 0.9294 - 104_categorical_accuracy: 0.7779 - 113_categorical_accuracy: 0.9306 - 114_categorical_accuracy: 0.7756 - 123_categorical_accuracy: 0.9295 - 124_categorical_accuracy: 0.7975 - val_loss: 8.6940 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3160 - val_14_loss: 0.2321 - val_23_loss: 0.4148 - val_24_loss: 0.5320 - val_33_loss: 0.8147 - val_34_loss: 1.1013 - val_43_loss: 2.5227e-09 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2340 - val_74_loss: 0.3791 - val_83_loss: 0.2251 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2601 - val_94_loss: 0.8307 - val_103_loss: 0.2667 - val_104_loss: 0.8903 - val_113_loss: 0.2517 - val_114_loss: 0.9469 - val_123_loss: 0.2504 - val_124_loss: 0.7480 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9149 - val_14_categorical_accuracy: 0.9562 - val_23_categorical_accuracy: 0.8866 - val_24_categorical_accuracy: 0.8641 - val_33_categorical_accuracy: 0.6578 - val_34_categorical_accuracy: 0.4615 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9439 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9409 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9292 - val_94_categorical_accuracy: 0.7510 - val_103_categorical_accuracy: 0.9299 - val_104_categorical_accuracy: 0.7637 - val_113_categorical_accuracy: 0.9311 - val_114_categorical_accuracy: 0.7714 - val_123_categorical_accuracy: 0.9322 - val_124_categorical_accuracy: 0.8304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 7.5022 - 03_loss: 4.8232e-10 - 04_loss: 5.2045e-10 - 13_loss: 0.3109 - 14_loss: 0.1587 - 23_loss: 0.4020 - 24_loss: 0.4691 - 33_loss: 0.8018 - 34_loss: 1.0145 - 43_loss: 1.6056e-07 - 44_loss: 4.0740e-10 - 53_loss: 5.4186e-10 - 54_loss: 8.0878e-10 - 63_loss: 3.6927e-10 - 64_loss: 5.5591e-10 - 73_loss: 0.2435 - 74_loss: 0.2329 - 83_loss: 0.2336 - 84_loss: 4.0740e-10 - 93_loss: 0.2525 - 94_loss: 0.6749 - 103_loss: 0.2603 - 104_loss: 0.6739 - 113_loss: 0.2514 - 114_loss: 0.6512 - 123_loss: 0.2545 - 124_loss: 0.6165 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9168 - 14_categorical_accuracy: 0.9586 - 23_categorical_accuracy: 0.8866 - 24_categorical_accuracy: 0.8702 - 33_categorical_accuracy: 0.6597 - 34_categorical_accuracy: 0.4969 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9407 - 74_categorical_accuracy: 0.9431 - 83_categorical_accuracy: 0.9376 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9320 - 94_categorical_accuracy: 0.7704 - 103_categorical_accuracy: 0.9294 - 104_categorical_accuracy: 0.7780 - 113_categorical_accuracy: 0.9305 - 114_categorical_accuracy: 0.7756 - 123_categorical_accuracy: 0.9295 - 124_categorical_accuracy: 0.7974 - val_loss: 8.7506 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3195 - val_14_loss: 0.2328 - val_23_loss: 0.4147 - val_24_loss: 0.5285 - val_33_loss: 0.8117 - val_34_loss: 1.0846 - val_43_loss: 5.4186e-10 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2348 - val_74_loss: 0.3930 - val_83_loss: 0.2251 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2606 - val_94_loss: 0.8587 - val_103_loss: 0.2613 - val_104_loss: 0.9189 - val_113_loss: 0.2517 - val_114_loss: 0.9429 - val_123_loss: 0.2489 - val_124_loss: 0.7630 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9145 - val_14_categorical_accuracy: 0.9544 - val_23_categorical_accuracy: 0.8868 - val_24_categorical_accuracy: 0.8642 - val_33_categorical_accuracy: 0.6578 - val_34_categorical_accuracy: 0.4761 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9439 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9409 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9292 - val_94_categorical_accuracy: 0.7474 - val_103_categorical_accuracy: 0.9299 - val_104_categorical_accuracy: 0.7675 - val_113_categorical_accuracy: 0.9311 - val_114_categorical_accuracy: 0.7687 - val_123_categorical_accuracy: 0.9323 - val_124_categorical_accuracy: 0.8325\n",
      "Epoch 8/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 7.4435 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.3106 - 14_loss: 0.1567 - 23_loss: 0.4002 - 24_loss: 0.4649 - 33_loss: 0.7989 - 34_loss: 1.0092 - 43_loss: 2.3260e-08 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 1.1105e-10 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2423 - 74_loss: 0.2286 - 83_loss: 0.2333 - 84_loss: 0.0000e+00 - 93_loss: 0.2523 - 94_loss: 0.6673 - 103_loss: 0.2601 - 104_loss: 0.6639 - 113_loss: 0.2512 - 114_loss: 0.6426 - 123_loss: 0.2540 - 124_loss: 0.6075 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9168 - 14_categorical_accuracy: 0.9586 - 23_categorical_accuracy: 0.8868 - 24_categorical_accuracy: 0.8705 - 33_categorical_accuracy: 0.6607 - 34_categorical_accuracy: 0.5005 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9407 - 74_categorical_accuracy: 0.9431 - 83_categorical_accuracy: 0.9376 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9320 - 94_categorical_accuracy: 0.7700 - 103_categorical_accuracy: 0.9294 - 104_categorical_accuracy: 0.7778 - 113_categorical_accuracy: 0.9305 - 114_categorical_accuracy: 0.7756 - 123_categorical_accuracy: 0.9295 - 124_categorical_accuracy: 0.7974 - val_loss: 9.0333 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3182 - val_14_loss: 0.2324 - val_23_loss: 0.4162 - val_24_loss: 0.5340 - val_33_loss: 0.8113 - val_34_loss: 1.0874 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2347 - val_74_loss: 0.3889 - val_83_loss: 0.2259 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2606 - val_94_loss: 0.8956 - val_103_loss: 0.2619 - val_104_loss: 0.9647 - val_113_loss: 0.2514 - val_114_loss: 1.0829 - val_123_loss: 0.2500 - val_124_loss: 0.8174 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9154 - val_14_categorical_accuracy: 0.9556 - val_23_categorical_accuracy: 0.8870 - val_24_categorical_accuracy: 0.8640 - val_33_categorical_accuracy: 0.6566 - val_34_categorical_accuracy: 0.4742 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9439 - val_74_categorical_accuracy: 0.9281 - val_83_categorical_accuracy: 0.9409 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9292 - val_94_categorical_accuracy: 0.7448 - val_103_categorical_accuracy: 0.9299 - val_104_categorical_accuracy: 0.7658 - val_113_categorical_accuracy: 0.9311 - val_114_categorical_accuracy: 0.7676 - val_123_categorical_accuracy: 0.9322 - val_124_categorical_accuracy: 0.8315\n",
      "Epoch 9/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 7.3939 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.3094 - 14_loss: 0.1550 - 23_loss: 0.3987 - 24_loss: 0.4606 - 33_loss: 0.7966 - 34_loss: 1.0045 - 43_loss: 4.5255e-09 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2414 - 74_loss: 0.2250 - 83_loss: 0.2331 - 84_loss: 0.0000e+00 - 93_loss: 0.2517 - 94_loss: 0.6601 - 103_loss: 0.2598 - 104_loss: 0.6565 - 113_loss: 0.2506 - 114_loss: 0.6358 - 123_loss: 0.2536 - 124_loss: 0.6013 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9591 - 23_categorical_accuracy: 0.8870 - 24_categorical_accuracy: 0.8707 - 33_categorical_accuracy: 0.6610 - 34_categorical_accuracy: 0.5036 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9407 - 74_categorical_accuracy: 0.9431 - 83_categorical_accuracy: 0.9376 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9320 - 94_categorical_accuracy: 0.7700 - 103_categorical_accuracy: 0.9294 - 104_categorical_accuracy: 0.7779 - 113_categorical_accuracy: 0.9305 - 114_categorical_accuracy: 0.7754 - 123_categorical_accuracy: 0.9295 - 124_categorical_accuracy: 0.7972 - val_loss: 9.0913 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3180 - val_14_loss: 0.2391 - val_23_loss: 0.4152 - val_24_loss: 0.5372 - val_33_loss: 0.8110 - val_34_loss: 1.0912 - val_43_loss: 4.2145e-11 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2356 - val_74_loss: 0.4108 - val_83_loss: 0.2255 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2608 - val_94_loss: 0.9159 - val_103_loss: 0.2613 - val_104_loss: 0.9892 - val_113_loss: 0.2519 - val_114_loss: 1.0387 - val_123_loss: 0.2501 - val_124_loss: 0.8398 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9146 - val_14_categorical_accuracy: 0.9565 - val_23_categorical_accuracy: 0.8869 - val_24_categorical_accuracy: 0.8640 - val_33_categorical_accuracy: 0.6577 - val_34_categorical_accuracy: 0.4789 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9439 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9409 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9292 - val_94_categorical_accuracy: 0.7474 - val_103_categorical_accuracy: 0.9299 - val_104_categorical_accuracy: 0.7615 - val_113_categorical_accuracy: 0.9311 - val_114_categorical_accuracy: 0.7663 - val_123_categorical_accuracy: 0.9322 - val_124_categorical_accuracy: 0.8310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 7.3483 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.3086 - 14_loss: 0.1532 - 23_loss: 0.3968 - 24_loss: 0.4575 - 33_loss: 0.7942 - 34_loss: 1.0002 - 43_loss: 2.6009e-09 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2404 - 74_loss: 0.2219 - 83_loss: 0.2330 - 84_loss: 0.0000e+00 - 93_loss: 0.2514 - 94_loss: 0.6544 - 103_loss: 0.2590 - 104_loss: 0.6496 - 113_loss: 0.2504 - 114_loss: 0.6298 - 123_loss: 0.2534 - 124_loss: 0.5946 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9169 - 14_categorical_accuracy: 0.9591 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6623 - 34_categorical_accuracy: 0.5053 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9407 - 74_categorical_accuracy: 0.9431 - 83_categorical_accuracy: 0.9376 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9320 - 94_categorical_accuracy: 0.7700 - 103_categorical_accuracy: 0.9294 - 104_categorical_accuracy: 0.7778 - 113_categorical_accuracy: 0.9304 - 114_categorical_accuracy: 0.7754 - 123_categorical_accuracy: 0.9296 - 124_categorical_accuracy: 0.7970 - val_loss: 9.3973 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3194 - val_14_loss: 0.2421 - val_23_loss: 0.4262 - val_24_loss: 0.5531 - val_33_loss: 0.8112 - val_34_loss: 1.1039 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2351 - val_74_loss: 0.4192 - val_83_loss: 0.2255 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2618 - val_94_loss: 0.9523 - val_103_loss: 0.2624 - val_104_loss: 1.0417 - val_113_loss: 0.2523 - val_114_loss: 1.1528 - val_123_loss: 0.2509 - val_124_loss: 0.8873 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9153 - val_14_categorical_accuracy: 0.9567 - val_23_categorical_accuracy: 0.8868 - val_24_categorical_accuracy: 0.8629 - val_33_categorical_accuracy: 0.6564 - val_34_categorical_accuracy: 0.4754 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9439 - val_74_categorical_accuracy: 0.9292 - val_83_categorical_accuracy: 0.9409 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9292 - val_94_categorical_accuracy: 0.7450 - val_103_categorical_accuracy: 0.9299 - val_104_categorical_accuracy: 0.7566 - val_113_categorical_accuracy: 0.9311 - val_114_categorical_accuracy: 0.7651 - val_123_categorical_accuracy: 0.9322 - val_124_categorical_accuracy: 0.8310\n",
      "Epoch 11/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 7.3066 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.3077 - 14_loss: 0.1518 - 23_loss: 0.3956 - 24_loss: 0.4540 - 33_loss: 0.7919 - 34_loss: 0.9964 - 43_loss: 2.4946e-09 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2396 - 74_loss: 0.2188 - 83_loss: 0.2326 - 84_loss: 0.0000e+00 - 93_loss: 0.2509 - 94_loss: 0.6495 - 103_loss: 0.2588 - 104_loss: 0.6433 - 113_loss: 0.2500 - 114_loss: 0.6245 - 123_loss: 0.2526 - 124_loss: 0.5885 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9172 - 14_categorical_accuracy: 0.9589 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8707 - 33_categorical_accuracy: 0.6630 - 34_categorical_accuracy: 0.5074 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9407 - 74_categorical_accuracy: 0.9431 - 83_categorical_accuracy: 0.9376 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9320 - 94_categorical_accuracy: 0.7702 - 103_categorical_accuracy: 0.9294 - 104_categorical_accuracy: 0.7777 - 113_categorical_accuracy: 0.9305 - 114_categorical_accuracy: 0.7753 - 123_categorical_accuracy: 0.9296 - 124_categorical_accuracy: 0.7969 - val_loss: 9.3478 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3200 - val_14_loss: 0.2473 - val_23_loss: 0.4184 - val_24_loss: 0.5440 - val_33_loss: 0.8112 - val_34_loss: 1.0926 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2378 - val_74_loss: 0.4555 - val_83_loss: 0.2261 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2613 - val_94_loss: 0.9351 - val_103_loss: 0.2615 - val_104_loss: 1.0510 - val_113_loss: 0.2521 - val_114_loss: 1.0673 - val_123_loss: 0.2498 - val_124_loss: 0.9169 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9154 - val_14_categorical_accuracy: 0.9549 - val_23_categorical_accuracy: 0.8872 - val_24_categorical_accuracy: 0.8645 - val_33_categorical_accuracy: 0.6567 - val_34_categorical_accuracy: 0.4807 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9439 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9409 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9292 - val_94_categorical_accuracy: 0.7520 - val_103_categorical_accuracy: 0.9299 - val_104_categorical_accuracy: 0.7634 - val_113_categorical_accuracy: 0.9311 - val_114_categorical_accuracy: 0.7599 - val_123_categorical_accuracy: 0.9322 - val_124_categorical_accuracy: 0.8312\n",
      "Epoch 12/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 7.2716 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.3067 - 14_loss: 0.1504 - 23_loss: 0.3944 - 24_loss: 0.4511 - 33_loss: 0.7901 - 34_loss: 0.9925 - 43_loss: 5.4213e-09 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2384 - 74_loss: 0.2167 - 83_loss: 0.2322 - 84_loss: 0.0000e+00 - 93_loss: 0.2502 - 94_loss: 0.6455 - 103_loss: 0.2583 - 104_loss: 0.6382 - 113_loss: 0.2495 - 114_loss: 0.6204 - 123_loss: 0.2523 - 124_loss: 0.5848 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9170 - 14_categorical_accuracy: 0.9591 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6636 - 34_categorical_accuracy: 0.5092 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9407 - 74_categorical_accuracy: 0.9431 - 83_categorical_accuracy: 0.9376 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9320 - 94_categorical_accuracy: 0.7700 - 103_categorical_accuracy: 0.9294 - 104_categorical_accuracy: 0.7775 - 113_categorical_accuracy: 0.9305 - 114_categorical_accuracy: 0.7754 - 123_categorical_accuracy: 0.9294 - 124_categorical_accuracy: 0.7972 - val_loss: 9.6704 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3203 - val_14_loss: 0.2485 - val_23_loss: 0.4247 - val_24_loss: 0.5634 - val_33_loss: 0.8187 - val_34_loss: 1.1123 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2371 - val_74_loss: 0.4807 - val_83_loss: 0.2268 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2629 - val_94_loss: 0.9800 - val_103_loss: 0.2628 - val_104_loss: 1.1010 - val_113_loss: 0.2536 - val_114_loss: 1.1575 - val_123_loss: 0.2512 - val_124_loss: 0.9689 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9152 - val_14_categorical_accuracy: 0.9566 - val_23_categorical_accuracy: 0.8862 - val_24_categorical_accuracy: 0.8630 - val_33_categorical_accuracy: 0.6547 - val_34_categorical_accuracy: 0.4724 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9439 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9409 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9292 - val_94_categorical_accuracy: 0.7462 - val_103_categorical_accuracy: 0.9299 - val_104_categorical_accuracy: 0.7651 - val_113_categorical_accuracy: 0.9308 - val_114_categorical_accuracy: 0.7710 - val_123_categorical_accuracy: 0.9322 - val_124_categorical_accuracy: 0.8306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 7.2352 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.3055 - 14_loss: 0.1489 - 23_loss: 0.3924 - 24_loss: 0.4481 - 33_loss: 0.7879 - 34_loss: 0.9893 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2373 - 74_loss: 0.2147 - 83_loss: 0.2320 - 84_loss: 0.0000e+00 - 93_loss: 0.2496 - 94_loss: 0.6412 - 103_loss: 0.2576 - 104_loss: 0.6343 - 113_loss: 0.2490 - 114_loss: 0.6154 - 123_loss: 0.2516 - 124_loss: 0.5805 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9174 - 14_categorical_accuracy: 0.9590 - 23_categorical_accuracy: 0.8873 - 24_categorical_accuracy: 0.8710 - 33_categorical_accuracy: 0.6634 - 34_categorical_accuracy: 0.5099 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9407 - 74_categorical_accuracy: 0.9431 - 83_categorical_accuracy: 0.9376 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9320 - 94_categorical_accuracy: 0.7699 - 103_categorical_accuracy: 0.9293 - 104_categorical_accuracy: 0.7777 - 113_categorical_accuracy: 0.9305 - 114_categorical_accuracy: 0.7753 - 123_categorical_accuracy: 0.9295 - 124_categorical_accuracy: 0.7972 - val_loss: 9.8089 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3221 - val_14_loss: 0.2520 - val_23_loss: 0.4297 - val_24_loss: 0.5699 - val_33_loss: 0.8165 - val_34_loss: 1.1212 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2421 - val_74_loss: 0.4898 - val_83_loss: 0.2273 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2626 - val_94_loss: 1.0610 - val_103_loss: 0.2625 - val_104_loss: 1.1173 - val_113_loss: 0.2547 - val_114_loss: 1.1742 - val_123_loss: 0.2517 - val_124_loss: 0.9543 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9157 - val_14_categorical_accuracy: 0.9564 - val_23_categorical_accuracy: 0.8868 - val_24_categorical_accuracy: 0.8633 - val_33_categorical_accuracy: 0.6551 - val_34_categorical_accuracy: 0.4732 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9439 - val_74_categorical_accuracy: 0.9290 - val_83_categorical_accuracy: 0.9409 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9291 - val_94_categorical_accuracy: 0.7468 - val_103_categorical_accuracy: 0.9299 - val_104_categorical_accuracy: 0.7573 - val_113_categorical_accuracy: 0.9310 - val_114_categorical_accuracy: 0.7694 - val_123_categorical_accuracy: 0.9320 - val_124_categorical_accuracy: 0.8236\n",
      "Epoch 14/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 7.2089 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.3044 - 14_loss: 0.1481 - 23_loss: 0.3911 - 24_loss: 0.4460 - 33_loss: 0.7859 - 34_loss: 0.9864 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2366 - 74_loss: 0.2135 - 83_loss: 0.2316 - 84_loss: 0.0000e+00 - 93_loss: 0.2492 - 94_loss: 0.6382 - 103_loss: 0.2570 - 104_loss: 0.6313 - 113_loss: 0.2482 - 114_loss: 0.6127 - 123_loss: 0.2512 - 124_loss: 0.5775 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9592 - 23_categorical_accuracy: 0.8872 - 24_categorical_accuracy: 0.8709 - 33_categorical_accuracy: 0.6639 - 34_categorical_accuracy: 0.5117 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9407 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9376 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9320 - 94_categorical_accuracy: 0.7699 - 103_categorical_accuracy: 0.9294 - 104_categorical_accuracy: 0.7776 - 113_categorical_accuracy: 0.9305 - 114_categorical_accuracy: 0.7752 - 123_categorical_accuracy: 0.9295 - 124_categorical_accuracy: 0.7970 - val_loss: 9.8760 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3242 - val_14_loss: 0.2584 - val_23_loss: 0.4284 - val_24_loss: 0.5704 - val_33_loss: 0.8166 - val_34_loss: 1.1163 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2409 - val_74_loss: 0.4898 - val_83_loss: 0.2270 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2642 - val_94_loss: 1.0545 - val_103_loss: 0.2630 - val_104_loss: 1.1824 - val_113_loss: 0.2557 - val_114_loss: 1.1667 - val_123_loss: 0.2529 - val_124_loss: 0.9646 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9155 - val_14_categorical_accuracy: 0.9562 - val_23_categorical_accuracy: 0.8863 - val_24_categorical_accuracy: 0.8634 - val_33_categorical_accuracy: 0.6531 - val_34_categorical_accuracy: 0.4747 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9439 - val_74_categorical_accuracy: 0.9289 - val_83_categorical_accuracy: 0.9408 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9290 - val_94_categorical_accuracy: 0.7492 - val_103_categorical_accuracy: 0.9298 - val_104_categorical_accuracy: 0.7592 - val_113_categorical_accuracy: 0.9301 - val_114_categorical_accuracy: 0.7652 - val_123_categorical_accuracy: 0.9318 - val_124_categorical_accuracy: 0.8256\n",
      "Epoch 15/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 7.1797 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.3035 - 14_loss: 0.1466 - 23_loss: 0.3900 - 24_loss: 0.4436 - 33_loss: 0.7843 - 34_loss: 0.9842 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2355 - 74_loss: 0.2114 - 83_loss: 0.2310 - 84_loss: 0.0000e+00 - 93_loss: 0.2481 - 94_loss: 0.6354 - 103_loss: 0.2563 - 104_loss: 0.6274 - 113_loss: 0.2478 - 114_loss: 0.6094 - 123_loss: 0.2505 - 124_loss: 0.5748 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9172 - 14_categorical_accuracy: 0.9590 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6646 - 34_categorical_accuracy: 0.5132 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9406 - 74_categorical_accuracy: 0.9431 - 83_categorical_accuracy: 0.9376 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9319 - 94_categorical_accuracy: 0.7701 - 103_categorical_accuracy: 0.9293 - 104_categorical_accuracy: 0.7777 - 113_categorical_accuracy: 0.9304 - 114_categorical_accuracy: 0.7752 - 123_categorical_accuracy: 0.9296 - 124_categorical_accuracy: 0.7971 - val_loss: 10.3787 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3306 - val_14_loss: 0.2771 - val_23_loss: 0.4443 - val_24_loss: 0.5853 - val_33_loss: 0.8265 - val_34_loss: 1.1486 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2461 - val_74_loss: 0.5049 - val_83_loss: 0.2286 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2650 - val_94_loss: 1.1047 - val_103_loss: 0.2660 - val_104_loss: 1.2415 - val_113_loss: 0.2577 - val_114_loss: 1.3330 - val_123_loss: 0.2537 - val_124_loss: 1.0650 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9149 - val_14_categorical_accuracy: 0.9558 - val_23_categorical_accuracy: 0.8870 - val_24_categorical_accuracy: 0.8633 - val_33_categorical_accuracy: 0.6522 - val_34_categorical_accuracy: 0.4646 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9436 - val_74_categorical_accuracy: 0.9295 - val_83_categorical_accuracy: 0.9409 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9292 - val_94_categorical_accuracy: 0.7439 - val_103_categorical_accuracy: 0.9299 - val_104_categorical_accuracy: 0.7660 - val_113_categorical_accuracy: 0.9311 - val_114_categorical_accuracy: 0.7578 - val_123_categorical_accuracy: 0.9323 - val_124_categorical_accuracy: 0.8298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 7.1626 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.3024 - 14_loss: 0.1458 - 23_loss: 0.3884 - 24_loss: 0.4414 - 33_loss: 0.7837 - 34_loss: 0.9831 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2350 - 74_loss: 0.2106 - 83_loss: 0.2305 - 84_loss: 0.0000e+00 - 93_loss: 0.2480 - 94_loss: 0.6341 - 103_loss: 0.2559 - 104_loss: 0.6255 - 113_loss: 0.2472 - 114_loss: 0.6079 - 123_loss: 0.2501 - 124_loss: 0.5732 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9174 - 14_categorical_accuracy: 0.9592 - 23_categorical_accuracy: 0.8873 - 24_categorical_accuracy: 0.8711 - 33_categorical_accuracy: 0.6648 - 34_categorical_accuracy: 0.5133 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9406 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9376 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9319 - 94_categorical_accuracy: 0.7698 - 103_categorical_accuracy: 0.9292 - 104_categorical_accuracy: 0.7772 - 113_categorical_accuracy: 0.9304 - 114_categorical_accuracy: 0.7752 - 123_categorical_accuracy: 0.9295 - 124_categorical_accuracy: 0.7970 - val_loss: 10.2980 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3284 - val_14_loss: 0.2954 - val_23_loss: 0.4433 - val_24_loss: 0.5794 - val_33_loss: 0.8200 - val_34_loss: 1.1196 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2438 - val_74_loss: 0.5042 - val_83_loss: 0.2306 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2661 - val_94_loss: 1.1237 - val_103_loss: 0.2682 - val_104_loss: 1.2207 - val_113_loss: 0.2570 - val_114_loss: 1.3436 - val_123_loss: 0.2534 - val_124_loss: 1.0009 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9154 - val_14_categorical_accuracy: 0.9567 - val_23_categorical_accuracy: 0.8867 - val_24_categorical_accuracy: 0.8623 - val_33_categorical_accuracy: 0.6497 - val_34_categorical_accuracy: 0.4711 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9437 - val_74_categorical_accuracy: 0.9285 - val_83_categorical_accuracy: 0.9409 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9288 - val_94_categorical_accuracy: 0.7474 - val_103_categorical_accuracy: 0.9295 - val_104_categorical_accuracy: 0.7693 - val_113_categorical_accuracy: 0.9309 - val_114_categorical_accuracy: 0.7691 - val_123_categorical_accuracy: 0.9323 - val_124_categorical_accuracy: 0.8197\n",
      "Epoch 17/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 7.1371 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.3012 - 14_loss: 0.1449 - 23_loss: 0.3874 - 24_loss: 0.4391 - 33_loss: 0.7817 - 34_loss: 0.9797 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2336 - 74_loss: 0.2091 - 83_loss: 0.2300 - 84_loss: 0.0000e+00 - 93_loss: 0.2471 - 94_loss: 0.6319 - 103_loss: 0.2552 - 104_loss: 0.6235 - 113_loss: 0.2466 - 114_loss: 0.6056 - 123_loss: 0.2493 - 124_loss: 0.5711 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9174 - 14_categorical_accuracy: 0.9591 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6650 - 34_categorical_accuracy: 0.5146 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9406 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9376 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9320 - 94_categorical_accuracy: 0.7698 - 103_categorical_accuracy: 0.9293 - 104_categorical_accuracy: 0.7776 - 113_categorical_accuracy: 0.9304 - 114_categorical_accuracy: 0.7752 - 123_categorical_accuracy: 0.9294 - 124_categorical_accuracy: 0.7970 - val_loss: 10.2689 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3269 - val_14_loss: 0.2748 - val_23_loss: 0.4446 - val_24_loss: 0.6036 - val_33_loss: 0.8215 - val_34_loss: 1.1272 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2459 - val_74_loss: 0.5080 - val_83_loss: 0.2304 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2673 - val_94_loss: 1.0913 - val_103_loss: 0.2668 - val_104_loss: 1.2880 - val_113_loss: 0.2557 - val_114_loss: 1.2398 - val_123_loss: 0.2554 - val_124_loss: 1.0217 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9143 - val_14_categorical_accuracy: 0.9543 - val_23_categorical_accuracy: 0.8870 - val_24_categorical_accuracy: 0.8629 - val_33_categorical_accuracy: 0.6515 - val_34_categorical_accuracy: 0.4749 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9439 - val_74_categorical_accuracy: 0.9287 - val_83_categorical_accuracy: 0.9409 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9291 - val_94_categorical_accuracy: 0.7493 - val_103_categorical_accuracy: 0.9295 - val_104_categorical_accuracy: 0.7618 - val_113_categorical_accuracy: 0.9305 - val_114_categorical_accuracy: 0.7634 - val_123_categorical_accuracy: 0.9323 - val_124_categorical_accuracy: 0.8144\n",
      "Epoch 18/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 7.1121 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.3005 - 14_loss: 0.1438 - 23_loss: 0.3858 - 24_loss: 0.4369 - 33_loss: 0.7795 - 34_loss: 0.9768 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2330 - 74_loss: 0.2082 - 83_loss: 0.2291 - 84_loss: 0.0000e+00 - 93_loss: 0.2462 - 94_loss: 0.6291 - 103_loss: 0.2545 - 104_loss: 0.6211 - 113_loss: 0.2459 - 114_loss: 0.6041 - 123_loss: 0.2488 - 124_loss: 0.5690 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9172 - 14_categorical_accuracy: 0.9592 - 23_categorical_accuracy: 0.8870 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6657 - 34_categorical_accuracy: 0.5179 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9406 - 74_categorical_accuracy: 0.9431 - 83_categorical_accuracy: 0.9376 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9319 - 94_categorical_accuracy: 0.7698 - 103_categorical_accuracy: 0.9292 - 104_categorical_accuracy: 0.7773 - 113_categorical_accuracy: 0.9303 - 114_categorical_accuracy: 0.7753 - 123_categorical_accuracy: 0.9294 - 124_categorical_accuracy: 0.7970 - val_loss: 10.5961 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3328 - val_14_loss: 0.2967 - val_23_loss: 0.4446 - val_24_loss: 0.6056 - val_33_loss: 0.8218 - val_34_loss: 1.1391 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2503 - val_74_loss: 0.5389 - val_83_loss: 0.2299 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2681 - val_94_loss: 1.1835 - val_103_loss: 0.2689 - val_104_loss: 1.2833 - val_113_loss: 0.2580 - val_114_loss: 1.3505 - val_123_loss: 0.2581 - val_124_loss: 1.0658 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9141 - val_14_categorical_accuracy: 0.9552 - val_23_categorical_accuracy: 0.8868 - val_24_categorical_accuracy: 0.8635 - val_33_categorical_accuracy: 0.6517 - val_34_categorical_accuracy: 0.4726 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9437 - val_74_categorical_accuracy: 0.9277 - val_83_categorical_accuracy: 0.9409 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9288 - val_94_categorical_accuracy: 0.7456 - val_103_categorical_accuracy: 0.9297 - val_104_categorical_accuracy: 0.7534 - val_113_categorical_accuracy: 0.9305 - val_114_categorical_accuracy: 0.7648 - val_123_categorical_accuracy: 0.9319 - val_124_categorical_accuracy: 0.8290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 7.0932 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2993 - 14_loss: 0.1434 - 23_loss: 0.3842 - 24_loss: 0.4352 - 33_loss: 0.7781 - 34_loss: 0.9762 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2319 - 74_loss: 0.2069 - 83_loss: 0.2286 - 84_loss: 0.0000e+00 - 93_loss: 0.2457 - 94_loss: 0.6281 - 103_loss: 0.2536 - 104_loss: 0.6186 - 113_loss: 0.2454 - 114_loss: 0.6026 - 123_loss: 0.2479 - 124_loss: 0.5676 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9174 - 14_categorical_accuracy: 0.9592 - 23_categorical_accuracy: 0.8873 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6658 - 34_categorical_accuracy: 0.5171 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9406 - 74_categorical_accuracy: 0.9431 - 83_categorical_accuracy: 0.9375 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9319 - 94_categorical_accuracy: 0.7698 - 103_categorical_accuracy: 0.9293 - 104_categorical_accuracy: 0.7780 - 113_categorical_accuracy: 0.9303 - 114_categorical_accuracy: 0.7750 - 123_categorical_accuracy: 0.9295 - 124_categorical_accuracy: 0.7969 - val_loss: 10.6302 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3313 - val_14_loss: 0.2841 - val_23_loss: 0.4507 - val_24_loss: 0.5952 - val_33_loss: 0.8256 - val_34_loss: 1.1349 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2502 - val_74_loss: 0.5393 - val_83_loss: 0.2309 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2703 - val_94_loss: 1.1773 - val_103_loss: 0.2696 - val_104_loss: 1.3339 - val_113_loss: 0.2587 - val_114_loss: 1.3331 - val_123_loss: 0.2594 - val_124_loss: 1.0855 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9145 - val_14_categorical_accuracy: 0.9556 - val_23_categorical_accuracy: 0.8867 - val_24_categorical_accuracy: 0.8630 - val_33_categorical_accuracy: 0.6486 - val_34_categorical_accuracy: 0.4631 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9438 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9409 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9289 - val_94_categorical_accuracy: 0.7422 - val_103_categorical_accuracy: 0.9295 - val_104_categorical_accuracy: 0.7641 - val_113_categorical_accuracy: 0.9306 - val_114_categorical_accuracy: 0.7674 - val_123_categorical_accuracy: 0.9317 - val_124_categorical_accuracy: 0.8312\n",
      "Epoch 20/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 7.0763 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2986 - 14_loss: 0.1427 - 23_loss: 0.3832 - 24_loss: 0.4335 - 33_loss: 0.7767 - 34_loss: 0.9738 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2316 - 74_loss: 0.2063 - 83_loss: 0.2281 - 84_loss: 0.0000e+00 - 93_loss: 0.2451 - 94_loss: 0.6271 - 103_loss: 0.2529 - 104_loss: 0.6173 - 113_loss: 0.2447 - 114_loss: 0.6012 - 123_loss: 0.2474 - 124_loss: 0.5660 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9589 - 23_categorical_accuracy: 0.8872 - 24_categorical_accuracy: 0.8712 - 33_categorical_accuracy: 0.6664 - 34_categorical_accuracy: 0.5176 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9406 - 74_categorical_accuracy: 0.9431 - 83_categorical_accuracy: 0.9375 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9319 - 94_categorical_accuracy: 0.7698 - 103_categorical_accuracy: 0.9292 - 104_categorical_accuracy: 0.7774 - 113_categorical_accuracy: 0.9304 - 114_categorical_accuracy: 0.7749 - 123_categorical_accuracy: 0.9294 - 124_categorical_accuracy: 0.7973 - val_loss: 10.9883 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3331 - val_14_loss: 0.2898 - val_23_loss: 0.4590 - val_24_loss: 0.6254 - val_33_loss: 0.8300 - val_34_loss: 1.1537 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2551 - val_74_loss: 0.5959 - val_83_loss: 0.2333 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2713 - val_94_loss: 1.2155 - val_103_loss: 0.2712 - val_104_loss: 1.4077 - val_113_loss: 0.2583 - val_114_loss: 1.3891 - val_123_loss: 0.2598 - val_124_loss: 1.1401 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9146 - val_14_categorical_accuracy: 0.9553 - val_23_categorical_accuracy: 0.8860 - val_24_categorical_accuracy: 0.8629 - val_33_categorical_accuracy: 0.6520 - val_34_categorical_accuracy: 0.4698 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9437 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9405 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9286 - val_94_categorical_accuracy: 0.7436 - val_103_categorical_accuracy: 0.9292 - val_104_categorical_accuracy: 0.7628 - val_113_categorical_accuracy: 0.9310 - val_114_categorical_accuracy: 0.7676 - val_123_categorical_accuracy: 0.9303 - val_124_categorical_accuracy: 0.8128\n",
      "Epoch 21/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 7.0612 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2974 - 14_loss: 0.1421 - 23_loss: 0.3819 - 24_loss: 0.4317 - 33_loss: 0.7759 - 34_loss: 0.9722 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2307 - 74_loss: 0.2058 - 83_loss: 0.2275 - 84_loss: 0.0000e+00 - 93_loss: 0.2440 - 94_loss: 0.6266 - 103_loss: 0.2521 - 104_loss: 0.6165 - 113_loss: 0.2437 - 114_loss: 0.6005 - 123_loss: 0.2469 - 124_loss: 0.5655 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9593 - 23_categorical_accuracy: 0.8870 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6667 - 34_categorical_accuracy: 0.5191 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9406 - 74_categorical_accuracy: 0.9431 - 83_categorical_accuracy: 0.9375 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9318 - 94_categorical_accuracy: 0.7700 - 103_categorical_accuracy: 0.9291 - 104_categorical_accuracy: 0.7774 - 113_categorical_accuracy: 0.9304 - 114_categorical_accuracy: 0.7750 - 123_categorical_accuracy: 0.9293 - 124_categorical_accuracy: 0.7969 - val_loss: 10.8534 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3326 - val_14_loss: 0.3079 - val_23_loss: 0.4639 - val_24_loss: 0.6260 - val_33_loss: 0.8285 - val_34_loss: 1.1317 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2537 - val_74_loss: 0.5923 - val_83_loss: 0.2323 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2700 - val_94_loss: 1.1917 - val_103_loss: 0.2748 - val_104_loss: 1.3216 - val_113_loss: 0.2608 - val_114_loss: 1.4132 - val_123_loss: 0.2558 - val_124_loss: 1.0967 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9141 - val_14_categorical_accuracy: 0.9555 - val_23_categorical_accuracy: 0.8874 - val_24_categorical_accuracy: 0.8634 - val_33_categorical_accuracy: 0.6510 - val_34_categorical_accuracy: 0.4711 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9436 - val_74_categorical_accuracy: 0.9289 - val_83_categorical_accuracy: 0.9409 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9292 - val_94_categorical_accuracy: 0.7490 - val_103_categorical_accuracy: 0.9295 - val_104_categorical_accuracy: 0.7604 - val_113_categorical_accuracy: 0.9297 - val_114_categorical_accuracy: 0.7668 - val_123_categorical_accuracy: 0.9318 - val_124_categorical_accuracy: 0.8214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 7.0441 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2967 - 14_loss: 0.1412 - 23_loss: 0.3809 - 24_loss: 0.4306 - 33_loss: 0.7746 - 34_loss: 0.9712 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2298 - 74_loss: 0.2051 - 83_loss: 0.2266 - 84_loss: 0.0000e+00 - 93_loss: 0.2435 - 94_loss: 0.6249 - 103_loss: 0.2518 - 104_loss: 0.6152 - 113_loss: 0.2431 - 114_loss: 0.5986 - 123_loss: 0.2460 - 124_loss: 0.5643 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9593 - 23_categorical_accuracy: 0.8870 - 24_categorical_accuracy: 0.8710 - 33_categorical_accuracy: 0.6669 - 34_categorical_accuracy: 0.5197 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9405 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9375 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9319 - 94_categorical_accuracy: 0.7697 - 103_categorical_accuracy: 0.9292 - 104_categorical_accuracy: 0.7775 - 113_categorical_accuracy: 0.9304 - 114_categorical_accuracy: 0.7750 - 123_categorical_accuracy: 0.9294 - 124_categorical_accuracy: 0.7968 - val_loss: 11.1194 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3365 - val_14_loss: 0.3118 - val_23_loss: 0.4577 - val_24_loss: 0.6438 - val_33_loss: 0.8323 - val_34_loss: 1.1463 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2549 - val_74_loss: 0.5947 - val_83_loss: 0.2321 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2711 - val_94_loss: 1.2171 - val_103_loss: 0.2739 - val_104_loss: 1.4034 - val_113_loss: 0.2621 - val_114_loss: 1.4484 - val_123_loss: 0.2622 - val_124_loss: 1.1711 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9145 - val_14_categorical_accuracy: 0.9559 - val_23_categorical_accuracy: 0.8868 - val_24_categorical_accuracy: 0.8622 - val_33_categorical_accuracy: 0.6484 - val_34_categorical_accuracy: 0.4763 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9436 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9405 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9288 - val_94_categorical_accuracy: 0.7407 - val_103_categorical_accuracy: 0.9297 - val_104_categorical_accuracy: 0.7740 - val_113_categorical_accuracy: 0.9288 - val_114_categorical_accuracy: 0.7657 - val_123_categorical_accuracy: 0.9322 - val_124_categorical_accuracy: 0.8144\n",
      "Epoch 23/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 7.0257 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2954 - 14_loss: 0.1403 - 23_loss: 0.3797 - 24_loss: 0.4289 - 33_loss: 0.7735 - 34_loss: 0.9698 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2284 - 74_loss: 0.2039 - 83_loss: 0.2263 - 84_loss: 0.0000e+00 - 93_loss: 0.2426 - 94_loss: 0.6232 - 103_loss: 0.2508 - 104_loss: 0.6137 - 113_loss: 0.2425 - 114_loss: 0.5974 - 123_loss: 0.2457 - 124_loss: 0.5636 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9592 - 23_categorical_accuracy: 0.8873 - 24_categorical_accuracy: 0.8711 - 33_categorical_accuracy: 0.6666 - 34_categorical_accuracy: 0.5205 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9406 - 74_categorical_accuracy: 0.9431 - 83_categorical_accuracy: 0.9375 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9318 - 94_categorical_accuracy: 0.7699 - 103_categorical_accuracy: 0.9293 - 104_categorical_accuracy: 0.7773 - 113_categorical_accuracy: 0.9303 - 114_categorical_accuracy: 0.7751 - 123_categorical_accuracy: 0.9294 - 124_categorical_accuracy: 0.7970 - val_loss: 11.3870 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3389 - val_14_loss: 0.3288 - val_23_loss: 0.4704 - val_24_loss: 0.6402 - val_33_loss: 0.8280 - val_34_loss: 1.1500 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2588 - val_74_loss: 0.6250 - val_83_loss: 0.2325 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2752 - val_94_loss: 1.2631 - val_103_loss: 0.2746 - val_104_loss: 1.4562 - val_113_loss: 0.2631 - val_114_loss: 1.4871 - val_123_loss: 0.2664 - val_124_loss: 1.2288 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9134 - val_14_categorical_accuracy: 0.9569 - val_23_categorical_accuracy: 0.8858 - val_24_categorical_accuracy: 0.8602 - val_33_categorical_accuracy: 0.6519 - val_34_categorical_accuracy: 0.4680 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9436 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9409 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9284 - val_94_categorical_accuracy: 0.7405 - val_103_categorical_accuracy: 0.9286 - val_104_categorical_accuracy: 0.7614 - val_113_categorical_accuracy: 0.9305 - val_114_categorical_accuracy: 0.7640 - val_123_categorical_accuracy: 0.9320 - val_124_categorical_accuracy: 0.8315\n",
      "Epoch 24/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 7.0128 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2944 - 14_loss: 0.1397 - 23_loss: 0.3784 - 24_loss: 0.4275 - 33_loss: 0.7725 - 34_loss: 0.9680 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2283 - 74_loss: 0.2043 - 83_loss: 0.2255 - 84_loss: 0.0000e+00 - 93_loss: 0.2423 - 94_loss: 0.6230 - 103_loss: 0.2500 - 104_loss: 0.6132 - 113_loss: 0.2413 - 114_loss: 0.5969 - 123_loss: 0.2453 - 124_loss: 0.5619 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9176 - 14_categorical_accuracy: 0.9592 - 23_categorical_accuracy: 0.8872 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6663 - 34_categorical_accuracy: 0.5215 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9405 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9374 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9318 - 94_categorical_accuracy: 0.7696 - 103_categorical_accuracy: 0.9293 - 104_categorical_accuracy: 0.7775 - 113_categorical_accuracy: 0.9304 - 114_categorical_accuracy: 0.7749 - 123_categorical_accuracy: 0.9294 - 124_categorical_accuracy: 0.7971 - val_loss: 11.3812 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3437 - val_14_loss: 0.3322 - val_23_loss: 0.4684 - val_24_loss: 0.6474 - val_33_loss: 0.8262 - val_34_loss: 1.1390 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2558 - val_74_loss: 0.5956 - val_83_loss: 0.2359 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2776 - val_94_loss: 1.2495 - val_103_loss: 0.2781 - val_104_loss: 1.3764 - val_113_loss: 0.2651 - val_114_loss: 1.6193 - val_123_loss: 0.2644 - val_124_loss: 1.2068 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9137 - val_14_categorical_accuracy: 0.9560 - val_23_categorical_accuracy: 0.8860 - val_24_categorical_accuracy: 0.8640 - val_33_categorical_accuracy: 0.6493 - val_34_categorical_accuracy: 0.4689 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9436 - val_74_categorical_accuracy: 0.9293 - val_83_categorical_accuracy: 0.9408 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9288 - val_94_categorical_accuracy: 0.7511 - val_103_categorical_accuracy: 0.9293 - val_104_categorical_accuracy: 0.7515 - val_113_categorical_accuracy: 0.9303 - val_114_categorical_accuracy: 0.7694 - val_123_categorical_accuracy: 0.9320 - val_124_categorical_accuracy: 0.8129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 6.9996 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2937 - 14_loss: 0.1391 - 23_loss: 0.3775 - 24_loss: 0.4262 - 33_loss: 0.7712 - 34_loss: 0.9671 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2278 - 74_loss: 0.2034 - 83_loss: 0.2253 - 84_loss: 0.0000e+00 - 93_loss: 0.2415 - 94_loss: 0.6220 - 103_loss: 0.2496 - 104_loss: 0.6121 - 113_loss: 0.2411 - 114_loss: 0.5963 - 123_loss: 0.2441 - 124_loss: 0.5617 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9593 - 23_categorical_accuracy: 0.8872 - 24_categorical_accuracy: 0.8709 - 33_categorical_accuracy: 0.6675 - 34_categorical_accuracy: 0.5215 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9405 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9374 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9318 - 94_categorical_accuracy: 0.7698 - 103_categorical_accuracy: 0.9292 - 104_categorical_accuracy: 0.7776 - 113_categorical_accuracy: 0.9304 - 114_categorical_accuracy: 0.7751 - 123_categorical_accuracy: 0.9294 - 124_categorical_accuracy: 0.7969 - val_loss: 11.4620 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3415 - val_14_loss: 0.3380 - val_23_loss: 0.4815 - val_24_loss: 0.6626 - val_33_loss: 0.8296 - val_34_loss: 1.1507 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2586 - val_74_loss: 0.6308 - val_83_loss: 0.2375 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2774 - val_94_loss: 1.2930 - val_103_loss: 0.2773 - val_104_loss: 1.4817 - val_113_loss: 0.2631 - val_114_loss: 1.4579 - val_123_loss: 0.2681 - val_124_loss: 1.2128 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9147 - val_14_categorical_accuracy: 0.9554 - val_23_categorical_accuracy: 0.8869 - val_24_categorical_accuracy: 0.8638 - val_33_categorical_accuracy: 0.6520 - val_34_categorical_accuracy: 0.4665 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9435 - val_74_categorical_accuracy: 0.9280 - val_83_categorical_accuracy: 0.9405 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9287 - val_94_categorical_accuracy: 0.7473 - val_103_categorical_accuracy: 0.9296 - val_104_categorical_accuracy: 0.7693 - val_113_categorical_accuracy: 0.9307 - val_114_categorical_accuracy: 0.7603 - val_123_categorical_accuracy: 0.9319 - val_124_categorical_accuracy: 0.8326\n",
      "Epoch 26/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.9856 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2933 - 14_loss: 0.1386 - 23_loss: 0.3764 - 24_loss: 0.4250 - 33_loss: 0.7704 - 34_loss: 0.9658 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2268 - 74_loss: 0.2028 - 83_loss: 0.2245 - 84_loss: 0.0000e+00 - 93_loss: 0.2409 - 94_loss: 0.6210 - 103_loss: 0.2488 - 104_loss: 0.6113 - 113_loss: 0.2403 - 114_loss: 0.5955 - 123_loss: 0.2435 - 124_loss: 0.5607 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9174 - 14_categorical_accuracy: 0.9592 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8710 - 33_categorical_accuracy: 0.6675 - 34_categorical_accuracy: 0.5220 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9405 - 74_categorical_accuracy: 0.9431 - 83_categorical_accuracy: 0.9374 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9319 - 94_categorical_accuracy: 0.7698 - 103_categorical_accuracy: 0.9293 - 104_categorical_accuracy: 0.7774 - 113_categorical_accuracy: 0.9303 - 114_categorical_accuracy: 0.7753 - 123_categorical_accuracy: 0.9294 - 124_categorical_accuracy: 0.7969 - val_loss: 11.4166 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3421 - val_14_loss: 0.3254 - val_23_loss: 0.4731 - val_24_loss: 0.6365 - val_33_loss: 0.8318 - val_34_loss: 1.1581 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2661 - val_74_loss: 0.6204 - val_83_loss: 0.2370 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2803 - val_94_loss: 1.2502 - val_103_loss: 0.2793 - val_104_loss: 1.4952 - val_113_loss: 0.2633 - val_114_loss: 1.4777 - val_123_loss: 0.2633 - val_124_loss: 1.2170 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9143 - val_14_categorical_accuracy: 0.9559 - val_23_categorical_accuracy: 0.8865 - val_24_categorical_accuracy: 0.8633 - val_33_categorical_accuracy: 0.6526 - val_34_categorical_accuracy: 0.4678 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9437 - val_74_categorical_accuracy: 0.9290 - val_83_categorical_accuracy: 0.9407 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9288 - val_94_categorical_accuracy: 0.7476 - val_103_categorical_accuracy: 0.9297 - val_104_categorical_accuracy: 0.7671 - val_113_categorical_accuracy: 0.9307 - val_114_categorical_accuracy: 0.7633 - val_123_categorical_accuracy: 0.9321 - val_124_categorical_accuracy: 0.8149\n",
      "Epoch 27/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.9725 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2918 - 14_loss: 0.1384 - 23_loss: 0.3757 - 24_loss: 0.4238 - 33_loss: 0.7688 - 34_loss: 0.9636 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2258 - 74_loss: 0.2022 - 83_loss: 0.2242 - 84_loss: 0.0000e+00 - 93_loss: 0.2403 - 94_loss: 0.6211 - 103_loss: 0.2482 - 104_loss: 0.6105 - 113_loss: 0.2400 - 114_loss: 0.5951 - 123_loss: 0.2430 - 124_loss: 0.5602 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9593 - 23_categorical_accuracy: 0.8874 - 24_categorical_accuracy: 0.8709 - 33_categorical_accuracy: 0.6675 - 34_categorical_accuracy: 0.5238 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9404 - 74_categorical_accuracy: 0.9431 - 83_categorical_accuracy: 0.9374 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9317 - 94_categorical_accuracy: 0.7696 - 103_categorical_accuracy: 0.9292 - 104_categorical_accuracy: 0.7772 - 113_categorical_accuracy: 0.9302 - 114_categorical_accuracy: 0.7749 - 123_categorical_accuracy: 0.9294 - 124_categorical_accuracy: 0.7970 - val_loss: 11.8210 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3480 - val_14_loss: 0.3519 - val_23_loss: 0.4896 - val_24_loss: 0.6989 - val_33_loss: 0.8354 - val_34_loss: 1.1884 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2685 - val_74_loss: 0.6685 - val_83_loss: 0.2378 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2827 - val_94_loss: 1.3420 - val_103_loss: 0.2828 - val_104_loss: 1.4645 - val_113_loss: 0.2678 - val_114_loss: 1.5254 - val_123_loss: 0.2696 - val_124_loss: 1.2993 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9146 - val_14_categorical_accuracy: 0.9567 - val_23_categorical_accuracy: 0.8862 - val_24_categorical_accuracy: 0.8627 - val_33_categorical_accuracy: 0.6472 - val_34_categorical_accuracy: 0.4608 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9436 - val_74_categorical_accuracy: 0.9282 - val_83_categorical_accuracy: 0.9408 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9285 - val_94_categorical_accuracy: 0.7505 - val_103_categorical_accuracy: 0.9296 - val_104_categorical_accuracy: 0.7705 - val_113_categorical_accuracy: 0.9303 - val_114_categorical_accuracy: 0.7604 - val_123_categorical_accuracy: 0.9317 - val_124_categorical_accuracy: 0.8283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 6.9592 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2913 - 14_loss: 0.1377 - 23_loss: 0.3744 - 24_loss: 0.4231 - 33_loss: 0.7676 - 34_loss: 0.9631 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2249 - 74_loss: 0.2018 - 83_loss: 0.2234 - 84_loss: 0.0000e+00 - 93_loss: 0.2393 - 94_loss: 0.6206 - 103_loss: 0.2473 - 104_loss: 0.6096 - 113_loss: 0.2393 - 114_loss: 0.5940 - 123_loss: 0.2426 - 124_loss: 0.5592 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9593 - 23_categorical_accuracy: 0.8874 - 24_categorical_accuracy: 0.8709 - 33_categorical_accuracy: 0.6675 - 34_categorical_accuracy: 0.5231 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9404 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9373 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9318 - 94_categorical_accuracy: 0.7699 - 103_categorical_accuracy: 0.9291 - 104_categorical_accuracy: 0.7774 - 113_categorical_accuracy: 0.9303 - 114_categorical_accuracy: 0.7749 - 123_categorical_accuracy: 0.9293 - 124_categorical_accuracy: 0.7974 - val_loss: 12.0238 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3445 - val_14_loss: 0.3441 - val_23_loss: 0.4919 - val_24_loss: 0.6951 - val_33_loss: 0.8430 - val_34_loss: 1.1690 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2720 - val_74_loss: 0.6730 - val_83_loss: 0.2407 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2840 - val_94_loss: 1.3382 - val_103_loss: 0.2846 - val_104_loss: 1.5720 - val_113_loss: 0.2703 - val_114_loss: 1.6357 - val_123_loss: 0.2716 - val_124_loss: 1.2939 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9147 - val_14_categorical_accuracy: 0.9563 - val_23_categorical_accuracy: 0.8860 - val_24_categorical_accuracy: 0.8631 - val_33_categorical_accuracy: 0.6494 - val_34_categorical_accuracy: 0.4692 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9434 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9404 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9281 - val_94_categorical_accuracy: 0.7360 - val_103_categorical_accuracy: 0.9296 - val_104_categorical_accuracy: 0.7548 - val_113_categorical_accuracy: 0.9290 - val_114_categorical_accuracy: 0.7707 - val_123_categorical_accuracy: 0.9315 - val_124_categorical_accuracy: 0.8167\n",
      "Epoch 29/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 6.9498 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2905 - 14_loss: 0.1373 - 23_loss: 0.3731 - 24_loss: 0.4218 - 33_loss: 0.7672 - 34_loss: 0.9620 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2244 - 74_loss: 0.2012 - 83_loss: 0.2235 - 84_loss: 0.0000e+00 - 93_loss: 0.2392 - 94_loss: 0.6202 - 103_loss: 0.2469 - 104_loss: 0.6090 - 113_loss: 0.2391 - 114_loss: 0.5930 - 123_loss: 0.2422 - 124_loss: 0.5594 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9175 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8710 - 33_categorical_accuracy: 0.6674 - 34_categorical_accuracy: 0.5234 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9404 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9374 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9317 - 94_categorical_accuracy: 0.7697 - 103_categorical_accuracy: 0.9291 - 104_categorical_accuracy: 0.7775 - 113_categorical_accuracy: 0.9302 - 114_categorical_accuracy: 0.7751 - 123_categorical_accuracy: 0.9291 - 124_categorical_accuracy: 0.7972 - val_loss: 11.8963 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3486 - val_14_loss: 0.3324 - val_23_loss: 0.4892 - val_24_loss: 0.6764 - val_33_loss: 0.8376 - val_34_loss: 1.1718 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2689 - val_74_loss: 0.6823 - val_83_loss: 0.2420 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2850 - val_94_loss: 1.3463 - val_103_loss: 0.2834 - val_104_loss: 1.5188 - val_113_loss: 0.2657 - val_114_loss: 1.5872 - val_123_loss: 0.2730 - val_124_loss: 1.2875 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9152 - val_14_categorical_accuracy: 0.9569 - val_23_categorical_accuracy: 0.8875 - val_24_categorical_accuracy: 0.8618 - val_33_categorical_accuracy: 0.6491 - val_34_categorical_accuracy: 0.4714 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9433 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9402 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9282 - val_94_categorical_accuracy: 0.7402 - val_103_categorical_accuracy: 0.9293 - val_104_categorical_accuracy: 0.7588 - val_113_categorical_accuracy: 0.9306 - val_114_categorical_accuracy: 0.7578 - val_123_categorical_accuracy: 0.9319 - val_124_categorical_accuracy: 0.8228\n",
      "Epoch 30/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 6.9407 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2895 - 14_loss: 0.1370 - 23_loss: 0.3728 - 24_loss: 0.4213 - 33_loss: 0.7664 - 34_loss: 0.9613 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2237 - 74_loss: 0.2009 - 83_loss: 0.2226 - 84_loss: 0.0000e+00 - 93_loss: 0.2389 - 94_loss: 0.6191 - 103_loss: 0.2463 - 104_loss: 0.6089 - 113_loss: 0.2380 - 114_loss: 0.5935 - 123_loss: 0.2416 - 124_loss: 0.5590 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9175 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8873 - 24_categorical_accuracy: 0.8709 - 33_categorical_accuracy: 0.6680 - 34_categorical_accuracy: 0.5247 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9406 - 74_categorical_accuracy: 0.9431 - 83_categorical_accuracy: 0.9374 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9318 - 94_categorical_accuracy: 0.7696 - 103_categorical_accuracy: 0.9293 - 104_categorical_accuracy: 0.7776 - 113_categorical_accuracy: 0.9302 - 114_categorical_accuracy: 0.7750 - 123_categorical_accuracy: 0.9293 - 124_categorical_accuracy: 0.7969 - val_loss: 11.6973 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3476 - val_14_loss: 0.3387 - val_23_loss: 0.4786 - val_24_loss: 0.6559 - val_33_loss: 0.8370 - val_34_loss: 1.1614 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2696 - val_74_loss: 0.6401 - val_83_loss: 0.2392 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2813 - val_94_loss: 1.3148 - val_103_loss: 0.2802 - val_104_loss: 1.4667 - val_113_loss: 0.2709 - val_114_loss: 1.6103 - val_123_loss: 0.2668 - val_124_loss: 1.2382 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9146 - val_14_categorical_accuracy: 0.9555 - val_23_categorical_accuracy: 0.8864 - val_24_categorical_accuracy: 0.8633 - val_33_categorical_accuracy: 0.6501 - val_34_categorical_accuracy: 0.4716 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9434 - val_74_categorical_accuracy: 0.9289 - val_83_categorical_accuracy: 0.9406 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9287 - val_94_categorical_accuracy: 0.7462 - val_103_categorical_accuracy: 0.9292 - val_104_categorical_accuracy: 0.7665 - val_113_categorical_accuracy: 0.9303 - val_114_categorical_accuracy: 0.7672 - val_123_categorical_accuracy: 0.9312 - val_124_categorical_accuracy: 0.8273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.9305 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2892 - 14_loss: 0.1364 - 23_loss: 0.3717 - 24_loss: 0.4201 - 33_loss: 0.7652 - 34_loss: 0.9600 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2237 - 74_loss: 0.2008 - 83_loss: 0.2218 - 84_loss: 0.0000e+00 - 93_loss: 0.2383 - 94_loss: 0.6188 - 103_loss: 0.2456 - 104_loss: 0.6085 - 113_loss: 0.2375 - 114_loss: 0.5934 - 123_loss: 0.2408 - 124_loss: 0.5585 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9174 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8872 - 24_categorical_accuracy: 0.8710 - 33_categorical_accuracy: 0.6680 - 34_categorical_accuracy: 0.5252 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9404 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9373 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9317 - 94_categorical_accuracy: 0.7697 - 103_categorical_accuracy: 0.9291 - 104_categorical_accuracy: 0.7772 - 113_categorical_accuracy: 0.9300 - 114_categorical_accuracy: 0.7750 - 123_categorical_accuracy: 0.9293 - 124_categorical_accuracy: 0.7968 - val_loss: 12.0483 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3539 - val_14_loss: 0.3504 - val_23_loss: 0.4976 - val_24_loss: 0.6965 - val_33_loss: 0.8440 - val_34_loss: 1.1642 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2786 - val_74_loss: 0.6837 - val_83_loss: 0.2404 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2838 - val_94_loss: 1.4170 - val_103_loss: 0.2849 - val_104_loss: 1.5552 - val_113_loss: 0.2716 - val_114_loss: 1.5441 - val_123_loss: 0.2747 - val_124_loss: 1.3078 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9145 - val_14_categorical_accuracy: 0.9555 - val_23_categorical_accuracy: 0.8864 - val_24_categorical_accuracy: 0.8641 - val_33_categorical_accuracy: 0.6450 - val_34_categorical_accuracy: 0.4734 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9432 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9406 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9287 - val_94_categorical_accuracy: 0.7416 - val_103_categorical_accuracy: 0.9291 - val_104_categorical_accuracy: 0.7641 - val_113_categorical_accuracy: 0.9295 - val_114_categorical_accuracy: 0.7668 - val_123_categorical_accuracy: 0.9320 - val_124_categorical_accuracy: 0.8246\n",
      "Epoch 32/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 6.9192 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2882 - 14_loss: 0.1358 - 23_loss: 0.3708 - 24_loss: 0.4191 - 33_loss: 0.7641 - 34_loss: 0.9596 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2227 - 74_loss: 0.2004 - 83_loss: 0.2218 - 84_loss: 0.0000e+00 - 93_loss: 0.2374 - 94_loss: 0.6188 - 103_loss: 0.2451 - 104_loss: 0.6079 - 113_loss: 0.2370 - 114_loss: 0.5923 - 123_loss: 0.2406 - 124_loss: 0.5576 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9174 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8710 - 33_categorical_accuracy: 0.6682 - 34_categorical_accuracy: 0.5250 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9404 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9373 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9316 - 94_categorical_accuracy: 0.7698 - 103_categorical_accuracy: 0.9290 - 104_categorical_accuracy: 0.7776 - 113_categorical_accuracy: 0.9303 - 114_categorical_accuracy: 0.7750 - 123_categorical_accuracy: 0.9292 - 124_categorical_accuracy: 0.7970 - val_loss: 11.9892 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3534 - val_14_loss: 0.3651 - val_23_loss: 0.4946 - val_24_loss: 0.6970 - val_33_loss: 0.8437 - val_34_loss: 1.1592 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2748 - val_74_loss: 0.6573 - val_83_loss: 0.2432 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2818 - val_94_loss: 1.3088 - val_103_loss: 0.2845 - val_104_loss: 1.5285 - val_113_loss: 0.2691 - val_114_loss: 1.6570 - val_123_loss: 0.2736 - val_124_loss: 1.2975 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9144 - val_14_categorical_accuracy: 0.9564 - val_23_categorical_accuracy: 0.8866 - val_24_categorical_accuracy: 0.8629 - val_33_categorical_accuracy: 0.6472 - val_34_categorical_accuracy: 0.4666 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9433 - val_74_categorical_accuracy: 0.9289 - val_83_categorical_accuracy: 0.9406 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9290 - val_94_categorical_accuracy: 0.7448 - val_103_categorical_accuracy: 0.9298 - val_104_categorical_accuracy: 0.7569 - val_113_categorical_accuracy: 0.9292 - val_114_categorical_accuracy: 0.7655 - val_123_categorical_accuracy: 0.9316 - val_124_categorical_accuracy: 0.8318\n",
      "Epoch 33/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.9107 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2873 - 14_loss: 0.1357 - 23_loss: 0.3701 - 24_loss: 0.4185 - 33_loss: 0.7635 - 34_loss: 0.9584 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2223 - 74_loss: 0.2005 - 83_loss: 0.2213 - 84_loss: 0.0000e+00 - 93_loss: 0.2371 - 94_loss: 0.6186 - 103_loss: 0.2443 - 104_loss: 0.6069 - 113_loss: 0.2366 - 114_loss: 0.5918 - 123_loss: 0.2401 - 124_loss: 0.5578 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9174 - 14_categorical_accuracy: 0.9596 - 23_categorical_accuracy: 0.8872 - 24_categorical_accuracy: 0.8712 - 33_categorical_accuracy: 0.6685 - 34_categorical_accuracy: 0.5263 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9404 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9373 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9317 - 94_categorical_accuracy: 0.7693 - 103_categorical_accuracy: 0.9292 - 104_categorical_accuracy: 0.7774 - 113_categorical_accuracy: 0.9303 - 114_categorical_accuracy: 0.7753 - 123_categorical_accuracy: 0.9293 - 124_categorical_accuracy: 0.7969 - val_loss: 12.2436 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3624 - val_14_loss: 0.3560 - val_23_loss: 0.4974 - val_24_loss: 0.6930 - val_33_loss: 0.8496 - val_34_loss: 1.1841 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2838 - val_74_loss: 0.6554 - val_83_loss: 0.2451 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2913 - val_94_loss: 1.4096 - val_103_loss: 0.2882 - val_104_loss: 1.6274 - val_113_loss: 0.2745 - val_114_loss: 1.6284 - val_123_loss: 0.2758 - val_124_loss: 1.3215 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9140 - val_14_categorical_accuracy: 0.9561 - val_23_categorical_accuracy: 0.8849 - val_24_categorical_accuracy: 0.8607 - val_33_categorical_accuracy: 0.6499 - val_34_categorical_accuracy: 0.4661 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9428 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9402 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9287 - val_94_categorical_accuracy: 0.7455 - val_103_categorical_accuracy: 0.9289 - val_104_categorical_accuracy: 0.7681 - val_113_categorical_accuracy: 0.9286 - val_114_categorical_accuracy: 0.7584 - val_123_categorical_accuracy: 0.9315 - val_124_categorical_accuracy: 0.8290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 6.9033 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2870 - 14_loss: 0.1357 - 23_loss: 0.3691 - 24_loss: 0.4174 - 33_loss: 0.7624 - 34_loss: 0.9580 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2217 - 74_loss: 0.2003 - 83_loss: 0.2206 - 84_loss: 0.0000e+00 - 93_loss: 0.2367 - 94_loss: 0.6176 - 103_loss: 0.2441 - 104_loss: 0.6077 - 113_loss: 0.2365 - 114_loss: 0.5917 - 123_loss: 0.2398 - 124_loss: 0.5570 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9593 - 23_categorical_accuracy: 0.8874 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6688 - 34_categorical_accuracy: 0.5255 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9404 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9373 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9316 - 94_categorical_accuracy: 0.7698 - 103_categorical_accuracy: 0.9291 - 104_categorical_accuracy: 0.7772 - 113_categorical_accuracy: 0.9301 - 114_categorical_accuracy: 0.7752 - 123_categorical_accuracy: 0.9292 - 124_categorical_accuracy: 0.7970 - val_loss: 12.2111 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3596 - val_14_loss: 0.3744 - val_23_loss: 0.5039 - val_24_loss: 0.6832 - val_33_loss: 0.8477 - val_34_loss: 1.1765 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2819 - val_74_loss: 0.7158 - val_83_loss: 0.2407 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2866 - val_94_loss: 1.3433 - val_103_loss: 0.2886 - val_104_loss: 1.5964 - val_113_loss: 0.2728 - val_114_loss: 1.6177 - val_123_loss: 0.2780 - val_124_loss: 1.3442 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9146 - val_14_categorical_accuracy: 0.9554 - val_23_categorical_accuracy: 0.8870 - val_24_categorical_accuracy: 0.8620 - val_33_categorical_accuracy: 0.6476 - val_34_categorical_accuracy: 0.4632 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9433 - val_74_categorical_accuracy: 0.9289 - val_83_categorical_accuracy: 0.9399 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9281 - val_94_categorical_accuracy: 0.7425 - val_103_categorical_accuracy: 0.9289 - val_104_categorical_accuracy: 0.7615 - val_113_categorical_accuracy: 0.9307 - val_114_categorical_accuracy: 0.7621 - val_123_categorical_accuracy: 0.9299 - val_124_categorical_accuracy: 0.8209\n",
      "Epoch 35/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 6.8931 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2858 - 14_loss: 0.1351 - 23_loss: 0.3687 - 24_loss: 0.4168 - 33_loss: 0.7612 - 34_loss: 0.9565 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2213 - 74_loss: 0.2004 - 83_loss: 0.2204 - 84_loss: 0.0000e+00 - 93_loss: 0.2363 - 94_loss: 0.6175 - 103_loss: 0.2436 - 104_loss: 0.6062 - 113_loss: 0.2358 - 114_loss: 0.5913 - 123_loss: 0.2391 - 124_loss: 0.5571 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9175 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8874 - 24_categorical_accuracy: 0.8713 - 33_categorical_accuracy: 0.6692 - 34_categorical_accuracy: 0.5272 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9403 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9374 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9315 - 94_categorical_accuracy: 0.7696 - 103_categorical_accuracy: 0.9291 - 104_categorical_accuracy: 0.7772 - 113_categorical_accuracy: 0.9303 - 114_categorical_accuracy: 0.7749 - 123_categorical_accuracy: 0.9292 - 124_categorical_accuracy: 0.7970 - val_loss: 12.9742 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3703 - val_14_loss: 0.4151 - val_23_loss: 0.5165 - val_24_loss: 0.7371 - val_33_loss: 0.8593 - val_34_loss: 1.2047 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2903 - val_74_loss: 0.7361 - val_83_loss: 0.2446 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2952 - val_94_loss: 1.4510 - val_103_loss: 0.2931 - val_104_loss: 1.7889 - val_113_loss: 0.2782 - val_114_loss: 1.7723 - val_123_loss: 0.2841 - val_124_loss: 1.4373 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9144 - val_14_categorical_accuracy: 0.9560 - val_23_categorical_accuracy: 0.8859 - val_24_categorical_accuracy: 0.8634 - val_33_categorical_accuracy: 0.6392 - val_34_categorical_accuracy: 0.4617 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9435 - val_74_categorical_accuracy: 0.9287 - val_83_categorical_accuracy: 0.9405 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9286 - val_94_categorical_accuracy: 0.7415 - val_103_categorical_accuracy: 0.9294 - val_104_categorical_accuracy: 0.7561 - val_113_categorical_accuracy: 0.9303 - val_114_categorical_accuracy: 0.7566 - val_123_categorical_accuracy: 0.9309 - val_124_categorical_accuracy: 0.8239\n",
      "Epoch 36/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 6.8855 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2854 - 14_loss: 0.1345 - 23_loss: 0.3677 - 24_loss: 0.4163 - 33_loss: 0.7609 - 34_loss: 0.9566 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2209 - 74_loss: 0.1992 - 83_loss: 0.2197 - 84_loss: 0.0000e+00 - 93_loss: 0.2357 - 94_loss: 0.6169 - 103_loss: 0.2433 - 104_loss: 0.6063 - 113_loss: 0.2354 - 114_loss: 0.5916 - 123_loss: 0.2384 - 124_loss: 0.5566 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8872 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6684 - 34_categorical_accuracy: 0.5264 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9403 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9372 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9317 - 94_categorical_accuracy: 0.7699 - 103_categorical_accuracy: 0.9291 - 104_categorical_accuracy: 0.7774 - 113_categorical_accuracy: 0.9301 - 114_categorical_accuracy: 0.7749 - 123_categorical_accuracy: 0.9291 - 124_categorical_accuracy: 0.7969 - val_loss: 12.5695 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3634 - val_14_loss: 0.4006 - val_23_loss: 0.5116 - val_24_loss: 0.7237 - val_33_loss: 0.8538 - val_34_loss: 1.1934 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2861 - val_74_loss: 0.7049 - val_83_loss: 0.2471 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2952 - val_94_loss: 1.4282 - val_103_loss: 0.2954 - val_104_loss: 1.6342 - val_113_loss: 0.2773 - val_114_loss: 1.6636 - val_123_loss: 0.2832 - val_124_loss: 1.4076 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9151 - val_14_categorical_accuracy: 0.9564 - val_23_categorical_accuracy: 0.8867 - val_24_categorical_accuracy: 0.8614 - val_33_categorical_accuracy: 0.6501 - val_34_categorical_accuracy: 0.4673 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9435 - val_74_categorical_accuracy: 0.9290 - val_83_categorical_accuracy: 0.9398 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9281 - val_94_categorical_accuracy: 0.7440 - val_103_categorical_accuracy: 0.9296 - val_104_categorical_accuracy: 0.7606 - val_113_categorical_accuracy: 0.9289 - val_114_categorical_accuracy: 0.7616 - val_123_categorical_accuracy: 0.9311 - val_124_categorical_accuracy: 0.8240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.8748 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2849 - 14_loss: 0.1342 - 23_loss: 0.3667 - 24_loss: 0.4154 - 33_loss: 0.7599 - 34_loss: 0.9556 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2195 - 74_loss: 0.1990 - 83_loss: 0.2193 - 84_loss: 0.0000e+00 - 93_loss: 0.2352 - 94_loss: 0.6172 - 103_loss: 0.2427 - 104_loss: 0.6057 - 113_loss: 0.2351 - 114_loss: 0.5901 - 123_loss: 0.2384 - 124_loss: 0.5558 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9172 - 14_categorical_accuracy: 0.9592 - 23_categorical_accuracy: 0.8873 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6689 - 34_categorical_accuracy: 0.5265 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9404 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9373 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9316 - 94_categorical_accuracy: 0.7697 - 103_categorical_accuracy: 0.9292 - 104_categorical_accuracy: 0.7775 - 113_categorical_accuracy: 0.9301 - 114_categorical_accuracy: 0.7748 - 123_categorical_accuracy: 0.9291 - 124_categorical_accuracy: 0.7966 - val_loss: 12.6756 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3721 - val_14_loss: 0.3996 - val_23_loss: 0.5243 - val_24_loss: 0.7240 - val_33_loss: 0.8540 - val_34_loss: 1.1737 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2974 - val_74_loss: 0.7039 - val_83_loss: 0.2452 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2965 - val_94_loss: 1.4998 - val_103_loss: 0.3001 - val_104_loss: 1.6523 - val_113_loss: 0.2777 - val_114_loss: 1.7179 - val_123_loss: 0.2834 - val_124_loss: 1.3537 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9149 - val_14_categorical_accuracy: 0.9554 - val_23_categorical_accuracy: 0.8854 - val_24_categorical_accuracy: 0.8634 - val_33_categorical_accuracy: 0.6460 - val_34_categorical_accuracy: 0.4635 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9433 - val_74_categorical_accuracy: 0.9285 - val_83_categorical_accuracy: 0.9404 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9278 - val_94_categorical_accuracy: 0.7472 - val_103_categorical_accuracy: 0.9273 - val_104_categorical_accuracy: 0.7643 - val_113_categorical_accuracy: 0.9301 - val_114_categorical_accuracy: 0.7654 - val_123_categorical_accuracy: 0.9306 - val_124_categorical_accuracy: 0.8206\n",
      "Epoch 38/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.8729 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2842 - 14_loss: 0.1343 - 23_loss: 0.3662 - 24_loss: 0.4148 - 33_loss: 0.7594 - 34_loss: 0.9543 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2199 - 74_loss: 0.1993 - 83_loss: 0.2190 - 84_loss: 0.0000e+00 - 93_loss: 0.2350 - 94_loss: 0.6170 - 103_loss: 0.2427 - 104_loss: 0.6057 - 113_loss: 0.2347 - 114_loss: 0.5909 - 123_loss: 0.2383 - 124_loss: 0.5571 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9172 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8872 - 24_categorical_accuracy: 0.8710 - 33_categorical_accuracy: 0.6697 - 34_categorical_accuracy: 0.5274 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9404 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9373 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9314 - 94_categorical_accuracy: 0.7691 - 103_categorical_accuracy: 0.9289 - 104_categorical_accuracy: 0.7774 - 113_categorical_accuracy: 0.9302 - 114_categorical_accuracy: 0.7751 - 123_categorical_accuracy: 0.9291 - 124_categorical_accuracy: 0.7971 - val_loss: 12.3081 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3585 - val_14_loss: 0.3865 - val_23_loss: 0.5142 - val_24_loss: 0.7280 - val_33_loss: 0.8514 - val_34_loss: 1.2060 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2874 - val_74_loss: 0.7050 - val_83_loss: 0.2459 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2956 - val_94_loss: 1.3359 - val_103_loss: 0.2919 - val_104_loss: 1.6591 - val_113_loss: 0.2749 - val_114_loss: 1.5856 - val_123_loss: 0.2777 - val_124_loss: 1.3045 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9140 - val_14_categorical_accuracy: 0.9569 - val_23_categorical_accuracy: 0.8863 - val_24_categorical_accuracy: 0.8630 - val_33_categorical_accuracy: 0.6490 - val_34_categorical_accuracy: 0.4605 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9436 - val_74_categorical_accuracy: 0.9285 - val_83_categorical_accuracy: 0.9404 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9289 - val_94_categorical_accuracy: 0.7473 - val_103_categorical_accuracy: 0.9285 - val_104_categorical_accuracy: 0.7724 - val_113_categorical_accuracy: 0.9295 - val_114_categorical_accuracy: 0.7566 - val_123_categorical_accuracy: 0.9311 - val_124_categorical_accuracy: 0.8246\n",
      "Epoch 39/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 6.8625 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2835 - 14_loss: 0.1338 - 23_loss: 0.3660 - 24_loss: 0.4142 - 33_loss: 0.7586 - 34_loss: 0.9540 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2196 - 74_loss: 0.1988 - 83_loss: 0.2190 - 84_loss: 0.0000e+00 - 93_loss: 0.2344 - 94_loss: 0.6162 - 103_loss: 0.2420 - 104_loss: 0.6055 - 113_loss: 0.2345 - 114_loss: 0.5895 - 123_loss: 0.2374 - 124_loss: 0.5556 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9174 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8873 - 24_categorical_accuracy: 0.8709 - 33_categorical_accuracy: 0.6691 - 34_categorical_accuracy: 0.5276 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9404 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9372 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9315 - 94_categorical_accuracy: 0.7696 - 103_categorical_accuracy: 0.9291 - 104_categorical_accuracy: 0.7773 - 113_categorical_accuracy: 0.9301 - 114_categorical_accuracy: 0.7749 - 123_categorical_accuracy: 0.9291 - 124_categorical_accuracy: 0.7972 - val_loss: 12.6038 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3632 - val_14_loss: 0.3869 - val_23_loss: 0.5181 - val_24_loss: 0.7385 - val_33_loss: 0.8538 - val_34_loss: 1.1989 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2872 - val_74_loss: 0.7401 - val_83_loss: 0.2460 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2889 - val_94_loss: 1.4414 - val_103_loss: 0.2912 - val_104_loss: 1.6255 - val_113_loss: 0.2762 - val_114_loss: 1.7521 - val_123_loss: 0.2839 - val_124_loss: 1.3121 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9147 - val_14_categorical_accuracy: 0.9569 - val_23_categorical_accuracy: 0.8857 - val_24_categorical_accuracy: 0.8624 - val_33_categorical_accuracy: 0.6447 - val_34_categorical_accuracy: 0.4571 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9432 - val_74_categorical_accuracy: 0.9287 - val_83_categorical_accuracy: 0.9402 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9285 - val_94_categorical_accuracy: 0.7460 - val_103_categorical_accuracy: 0.9288 - val_104_categorical_accuracy: 0.7713 - val_113_categorical_accuracy: 0.9302 - val_114_categorical_accuracy: 0.7696 - val_123_categorical_accuracy: 0.9316 - val_124_categorical_accuracy: 0.8227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.8555 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2831 - 14_loss: 0.1334 - 23_loss: 0.3654 - 24_loss: 0.4131 - 33_loss: 0.7581 - 34_loss: 0.9534 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2188 - 74_loss: 0.1987 - 83_loss: 0.2183 - 84_loss: 0.0000e+00 - 93_loss: 0.2343 - 94_loss: 0.6160 - 103_loss: 0.2417 - 104_loss: 0.6050 - 113_loss: 0.2337 - 114_loss: 0.5897 - 123_loss: 0.2371 - 124_loss: 0.5558 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9591 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6694 - 34_categorical_accuracy: 0.5282 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9403 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9373 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9315 - 94_categorical_accuracy: 0.7696 - 103_categorical_accuracy: 0.9293 - 104_categorical_accuracy: 0.7774 - 113_categorical_accuracy: 0.9301 - 114_categorical_accuracy: 0.7746 - 123_categorical_accuracy: 0.9290 - 124_categorical_accuracy: 0.7967 - val_loss: 12.8286 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3682 - val_14_loss: 0.4042 - val_23_loss: 0.5123 - val_24_loss: 0.7475 - val_33_loss: 0.8600 - val_34_loss: 1.2089 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2939 - val_74_loss: 0.7383 - val_83_loss: 0.2491 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2987 - val_94_loss: 1.4319 - val_103_loss: 0.2978 - val_104_loss: 1.6369 - val_113_loss: 0.2791 - val_114_loss: 1.8184 - val_123_loss: 0.2862 - val_124_loss: 1.3973 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9133 - val_14_categorical_accuracy: 0.9571 - val_23_categorical_accuracy: 0.8873 - val_24_categorical_accuracy: 0.8641 - val_33_categorical_accuracy: 0.6433 - val_34_categorical_accuracy: 0.4649 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9433 - val_74_categorical_accuracy: 0.9289 - val_83_categorical_accuracy: 0.9404 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9280 - val_94_categorical_accuracy: 0.7466 - val_103_categorical_accuracy: 0.9282 - val_104_categorical_accuracy: 0.7550 - val_113_categorical_accuracy: 0.9308 - val_114_categorical_accuracy: 0.7649 - val_123_categorical_accuracy: 0.9311 - val_124_categorical_accuracy: 0.8256\n",
      "Epoch 41/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.8480 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2827 - 14_loss: 0.1330 - 23_loss: 0.3645 - 24_loss: 0.4122 - 33_loss: 0.7570 - 34_loss: 0.9528 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2185 - 74_loss: 0.1982 - 83_loss: 0.2180 - 84_loss: 0.0000e+00 - 93_loss: 0.2338 - 94_loss: 0.6164 - 103_loss: 0.2409 - 104_loss: 0.6047 - 113_loss: 0.2338 - 114_loss: 0.5901 - 123_loss: 0.2366 - 124_loss: 0.5549 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8711 - 33_categorical_accuracy: 0.6696 - 34_categorical_accuracy: 0.5290 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9404 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9373 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9316 - 94_categorical_accuracy: 0.7698 - 103_categorical_accuracy: 0.9291 - 104_categorical_accuracy: 0.7775 - 113_categorical_accuracy: 0.9301 - 114_categorical_accuracy: 0.7749 - 123_categorical_accuracy: 0.9292 - 124_categorical_accuracy: 0.7969 - val_loss: 13.0100 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3687 - val_14_loss: 0.4045 - val_23_loss: 0.5367 - val_24_loss: 0.7931 - val_33_loss: 0.8596 - val_34_loss: 1.2142 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2924 - val_74_loss: 0.7503 - val_83_loss: 0.2497 - val_84_loss: 0.0000e+00 - val_93_loss: 0.2947 - val_94_loss: 1.4875 - val_103_loss: 0.3001 - val_104_loss: 1.7042 - val_113_loss: 0.2807 - val_114_loss: 1.8098 - val_123_loss: 0.2835 - val_124_loss: 1.3803 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9139 - val_14_categorical_accuracy: 0.9560 - val_23_categorical_accuracy: 0.8867 - val_24_categorical_accuracy: 0.8624 - val_33_categorical_accuracy: 0.6484 - val_34_categorical_accuracy: 0.4652 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9433 - val_74_categorical_accuracy: 0.9290 - val_83_categorical_accuracy: 0.9396 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9284 - val_94_categorical_accuracy: 0.7462 - val_103_categorical_accuracy: 0.9288 - val_104_categorical_accuracy: 0.7590 - val_113_categorical_accuracy: 0.9303 - val_114_categorical_accuracy: 0.7665 - val_123_categorical_accuracy: 0.9315 - val_124_categorical_accuracy: 0.8171\n",
      "Epoch 42/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.8422 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2820 - 14_loss: 0.1330 - 23_loss: 0.3638 - 24_loss: 0.4115 - 33_loss: 0.7571 - 34_loss: 0.9526 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2182 - 74_loss: 0.1987 - 83_loss: 0.2174 - 84_loss: 0.0000e+00 - 93_loss: 0.2332 - 94_loss: 0.6160 - 103_loss: 0.2408 - 104_loss: 0.6041 - 113_loss: 0.2331 - 114_loss: 0.5892 - 123_loss: 0.2365 - 124_loss: 0.5549 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9597 - 23_categorical_accuracy: 0.8872 - 24_categorical_accuracy: 0.8709 - 33_categorical_accuracy: 0.6692 - 34_categorical_accuracy: 0.5290 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9403 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9372 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9314 - 94_categorical_accuracy: 0.7694 - 103_categorical_accuracy: 0.9289 - 104_categorical_accuracy: 0.7773 - 113_categorical_accuracy: 0.9301 - 114_categorical_accuracy: 0.7746 - 123_categorical_accuracy: 0.9291 - 124_categorical_accuracy: 0.7970 - val_loss: 12.9625 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3695 - val_14_loss: 0.3865 - val_23_loss: 0.5318 - val_24_loss: 0.7460 - val_33_loss: 0.8637 - val_34_loss: 1.1979 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2944 - val_74_loss: 0.7567 - val_83_loss: 0.2512 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3052 - val_94_loss: 1.4901 - val_103_loss: 0.2969 - val_104_loss: 1.7796 - val_113_loss: 0.2800 - val_114_loss: 1.7471 - val_123_loss: 0.2865 - val_124_loss: 1.3793 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9144 - val_14_categorical_accuracy: 0.9563 - val_23_categorical_accuracy: 0.8859 - val_24_categorical_accuracy: 0.8625 - val_33_categorical_accuracy: 0.6447 - val_34_categorical_accuracy: 0.4695 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9427 - val_74_categorical_accuracy: 0.9274 - val_83_categorical_accuracy: 0.9404 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9279 - val_94_categorical_accuracy: 0.7462 - val_103_categorical_accuracy: 0.9295 - val_104_categorical_accuracy: 0.7599 - val_113_categorical_accuracy: 0.9303 - val_114_categorical_accuracy: 0.7591 - val_123_categorical_accuracy: 0.9308 - val_124_categorical_accuracy: 0.8222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 6.8359 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2818 - 14_loss: 0.1328 - 23_loss: 0.3637 - 24_loss: 0.4116 - 33_loss: 0.7563 - 34_loss: 0.9518 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2172 - 74_loss: 0.1983 - 83_loss: 0.2175 - 84_loss: 0.0000e+00 - 93_loss: 0.2329 - 94_loss: 0.6152 - 103_loss: 0.2402 - 104_loss: 0.6045 - 113_loss: 0.2324 - 114_loss: 0.5892 - 123_loss: 0.2357 - 124_loss: 0.5547 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8872 - 24_categorical_accuracy: 0.8711 - 33_categorical_accuracy: 0.6705 - 34_categorical_accuracy: 0.5291 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9403 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9373 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9315 - 94_categorical_accuracy: 0.7697 - 103_categorical_accuracy: 0.9289 - 104_categorical_accuracy: 0.7773 - 113_categorical_accuracy: 0.9301 - 114_categorical_accuracy: 0.7750 - 123_categorical_accuracy: 0.9292 - 124_categorical_accuracy: 0.7969 - val_loss: 13.0283 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3756 - val_14_loss: 0.4019 - val_23_loss: 0.5323 - val_24_loss: 0.7800 - val_33_loss: 0.8624 - val_34_loss: 1.2078 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.2964 - val_74_loss: 0.7785 - val_83_loss: 0.2475 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3031 - val_94_loss: 1.4555 - val_103_loss: 0.2972 - val_104_loss: 1.7204 - val_113_loss: 0.2808 - val_114_loss: 1.7636 - val_123_loss: 0.2943 - val_124_loss: 1.4310 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9145 - val_14_categorical_accuracy: 0.9560 - val_23_categorical_accuracy: 0.8855 - val_24_categorical_accuracy: 0.8624 - val_33_categorical_accuracy: 0.6423 - val_34_categorical_accuracy: 0.4652 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9427 - val_74_categorical_accuracy: 0.9285 - val_83_categorical_accuracy: 0.9405 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9286 - val_94_categorical_accuracy: 0.7467 - val_103_categorical_accuracy: 0.9290 - val_104_categorical_accuracy: 0.7630 - val_113_categorical_accuracy: 0.9295 - val_114_categorical_accuracy: 0.7680 - val_123_categorical_accuracy: 0.9306 - val_124_categorical_accuracy: 0.8151\n",
      "Epoch 44/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.8317 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2812 - 14_loss: 0.1327 - 23_loss: 0.3630 - 24_loss: 0.4109 - 33_loss: 0.7551 - 34_loss: 0.9510 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2175 - 74_loss: 0.1984 - 83_loss: 0.2171 - 84_loss: 0.0000e+00 - 93_loss: 0.2325 - 94_loss: 0.6164 - 103_loss: 0.2399 - 104_loss: 0.6043 - 113_loss: 0.2321 - 114_loss: 0.5892 - 123_loss: 0.2353 - 124_loss: 0.5551 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9174 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8874 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6703 - 34_categorical_accuracy: 0.5280 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9403 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9372 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9315 - 94_categorical_accuracy: 0.7699 - 103_categorical_accuracy: 0.9290 - 104_categorical_accuracy: 0.7775 - 113_categorical_accuracy: 0.9301 - 114_categorical_accuracy: 0.7749 - 123_categorical_accuracy: 0.9292 - 124_categorical_accuracy: 0.7969 - val_loss: 13.2793 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3723 - val_14_loss: 0.4088 - val_23_loss: 0.5504 - val_24_loss: 0.8166 - val_33_loss: 0.8666 - val_34_loss: 1.2189 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3035 - val_74_loss: 0.8219 - val_83_loss: 0.2547 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3009 - val_94_loss: 1.4735 - val_103_loss: 0.3073 - val_104_loss: 1.7114 - val_113_loss: 0.2884 - val_114_loss: 1.8419 - val_123_loss: 0.2964 - val_124_loss: 1.4457 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9136 - val_14_categorical_accuracy: 0.9566 - val_23_categorical_accuracy: 0.8869 - val_24_categorical_accuracy: 0.8624 - val_33_categorical_accuracy: 0.6463 - val_34_categorical_accuracy: 0.4650 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9426 - val_74_categorical_accuracy: 0.9288 - val_83_categorical_accuracy: 0.9389 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9289 - val_94_categorical_accuracy: 0.7457 - val_103_categorical_accuracy: 0.9287 - val_104_categorical_accuracy: 0.7689 - val_113_categorical_accuracy: 0.9298 - val_114_categorical_accuracy: 0.7594 - val_123_categorical_accuracy: 0.9295 - val_124_categorical_accuracy: 0.8164\n",
      "Epoch 45/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.8231 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2803 - 14_loss: 0.1323 - 23_loss: 0.3630 - 24_loss: 0.4110 - 33_loss: 0.7548 - 34_loss: 0.9504 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2169 - 74_loss: 0.1974 - 83_loss: 0.2163 - 84_loss: 0.0000e+00 - 93_loss: 0.2323 - 94_loss: 0.6148 - 103_loss: 0.2392 - 104_loss: 0.6039 - 113_loss: 0.2320 - 114_loss: 0.5887 - 123_loss: 0.2350 - 124_loss: 0.5546 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9175 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8711 - 33_categorical_accuracy: 0.6703 - 34_categorical_accuracy: 0.5301 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9404 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9372 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9316 - 94_categorical_accuracy: 0.7697 - 103_categorical_accuracy: 0.9290 - 104_categorical_accuracy: 0.7773 - 113_categorical_accuracy: 0.9299 - 114_categorical_accuracy: 0.7753 - 123_categorical_accuracy: 0.9292 - 124_categorical_accuracy: 0.7966 - val_loss: 13.4276 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3856 - val_14_loss: 0.4184 - val_23_loss: 0.5360 - val_24_loss: 0.8019 - val_33_loss: 0.8732 - val_34_loss: 1.2265 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3008 - val_74_loss: 0.8466 - val_83_loss: 0.2560 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3089 - val_94_loss: 1.5099 - val_103_loss: 0.3116 - val_104_loss: 1.7653 - val_113_loss: 0.2839 - val_114_loss: 1.8423 - val_123_loss: 0.2961 - val_124_loss: 1.4646 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9138 - val_14_categorical_accuracy: 0.9567 - val_23_categorical_accuracy: 0.8866 - val_24_categorical_accuracy: 0.8626 - val_33_categorical_accuracy: 0.6302 - val_34_categorical_accuracy: 0.4544 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9425 - val_74_categorical_accuracy: 0.9277 - val_83_categorical_accuracy: 0.9409 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9269 - val_94_categorical_accuracy: 0.7452 - val_103_categorical_accuracy: 0.9287 - val_104_categorical_accuracy: 0.7626 - val_113_categorical_accuracy: 0.9307 - val_114_categorical_accuracy: 0.7632 - val_123_categorical_accuracy: 0.9301 - val_124_categorical_accuracy: 0.8185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 6.8203 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2799 - 14_loss: 0.1325 - 23_loss: 0.3614 - 24_loss: 0.4103 - 33_loss: 0.7546 - 34_loss: 0.9505 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2165 - 74_loss: 0.1974 - 83_loss: 0.2163 - 84_loss: 0.0000e+00 - 93_loss: 0.2325 - 94_loss: 0.6157 - 103_loss: 0.2391 - 104_loss: 0.6043 - 113_loss: 0.2318 - 114_loss: 0.5887 - 123_loss: 0.2349 - 124_loss: 0.5540 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9172 - 14_categorical_accuracy: 0.9593 - 23_categorical_accuracy: 0.8870 - 24_categorical_accuracy: 0.8712 - 33_categorical_accuracy: 0.6699 - 34_categorical_accuracy: 0.5297 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9403 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9372 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9315 - 94_categorical_accuracy: 0.7698 - 103_categorical_accuracy: 0.9290 - 104_categorical_accuracy: 0.7772 - 113_categorical_accuracy: 0.9299 - 114_categorical_accuracy: 0.7748 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7970 - val_loss: 13.3609 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3886 - val_14_loss: 0.4319 - val_23_loss: 0.5568 - val_24_loss: 0.8175 - val_33_loss: 0.8760 - val_34_loss: 1.2131 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3054 - val_74_loss: 0.8564 - val_83_loss: 0.2560 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3050 - val_94_loss: 1.4447 - val_103_loss: 0.3047 - val_104_loss: 1.7857 - val_113_loss: 0.2897 - val_114_loss: 1.7905 - val_123_loss: 0.2958 - val_124_loss: 1.4431 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9113 - val_14_categorical_accuracy: 0.9557 - val_23_categorical_accuracy: 0.8843 - val_24_categorical_accuracy: 0.8629 - val_33_categorical_accuracy: 0.6406 - val_34_categorical_accuracy: 0.4583 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9437 - val_74_categorical_accuracy: 0.9287 - val_83_categorical_accuracy: 0.9399 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9284 - val_94_categorical_accuracy: 0.7452 - val_103_categorical_accuracy: 0.9284 - val_104_categorical_accuracy: 0.7645 - val_113_categorical_accuracy: 0.9294 - val_114_categorical_accuracy: 0.7639 - val_123_categorical_accuracy: 0.9301 - val_124_categorical_accuracy: 0.8264\n",
      "Epoch 47/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 6.8162 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2796 - 14_loss: 0.1321 - 23_loss: 0.3618 - 24_loss: 0.4101 - 33_loss: 0.7544 - 34_loss: 0.9502 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2163 - 74_loss: 0.1973 - 83_loss: 0.2158 - 84_loss: 0.0000e+00 - 93_loss: 0.2316 - 94_loss: 0.6152 - 103_loss: 0.2383 - 104_loss: 0.6039 - 113_loss: 0.2317 - 114_loss: 0.5890 - 123_loss: 0.2346 - 124_loss: 0.5543 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8872 - 24_categorical_accuracy: 0.8709 - 33_categorical_accuracy: 0.6698 - 34_categorical_accuracy: 0.5302 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9403 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9372 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9315 - 94_categorical_accuracy: 0.7695 - 103_categorical_accuracy: 0.9290 - 104_categorical_accuracy: 0.7772 - 113_categorical_accuracy: 0.9300 - 114_categorical_accuracy: 0.7750 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7966 - val_loss: 13.3989 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3918 - val_14_loss: 0.4384 - val_23_loss: 0.5494 - val_24_loss: 0.7965 - val_33_loss: 0.8748 - val_34_loss: 1.2229 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3105 - val_74_loss: 0.8520 - val_83_loss: 0.2564 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3054 - val_94_loss: 1.5015 - val_103_loss: 0.3056 - val_104_loss: 1.8032 - val_113_loss: 0.2901 - val_114_loss: 1.8019 - val_123_loss: 0.2960 - val_124_loss: 1.4026 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9135 - val_14_categorical_accuracy: 0.9548 - val_23_categorical_accuracy: 0.8867 - val_24_categorical_accuracy: 0.8631 - val_33_categorical_accuracy: 0.6385 - val_34_categorical_accuracy: 0.4632 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9425 - val_74_categorical_accuracy: 0.9288 - val_83_categorical_accuracy: 0.9401 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9288 - val_94_categorical_accuracy: 0.7454 - val_103_categorical_accuracy: 0.9281 - val_104_categorical_accuracy: 0.7720 - val_113_categorical_accuracy: 0.9281 - val_114_categorical_accuracy: 0.7670 - val_123_categorical_accuracy: 0.9300 - val_124_categorical_accuracy: 0.8158\n",
      "Epoch 48/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 6.8119 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2795 - 14_loss: 0.1323 - 23_loss: 0.3616 - 24_loss: 0.4096 - 33_loss: 0.7533 - 34_loss: 0.9493 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2156 - 74_loss: 0.1969 - 83_loss: 0.2157 - 84_loss: 0.0000e+00 - 93_loss: 0.2313 - 94_loss: 0.6152 - 103_loss: 0.2384 - 104_loss: 0.6037 - 113_loss: 0.2313 - 114_loss: 0.5889 - 123_loss: 0.2345 - 124_loss: 0.5549 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8872 - 24_categorical_accuracy: 0.8710 - 33_categorical_accuracy: 0.6703 - 34_categorical_accuracy: 0.5297 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9402 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9371 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9315 - 94_categorical_accuracy: 0.7693 - 103_categorical_accuracy: 0.9289 - 104_categorical_accuracy: 0.7773 - 113_categorical_accuracy: 0.9300 - 114_categorical_accuracy: 0.7748 - 123_categorical_accuracy: 0.9291 - 124_categorical_accuracy: 0.7970 - val_loss: 13.3588 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3838 - val_14_loss: 0.4151 - val_23_loss: 0.5410 - val_24_loss: 0.7903 - val_33_loss: 0.8680 - val_34_loss: 1.2051 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3044 - val_74_loss: 0.8593 - val_83_loss: 0.2516 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3095 - val_94_loss: 1.5405 - val_103_loss: 0.3087 - val_104_loss: 1.7413 - val_113_loss: 0.2875 - val_114_loss: 1.8375 - val_123_loss: 0.2944 - val_124_loss: 1.4207 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9134 - val_14_categorical_accuracy: 0.9564 - val_23_categorical_accuracy: 0.8861 - val_24_categorical_accuracy: 0.8627 - val_33_categorical_accuracy: 0.6453 - val_34_categorical_accuracy: 0.4617 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9430 - val_74_categorical_accuracy: 0.9290 - val_83_categorical_accuracy: 0.9400 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9285 - val_94_categorical_accuracy: 0.7469 - val_103_categorical_accuracy: 0.9297 - val_104_categorical_accuracy: 0.7644 - val_113_categorical_accuracy: 0.9288 - val_114_categorical_accuracy: 0.7598 - val_123_categorical_accuracy: 0.9311 - val_124_categorical_accuracy: 0.8143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 6.8030 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2789 - 14_loss: 0.1317 - 23_loss: 0.3607 - 24_loss: 0.4092 - 33_loss: 0.7528 - 34_loss: 0.9489 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2151 - 74_loss: 0.1971 - 83_loss: 0.2154 - 84_loss: 0.0000e+00 - 93_loss: 0.2307 - 94_loss: 0.6145 - 103_loss: 0.2380 - 104_loss: 0.6033 - 113_loss: 0.2306 - 114_loss: 0.5882 - 123_loss: 0.2341 - 124_loss: 0.5540 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9174 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8709 - 33_categorical_accuracy: 0.6702 - 34_categorical_accuracy: 0.5301 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9402 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9314 - 94_categorical_accuracy: 0.7693 - 103_categorical_accuracy: 0.9291 - 104_categorical_accuracy: 0.7774 - 113_categorical_accuracy: 0.9300 - 114_categorical_accuracy: 0.7749 - 123_categorical_accuracy: 0.9290 - 124_categorical_accuracy: 0.7969 - val_loss: 13.7837 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3877 - val_14_loss: 0.4626 - val_23_loss: 0.5601 - val_24_loss: 0.8101 - val_33_loss: 0.8746 - val_34_loss: 1.2289 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3105 - val_74_loss: 0.8691 - val_83_loss: 0.2549 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3102 - val_94_loss: 1.4917 - val_103_loss: 0.3113 - val_104_loss: 1.8506 - val_113_loss: 0.2956 - val_114_loss: 1.9074 - val_123_loss: 0.2965 - val_124_loss: 1.5619 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9136 - val_14_categorical_accuracy: 0.9553 - val_23_categorical_accuracy: 0.8853 - val_24_categorical_accuracy: 0.8630 - val_33_categorical_accuracy: 0.6395 - val_34_categorical_accuracy: 0.4594 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9423 - val_74_categorical_accuracy: 0.9279 - val_83_categorical_accuracy: 0.9394 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9284 - val_94_categorical_accuracy: 0.7508 - val_103_categorical_accuracy: 0.9292 - val_104_categorical_accuracy: 0.7579 - val_113_categorical_accuracy: 0.9301 - val_114_categorical_accuracy: 0.7575 - val_123_categorical_accuracy: 0.9310 - val_124_categorical_accuracy: 0.8094\n",
      "Epoch 50/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.8037 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2786 - 14_loss: 0.1318 - 23_loss: 0.3606 - 24_loss: 0.4086 - 33_loss: 0.7531 - 34_loss: 0.9488 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2152 - 74_loss: 0.1969 - 83_loss: 0.2153 - 84_loss: 0.0000e+00 - 93_loss: 0.2312 - 94_loss: 0.6148 - 103_loss: 0.2378 - 104_loss: 0.6029 - 113_loss: 0.2306 - 114_loss: 0.5886 - 123_loss: 0.2339 - 124_loss: 0.5552 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9172 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8710 - 33_categorical_accuracy: 0.6700 - 34_categorical_accuracy: 0.5303 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9403 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9315 - 94_categorical_accuracy: 0.7696 - 103_categorical_accuracy: 0.9289 - 104_categorical_accuracy: 0.7774 - 113_categorical_accuracy: 0.9300 - 114_categorical_accuracy: 0.7748 - 123_categorical_accuracy: 0.9292 - 124_categorical_accuracy: 0.7970 - val_loss: 14.1127 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3861 - val_14_loss: 0.4343 - val_23_loss: 0.5682 - val_24_loss: 0.8673 - val_33_loss: 0.8669 - val_34_loss: 1.2497 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3168 - val_74_loss: 0.9228 - val_83_loss: 0.2621 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3126 - val_94_loss: 1.6248 - val_103_loss: 0.3227 - val_104_loss: 1.9551 - val_113_loss: 0.2902 - val_114_loss: 1.9660 - val_123_loss: 0.2972 - val_124_loss: 1.4699 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9146 - val_14_categorical_accuracy: 0.9563 - val_23_categorical_accuracy: 0.8853 - val_24_categorical_accuracy: 0.8609 - val_33_categorical_accuracy: 0.6445 - val_34_categorical_accuracy: 0.4635 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9416 - val_74_categorical_accuracy: 0.9288 - val_83_categorical_accuracy: 0.9399 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9282 - val_94_categorical_accuracy: 0.7412 - val_103_categorical_accuracy: 0.9271 - val_104_categorical_accuracy: 0.7570 - val_113_categorical_accuracy: 0.9294 - val_114_categorical_accuracy: 0.7665 - val_123_categorical_accuracy: 0.9301 - val_124_categorical_accuracy: 0.8152\n",
      "Epoch 51/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.7960 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2779 - 14_loss: 0.1313 - 23_loss: 0.3600 - 24_loss: 0.4080 - 33_loss: 0.7530 - 34_loss: 0.9485 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2141 - 74_loss: 0.1966 - 83_loss: 0.2148 - 84_loss: 0.0000e+00 - 93_loss: 0.2305 - 94_loss: 0.6146 - 103_loss: 0.2381 - 104_loss: 0.6030 - 113_loss: 0.2299 - 114_loss: 0.5887 - 123_loss: 0.2329 - 124_loss: 0.5541 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9174 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8872 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6702 - 34_categorical_accuracy: 0.5310 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9315 - 94_categorical_accuracy: 0.7695 - 103_categorical_accuracy: 0.9289 - 104_categorical_accuracy: 0.7773 - 113_categorical_accuracy: 0.9301 - 114_categorical_accuracy: 0.7751 - 123_categorical_accuracy: 0.9291 - 124_categorical_accuracy: 0.7965 - val_loss: 13.5489 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3848 - val_14_loss: 0.4253 - val_23_loss: 0.5529 - val_24_loss: 0.7893 - val_33_loss: 0.8777 - val_34_loss: 1.2288 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3103 - val_74_loss: 0.8731 - val_83_loss: 0.2564 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3037 - val_94_loss: 1.5710 - val_103_loss: 0.3103 - val_104_loss: 1.8858 - val_113_loss: 0.2882 - val_114_loss: 1.7955 - val_123_loss: 0.2964 - val_124_loss: 1.3993 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9147 - val_14_categorical_accuracy: 0.9566 - val_23_categorical_accuracy: 0.8863 - val_24_categorical_accuracy: 0.8625 - val_33_categorical_accuracy: 0.6418 - val_34_categorical_accuracy: 0.4575 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9434 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9406 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9282 - val_94_categorical_accuracy: 0.7407 - val_103_categorical_accuracy: 0.9285 - val_104_categorical_accuracy: 0.7661 - val_113_categorical_accuracy: 0.9298 - val_114_categorical_accuracy: 0.7636 - val_123_categorical_accuracy: 0.9307 - val_124_categorical_accuracy: 0.8254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 6.7908 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2773 - 14_loss: 0.1316 - 23_loss: 0.3596 - 24_loss: 0.4081 - 33_loss: 0.7516 - 34_loss: 0.9476 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2146 - 74_loss: 0.1964 - 83_loss: 0.2147 - 84_loss: 0.0000e+00 - 93_loss: 0.2301 - 94_loss: 0.6147 - 103_loss: 0.2371 - 104_loss: 0.6027 - 113_loss: 0.2298 - 114_loss: 0.5878 - 123_loss: 0.2339 - 124_loss: 0.5535 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8870 - 24_categorical_accuracy: 0.8710 - 33_categorical_accuracy: 0.6698 - 34_categorical_accuracy: 0.5316 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9402 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9371 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9314 - 94_categorical_accuracy: 0.7693 - 103_categorical_accuracy: 0.9289 - 104_categorical_accuracy: 0.7776 - 113_categorical_accuracy: 0.9301 - 114_categorical_accuracy: 0.7749 - 123_categorical_accuracy: 0.9291 - 124_categorical_accuracy: 0.7971 - val_loss: 13.7707 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3886 - val_14_loss: 0.4041 - val_23_loss: 0.5686 - val_24_loss: 0.8530 - val_33_loss: 0.8787 - val_34_loss: 1.2336 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3136 - val_74_loss: 0.9422 - val_83_loss: 0.2573 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3110 - val_94_loss: 1.6164 - val_103_loss: 0.3130 - val_104_loss: 1.8514 - val_113_loss: 0.2919 - val_114_loss: 1.8040 - val_123_loss: 0.2925 - val_124_loss: 1.4509 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9147 - val_14_categorical_accuracy: 0.9571 - val_23_categorical_accuracy: 0.8857 - val_24_categorical_accuracy: 0.8631 - val_33_categorical_accuracy: 0.6437 - val_34_categorical_accuracy: 0.4652 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9428 - val_74_categorical_accuracy: 0.9267 - val_83_categorical_accuracy: 0.9403 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9268 - val_94_categorical_accuracy: 0.7481 - val_103_categorical_accuracy: 0.9292 - val_104_categorical_accuracy: 0.7752 - val_113_categorical_accuracy: 0.9299 - val_114_categorical_accuracy: 0.7619 - val_123_categorical_accuracy: 0.9304 - val_124_categorical_accuracy: 0.8165\n",
      "Epoch 53/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 6.7890 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2771 - 14_loss: 0.1313 - 23_loss: 0.3594 - 24_loss: 0.4079 - 33_loss: 0.7515 - 34_loss: 0.9473 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2140 - 74_loss: 0.1967 - 83_loss: 0.2139 - 84_loss: 0.0000e+00 - 93_loss: 0.2303 - 94_loss: 0.6144 - 103_loss: 0.2374 - 104_loss: 0.6028 - 113_loss: 0.2299 - 114_loss: 0.5876 - 123_loss: 0.2332 - 124_loss: 0.5542 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9170 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8712 - 33_categorical_accuracy: 0.6701 - 34_categorical_accuracy: 0.5316 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9371 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7696 - 103_categorical_accuracy: 0.9289 - 104_categorical_accuracy: 0.7772 - 113_categorical_accuracy: 0.9300 - 114_categorical_accuracy: 0.7751 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7969 - val_loss: 13.8345 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3949 - val_14_loss: 0.4402 - val_23_loss: 0.5587 - val_24_loss: 0.8142 - val_33_loss: 0.8742 - val_34_loss: 1.2314 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3142 - val_74_loss: 0.9039 - val_83_loss: 0.2645 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3113 - val_94_loss: 1.5308 - val_103_loss: 0.3064 - val_104_loss: 1.7859 - val_113_loss: 0.2933 - val_114_loss: 2.0012 - val_123_loss: 0.3020 - val_124_loss: 1.5074 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9148 - val_14_categorical_accuracy: 0.9564 - val_23_categorical_accuracy: 0.8865 - val_24_categorical_accuracy: 0.8630 - val_33_categorical_accuracy: 0.6435 - val_34_categorical_accuracy: 0.4664 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9425 - val_74_categorical_accuracy: 0.9288 - val_83_categorical_accuracy: 0.9406 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9276 - val_94_categorical_accuracy: 0.7460 - val_103_categorical_accuracy: 0.9288 - val_104_categorical_accuracy: 0.7572 - val_113_categorical_accuracy: 0.9299 - val_114_categorical_accuracy: 0.7599 - val_123_categorical_accuracy: 0.9305 - val_124_categorical_accuracy: 0.8192\n",
      "Epoch 54/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.7844 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2777 - 14_loss: 0.1309 - 23_loss: 0.3586 - 24_loss: 0.4068 - 33_loss: 0.7510 - 34_loss: 0.9478 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2137 - 74_loss: 0.1967 - 83_loss: 0.2142 - 84_loss: 0.0000e+00 - 93_loss: 0.2298 - 94_loss: 0.6143 - 103_loss: 0.2367 - 104_loss: 0.6026 - 113_loss: 0.2294 - 114_loss: 0.5878 - 123_loss: 0.2329 - 124_loss: 0.5535 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9170 - 14_categorical_accuracy: 0.9593 - 23_categorical_accuracy: 0.8873 - 24_categorical_accuracy: 0.8710 - 33_categorical_accuracy: 0.6706 - 34_categorical_accuracy: 0.5317 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9403 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9312 - 94_categorical_accuracy: 0.7696 - 103_categorical_accuracy: 0.9290 - 104_categorical_accuracy: 0.7772 - 113_categorical_accuracy: 0.9299 - 114_categorical_accuracy: 0.7749 - 123_categorical_accuracy: 0.9288 - 124_categorical_accuracy: 0.7969 - val_loss: 13.7789 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3909 - val_14_loss: 0.4279 - val_23_loss: 0.5758 - val_24_loss: 0.8490 - val_33_loss: 0.8774 - val_34_loss: 1.2229 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3134 - val_74_loss: 0.8990 - val_83_loss: 0.2566 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3170 - val_94_loss: 1.5604 - val_103_loss: 0.3234 - val_104_loss: 1.8837 - val_113_loss: 0.2957 - val_114_loss: 1.8246 - val_123_loss: 0.3110 - val_124_loss: 1.4502 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9147 - val_14_categorical_accuracy: 0.9563 - val_23_categorical_accuracy: 0.8863 - val_24_categorical_accuracy: 0.8625 - val_33_categorical_accuracy: 0.6390 - val_34_categorical_accuracy: 0.4637 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9433 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9401 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9279 - val_94_categorical_accuracy: 0.7486 - val_103_categorical_accuracy: 0.9297 - val_104_categorical_accuracy: 0.7668 - val_113_categorical_accuracy: 0.9298 - val_114_categorical_accuracy: 0.7647 - val_123_categorical_accuracy: 0.9312 - val_124_categorical_accuracy: 0.8298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.7801 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2763 - 14_loss: 0.1305 - 23_loss: 0.3580 - 24_loss: 0.4069 - 33_loss: 0.7507 - 34_loss: 0.9477 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2138 - 74_loss: 0.1963 - 83_loss: 0.2136 - 84_loss: 0.0000e+00 - 93_loss: 0.2295 - 94_loss: 0.6146 - 103_loss: 0.2365 - 104_loss: 0.6023 - 113_loss: 0.2293 - 114_loss: 0.5882 - 123_loss: 0.2322 - 124_loss: 0.5538 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9176 - 14_categorical_accuracy: 0.9596 - 23_categorical_accuracy: 0.8873 - 24_categorical_accuracy: 0.8709 - 33_categorical_accuracy: 0.6704 - 34_categorical_accuracy: 0.5314 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9402 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9371 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9314 - 94_categorical_accuracy: 0.7695 - 103_categorical_accuracy: 0.9290 - 104_categorical_accuracy: 0.7773 - 113_categorical_accuracy: 0.9298 - 114_categorical_accuracy: 0.7749 - 123_categorical_accuracy: 0.9290 - 124_categorical_accuracy: 0.7966 - val_loss: 14.1305 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3942 - val_14_loss: 0.4251 - val_23_loss: 0.5859 - val_24_loss: 0.8768 - val_33_loss: 0.8877 - val_34_loss: 1.2456 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3160 - val_74_loss: 0.9187 - val_83_loss: 0.2578 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3273 - val_94_loss: 1.6396 - val_103_loss: 0.3188 - val_104_loss: 1.9375 - val_113_loss: 0.2962 - val_114_loss: 1.8883 - val_123_loss: 0.3056 - val_124_loss: 1.5096 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9136 - val_14_categorical_accuracy: 0.9565 - val_23_categorical_accuracy: 0.8857 - val_24_categorical_accuracy: 0.8600 - val_33_categorical_accuracy: 0.6420 - val_34_categorical_accuracy: 0.4610 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9423 - val_74_categorical_accuracy: 0.9272 - val_83_categorical_accuracy: 0.9403 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9264 - val_94_categorical_accuracy: 0.7399 - val_103_categorical_accuracy: 0.9260 - val_104_categorical_accuracy: 0.7543 - val_113_categorical_accuracy: 0.9296 - val_114_categorical_accuracy: 0.7648 - val_123_categorical_accuracy: 0.9298 - val_124_categorical_accuracy: 0.8264\n",
      "Epoch 56/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.7778 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2761 - 14_loss: 0.1307 - 23_loss: 0.3583 - 24_loss: 0.4073 - 33_loss: 0.7501 - 34_loss: 0.9467 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2132 - 74_loss: 0.1961 - 83_loss: 0.2138 - 84_loss: 0.0000e+00 - 93_loss: 0.2292 - 94_loss: 0.6147 - 103_loss: 0.2366 - 104_loss: 0.6026 - 113_loss: 0.2289 - 114_loss: 0.5879 - 123_loss: 0.2322 - 124_loss: 0.5534 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9596 - 23_categorical_accuracy: 0.8867 - 24_categorical_accuracy: 0.8707 - 33_categorical_accuracy: 0.6711 - 34_categorical_accuracy: 0.5311 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9402 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9371 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9314 - 94_categorical_accuracy: 0.7694 - 103_categorical_accuracy: 0.9289 - 104_categorical_accuracy: 0.7772 - 113_categorical_accuracy: 0.9299 - 114_categorical_accuracy: 0.7748 - 123_categorical_accuracy: 0.9292 - 124_categorical_accuracy: 0.7972 - val_loss: 14.1854 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4003 - val_14_loss: 0.4600 - val_23_loss: 0.5787 - val_24_loss: 0.8549 - val_33_loss: 0.8811 - val_34_loss: 1.2325 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3204 - val_74_loss: 0.9370 - val_83_loss: 0.2673 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3164 - val_94_loss: 1.6034 - val_103_loss: 0.3187 - val_104_loss: 1.8903 - val_113_loss: 0.2974 - val_114_loss: 1.9960 - val_123_loss: 0.3066 - val_124_loss: 1.5246 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9143 - val_14_categorical_accuracy: 0.9559 - val_23_categorical_accuracy: 0.8851 - val_24_categorical_accuracy: 0.8617 - val_33_categorical_accuracy: 0.6395 - val_34_categorical_accuracy: 0.4641 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9427 - val_74_categorical_accuracy: 0.9288 - val_83_categorical_accuracy: 0.9405 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9280 - val_94_categorical_accuracy: 0.7451 - val_103_categorical_accuracy: 0.9283 - val_104_categorical_accuracy: 0.7564 - val_113_categorical_accuracy: 0.9278 - val_114_categorical_accuracy: 0.7625 - val_123_categorical_accuracy: 0.9306 - val_124_categorical_accuracy: 0.8154\n",
      "Epoch 57/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.7767 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2759 - 14_loss: 0.1308 - 23_loss: 0.3573 - 24_loss: 0.4066 - 33_loss: 0.7501 - 34_loss: 0.9463 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2134 - 74_loss: 0.1958 - 83_loss: 0.2138 - 84_loss: 0.0000e+00 - 93_loss: 0.2299 - 94_loss: 0.6145 - 103_loss: 0.2367 - 104_loss: 0.6023 - 113_loss: 0.2295 - 114_loss: 0.5878 - 123_loss: 0.2324 - 124_loss: 0.5539 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9174 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8873 - 24_categorical_accuracy: 0.8710 - 33_categorical_accuracy: 0.6706 - 34_categorical_accuracy: 0.5312 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9371 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7695 - 103_categorical_accuracy: 0.9288 - 104_categorical_accuracy: 0.7774 - 113_categorical_accuracy: 0.9299 - 114_categorical_accuracy: 0.7749 - 123_categorical_accuracy: 0.9291 - 124_categorical_accuracy: 0.7966 - val_loss: 13.8005 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3850 - val_14_loss: 0.4087 - val_23_loss: 0.5616 - val_24_loss: 0.8400 - val_33_loss: 0.8820 - val_34_loss: 1.2282 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3128 - val_74_loss: 0.9410 - val_83_loss: 0.2598 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3145 - val_94_loss: 1.5767 - val_103_loss: 0.3165 - val_104_loss: 1.8558 - val_113_loss: 0.2971 - val_114_loss: 1.8474 - val_123_loss: 0.2976 - val_124_loss: 1.4760 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9132 - val_14_categorical_accuracy: 0.9550 - val_23_categorical_accuracy: 0.8850 - val_24_categorical_accuracy: 0.8627 - val_33_categorical_accuracy: 0.6460 - val_34_categorical_accuracy: 0.4584 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9421 - val_74_categorical_accuracy: 0.9289 - val_83_categorical_accuracy: 0.9404 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9284 - val_94_categorical_accuracy: 0.7462 - val_103_categorical_accuracy: 0.9296 - val_104_categorical_accuracy: 0.7641 - val_113_categorical_accuracy: 0.9308 - val_114_categorical_accuracy: 0.7556 - val_123_categorical_accuracy: 0.9312 - val_124_categorical_accuracy: 0.8257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.7679 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2757 - 14_loss: 0.1306 - 23_loss: 0.3574 - 24_loss: 0.4058 - 33_loss: 0.7495 - 34_loss: 0.9456 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2125 - 74_loss: 0.1956 - 83_loss: 0.2132 - 84_loss: 0.0000e+00 - 93_loss: 0.2287 - 94_loss: 0.6140 - 103_loss: 0.2356 - 104_loss: 0.6026 - 113_loss: 0.2285 - 114_loss: 0.5875 - 123_loss: 0.2316 - 124_loss: 0.5534 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9172 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6708 - 34_categorical_accuracy: 0.5328 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9400 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9371 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9315 - 94_categorical_accuracy: 0.7692 - 103_categorical_accuracy: 0.9292 - 104_categorical_accuracy: 0.7774 - 113_categorical_accuracy: 0.9300 - 114_categorical_accuracy: 0.7749 - 123_categorical_accuracy: 0.9291 - 124_categorical_accuracy: 0.7970 - val_loss: 13.7204 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3920 - val_14_loss: 0.4306 - val_23_loss: 0.5685 - val_24_loss: 0.8374 - val_33_loss: 0.8655 - val_34_loss: 1.2208 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3138 - val_74_loss: 0.8588 - val_83_loss: 0.2598 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3088 - val_94_loss: 1.5127 - val_103_loss: 0.3153 - val_104_loss: 1.8839 - val_113_loss: 0.2982 - val_114_loss: 1.9257 - val_123_loss: 0.3045 - val_124_loss: 1.4242 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9141 - val_14_categorical_accuracy: 0.9557 - val_23_categorical_accuracy: 0.8856 - val_24_categorical_accuracy: 0.8632 - val_33_categorical_accuracy: 0.6455 - val_34_categorical_accuracy: 0.4690 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9429 - val_74_categorical_accuracy: 0.9285 - val_83_categorical_accuracy: 0.9399 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9272 - val_94_categorical_accuracy: 0.7496 - val_103_categorical_accuracy: 0.9291 - val_104_categorical_accuracy: 0.7641 - val_113_categorical_accuracy: 0.9276 - val_114_categorical_accuracy: 0.7625 - val_123_categorical_accuracy: 0.9304 - val_124_categorical_accuracy: 0.8221\n",
      "Epoch 59/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.7617 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2749 - 14_loss: 0.1304 - 23_loss: 0.3566 - 24_loss: 0.4054 - 33_loss: 0.7487 - 34_loss: 0.9460 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2123 - 74_loss: 0.1956 - 83_loss: 0.2131 - 84_loss: 0.0000e+00 - 93_loss: 0.2283 - 94_loss: 0.6137 - 103_loss: 0.2350 - 104_loss: 0.6018 - 113_loss: 0.2286 - 114_loss: 0.5867 - 123_loss: 0.2313 - 124_loss: 0.5531 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9174 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6708 - 34_categorical_accuracy: 0.5322 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9402 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9371 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7696 - 103_categorical_accuracy: 0.9291 - 104_categorical_accuracy: 0.7774 - 113_categorical_accuracy: 0.9297 - 114_categorical_accuracy: 0.7749 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7970 - val_loss: 14.3086 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4025 - val_14_loss: 0.4515 - val_23_loss: 0.5953 - val_24_loss: 0.8650 - val_33_loss: 0.8829 - val_34_loss: 1.2267 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3356 - val_74_loss: 0.9577 - val_83_loss: 0.2641 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3266 - val_94_loss: 1.5965 - val_103_loss: 0.3284 - val_104_loss: 2.0570 - val_113_loss: 0.2999 - val_114_loss: 1.8869 - val_123_loss: 0.3121 - val_124_loss: 1.5199 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9140 - val_14_categorical_accuracy: 0.9560 - val_23_categorical_accuracy: 0.8861 - val_24_categorical_accuracy: 0.8627 - val_33_categorical_accuracy: 0.6427 - val_34_categorical_accuracy: 0.4655 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9421 - val_74_categorical_accuracy: 0.9290 - val_83_categorical_accuracy: 0.9398 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9276 - val_94_categorical_accuracy: 0.7506 - val_103_categorical_accuracy: 0.9287 - val_104_categorical_accuracy: 0.7567 - val_113_categorical_accuracy: 0.9297 - val_114_categorical_accuracy: 0.7617 - val_123_categorical_accuracy: 0.9285 - val_124_categorical_accuracy: 0.8306\n",
      "Epoch 60/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 6.7618 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2748 - 14_loss: 0.1301 - 23_loss: 0.3566 - 24_loss: 0.4048 - 33_loss: 0.7491 - 34_loss: 0.9461 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2125 - 74_loss: 0.1962 - 83_loss: 0.2122 - 84_loss: 0.0000e+00 - 93_loss: 0.2282 - 94_loss: 0.6143 - 103_loss: 0.2356 - 104_loss: 0.6020 - 113_loss: 0.2285 - 114_loss: 0.5867 - 123_loss: 0.2307 - 124_loss: 0.5533 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9596 - 23_categorical_accuracy: 0.8870 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6705 - 34_categorical_accuracy: 0.5314 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7694 - 103_categorical_accuracy: 0.9288 - 104_categorical_accuracy: 0.7770 - 113_categorical_accuracy: 0.9300 - 114_categorical_accuracy: 0.7748 - 123_categorical_accuracy: 0.9291 - 124_categorical_accuracy: 0.7967 - val_loss: 13.7322 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.3912 - val_14_loss: 0.4385 - val_23_loss: 0.5584 - val_24_loss: 0.8130 - val_33_loss: 0.8758 - val_34_loss: 1.2375 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3236 - val_74_loss: 0.9496 - val_83_loss: 0.2659 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3232 - val_94_loss: 1.4844 - val_103_loss: 0.3181 - val_104_loss: 1.8626 - val_113_loss: 0.2934 - val_114_loss: 1.8530 - val_123_loss: 0.3092 - val_124_loss: 1.4348 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9136 - val_14_categorical_accuracy: 0.9555 - val_23_categorical_accuracy: 0.8870 - val_24_categorical_accuracy: 0.8639 - val_33_categorical_accuracy: 0.6432 - val_34_categorical_accuracy: 0.4592 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9430 - val_74_categorical_accuracy: 0.9287 - val_83_categorical_accuracy: 0.9408 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9280 - val_94_categorical_accuracy: 0.7417 - val_103_categorical_accuracy: 0.9291 - val_104_categorical_accuracy: 0.7608 - val_113_categorical_accuracy: 0.9297 - val_114_categorical_accuracy: 0.7630 - val_123_categorical_accuracy: 0.9309 - val_124_categorical_accuracy: 0.8277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.7563 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2751 - 14_loss: 0.1299 - 23_loss: 0.3562 - 24_loss: 0.4053 - 33_loss: 0.7487 - 34_loss: 0.9451 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2117 - 74_loss: 0.1955 - 83_loss: 0.2121 - 84_loss: 0.0000e+00 - 93_loss: 0.2279 - 94_loss: 0.6133 - 103_loss: 0.2352 - 104_loss: 0.6019 - 113_loss: 0.2280 - 114_loss: 0.5866 - 123_loss: 0.2311 - 124_loss: 0.5527 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9170 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8870 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6712 - 34_categorical_accuracy: 0.5318 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9314 - 94_categorical_accuracy: 0.7691 - 103_categorical_accuracy: 0.9290 - 104_categorical_accuracy: 0.7773 - 113_categorical_accuracy: 0.9299 - 114_categorical_accuracy: 0.7748 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7969 - val_loss: 14.3554 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4072 - val_14_loss: 0.4818 - val_23_loss: 0.5830 - val_24_loss: 0.8712 - val_33_loss: 0.8890 - val_34_loss: 1.2488 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3278 - val_74_loss: 1.0382 - val_83_loss: 0.2703 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3189 - val_94_loss: 1.6563 - val_103_loss: 0.3222 - val_104_loss: 1.9333 - val_113_loss: 0.2987 - val_114_loss: 1.8611 - val_123_loss: 0.3147 - val_124_loss: 1.5330 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9136 - val_14_categorical_accuracy: 0.9566 - val_23_categorical_accuracy: 0.8852 - val_24_categorical_accuracy: 0.8626 - val_33_categorical_accuracy: 0.6463 - val_34_categorical_accuracy: 0.4586 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9418 - val_74_categorical_accuracy: 0.9286 - val_83_categorical_accuracy: 0.9396 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9275 - val_94_categorical_accuracy: 0.7372 - val_103_categorical_accuracy: 0.9285 - val_104_categorical_accuracy: 0.7719 - val_113_categorical_accuracy: 0.9298 - val_114_categorical_accuracy: 0.7577 - val_123_categorical_accuracy: 0.9298 - val_124_categorical_accuracy: 0.8288\n",
      "Epoch 62/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.7564 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2749 - 14_loss: 0.1296 - 23_loss: 0.3564 - 24_loss: 0.4049 - 33_loss: 0.7483 - 34_loss: 0.9453 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2119 - 74_loss: 0.1958 - 83_loss: 0.2123 - 84_loss: 0.0000e+00 - 93_loss: 0.2279 - 94_loss: 0.6137 - 103_loss: 0.2350 - 104_loss: 0.6023 - 113_loss: 0.2279 - 114_loss: 0.5870 - 123_loss: 0.2304 - 124_loss: 0.5529 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9172 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8709 - 33_categorical_accuracy: 0.6710 - 34_categorical_accuracy: 0.5314 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9371 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9314 - 94_categorical_accuracy: 0.7693 - 103_categorical_accuracy: 0.9291 - 104_categorical_accuracy: 0.7775 - 113_categorical_accuracy: 0.9299 - 114_categorical_accuracy: 0.7748 - 123_categorical_accuracy: 0.9290 - 124_categorical_accuracy: 0.7968 - val_loss: 14.5903 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4084 - val_14_loss: 0.4677 - val_23_loss: 0.5814 - val_24_loss: 0.8821 - val_33_loss: 0.8925 - val_34_loss: 1.2422 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3385 - val_74_loss: 1.0423 - val_83_loss: 0.2686 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3224 - val_94_loss: 1.6944 - val_103_loss: 0.3266 - val_104_loss: 1.9242 - val_113_loss: 0.3071 - val_114_loss: 1.9651 - val_123_loss: 0.3264 - val_124_loss: 1.6005 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9124 - val_14_categorical_accuracy: 0.9565 - val_23_categorical_accuracy: 0.8858 - val_24_categorical_accuracy: 0.8611 - val_33_categorical_accuracy: 0.6414 - val_34_categorical_accuracy: 0.4538 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9429 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9397 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9280 - val_94_categorical_accuracy: 0.7460 - val_103_categorical_accuracy: 0.9286 - val_104_categorical_accuracy: 0.7547 - val_113_categorical_accuracy: 0.9277 - val_114_categorical_accuracy: 0.7585 - val_123_categorical_accuracy: 0.9305 - val_124_categorical_accuracy: 0.8191\n",
      "Epoch 63/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.7590 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2746 - 14_loss: 0.1299 - 23_loss: 0.3564 - 24_loss: 0.4051 - 33_loss: 0.7486 - 34_loss: 0.9453 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2119 - 74_loss: 0.1963 - 83_loss: 0.2122 - 84_loss: 0.0000e+00 - 93_loss: 0.2279 - 94_loss: 0.6143 - 103_loss: 0.2354 - 104_loss: 0.6021 - 113_loss: 0.2277 - 114_loss: 0.5871 - 123_loss: 0.2306 - 124_loss: 0.5533 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9596 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8710 - 33_categorical_accuracy: 0.6701 - 34_categorical_accuracy: 0.5320 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9402 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9372 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9314 - 94_categorical_accuracy: 0.7693 - 103_categorical_accuracy: 0.9288 - 104_categorical_accuracy: 0.7770 - 113_categorical_accuracy: 0.9300 - 114_categorical_accuracy: 0.7746 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7965 - val_loss: 14.6708 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4081 - val_14_loss: 0.4664 - val_23_loss: 0.5890 - val_24_loss: 0.9083 - val_33_loss: 0.9036 - val_34_loss: 1.2601 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3287 - val_74_loss: 1.0468 - val_83_loss: 0.2752 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3349 - val_94_loss: 1.6195 - val_103_loss: 0.3264 - val_104_loss: 2.0166 - val_113_loss: 0.3077 - val_114_loss: 1.9554 - val_123_loss: 0.3218 - val_124_loss: 1.6022 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9131 - val_14_categorical_accuracy: 0.9562 - val_23_categorical_accuracy: 0.8862 - val_24_categorical_accuracy: 0.8621 - val_33_categorical_accuracy: 0.6411 - val_34_categorical_accuracy: 0.4696 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9420 - val_74_categorical_accuracy: 0.9285 - val_83_categorical_accuracy: 0.9403 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9277 - val_94_categorical_accuracy: 0.7485 - val_103_categorical_accuracy: 0.9293 - val_104_categorical_accuracy: 0.7692 - val_113_categorical_accuracy: 0.9290 - val_114_categorical_accuracy: 0.7606 - val_123_categorical_accuracy: 0.9304 - val_124_categorical_accuracy: 0.8213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.7455 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2735 - 14_loss: 0.1294 - 23_loss: 0.3554 - 24_loss: 0.4038 - 33_loss: 0.7472 - 34_loss: 0.9442 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2110 - 74_loss: 0.1954 - 83_loss: 0.2120 - 84_loss: 0.0000e+00 - 93_loss: 0.2274 - 94_loss: 0.6135 - 103_loss: 0.2342 - 104_loss: 0.6018 - 113_loss: 0.2269 - 114_loss: 0.5865 - 123_loss: 0.2306 - 124_loss: 0.5527 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6716 - 34_categorical_accuracy: 0.5328 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9402 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9312 - 94_categorical_accuracy: 0.7695 - 103_categorical_accuracy: 0.9290 - 104_categorical_accuracy: 0.7769 - 113_categorical_accuracy: 0.9299 - 114_categorical_accuracy: 0.7748 - 123_categorical_accuracy: 0.9290 - 124_categorical_accuracy: 0.7967 - val_loss: 14.2211 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4037 - val_14_loss: 0.4468 - val_23_loss: 0.5795 - val_24_loss: 0.8678 - val_33_loss: 0.8978 - val_34_loss: 1.2530 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3290 - val_74_loss: 0.9890 - val_83_loss: 0.2708 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3243 - val_94_loss: 1.5094 - val_103_loss: 0.3250 - val_104_loss: 1.9401 - val_113_loss: 0.3009 - val_114_loss: 1.9751 - val_123_loss: 0.3060 - val_124_loss: 1.5028 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9141 - val_14_categorical_accuracy: 0.9568 - val_23_categorical_accuracy: 0.8855 - val_24_categorical_accuracy: 0.8616 - val_33_categorical_accuracy: 0.6420 - val_34_categorical_accuracy: 0.4649 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9421 - val_74_categorical_accuracy: 0.9289 - val_83_categorical_accuracy: 0.9406 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9275 - val_94_categorical_accuracy: 0.7481 - val_103_categorical_accuracy: 0.9277 - val_104_categorical_accuracy: 0.7567 - val_113_categorical_accuracy: 0.9303 - val_114_categorical_accuracy: 0.7625 - val_123_categorical_accuracy: 0.9309 - val_124_categorical_accuracy: 0.8292\n",
      "Epoch 65/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.7466 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2732 - 14_loss: 0.1294 - 23_loss: 0.3554 - 24_loss: 0.4046 - 33_loss: 0.7474 - 34_loss: 0.9440 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2114 - 74_loss: 0.1956 - 83_loss: 0.2120 - 84_loss: 0.0000e+00 - 93_loss: 0.2268 - 94_loss: 0.6134 - 103_loss: 0.2346 - 104_loss: 0.6019 - 113_loss: 0.2270 - 114_loss: 0.5870 - 123_loss: 0.2305 - 124_loss: 0.5526 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9170 - 14_categorical_accuracy: 0.9593 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8707 - 33_categorical_accuracy: 0.6716 - 34_categorical_accuracy: 0.5327 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7697 - 103_categorical_accuracy: 0.9288 - 104_categorical_accuracy: 0.7771 - 113_categorical_accuracy: 0.9299 - 114_categorical_accuracy: 0.7751 - 123_categorical_accuracy: 0.9290 - 124_categorical_accuracy: 0.7969 - val_loss: 14.4468 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4129 - val_14_loss: 0.4699 - val_23_loss: 0.5947 - val_24_loss: 0.8845 - val_33_loss: 0.8950 - val_34_loss: 1.2451 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3358 - val_74_loss: 0.9916 - val_83_loss: 0.2713 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3242 - val_94_loss: 1.6479 - val_103_loss: 0.3214 - val_104_loss: 1.9547 - val_113_loss: 0.3018 - val_114_loss: 1.9666 - val_123_loss: 0.3100 - val_124_loss: 1.5194 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9130 - val_14_categorical_accuracy: 0.9565 - val_23_categorical_accuracy: 0.8848 - val_24_categorical_accuracy: 0.8626 - val_33_categorical_accuracy: 0.6385 - val_34_categorical_accuracy: 0.4674 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9429 - val_74_categorical_accuracy: 0.9285 - val_83_categorical_accuracy: 0.9397 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9278 - val_94_categorical_accuracy: 0.7485 - val_103_categorical_accuracy: 0.9292 - val_104_categorical_accuracy: 0.7613 - val_113_categorical_accuracy: 0.9293 - val_114_categorical_accuracy: 0.7596 - val_123_categorical_accuracy: 0.9296 - val_124_categorical_accuracy: 0.8071\n",
      "Epoch 66/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.7452 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2731 - 14_loss: 0.1292 - 23_loss: 0.3555 - 24_loss: 0.4043 - 33_loss: 0.7471 - 34_loss: 0.9436 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2109 - 74_loss: 0.1957 - 83_loss: 0.2119 - 84_loss: 0.0000e+00 - 93_loss: 0.2274 - 94_loss: 0.6133 - 103_loss: 0.2343 - 104_loss: 0.6014 - 113_loss: 0.2276 - 114_loss: 0.5874 - 123_loss: 0.2302 - 124_loss: 0.5522 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9596 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8709 - 33_categorical_accuracy: 0.6711 - 34_categorical_accuracy: 0.5325 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9402 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9371 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9314 - 94_categorical_accuracy: 0.7692 - 103_categorical_accuracy: 0.9288 - 104_categorical_accuracy: 0.7774 - 113_categorical_accuracy: 0.9299 - 114_categorical_accuracy: 0.7745 - 123_categorical_accuracy: 0.9287 - 124_categorical_accuracy: 0.7970 - val_loss: 14.2688 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4060 - val_14_loss: 0.4706 - val_23_loss: 0.5987 - val_24_loss: 0.8860 - val_33_loss: 0.8904 - val_34_loss: 1.2484 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3259 - val_74_loss: 0.9330 - val_83_loss: 0.2672 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3194 - val_94_loss: 1.5893 - val_103_loss: 0.3274 - val_104_loss: 1.9056 - val_113_loss: 0.3023 - val_114_loss: 1.9397 - val_123_loss: 0.3192 - val_124_loss: 1.5397 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9146 - val_14_categorical_accuracy: 0.9561 - val_23_categorical_accuracy: 0.8855 - val_24_categorical_accuracy: 0.8620 - val_33_categorical_accuracy: 0.6387 - val_34_categorical_accuracy: 0.4596 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9425 - val_74_categorical_accuracy: 0.9272 - val_83_categorical_accuracy: 0.9404 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9274 - val_94_categorical_accuracy: 0.7418 - val_103_categorical_accuracy: 0.9278 - val_104_categorical_accuracy: 0.7645 - val_113_categorical_accuracy: 0.9295 - val_114_categorical_accuracy: 0.7619 - val_123_categorical_accuracy: 0.9302 - val_124_categorical_accuracy: 0.8183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.7391 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2734 - 14_loss: 0.1295 - 23_loss: 0.3548 - 24_loss: 0.4037 - 33_loss: 0.7465 - 34_loss: 0.9434 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2104 - 74_loss: 0.1952 - 83_loss: 0.2115 - 84_loss: 0.0000e+00 - 93_loss: 0.2266 - 94_loss: 0.6134 - 103_loss: 0.2337 - 104_loss: 0.6013 - 113_loss: 0.2272 - 114_loss: 0.5869 - 123_loss: 0.2296 - 124_loss: 0.5521 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9174 - 14_categorical_accuracy: 0.9596 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8707 - 33_categorical_accuracy: 0.6717 - 34_categorical_accuracy: 0.5337 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9311 - 94_categorical_accuracy: 0.7696 - 103_categorical_accuracy: 0.9288 - 104_categorical_accuracy: 0.7771 - 113_categorical_accuracy: 0.9299 - 114_categorical_accuracy: 0.7747 - 123_categorical_accuracy: 0.9290 - 124_categorical_accuracy: 0.7967 - val_loss: 14.3488 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4186 - val_14_loss: 0.4869 - val_23_loss: 0.5987 - val_24_loss: 0.9157 - val_33_loss: 0.8880 - val_34_loss: 1.2416 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3373 - val_74_loss: 0.9637 - val_83_loss: 0.2734 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3271 - val_94_loss: 1.6761 - val_103_loss: 0.3267 - val_104_loss: 1.8212 - val_113_loss: 0.3073 - val_114_loss: 1.8384 - val_123_loss: 0.3217 - val_124_loss: 1.6066 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9143 - val_14_categorical_accuracy: 0.9546 - val_23_categorical_accuracy: 0.8859 - val_24_categorical_accuracy: 0.8629 - val_33_categorical_accuracy: 0.6463 - val_34_categorical_accuracy: 0.4620 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9430 - val_74_categorical_accuracy: 0.9277 - val_83_categorical_accuracy: 0.9404 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9266 - val_94_categorical_accuracy: 0.7463 - val_103_categorical_accuracy: 0.9295 - val_104_categorical_accuracy: 0.7530 - val_113_categorical_accuracy: 0.9301 - val_114_categorical_accuracy: 0.7691 - val_123_categorical_accuracy: 0.9294 - val_124_categorical_accuracy: 0.8242\n",
      "Epoch 68/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.7342 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2730 - 14_loss: 0.1291 - 23_loss: 0.3551 - 24_loss: 0.4031 - 33_loss: 0.7454 - 34_loss: 0.9433 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2095 - 74_loss: 0.1948 - 83_loss: 0.2110 - 84_loss: 0.0000e+00 - 93_loss: 0.2266 - 94_loss: 0.6132 - 103_loss: 0.2333 - 104_loss: 0.6014 - 113_loss: 0.2269 - 114_loss: 0.5863 - 123_loss: 0.2298 - 124_loss: 0.5524 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6712 - 34_categorical_accuracy: 0.5333 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9315 - 94_categorical_accuracy: 0.7694 - 103_categorical_accuracy: 0.9289 - 104_categorical_accuracy: 0.7769 - 113_categorical_accuracy: 0.9297 - 114_categorical_accuracy: 0.7749 - 123_categorical_accuracy: 0.9290 - 124_categorical_accuracy: 0.7970 - val_loss: 14.4099 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4183 - val_14_loss: 0.4900 - val_23_loss: 0.5900 - val_24_loss: 0.9179 - val_33_loss: 0.8962 - val_34_loss: 1.2502 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3365 - val_74_loss: 0.9904 - val_83_loss: 0.2674 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3248 - val_94_loss: 1.6043 - val_103_loss: 0.3305 - val_104_loss: 1.9019 - val_113_loss: 0.3093 - val_114_loss: 1.8913 - val_123_loss: 0.3094 - val_124_loss: 1.5815 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9141 - val_14_categorical_accuracy: 0.9561 - val_23_categorical_accuracy: 0.8858 - val_24_categorical_accuracy: 0.8615 - val_33_categorical_accuracy: 0.6382 - val_34_categorical_accuracy: 0.4671 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9433 - val_74_categorical_accuracy: 0.9289 - val_83_categorical_accuracy: 0.9393 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9277 - val_94_categorical_accuracy: 0.7406 - val_103_categorical_accuracy: 0.9271 - val_104_categorical_accuracy: 0.7647 - val_113_categorical_accuracy: 0.9305 - val_114_categorical_accuracy: 0.7643 - val_123_categorical_accuracy: 0.9310 - val_124_categorical_accuracy: 0.8293\n",
      "Epoch 69/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 6.7359 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2722 - 14_loss: 0.1295 - 23_loss: 0.3544 - 24_loss: 0.4034 - 33_loss: 0.7465 - 34_loss: 0.9433 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2105 - 74_loss: 0.1951 - 83_loss: 0.2110 - 84_loss: 0.0000e+00 - 93_loss: 0.2266 - 94_loss: 0.6133 - 103_loss: 0.2335 - 104_loss: 0.6011 - 113_loss: 0.2268 - 114_loss: 0.5866 - 123_loss: 0.2292 - 124_loss: 0.5530 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8870 - 24_categorical_accuracy: 0.8709 - 33_categorical_accuracy: 0.6720 - 34_categorical_accuracy: 0.5331 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9402 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9312 - 94_categorical_accuracy: 0.7694 - 103_categorical_accuracy: 0.9288 - 104_categorical_accuracy: 0.7767 - 113_categorical_accuracy: 0.9299 - 114_categorical_accuracy: 0.7745 - 123_categorical_accuracy: 0.9290 - 124_categorical_accuracy: 0.7969 - val_loss: 14.5660 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4204 - val_14_loss: 0.4683 - val_23_loss: 0.6004 - val_24_loss: 0.9239 - val_33_loss: 0.8833 - val_34_loss: 1.2476 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3426 - val_74_loss: 1.0192 - val_83_loss: 0.2721 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3352 - val_94_loss: 1.6771 - val_103_loss: 0.3307 - val_104_loss: 1.8770 - val_113_loss: 0.3050 - val_114_loss: 1.9361 - val_123_loss: 0.3213 - val_124_loss: 1.6058 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9119 - val_14_categorical_accuracy: 0.9563 - val_23_categorical_accuracy: 0.8868 - val_24_categorical_accuracy: 0.8614 - val_33_categorical_accuracy: 0.6479 - val_34_categorical_accuracy: 0.4622 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9428 - val_74_categorical_accuracy: 0.9286 - val_83_categorical_accuracy: 0.9394 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9283 - val_94_categorical_accuracy: 0.7511 - val_103_categorical_accuracy: 0.9285 - val_104_categorical_accuracy: 0.7677 - val_113_categorical_accuracy: 0.9297 - val_114_categorical_accuracy: 0.7619 - val_123_categorical_accuracy: 0.9292 - val_124_categorical_accuracy: 0.8094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.7329 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2721 - 14_loss: 0.1291 - 23_loss: 0.3536 - 24_loss: 0.4031 - 33_loss: 0.7463 - 34_loss: 0.9435 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2100 - 74_loss: 0.1951 - 83_loss: 0.2112 - 84_loss: 0.0000e+00 - 93_loss: 0.2264 - 94_loss: 0.6134 - 103_loss: 0.2330 - 104_loss: 0.6009 - 113_loss: 0.2265 - 114_loss: 0.5866 - 123_loss: 0.2300 - 124_loss: 0.5520 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9172 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8707 - 33_categorical_accuracy: 0.6709 - 34_categorical_accuracy: 0.5335 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9314 - 94_categorical_accuracy: 0.7693 - 103_categorical_accuracy: 0.9289 - 104_categorical_accuracy: 0.7771 - 113_categorical_accuracy: 0.9300 - 114_categorical_accuracy: 0.7747 - 123_categorical_accuracy: 0.9288 - 124_categorical_accuracy: 0.7969 - val_loss: 14.6529 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4252 - val_14_loss: 0.5068 - val_23_loss: 0.6111 - val_24_loss: 0.9492 - val_33_loss: 0.8888 - val_34_loss: 1.2547 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3367 - val_74_loss: 1.0115 - val_83_loss: 0.2775 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3240 - val_94_loss: 1.6446 - val_103_loss: 0.3320 - val_104_loss: 1.8971 - val_113_loss: 0.3076 - val_114_loss: 1.9391 - val_123_loss: 0.3290 - val_124_loss: 1.6180 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9136 - val_14_categorical_accuracy: 0.9565 - val_23_categorical_accuracy: 0.8867 - val_24_categorical_accuracy: 0.8611 - val_33_categorical_accuracy: 0.6414 - val_34_categorical_accuracy: 0.4647 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9428 - val_74_categorical_accuracy: 0.9289 - val_83_categorical_accuracy: 0.9396 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9267 - val_94_categorical_accuracy: 0.7499 - val_103_categorical_accuracy: 0.9276 - val_104_categorical_accuracy: 0.7481 - val_113_categorical_accuracy: 0.9303 - val_114_categorical_accuracy: 0.7576 - val_123_categorical_accuracy: 0.9312 - val_124_categorical_accuracy: 0.8109\n",
      "Epoch 71/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.7324 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2723 - 14_loss: 0.1291 - 23_loss: 0.3540 - 24_loss: 0.4020 - 33_loss: 0.7452 - 34_loss: 0.9430 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2103 - 74_loss: 0.1953 - 83_loss: 0.2109 - 84_loss: 0.0000e+00 - 93_loss: 0.2264 - 94_loss: 0.6133 - 103_loss: 0.2335 - 104_loss: 0.6012 - 113_loss: 0.2264 - 114_loss: 0.5869 - 123_loss: 0.2295 - 124_loss: 0.5531 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9174 - 14_categorical_accuracy: 0.9596 - 23_categorical_accuracy: 0.8870 - 24_categorical_accuracy: 0.8711 - 33_categorical_accuracy: 0.6711 - 34_categorical_accuracy: 0.5331 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9314 - 94_categorical_accuracy: 0.7695 - 103_categorical_accuracy: 0.9288 - 104_categorical_accuracy: 0.7774 - 113_categorical_accuracy: 0.9299 - 114_categorical_accuracy: 0.7748 - 123_categorical_accuracy: 0.9287 - 124_categorical_accuracy: 0.7966 - val_loss: 14.5404 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4127 - val_14_loss: 0.5032 - val_23_loss: 0.6077 - val_24_loss: 0.9590 - val_33_loss: 0.8954 - val_34_loss: 1.2554 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3338 - val_74_loss: 0.9881 - val_83_loss: 0.2748 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3227 - val_94_loss: 1.6532 - val_103_loss: 0.3236 - val_104_loss: 1.9382 - val_113_loss: 0.3003 - val_114_loss: 1.9747 - val_123_loss: 0.3160 - val_124_loss: 1.4816 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9134 - val_14_categorical_accuracy: 0.9561 - val_23_categorical_accuracy: 0.8866 - val_24_categorical_accuracy: 0.8628 - val_33_categorical_accuracy: 0.6364 - val_34_categorical_accuracy: 0.4652 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9425 - val_74_categorical_accuracy: 0.9289 - val_83_categorical_accuracy: 0.9397 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9283 - val_94_categorical_accuracy: 0.7414 - val_103_categorical_accuracy: 0.9284 - val_104_categorical_accuracy: 0.7648 - val_113_categorical_accuracy: 0.9299 - val_114_categorical_accuracy: 0.7568 - val_123_categorical_accuracy: 0.9305 - val_124_categorical_accuracy: 0.8180\n",
      "Epoch 72/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 6.7287 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2720 - 14_loss: 0.1288 - 23_loss: 0.3534 - 24_loss: 0.4024 - 33_loss: 0.7453 - 34_loss: 0.9422 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2100 - 74_loss: 0.1952 - 83_loss: 0.2106 - 84_loss: 0.0000e+00 - 93_loss: 0.2261 - 94_loss: 0.6132 - 103_loss: 0.2332 - 104_loss: 0.6013 - 113_loss: 0.2266 - 114_loss: 0.5865 - 123_loss: 0.2291 - 124_loss: 0.5529 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9172 - 14_categorical_accuracy: 0.9593 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8707 - 33_categorical_accuracy: 0.6718 - 34_categorical_accuracy: 0.5339 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7694 - 103_categorical_accuracy: 0.9288 - 104_categorical_accuracy: 0.7771 - 113_categorical_accuracy: 0.9296 - 114_categorical_accuracy: 0.7748 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7969 - val_loss: 14.7794 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4136 - val_14_loss: 0.4608 - val_23_loss: 0.6212 - val_24_loss: 0.9417 - val_33_loss: 0.9104 - val_34_loss: 1.2668 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3416 - val_74_loss: 1.0206 - val_83_loss: 0.2744 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3224 - val_94_loss: 1.6863 - val_103_loss: 0.3341 - val_104_loss: 1.9201 - val_113_loss: 0.3014 - val_114_loss: 2.0684 - val_123_loss: 0.3214 - val_124_loss: 1.5742 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9138 - val_14_categorical_accuracy: 0.9568 - val_23_categorical_accuracy: 0.8844 - val_24_categorical_accuracy: 0.8606 - val_33_categorical_accuracy: 0.6384 - val_34_categorical_accuracy: 0.4630 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9420 - val_74_categorical_accuracy: 0.9284 - val_83_categorical_accuracy: 0.9401 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9272 - val_94_categorical_accuracy: 0.7475 - val_103_categorical_accuracy: 0.9291 - val_104_categorical_accuracy: 0.7650 - val_113_categorical_accuracy: 0.9299 - val_114_categorical_accuracy: 0.7648 - val_123_categorical_accuracy: 0.9304 - val_124_categorical_accuracy: 0.8253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 6.7262 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2718 - 14_loss: 0.1288 - 23_loss: 0.3532 - 24_loss: 0.4025 - 33_loss: 0.7451 - 34_loss: 0.9415 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2098 - 74_loss: 0.1953 - 83_loss: 0.2106 - 84_loss: 0.0000e+00 - 93_loss: 0.2257 - 94_loss: 0.6130 - 103_loss: 0.2332 - 104_loss: 0.6012 - 113_loss: 0.2262 - 114_loss: 0.5867 - 123_loss: 0.2293 - 124_loss: 0.5525 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8870 - 24_categorical_accuracy: 0.8709 - 33_categorical_accuracy: 0.6711 - 34_categorical_accuracy: 0.5342 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9402 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7694 - 103_categorical_accuracy: 0.9290 - 104_categorical_accuracy: 0.7774 - 113_categorical_accuracy: 0.9299 - 114_categorical_accuracy: 0.7746 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7966 - val_loss: 14.6504 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4240 - val_14_loss: 0.4720 - val_23_loss: 0.6173 - val_24_loss: 0.9534 - val_33_loss: 0.8929 - val_34_loss: 1.2498 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3436 - val_74_loss: 1.0923 - val_83_loss: 0.2739 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3329 - val_94_loss: 1.7037 - val_103_loss: 0.3307 - val_104_loss: 1.8760 - val_113_loss: 0.3044 - val_114_loss: 1.9224 - val_123_loss: 0.3198 - val_124_loss: 1.5413 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9142 - val_14_categorical_accuracy: 0.9560 - val_23_categorical_accuracy: 0.8864 - val_24_categorical_accuracy: 0.8613 - val_33_categorical_accuracy: 0.6436 - val_34_categorical_accuracy: 0.4621 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9422 - val_74_categorical_accuracy: 0.9286 - val_83_categorical_accuracy: 0.9392 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9282 - val_94_categorical_accuracy: 0.7407 - val_103_categorical_accuracy: 0.9288 - val_104_categorical_accuracy: 0.7640 - val_113_categorical_accuracy: 0.9297 - val_114_categorical_accuracy: 0.7664 - val_123_categorical_accuracy: 0.9292 - val_124_categorical_accuracy: 0.8059\n",
      "Epoch 74/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 6.7301 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2718 - 14_loss: 0.1293 - 23_loss: 0.3537 - 24_loss: 0.4028 - 33_loss: 0.7453 - 34_loss: 0.9426 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2095 - 74_loss: 0.1955 - 83_loss: 0.2110 - 84_loss: 0.0000e+00 - 93_loss: 0.2257 - 94_loss: 0.6134 - 103_loss: 0.2329 - 104_loss: 0.6014 - 113_loss: 0.2264 - 114_loss: 0.5867 - 123_loss: 0.2295 - 124_loss: 0.5527 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9593 - 23_categorical_accuracy: 0.8872 - 24_categorical_accuracy: 0.8711 - 33_categorical_accuracy: 0.6712 - 34_categorical_accuracy: 0.5334 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7693 - 103_categorical_accuracy: 0.9290 - 104_categorical_accuracy: 0.7773 - 113_categorical_accuracy: 0.9299 - 114_categorical_accuracy: 0.7751 - 123_categorical_accuracy: 0.9290 - 124_categorical_accuracy: 0.7968 - val_loss: 14.5449 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4178 - val_14_loss: 0.4567 - val_23_loss: 0.6053 - val_24_loss: 0.9495 - val_33_loss: 0.8897 - val_34_loss: 1.2428 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3422 - val_74_loss: 1.0311 - val_83_loss: 0.2731 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3325 - val_94_loss: 1.6131 - val_103_loss: 0.3264 - val_104_loss: 1.9904 - val_113_loss: 0.3164 - val_114_loss: 1.9472 - val_123_loss: 0.3151 - val_124_loss: 1.4957 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9122 - val_14_categorical_accuracy: 0.9564 - val_23_categorical_accuracy: 0.8846 - val_24_categorical_accuracy: 0.8631 - val_33_categorical_accuracy: 0.6418 - val_34_categorical_accuracy: 0.4663 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9429 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9396 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9282 - val_94_categorical_accuracy: 0.7421 - val_103_categorical_accuracy: 0.9290 - val_104_categorical_accuracy: 0.7684 - val_113_categorical_accuracy: 0.9298 - val_114_categorical_accuracy: 0.7613 - val_123_categorical_accuracy: 0.9297 - val_124_categorical_accuracy: 0.8303\n",
      "Epoch 75/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 6.7205 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2714 - 14_loss: 0.1284 - 23_loss: 0.3532 - 24_loss: 0.4022 - 33_loss: 0.7446 - 34_loss: 0.9418 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2094 - 74_loss: 0.1947 - 83_loss: 0.2100 - 84_loss: 0.0000e+00 - 93_loss: 0.2258 - 94_loss: 0.6131 - 103_loss: 0.2326 - 104_loss: 0.6007 - 113_loss: 0.2259 - 114_loss: 0.5863 - 123_loss: 0.2283 - 124_loss: 0.5522 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9172 - 14_categorical_accuracy: 0.9597 - 23_categorical_accuracy: 0.8868 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6718 - 34_categorical_accuracy: 0.5331 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7693 - 103_categorical_accuracy: 0.9289 - 104_categorical_accuracy: 0.7771 - 113_categorical_accuracy: 0.9301 - 114_categorical_accuracy: 0.7747 - 123_categorical_accuracy: 0.9291 - 124_categorical_accuracy: 0.7967 - val_loss: 14.5145 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4222 - val_14_loss: 0.4828 - val_23_loss: 0.6137 - val_24_loss: 0.9120 - val_33_loss: 0.8841 - val_34_loss: 1.2583 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3334 - val_74_loss: 0.9954 - val_83_loss: 0.2760 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3292 - val_94_loss: 1.6361 - val_103_loss: 0.3272 - val_104_loss: 1.8537 - val_113_loss: 0.3096 - val_114_loss: 2.0482 - val_123_loss: 0.3196 - val_124_loss: 1.5132 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9139 - val_14_categorical_accuracy: 0.9569 - val_23_categorical_accuracy: 0.8841 - val_24_categorical_accuracy: 0.8613 - val_33_categorical_accuracy: 0.6380 - val_34_categorical_accuracy: 0.4565 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9431 - val_74_categorical_accuracy: 0.9288 - val_83_categorical_accuracy: 0.9388 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9287 - val_94_categorical_accuracy: 0.7455 - val_103_categorical_accuracy: 0.9277 - val_104_categorical_accuracy: 0.7561 - val_113_categorical_accuracy: 0.9279 - val_114_categorical_accuracy: 0.7652 - val_123_categorical_accuracy: 0.9281 - val_124_categorical_accuracy: 0.8257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.7187 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2712 - 14_loss: 0.1289 - 23_loss: 0.3530 - 24_loss: 0.4023 - 33_loss: 0.7445 - 34_loss: 0.9415 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2099 - 74_loss: 0.1945 - 83_loss: 0.2101 - 84_loss: 0.0000e+00 - 93_loss: 0.2251 - 94_loss: 0.6129 - 103_loss: 0.2322 - 104_loss: 0.6009 - 113_loss: 0.2252 - 114_loss: 0.5858 - 123_loss: 0.2283 - 124_loss: 0.5522 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8870 - 24_categorical_accuracy: 0.8710 - 33_categorical_accuracy: 0.6716 - 34_categorical_accuracy: 0.5343 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9400 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7694 - 103_categorical_accuracy: 0.9288 - 104_categorical_accuracy: 0.7777 - 113_categorical_accuracy: 0.9297 - 114_categorical_accuracy: 0.7747 - 123_categorical_accuracy: 0.9291 - 124_categorical_accuracy: 0.7965 - val_loss: 14.8558 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4202 - val_14_loss: 0.4850 - val_23_loss: 0.6044 - val_24_loss: 0.9105 - val_33_loss: 0.8971 - val_34_loss: 1.2804 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3622 - val_74_loss: 1.1013 - val_83_loss: 0.2712 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3421 - val_94_loss: 1.7056 - val_103_loss: 0.3356 - val_104_loss: 1.9772 - val_113_loss: 0.3033 - val_114_loss: 1.9613 - val_123_loss: 0.3273 - val_124_loss: 1.5710 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9146 - val_14_categorical_accuracy: 0.9553 - val_23_categorical_accuracy: 0.8870 - val_24_categorical_accuracy: 0.8627 - val_33_categorical_accuracy: 0.6394 - val_34_categorical_accuracy: 0.4581 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9433 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9397 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9282 - val_94_categorical_accuracy: 0.7477 - val_103_categorical_accuracy: 0.9281 - val_104_categorical_accuracy: 0.7551 - val_113_categorical_accuracy: 0.9293 - val_114_categorical_accuracy: 0.7629 - val_123_categorical_accuracy: 0.9296 - val_124_categorical_accuracy: 0.8084\n",
      "Epoch 77/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 6.7253 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2718 - 14_loss: 0.1290 - 23_loss: 0.3528 - 24_loss: 0.4027 - 33_loss: 0.7445 - 34_loss: 0.9427 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2096 - 74_loss: 0.1949 - 83_loss: 0.2101 - 84_loss: 0.0000e+00 - 93_loss: 0.2261 - 94_loss: 0.6133 - 103_loss: 0.2327 - 104_loss: 0.6015 - 113_loss: 0.2257 - 114_loss: 0.5871 - 123_loss: 0.2284 - 124_loss: 0.5525 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9172 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8710 - 33_categorical_accuracy: 0.6715 - 34_categorical_accuracy: 0.5332 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9402 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9312 - 94_categorical_accuracy: 0.7691 - 103_categorical_accuracy: 0.9286 - 104_categorical_accuracy: 0.7771 - 113_categorical_accuracy: 0.9299 - 114_categorical_accuracy: 0.7748 - 123_categorical_accuracy: 0.9287 - 124_categorical_accuracy: 0.7964 - val_loss: 14.8286 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4237 - val_14_loss: 0.4816 - val_23_loss: 0.6297 - val_24_loss: 0.9560 - val_33_loss: 0.8943 - val_34_loss: 1.2598 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3562 - val_74_loss: 1.0733 - val_83_loss: 0.2791 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3355 - val_94_loss: 1.7094 - val_103_loss: 0.3384 - val_104_loss: 1.9285 - val_113_loss: 0.3087 - val_114_loss: 1.9797 - val_123_loss: 0.3268 - val_124_loss: 1.5476 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9138 - val_14_categorical_accuracy: 0.9544 - val_23_categorical_accuracy: 0.8821 - val_24_categorical_accuracy: 0.8636 - val_33_categorical_accuracy: 0.6388 - val_34_categorical_accuracy: 0.4610 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9425 - val_74_categorical_accuracy: 0.9283 - val_83_categorical_accuracy: 0.9394 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9267 - val_94_categorical_accuracy: 0.7429 - val_103_categorical_accuracy: 0.9289 - val_104_categorical_accuracy: 0.7580 - val_113_categorical_accuracy: 0.9301 - val_114_categorical_accuracy: 0.7621 - val_123_categorical_accuracy: 0.9309 - val_124_categorical_accuracy: 0.8125\n",
      "Epoch 78/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 6.7156 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2704 - 14_loss: 0.1285 - 23_loss: 0.3528 - 24_loss: 0.4017 - 33_loss: 0.7439 - 34_loss: 0.9416 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2089 - 74_loss: 0.1949 - 83_loss: 0.2100 - 84_loss: 0.0000e+00 - 93_loss: 0.2253 - 94_loss: 0.6132 - 103_loss: 0.2316 - 104_loss: 0.6010 - 113_loss: 0.2254 - 114_loss: 0.5861 - 123_loss: 0.2280 - 124_loss: 0.5523 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9172 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8712 - 33_categorical_accuracy: 0.6722 - 34_categorical_accuracy: 0.5333 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9400 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9314 - 94_categorical_accuracy: 0.7694 - 103_categorical_accuracy: 0.9288 - 104_categorical_accuracy: 0.7774 - 113_categorical_accuracy: 0.9298 - 114_categorical_accuracy: 0.7747 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7968 - val_loss: 14.8627 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4285 - val_14_loss: 0.4701 - val_23_loss: 0.6466 - val_24_loss: 0.9964 - val_33_loss: 0.8979 - val_34_loss: 1.2779 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3447 - val_74_loss: 1.0709 - val_83_loss: 0.2807 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3394 - val_94_loss: 1.7083 - val_103_loss: 0.3470 - val_104_loss: 1.8283 - val_113_loss: 0.3100 - val_114_loss: 2.0362 - val_123_loss: 0.3295 - val_124_loss: 1.5503 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9158 - val_14_categorical_accuracy: 0.9565 - val_23_categorical_accuracy: 0.8866 - val_24_categorical_accuracy: 0.8635 - val_33_categorical_accuracy: 0.6376 - val_34_categorical_accuracy: 0.4658 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9417 - val_74_categorical_accuracy: 0.9286 - val_83_categorical_accuracy: 0.9395 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9282 - val_94_categorical_accuracy: 0.7482 - val_103_categorical_accuracy: 0.9280 - val_104_categorical_accuracy: 0.7614 - val_113_categorical_accuracy: 0.9301 - val_114_categorical_accuracy: 0.7544 - val_123_categorical_accuracy: 0.9295 - val_124_categorical_accuracy: 0.8310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.7141 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2710 - 14_loss: 0.1286 - 23_loss: 0.3524 - 24_loss: 0.4012 - 33_loss: 0.7436 - 34_loss: 0.9413 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2087 - 74_loss: 0.1945 - 83_loss: 0.2101 - 84_loss: 0.0000e+00 - 93_loss: 0.2254 - 94_loss: 0.6130 - 103_loss: 0.2316 - 104_loss: 0.6004 - 113_loss: 0.2253 - 114_loss: 0.5867 - 123_loss: 0.2279 - 124_loss: 0.5522 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9172 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8711 - 33_categorical_accuracy: 0.6712 - 34_categorical_accuracy: 0.5339 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9400 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7693 - 103_categorical_accuracy: 0.9289 - 104_categorical_accuracy: 0.7772 - 113_categorical_accuracy: 0.9298 - 114_categorical_accuracy: 0.7748 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7968 - val_loss: 14.8762 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4237 - val_14_loss: 0.4789 - val_23_loss: 0.6330 - val_24_loss: 0.9514 - val_33_loss: 0.9115 - val_34_loss: 1.2771 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3520 - val_74_loss: 1.0406 - val_83_loss: 0.2791 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3373 - val_94_loss: 1.6815 - val_103_loss: 0.3442 - val_104_loss: 1.9644 - val_113_loss: 0.3048 - val_114_loss: 1.9599 - val_123_loss: 0.3360 - val_124_loss: 1.6008 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9138 - val_14_categorical_accuracy: 0.9549 - val_23_categorical_accuracy: 0.8854 - val_24_categorical_accuracy: 0.8627 - val_33_categorical_accuracy: 0.6361 - val_34_categorical_accuracy: 0.4622 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9428 - val_74_categorical_accuracy: 0.9285 - val_83_categorical_accuracy: 0.9399 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9276 - val_94_categorical_accuracy: 0.7441 - val_103_categorical_accuracy: 0.9284 - val_104_categorical_accuracy: 0.7616 - val_113_categorical_accuracy: 0.9296 - val_114_categorical_accuracy: 0.7611 - val_123_categorical_accuracy: 0.9293 - val_124_categorical_accuracy: 0.8220\n",
      "Epoch 80/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.7160 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2703 - 14_loss: 0.1286 - 23_loss: 0.3519 - 24_loss: 0.4017 - 33_loss: 0.7444 - 34_loss: 0.9418 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2091 - 74_loss: 0.1946 - 83_loss: 0.2095 - 84_loss: 0.0000e+00 - 93_loss: 0.2257 - 94_loss: 0.6133 - 103_loss: 0.2317 - 104_loss: 0.6012 - 113_loss: 0.2252 - 114_loss: 0.5863 - 123_loss: 0.2284 - 124_loss: 0.5523 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9174 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6715 - 34_categorical_accuracy: 0.5334 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9400 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7694 - 103_categorical_accuracy: 0.9289 - 104_categorical_accuracy: 0.7774 - 113_categorical_accuracy: 0.9298 - 114_categorical_accuracy: 0.7748 - 123_categorical_accuracy: 0.9290 - 124_categorical_accuracy: 0.7971 - val_loss: 14.6625 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4323 - val_14_loss: 0.4770 - val_23_loss: 0.6336 - val_24_loss: 0.9396 - val_33_loss: 0.9050 - val_34_loss: 1.2624 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3340 - val_74_loss: 1.0807 - val_83_loss: 0.2750 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3320 - val_94_loss: 1.6423 - val_103_loss: 0.3434 - val_104_loss: 1.9005 - val_113_loss: 0.3074 - val_114_loss: 1.9258 - val_123_loss: 0.3405 - val_124_loss: 1.5310 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9143 - val_14_categorical_accuracy: 0.9561 - val_23_categorical_accuracy: 0.8868 - val_24_categorical_accuracy: 0.8622 - val_33_categorical_accuracy: 0.6446 - val_34_categorical_accuracy: 0.4605 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9432 - val_74_categorical_accuracy: 0.9282 - val_83_categorical_accuracy: 0.9391 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9273 - val_94_categorical_accuracy: 0.7506 - val_103_categorical_accuracy: 0.9283 - val_104_categorical_accuracy: 0.7657 - val_113_categorical_accuracy: 0.9293 - val_114_categorical_accuracy: 0.7597 - val_123_categorical_accuracy: 0.9297 - val_124_categorical_accuracy: 0.8239\n",
      "Epoch 81/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.7103 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2699 - 14_loss: 0.1284 - 23_loss: 0.3518 - 24_loss: 0.4010 - 33_loss: 0.7431 - 34_loss: 0.9408 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2087 - 74_loss: 0.1948 - 83_loss: 0.2096 - 84_loss: 0.0000e+00 - 93_loss: 0.2249 - 94_loss: 0.6131 - 103_loss: 0.2320 - 104_loss: 0.6008 - 113_loss: 0.2247 - 114_loss: 0.5865 - 123_loss: 0.2282 - 124_loss: 0.5520 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8710 - 33_categorical_accuracy: 0.6718 - 34_categorical_accuracy: 0.5345 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9399 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9314 - 94_categorical_accuracy: 0.7692 - 103_categorical_accuracy: 0.9290 - 104_categorical_accuracy: 0.7773 - 113_categorical_accuracy: 0.9299 - 114_categorical_accuracy: 0.7747 - 123_categorical_accuracy: 0.9288 - 124_categorical_accuracy: 0.7968 - val_loss: 14.3243 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4206 - val_14_loss: 0.4800 - val_23_loss: 0.6200 - val_24_loss: 0.9469 - val_33_loss: 0.8964 - val_34_loss: 1.2606 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3361 - val_74_loss: 1.0138 - val_83_loss: 0.2712 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3239 - val_94_loss: 1.6132 - val_103_loss: 0.3326 - val_104_loss: 1.8131 - val_113_loss: 0.3058 - val_114_loss: 1.7976 - val_123_loss: 0.3203 - val_124_loss: 1.5720 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9144 - val_14_categorical_accuracy: 0.9548 - val_23_categorical_accuracy: 0.8859 - val_24_categorical_accuracy: 0.8631 - val_33_categorical_accuracy: 0.6428 - val_34_categorical_accuracy: 0.4691 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9426 - val_74_categorical_accuracy: 0.9290 - val_83_categorical_accuracy: 0.9398 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9279 - val_94_categorical_accuracy: 0.7425 - val_103_categorical_accuracy: 0.9283 - val_104_categorical_accuracy: 0.7638 - val_113_categorical_accuracy: 0.9308 - val_114_categorical_accuracy: 0.7639 - val_123_categorical_accuracy: 0.9303 - val_124_categorical_accuracy: 0.8280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/1000\n",
      "697/697 [==============================] - 30s 43ms/step - loss: 6.7103 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2700 - 14_loss: 0.1284 - 23_loss: 0.3519 - 24_loss: 0.4013 - 33_loss: 0.7431 - 34_loss: 0.9407 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2082 - 74_loss: 0.1945 - 83_loss: 0.2096 - 84_loss: 0.0000e+00 - 93_loss: 0.2251 - 94_loss: 0.6133 - 103_loss: 0.2321 - 104_loss: 0.6011 - 113_loss: 0.2246 - 114_loss: 0.5863 - 123_loss: 0.2277 - 124_loss: 0.5526 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9170 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6721 - 34_categorical_accuracy: 0.5342 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9400 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9312 - 94_categorical_accuracy: 0.7693 - 103_categorical_accuracy: 0.9288 - 104_categorical_accuracy: 0.7771 - 113_categorical_accuracy: 0.9297 - 114_categorical_accuracy: 0.7748 - 123_categorical_accuracy: 0.9290 - 124_categorical_accuracy: 0.7968 - val_loss: 15.1435 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4431 - val_14_loss: 0.4723 - val_23_loss: 0.6256 - val_24_loss: 0.9912 - val_33_loss: 0.9069 - val_34_loss: 1.2799 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3647 - val_74_loss: 1.1109 - val_83_loss: 0.2811 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3458 - val_94_loss: 1.7792 - val_103_loss: 0.3466 - val_104_loss: 1.9461 - val_113_loss: 0.3103 - val_114_loss: 1.9967 - val_123_loss: 0.3409 - val_124_loss: 1.6020 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9148 - val_14_categorical_accuracy: 0.9565 - val_23_categorical_accuracy: 0.8856 - val_24_categorical_accuracy: 0.8624 - val_33_categorical_accuracy: 0.6373 - val_34_categorical_accuracy: 0.4540 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9427 - val_74_categorical_accuracy: 0.9287 - val_83_categorical_accuracy: 0.9391 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9279 - val_94_categorical_accuracy: 0.7433 - val_103_categorical_accuracy: 0.9270 - val_104_categorical_accuracy: 0.7602 - val_113_categorical_accuracy: 0.9298 - val_114_categorical_accuracy: 0.7529 - val_123_categorical_accuracy: 0.9299 - val_124_categorical_accuracy: 0.8221\n",
      "Epoch 83/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 6.7110 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2704 - 14_loss: 0.1287 - 23_loss: 0.3520 - 24_loss: 0.4011 - 33_loss: 0.7426 - 34_loss: 0.9413 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2080 - 74_loss: 0.1947 - 83_loss: 0.2094 - 84_loss: 0.0000e+00 - 93_loss: 0.2246 - 94_loss: 0.6132 - 103_loss: 0.2319 - 104_loss: 0.6009 - 113_loss: 0.2249 - 114_loss: 0.5868 - 123_loss: 0.2278 - 124_loss: 0.5527 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9169 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8870 - 24_categorical_accuracy: 0.8711 - 33_categorical_accuracy: 0.6721 - 34_categorical_accuracy: 0.5338 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9312 - 94_categorical_accuracy: 0.7691 - 103_categorical_accuracy: 0.9289 - 104_categorical_accuracy: 0.7774 - 113_categorical_accuracy: 0.9298 - 114_categorical_accuracy: 0.7747 - 123_categorical_accuracy: 0.9288 - 124_categorical_accuracy: 0.7967 - val_loss: 14.8079 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4288 - val_14_loss: 0.5009 - val_23_loss: 0.6221 - val_24_loss: 0.9748 - val_33_loss: 0.9077 - val_34_loss: 1.2616 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3538 - val_74_loss: 0.9968 - val_83_loss: 0.2733 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3288 - val_94_loss: 1.6759 - val_103_loss: 0.3401 - val_104_loss: 2.0139 - val_113_loss: 0.3171 - val_114_loss: 2.0040 - val_123_loss: 0.3258 - val_124_loss: 1.4826 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9144 - val_14_categorical_accuracy: 0.9562 - val_23_categorical_accuracy: 0.8853 - val_24_categorical_accuracy: 0.8630 - val_33_categorical_accuracy: 0.6402 - val_34_categorical_accuracy: 0.4640 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9428 - val_74_categorical_accuracy: 0.9287 - val_83_categorical_accuracy: 0.9403 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9271 - val_94_categorical_accuracy: 0.7469 - val_103_categorical_accuracy: 0.9268 - val_104_categorical_accuracy: 0.7714 - val_113_categorical_accuracy: 0.9295 - val_114_categorical_accuracy: 0.7693 - val_123_categorical_accuracy: 0.9293 - val_124_categorical_accuracy: 0.8200\n",
      "Epoch 84/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 6.7084 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2701 - 14_loss: 0.1283 - 23_loss: 0.3505 - 24_loss: 0.4013 - 33_loss: 0.7435 - 34_loss: 0.9408 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2080 - 74_loss: 0.1943 - 83_loss: 0.2091 - 84_loss: 0.0000e+00 - 93_loss: 0.2247 - 94_loss: 0.6126 - 103_loss: 0.2318 - 104_loss: 0.6014 - 113_loss: 0.2255 - 114_loss: 0.5861 - 123_loss: 0.2279 - 124_loss: 0.5525 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9172 - 14_categorical_accuracy: 0.9596 - 23_categorical_accuracy: 0.8872 - 24_categorical_accuracy: 0.8711 - 33_categorical_accuracy: 0.6714 - 34_categorical_accuracy: 0.5339 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9400 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9312 - 94_categorical_accuracy: 0.7691 - 103_categorical_accuracy: 0.9287 - 104_categorical_accuracy: 0.7770 - 113_categorical_accuracy: 0.9300 - 114_categorical_accuracy: 0.7748 - 123_categorical_accuracy: 0.9290 - 124_categorical_accuracy: 0.7969 - val_loss: 14.8075 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4317 - val_14_loss: 0.5061 - val_23_loss: 0.6306 - val_24_loss: 1.0004 - val_33_loss: 0.8983 - val_34_loss: 1.2510 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3549 - val_74_loss: 1.0952 - val_83_loss: 0.2809 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3372 - val_94_loss: 1.6866 - val_103_loss: 0.3441 - val_104_loss: 1.8887 - val_113_loss: 0.3172 - val_114_loss: 1.9150 - val_123_loss: 0.3200 - val_124_loss: 1.5494 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9135 - val_14_categorical_accuracy: 0.9556 - val_23_categorical_accuracy: 0.8860 - val_24_categorical_accuracy: 0.8627 - val_33_categorical_accuracy: 0.6350 - val_34_categorical_accuracy: 0.4666 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9426 - val_74_categorical_accuracy: 0.9277 - val_83_categorical_accuracy: 0.9402 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9266 - val_94_categorical_accuracy: 0.7485 - val_103_categorical_accuracy: 0.9278 - val_104_categorical_accuracy: 0.7648 - val_113_categorical_accuracy: 0.9286 - val_114_categorical_accuracy: 0.7657 - val_123_categorical_accuracy: 0.9308 - val_124_categorical_accuracy: 0.8284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.7075 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2701 - 14_loss: 0.1291 - 23_loss: 0.3514 - 24_loss: 0.4009 - 33_loss: 0.7424 - 34_loss: 0.9404 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2083 - 74_loss: 0.1948 - 83_loss: 0.2085 - 84_loss: 0.0000e+00 - 93_loss: 0.2244 - 94_loss: 0.6127 - 103_loss: 0.2316 - 104_loss: 0.6010 - 113_loss: 0.2248 - 114_loss: 0.5870 - 123_loss: 0.2279 - 124_loss: 0.5522 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9170 - 14_categorical_accuracy: 0.9596 - 23_categorical_accuracy: 0.8868 - 24_categorical_accuracy: 0.8709 - 33_categorical_accuracy: 0.6715 - 34_categorical_accuracy: 0.5337 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7689 - 103_categorical_accuracy: 0.9289 - 104_categorical_accuracy: 0.7772 - 113_categorical_accuracy: 0.9298 - 114_categorical_accuracy: 0.7747 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7968 - val_loss: 14.8876 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4372 - val_14_loss: 0.4859 - val_23_loss: 0.6057 - val_24_loss: 0.9563 - val_33_loss: 0.9003 - val_34_loss: 1.2577 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3589 - val_74_loss: 1.0827 - val_83_loss: 0.2859 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3369 - val_94_loss: 1.6770 - val_103_loss: 0.3388 - val_104_loss: 1.9724 - val_113_loss: 0.3108 - val_114_loss: 2.0153 - val_123_loss: 0.3280 - val_124_loss: 1.5378 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9147 - val_14_categorical_accuracy: 0.9558 - val_23_categorical_accuracy: 0.8863 - val_24_categorical_accuracy: 0.8629 - val_33_categorical_accuracy: 0.6417 - val_34_categorical_accuracy: 0.4625 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9427 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9400 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9273 - val_94_categorical_accuracy: 0.7462 - val_103_categorical_accuracy: 0.9275 - val_104_categorical_accuracy: 0.7542 - val_113_categorical_accuracy: 0.9296 - val_114_categorical_accuracy: 0.7625 - val_123_categorical_accuracy: 0.9317 - val_124_categorical_accuracy: 0.8185\n",
      "Epoch 86/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.7017 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2694 - 14_loss: 0.1277 - 23_loss: 0.3505 - 24_loss: 0.4007 - 33_loss: 0.7424 - 34_loss: 0.9404 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2084 - 74_loss: 0.1947 - 83_loss: 0.2090 - 84_loss: 0.0000e+00 - 93_loss: 0.2242 - 94_loss: 0.6129 - 103_loss: 0.2315 - 104_loss: 0.6004 - 113_loss: 0.2246 - 114_loss: 0.5855 - 123_loss: 0.2271 - 124_loss: 0.5523 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8705 - 33_categorical_accuracy: 0.6715 - 34_categorical_accuracy: 0.5341 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9399 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7693 - 103_categorical_accuracy: 0.9288 - 104_categorical_accuracy: 0.7772 - 113_categorical_accuracy: 0.9296 - 114_categorical_accuracy: 0.7748 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7969 - val_loss: 15.5693 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4461 - val_14_loss: 0.5524 - val_23_loss: 0.6648 - val_24_loss: 1.0744 - val_33_loss: 0.9154 - val_34_loss: 1.2758 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3647 - val_74_loss: 1.1196 - val_83_loss: 0.2868 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3471 - val_94_loss: 1.8098 - val_103_loss: 0.3459 - val_104_loss: 2.0393 - val_113_loss: 0.3311 - val_114_loss: 2.0505 - val_123_loss: 0.3483 - val_124_loss: 1.5972 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9144 - val_14_categorical_accuracy: 0.9553 - val_23_categorical_accuracy: 0.8843 - val_24_categorical_accuracy: 0.8620 - val_33_categorical_accuracy: 0.6381 - val_34_categorical_accuracy: 0.4641 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9425 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9406 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9274 - val_94_categorical_accuracy: 0.7401 - val_103_categorical_accuracy: 0.9275 - val_104_categorical_accuracy: 0.7559 - val_113_categorical_accuracy: 0.9291 - val_114_categorical_accuracy: 0.7640 - val_123_categorical_accuracy: 0.9297 - val_124_categorical_accuracy: 0.8168\n",
      "Epoch 87/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 6.7032 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2693 - 14_loss: 0.1289 - 23_loss: 0.3513 - 24_loss: 0.4002 - 33_loss: 0.7425 - 34_loss: 0.9405 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2074 - 74_loss: 0.1946 - 83_loss: 0.2091 - 84_loss: 0.0000e+00 - 93_loss: 0.2241 - 94_loss: 0.6130 - 103_loss: 0.2311 - 104_loss: 0.6012 - 113_loss: 0.2241 - 114_loss: 0.5865 - 123_loss: 0.2273 - 124_loss: 0.5521 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8709 - 33_categorical_accuracy: 0.6721 - 34_categorical_accuracy: 0.5344 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7694 - 103_categorical_accuracy: 0.9287 - 104_categorical_accuracy: 0.7771 - 113_categorical_accuracy: 0.9300 - 114_categorical_accuracy: 0.7745 - 123_categorical_accuracy: 0.9290 - 124_categorical_accuracy: 0.7968 - val_loss: 15.0524 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4352 - val_14_loss: 0.5158 - val_23_loss: 0.6514 - val_24_loss: 0.9905 - val_33_loss: 0.9006 - val_34_loss: 1.2629 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3583 - val_74_loss: 1.1542 - val_83_loss: 0.2839 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3433 - val_94_loss: 1.7226 - val_103_loss: 0.3436 - val_104_loss: 1.9263 - val_113_loss: 0.3271 - val_114_loss: 1.9643 - val_123_loss: 0.3303 - val_124_loss: 1.5422 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9141 - val_14_categorical_accuracy: 0.9566 - val_23_categorical_accuracy: 0.8849 - val_24_categorical_accuracy: 0.8606 - val_33_categorical_accuracy: 0.6422 - val_34_categorical_accuracy: 0.4631 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9424 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9396 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9278 - val_94_categorical_accuracy: 0.7458 - val_103_categorical_accuracy: 0.9285 - val_104_categorical_accuracy: 0.7510 - val_113_categorical_accuracy: 0.9297 - val_114_categorical_accuracy: 0.7627 - val_123_categorical_accuracy: 0.9290 - val_124_categorical_accuracy: 0.8127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.7011 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2692 - 14_loss: 0.1278 - 23_loss: 0.3512 - 24_loss: 0.3999 - 33_loss: 0.7424 - 34_loss: 0.9398 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2076 - 74_loss: 0.1949 - 83_loss: 0.2088 - 84_loss: 0.0000e+00 - 93_loss: 0.2245 - 94_loss: 0.6129 - 103_loss: 0.2312 - 104_loss: 0.6005 - 113_loss: 0.2240 - 114_loss: 0.5867 - 123_loss: 0.2271 - 124_loss: 0.5526 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9172 - 14_categorical_accuracy: 0.9596 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6717 - 34_categorical_accuracy: 0.5346 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9399 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9312 - 94_categorical_accuracy: 0.7691 - 103_categorical_accuracy: 0.9288 - 104_categorical_accuracy: 0.7769 - 113_categorical_accuracy: 0.9298 - 114_categorical_accuracy: 0.7745 - 123_categorical_accuracy: 0.9288 - 124_categorical_accuracy: 0.7968 - val_loss: 15.5568 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4365 - val_14_loss: 0.5294 - val_23_loss: 0.6591 - val_24_loss: 1.0583 - val_33_loss: 0.9133 - val_34_loss: 1.2858 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3548 - val_74_loss: 1.1109 - val_83_loss: 0.2992 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3535 - val_94_loss: 1.8634 - val_103_loss: 0.3588 - val_104_loss: 1.9787 - val_113_loss: 0.3217 - val_114_loss: 1.9958 - val_123_loss: 0.3442 - val_124_loss: 1.6931 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9137 - val_14_categorical_accuracy: 0.9560 - val_23_categorical_accuracy: 0.8843 - val_24_categorical_accuracy: 0.8631 - val_33_categorical_accuracy: 0.6449 - val_34_categorical_accuracy: 0.4642 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9409 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9391 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9278 - val_94_categorical_accuracy: 0.7411 - val_103_categorical_accuracy: 0.9286 - val_104_categorical_accuracy: 0.7627 - val_113_categorical_accuracy: 0.9288 - val_114_categorical_accuracy: 0.7637 - val_123_categorical_accuracy: 0.9294 - val_124_categorical_accuracy: 0.8057\n",
      "Epoch 89/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 6.6983 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2693 - 14_loss: 0.1280 - 23_loss: 0.3506 - 24_loss: 0.4004 - 33_loss: 0.7417 - 34_loss: 0.9400 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2079 - 74_loss: 0.1941 - 83_loss: 0.2088 - 84_loss: 0.0000e+00 - 93_loss: 0.2240 - 94_loss: 0.6129 - 103_loss: 0.2306 - 104_loss: 0.6010 - 113_loss: 0.2238 - 114_loss: 0.5864 - 123_loss: 0.2267 - 124_loss: 0.5521 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9170 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8709 - 33_categorical_accuracy: 0.6718 - 34_categorical_accuracy: 0.5341 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9371 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7697 - 103_categorical_accuracy: 0.9285 - 104_categorical_accuracy: 0.7770 - 113_categorical_accuracy: 0.9299 - 114_categorical_accuracy: 0.7747 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7968 - val_loss: 14.9127 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4274 - val_14_loss: 0.5180 - val_23_loss: 0.6145 - val_24_loss: 1.0068 - val_33_loss: 0.9045 - val_34_loss: 1.2719 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3572 - val_74_loss: 1.1619 - val_83_loss: 0.2869 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3338 - val_94_loss: 1.7115 - val_103_loss: 0.3395 - val_104_loss: 1.8854 - val_113_loss: 0.3091 - val_114_loss: 1.9070 - val_123_loss: 0.3391 - val_124_loss: 1.5381 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9130 - val_14_categorical_accuracy: 0.9551 - val_23_categorical_accuracy: 0.8867 - val_24_categorical_accuracy: 0.8630 - val_33_categorical_accuracy: 0.6417 - val_34_categorical_accuracy: 0.4605 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9425 - val_74_categorical_accuracy: 0.9290 - val_83_categorical_accuracy: 0.9398 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9287 - val_94_categorical_accuracy: 0.7343 - val_103_categorical_accuracy: 0.9286 - val_104_categorical_accuracy: 0.7709 - val_113_categorical_accuracy: 0.9297 - val_114_categorical_accuracy: 0.7646 - val_123_categorical_accuracy: 0.9296 - val_124_categorical_accuracy: 0.8031\n",
      "Epoch 90/1000\n",
      "697/697 [==============================] - 28s 39ms/step - loss: 6.6952 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2693 - 14_loss: 0.1281 - 23_loss: 0.3498 - 24_loss: 0.3994 - 33_loss: 0.7415 - 34_loss: 0.9394 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2076 - 74_loss: 0.1948 - 83_loss: 0.2087 - 84_loss: 0.0000e+00 - 93_loss: 0.2235 - 94_loss: 0.6131 - 103_loss: 0.2304 - 104_loss: 0.6009 - 113_loss: 0.2241 - 114_loss: 0.5856 - 123_loss: 0.2271 - 124_loss: 0.5521 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8709 - 33_categorical_accuracy: 0.6714 - 34_categorical_accuracy: 0.5347 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9371 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9314 - 94_categorical_accuracy: 0.7692 - 103_categorical_accuracy: 0.9287 - 104_categorical_accuracy: 0.7774 - 113_categorical_accuracy: 0.9297 - 114_categorical_accuracy: 0.7748 - 123_categorical_accuracy: 0.9288 - 124_categorical_accuracy: 0.7967 - val_loss: 15.4793 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4234 - val_14_loss: 0.5092 - val_23_loss: 0.6489 - val_24_loss: 1.0618 - val_33_loss: 0.9071 - val_34_loss: 1.2900 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3602 - val_74_loss: 1.1256 - val_83_loss: 0.2952 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3536 - val_94_loss: 1.7519 - val_103_loss: 0.3533 - val_104_loss: 2.0399 - val_113_loss: 0.3232 - val_114_loss: 2.0289 - val_123_loss: 0.3411 - val_124_loss: 1.6660 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9128 - val_14_categorical_accuracy: 0.9557 - val_23_categorical_accuracy: 0.8847 - val_24_categorical_accuracy: 0.8618 - val_33_categorical_accuracy: 0.6431 - val_34_categorical_accuracy: 0.4626 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9422 - val_74_categorical_accuracy: 0.9261 - val_83_categorical_accuracy: 0.9397 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9275 - val_94_categorical_accuracy: 0.7451 - val_103_categorical_accuracy: 0.9286 - val_104_categorical_accuracy: 0.7598 - val_113_categorical_accuracy: 0.9301 - val_114_categorical_accuracy: 0.7649 - val_123_categorical_accuracy: 0.9290 - val_124_categorical_accuracy: 0.8047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.7015 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2692 - 14_loss: 0.1283 - 23_loss: 0.3504 - 24_loss: 0.4011 - 33_loss: 0.7414 - 34_loss: 0.9400 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2070 - 74_loss: 0.1947 - 83_loss: 0.2087 - 84_loss: 0.0000e+00 - 93_loss: 0.2241 - 94_loss: 0.6137 - 103_loss: 0.2316 - 104_loss: 0.6010 - 113_loss: 0.2242 - 114_loss: 0.5868 - 123_loss: 0.2268 - 124_loss: 0.5527 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8870 - 24_categorical_accuracy: 0.8711 - 33_categorical_accuracy: 0.6720 - 34_categorical_accuracy: 0.5345 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9400 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7689 - 103_categorical_accuracy: 0.9287 - 104_categorical_accuracy: 0.7773 - 113_categorical_accuracy: 0.9300 - 114_categorical_accuracy: 0.7745 - 123_categorical_accuracy: 0.9290 - 124_categorical_accuracy: 0.7967 - val_loss: 15.3487 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4388 - val_14_loss: 0.5209 - val_23_loss: 0.6627 - val_24_loss: 1.0326 - val_33_loss: 0.9137 - val_34_loss: 1.2779 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3627 - val_74_loss: 1.1223 - val_83_loss: 0.2949 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3492 - val_94_loss: 1.7443 - val_103_loss: 0.3460 - val_104_loss: 1.9932 - val_113_loss: 0.3130 - val_114_loss: 2.0195 - val_123_loss: 0.3639 - val_124_loss: 1.5933 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9131 - val_14_categorical_accuracy: 0.9555 - val_23_categorical_accuracy: 0.8854 - val_24_categorical_accuracy: 0.8623 - val_33_categorical_accuracy: 0.6367 - val_34_categorical_accuracy: 0.4620 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9419 - val_74_categorical_accuracy: 0.9287 - val_83_categorical_accuracy: 0.9390 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9268 - val_94_categorical_accuracy: 0.7451 - val_103_categorical_accuracy: 0.9285 - val_104_categorical_accuracy: 0.7686 - val_113_categorical_accuracy: 0.9303 - val_114_categorical_accuracy: 0.7619 - val_123_categorical_accuracy: 0.9305 - val_124_categorical_accuracy: 0.8209\n",
      "Epoch 92/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.6963 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2691 - 14_loss: 0.1284 - 23_loss: 0.3504 - 24_loss: 0.4001 - 33_loss: 0.7415 - 34_loss: 0.9395 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2071 - 74_loss: 0.1941 - 83_loss: 0.2085 - 84_loss: 0.0000e+00 - 93_loss: 0.2235 - 94_loss: 0.6131 - 103_loss: 0.2308 - 104_loss: 0.6004 - 113_loss: 0.2241 - 114_loss: 0.5860 - 123_loss: 0.2273 - 124_loss: 0.5525 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8706 - 33_categorical_accuracy: 0.6719 - 34_categorical_accuracy: 0.5347 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9400 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7692 - 103_categorical_accuracy: 0.9287 - 104_categorical_accuracy: 0.7775 - 113_categorical_accuracy: 0.9298 - 114_categorical_accuracy: 0.7749 - 123_categorical_accuracy: 0.9288 - 124_categorical_accuracy: 0.7966 - val_loss: 15.4493 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4444 - val_14_loss: 0.5278 - val_23_loss: 0.6349 - val_24_loss: 0.9856 - val_33_loss: 0.9249 - val_34_loss: 1.2922 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3645 - val_74_loss: 1.1372 - val_83_loss: 0.2895 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3391 - val_94_loss: 1.8246 - val_103_loss: 0.3525 - val_104_loss: 1.9608 - val_113_loss: 0.3119 - val_114_loss: 2.0947 - val_123_loss: 0.3489 - val_124_loss: 1.6157 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9143 - val_14_categorical_accuracy: 0.9559 - val_23_categorical_accuracy: 0.8844 - val_24_categorical_accuracy: 0.8624 - val_33_categorical_accuracy: 0.6393 - val_34_categorical_accuracy: 0.4579 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9424 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9381 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9276 - val_94_categorical_accuracy: 0.7505 - val_103_categorical_accuracy: 0.9274 - val_104_categorical_accuracy: 0.7647 - val_113_categorical_accuracy: 0.9295 - val_114_categorical_accuracy: 0.7630 - val_123_categorical_accuracy: 0.9303 - val_124_categorical_accuracy: 0.8188\n",
      "Epoch 93/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 6.6931 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2683 - 14_loss: 0.1279 - 23_loss: 0.3504 - 24_loss: 0.4001 - 33_loss: 0.7410 - 34_loss: 0.9395 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2064 - 74_loss: 0.1941 - 83_loss: 0.2084 - 84_loss: 0.0000e+00 - 93_loss: 0.2239 - 94_loss: 0.6135 - 103_loss: 0.2304 - 104_loss: 0.6003 - 113_loss: 0.2240 - 114_loss: 0.5862 - 123_loss: 0.2265 - 124_loss: 0.5523 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9170 - 14_categorical_accuracy: 0.9593 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8710 - 33_categorical_accuracy: 0.6723 - 34_categorical_accuracy: 0.5344 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9367 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9314 - 94_categorical_accuracy: 0.7693 - 103_categorical_accuracy: 0.9288 - 104_categorical_accuracy: 0.7770 - 113_categorical_accuracy: 0.9298 - 114_categorical_accuracy: 0.7745 - 123_categorical_accuracy: 0.9290 - 124_categorical_accuracy: 0.7970 - val_loss: 15.2142 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4409 - val_14_loss: 0.5311 - val_23_loss: 0.6439 - val_24_loss: 1.0227 - val_33_loss: 0.9136 - val_34_loss: 1.2942 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3639 - val_74_loss: 1.1236 - val_83_loss: 0.2904 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3454 - val_94_loss: 1.6961 - val_103_loss: 0.3437 - val_104_loss: 2.0823 - val_113_loss: 0.3071 - val_114_loss: 1.9615 - val_123_loss: 0.3392 - val_124_loss: 1.5146 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9138 - val_14_categorical_accuracy: 0.9562 - val_23_categorical_accuracy: 0.8837 - val_24_categorical_accuracy: 0.8623 - val_33_categorical_accuracy: 0.6394 - val_34_categorical_accuracy: 0.4643 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9426 - val_74_categorical_accuracy: 0.9284 - val_83_categorical_accuracy: 0.9392 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9285 - val_94_categorical_accuracy: 0.7517 - val_103_categorical_accuracy: 0.9283 - val_104_categorical_accuracy: 0.7538 - val_113_categorical_accuracy: 0.9297 - val_114_categorical_accuracy: 0.7630 - val_123_categorical_accuracy: 0.9299 - val_124_categorical_accuracy: 0.8142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 6.7092 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2695 - 14_loss: 0.1283 - 23_loss: 0.3516 - 24_loss: 0.4018 - 33_loss: 0.7429 - 34_loss: 0.9412 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2080 - 74_loss: 0.1944 - 83_loss: 0.2093 - 84_loss: 0.0000e+00 - 93_loss: 0.2239 - 94_loss: 0.6139 - 103_loss: 0.2314 - 104_loss: 0.6014 - 113_loss: 0.2244 - 114_loss: 0.5869 - 123_loss: 0.2278 - 124_loss: 0.5524 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8867 - 24_categorical_accuracy: 0.8710 - 33_categorical_accuracy: 0.6715 - 34_categorical_accuracy: 0.5335 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7694 - 103_categorical_accuracy: 0.9287 - 104_categorical_accuracy: 0.7769 - 113_categorical_accuracy: 0.9299 - 114_categorical_accuracy: 0.7748 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7966 - val_loss: 15.2550 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4394 - val_14_loss: 0.5682 - val_23_loss: 0.6318 - val_24_loss: 1.0011 - val_33_loss: 0.9099 - val_34_loss: 1.2570 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3521 - val_74_loss: 1.1030 - val_83_loss: 0.2849 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3444 - val_94_loss: 1.6781 - val_103_loss: 0.3490 - val_104_loss: 2.0252 - val_113_loss: 0.3187 - val_114_loss: 2.0135 - val_123_loss: 0.3437 - val_124_loss: 1.6349 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9147 - val_14_categorical_accuracy: 0.9570 - val_23_categorical_accuracy: 0.8853 - val_24_categorical_accuracy: 0.8634 - val_33_categorical_accuracy: 0.6394 - val_34_categorical_accuracy: 0.4593 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9426 - val_74_categorical_accuracy: 0.9285 - val_83_categorical_accuracy: 0.9395 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9278 - val_94_categorical_accuracy: 0.7416 - val_103_categorical_accuracy: 0.9281 - val_104_categorical_accuracy: 0.7561 - val_113_categorical_accuracy: 0.9297 - val_114_categorical_accuracy: 0.7649 - val_123_categorical_accuracy: 0.9309 - val_124_categorical_accuracy: 0.8315\n",
      "Epoch 95/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.6987 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2692 - 14_loss: 0.1280 - 23_loss: 0.3504 - 24_loss: 0.4006 - 33_loss: 0.7412 - 34_loss: 0.9399 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2076 - 74_loss: 0.1941 - 83_loss: 0.2088 - 84_loss: 0.0000e+00 - 93_loss: 0.2240 - 94_loss: 0.6136 - 103_loss: 0.2313 - 104_loss: 0.6009 - 113_loss: 0.2234 - 114_loss: 0.5866 - 123_loss: 0.2268 - 124_loss: 0.5522 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9174 - 14_categorical_accuracy: 0.9593 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8710 - 33_categorical_accuracy: 0.6719 - 34_categorical_accuracy: 0.5338 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9402 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9312 - 94_categorical_accuracy: 0.7691 - 103_categorical_accuracy: 0.9286 - 104_categorical_accuracy: 0.7774 - 113_categorical_accuracy: 0.9299 - 114_categorical_accuracy: 0.7744 - 123_categorical_accuracy: 0.9290 - 124_categorical_accuracy: 0.7966 - val_loss: 16.0815 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4621 - val_14_loss: 0.5569 - val_23_loss: 0.6859 - val_24_loss: 1.0962 - val_33_loss: 0.9405 - val_34_loss: 1.3120 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3793 - val_74_loss: 1.1932 - val_83_loss: 0.2959 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3581 - val_94_loss: 1.8073 - val_103_loss: 0.3560 - val_104_loss: 2.1787 - val_113_loss: 0.3356 - val_114_loss: 2.1451 - val_123_loss: 0.3538 - val_124_loss: 1.6248 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9125 - val_14_categorical_accuracy: 0.9541 - val_23_categorical_accuracy: 0.8846 - val_24_categorical_accuracy: 0.8630 - val_33_categorical_accuracy: 0.6322 - val_34_categorical_accuracy: 0.4554 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9414 - val_74_categorical_accuracy: 0.9287 - val_83_categorical_accuracy: 0.9399 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9272 - val_94_categorical_accuracy: 0.7466 - val_103_categorical_accuracy: 0.9267 - val_104_categorical_accuracy: 0.7558 - val_113_categorical_accuracy: 0.9260 - val_114_categorical_accuracy: 0.7610 - val_123_categorical_accuracy: 0.9311 - val_124_categorical_accuracy: 0.8113\n",
      "Epoch 96/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 6.6939 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2685 - 14_loss: 0.1282 - 23_loss: 0.3506 - 24_loss: 0.3993 - 33_loss: 0.7413 - 34_loss: 0.9397 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2069 - 74_loss: 0.1942 - 83_loss: 0.2078 - 84_loss: 0.0000e+00 - 93_loss: 0.2233 - 94_loss: 0.6133 - 103_loss: 0.2305 - 104_loss: 0.6004 - 113_loss: 0.2244 - 114_loss: 0.5866 - 123_loss: 0.2266 - 124_loss: 0.5523 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8870 - 24_categorical_accuracy: 0.8709 - 33_categorical_accuracy: 0.6723 - 34_categorical_accuracy: 0.5349 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9400 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9311 - 94_categorical_accuracy: 0.7691 - 103_categorical_accuracy: 0.9288 - 104_categorical_accuracy: 0.7771 - 113_categorical_accuracy: 0.9297 - 114_categorical_accuracy: 0.7745 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7965 - val_loss: 15.5148 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4302 - val_14_loss: 0.5248 - val_23_loss: 0.6407 - val_24_loss: 1.0727 - val_33_loss: 0.9164 - val_34_loss: 1.2827 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3640 - val_74_loss: 1.1864 - val_83_loss: 0.2941 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3419 - val_94_loss: 1.8016 - val_103_loss: 0.3483 - val_104_loss: 2.0156 - val_113_loss: 0.3241 - val_114_loss: 1.9802 - val_123_loss: 0.3571 - val_124_loss: 1.6340 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9140 - val_14_categorical_accuracy: 0.9557 - val_23_categorical_accuracy: 0.8859 - val_24_categorical_accuracy: 0.8637 - val_33_categorical_accuracy: 0.6319 - val_34_categorical_accuracy: 0.4599 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9428 - val_74_categorical_accuracy: 0.9287 - val_83_categorical_accuracy: 0.9399 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9284 - val_94_categorical_accuracy: 0.7452 - val_103_categorical_accuracy: 0.9277 - val_104_categorical_accuracy: 0.7725 - val_113_categorical_accuracy: 0.9297 - val_114_categorical_accuracy: 0.7656 - val_123_categorical_accuracy: 0.9289 - val_124_categorical_accuracy: 0.8273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.7184 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2707 - 14_loss: 0.1290 - 23_loss: 0.3521 - 24_loss: 0.4028 - 33_loss: 0.7436 - 34_loss: 0.9410 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2076 - 74_loss: 0.1945 - 83_loss: 0.2083 - 84_loss: 0.0000e+00 - 93_loss: 0.2240 - 94_loss: 0.6163 - 103_loss: 0.2326 - 104_loss: 0.6022 - 113_loss: 0.2257 - 114_loss: 0.5866 - 123_loss: 0.2270 - 124_loss: 0.5543 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9172 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8867 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6714 - 34_categorical_accuracy: 0.5340 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9314 - 94_categorical_accuracy: 0.7693 - 103_categorical_accuracy: 0.9288 - 104_categorical_accuracy: 0.7768 - 113_categorical_accuracy: 0.9298 - 114_categorical_accuracy: 0.7747 - 123_categorical_accuracy: 0.9286 - 124_categorical_accuracy: 0.7966 - val_loss: 15.4739 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4499 - val_14_loss: 0.5431 - val_23_loss: 0.6266 - val_24_loss: 1.0103 - val_33_loss: 0.9093 - val_34_loss: 1.2937 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3609 - val_74_loss: 1.1768 - val_83_loss: 0.2893 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3498 - val_94_loss: 1.7277 - val_103_loss: 0.3523 - val_104_loss: 2.0313 - val_113_loss: 0.3120 - val_114_loss: 2.0795 - val_123_loss: 0.3480 - val_124_loss: 1.6134 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9143 - val_14_categorical_accuracy: 0.9557 - val_23_categorical_accuracy: 0.8845 - val_24_categorical_accuracy: 0.8615 - val_33_categorical_accuracy: 0.6406 - val_34_categorical_accuracy: 0.4638 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9424 - val_74_categorical_accuracy: 0.9293 - val_83_categorical_accuracy: 0.9379 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9282 - val_94_categorical_accuracy: 0.7463 - val_103_categorical_accuracy: 0.9275 - val_104_categorical_accuracy: 0.7723 - val_113_categorical_accuracy: 0.9298 - val_114_categorical_accuracy: 0.7535 - val_123_categorical_accuracy: 0.9300 - val_124_categorical_accuracy: 0.8280\n",
      "Epoch 98/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.6828 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2682 - 14_loss: 0.1275 - 23_loss: 0.3494 - 24_loss: 0.3984 - 33_loss: 0.7401 - 34_loss: 0.9384 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2062 - 74_loss: 0.1938 - 83_loss: 0.2077 - 84_loss: 0.0000e+00 - 93_loss: 0.2228 - 94_loss: 0.6127 - 103_loss: 0.2299 - 104_loss: 0.6005 - 113_loss: 0.2232 - 114_loss: 0.5861 - 123_loss: 0.2260 - 124_loss: 0.5520 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9593 - 23_categorical_accuracy: 0.8870 - 24_categorical_accuracy: 0.8709 - 33_categorical_accuracy: 0.6722 - 34_categorical_accuracy: 0.5346 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9400 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9368 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9312 - 94_categorical_accuracy: 0.7691 - 103_categorical_accuracy: 0.9287 - 104_categorical_accuracy: 0.7771 - 113_categorical_accuracy: 0.9297 - 114_categorical_accuracy: 0.7750 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7967 - val_loss: 15.7857 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4638 - val_14_loss: 0.5270 - val_23_loss: 0.6471 - val_24_loss: 1.0487 - val_33_loss: 0.9325 - val_34_loss: 1.3036 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3771 - val_74_loss: 1.1810 - val_83_loss: 0.2919 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3591 - val_94_loss: 1.8173 - val_103_loss: 0.3524 - val_104_loss: 2.1808 - val_113_loss: 0.3260 - val_114_loss: 2.0103 - val_123_loss: 0.3348 - val_124_loss: 1.6322 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9144 - val_14_categorical_accuracy: 0.9557 - val_23_categorical_accuracy: 0.8865 - val_24_categorical_accuracy: 0.8623 - val_33_categorical_accuracy: 0.6364 - val_34_categorical_accuracy: 0.4658 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9431 - val_74_categorical_accuracy: 0.9274 - val_83_categorical_accuracy: 0.9402 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9271 - val_94_categorical_accuracy: 0.7376 - val_103_categorical_accuracy: 0.9281 - val_104_categorical_accuracy: 0.7580 - val_113_categorical_accuracy: 0.9284 - val_114_categorical_accuracy: 0.7655 - val_123_categorical_accuracy: 0.9307 - val_124_categorical_accuracy: 0.8207\n",
      "Epoch 99/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 6.6887 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2685 - 14_loss: 0.1274 - 23_loss: 0.3499 - 24_loss: 0.4001 - 33_loss: 0.7401 - 34_loss: 0.9395 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2070 - 74_loss: 0.1940 - 83_loss: 0.2080 - 84_loss: 0.0000e+00 - 93_loss: 0.2243 - 94_loss: 0.6125 - 103_loss: 0.2297 - 104_loss: 0.6006 - 113_loss: 0.2232 - 114_loss: 0.5858 - 123_loss: 0.2261 - 124_loss: 0.5519 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9172 - 14_categorical_accuracy: 0.9596 - 23_categorical_accuracy: 0.8868 - 24_categorical_accuracy: 0.8706 - 33_categorical_accuracy: 0.6720 - 34_categorical_accuracy: 0.5347 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9314 - 94_categorical_accuracy: 0.7692 - 103_categorical_accuracy: 0.9286 - 104_categorical_accuracy: 0.7770 - 113_categorical_accuracy: 0.9299 - 114_categorical_accuracy: 0.7747 - 123_categorical_accuracy: 0.9288 - 124_categorical_accuracy: 0.7970 - val_loss: 15.5326 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4504 - val_14_loss: 0.5336 - val_23_loss: 0.6504 - val_24_loss: 1.0215 - val_33_loss: 0.9148 - val_34_loss: 1.2905 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3705 - val_74_loss: 1.1761 - val_83_loss: 0.2901 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3453 - val_94_loss: 1.7732 - val_103_loss: 0.3582 - val_104_loss: 2.0764 - val_113_loss: 0.3234 - val_114_loss: 2.0402 - val_123_loss: 0.3443 - val_124_loss: 1.5738 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9144 - val_14_categorical_accuracy: 0.9563 - val_23_categorical_accuracy: 0.8860 - val_24_categorical_accuracy: 0.8629 - val_33_categorical_accuracy: 0.6389 - val_34_categorical_accuracy: 0.4643 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9426 - val_74_categorical_accuracy: 0.9287 - val_83_categorical_accuracy: 0.9391 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9276 - val_94_categorical_accuracy: 0.7470 - val_103_categorical_accuracy: 0.9282 - val_104_categorical_accuracy: 0.7597 - val_113_categorical_accuracy: 0.9300 - val_114_categorical_accuracy: 0.7579 - val_123_categorical_accuracy: 0.9285 - val_124_categorical_accuracy: 0.8171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.7006 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2692 - 14_loss: 0.1283 - 23_loss: 0.3501 - 24_loss: 0.3998 - 33_loss: 0.7408 - 34_loss: 0.9391 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2074 - 74_loss: 0.1951 - 83_loss: 0.2083 - 84_loss: 0.0000e+00 - 93_loss: 0.2234 - 94_loss: 0.6135 - 103_loss: 0.2305 - 104_loss: 0.6017 - 113_loss: 0.2244 - 114_loss: 0.5877 - 123_loss: 0.2274 - 124_loss: 0.5539 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8867 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6711 - 34_categorical_accuracy: 0.5348 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9402 - 74_categorical_accuracy: 0.9428 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9311 - 94_categorical_accuracy: 0.7691 - 103_categorical_accuracy: 0.9288 - 104_categorical_accuracy: 0.7772 - 113_categorical_accuracy: 0.9297 - 114_categorical_accuracy: 0.7744 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7968 - val_loss: 15.2862 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4329 - val_14_loss: 0.5244 - val_23_loss: 0.6466 - val_24_loss: 1.0458 - val_33_loss: 0.9131 - val_34_loss: 1.2808 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3679 - val_74_loss: 1.1677 - val_83_loss: 0.2908 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3425 - val_94_loss: 1.6551 - val_103_loss: 0.3424 - val_104_loss: 2.1719 - val_113_loss: 0.3139 - val_114_loss: 1.9638 - val_123_loss: 0.3551 - val_124_loss: 1.4715 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9120 - val_14_categorical_accuracy: 0.9560 - val_23_categorical_accuracy: 0.8848 - val_24_categorical_accuracy: 0.8625 - val_33_categorical_accuracy: 0.6418 - val_34_categorical_accuracy: 0.4617 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9403 - val_74_categorical_accuracy: 0.9288 - val_83_categorical_accuracy: 0.9401 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9280 - val_94_categorical_accuracy: 0.7377 - val_103_categorical_accuracy: 0.9292 - val_104_categorical_accuracy: 0.7735 - val_113_categorical_accuracy: 0.9282 - val_114_categorical_accuracy: 0.7662 - val_123_categorical_accuracy: 0.9307 - val_124_categorical_accuracy: 0.8121\n",
      "Epoch 101/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.6845 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2675 - 14_loss: 0.1277 - 23_loss: 0.3497 - 24_loss: 0.3992 - 33_loss: 0.7405 - 34_loss: 0.9387 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2063 - 74_loss: 0.1939 - 83_loss: 0.2076 - 84_loss: 0.0000e+00 - 93_loss: 0.2225 - 94_loss: 0.6125 - 103_loss: 0.2304 - 104_loss: 0.6004 - 113_loss: 0.2233 - 114_loss: 0.5868 - 123_loss: 0.2262 - 124_loss: 0.5512 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9169 - 14_categorical_accuracy: 0.9596 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8707 - 33_categorical_accuracy: 0.6725 - 34_categorical_accuracy: 0.5350 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9399 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9368 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7696 - 103_categorical_accuracy: 0.9286 - 104_categorical_accuracy: 0.7772 - 113_categorical_accuracy: 0.9298 - 114_categorical_accuracy: 0.7745 - 123_categorical_accuracy: 0.9288 - 124_categorical_accuracy: 0.7966 - val_loss: 15.1991 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4449 - val_14_loss: 0.5221 - val_23_loss: 0.6437 - val_24_loss: 1.0219 - val_33_loss: 0.9176 - val_34_loss: 1.2827 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3643 - val_74_loss: 1.2412 - val_83_loss: 0.3051 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3518 - val_94_loss: 1.6631 - val_103_loss: 0.3473 - val_104_loss: 2.0439 - val_113_loss: 0.3268 - val_114_loss: 1.9669 - val_123_loss: 0.3318 - val_124_loss: 1.4239 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9145 - val_14_categorical_accuracy: 0.9558 - val_23_categorical_accuracy: 0.8866 - val_24_categorical_accuracy: 0.8622 - val_33_categorical_accuracy: 0.6466 - val_34_categorical_accuracy: 0.4610 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9417 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9393 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9284 - val_94_categorical_accuracy: 0.7487 - val_103_categorical_accuracy: 0.9279 - val_104_categorical_accuracy: 0.7666 - val_113_categorical_accuracy: 0.9287 - val_114_categorical_accuracy: 0.7656 - val_123_categorical_accuracy: 0.9295 - val_124_categorical_accuracy: 0.8206\n",
      "Epoch 102/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 6.6781 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2675 - 14_loss: 0.1274 - 23_loss: 0.3479 - 24_loss: 0.3983 - 33_loss: 0.7400 - 34_loss: 0.9377 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2066 - 74_loss: 0.1936 - 83_loss: 0.2075 - 84_loss: 0.0000e+00 - 93_loss: 0.2224 - 94_loss: 0.6123 - 103_loss: 0.2299 - 104_loss: 0.6004 - 113_loss: 0.2226 - 114_loss: 0.5858 - 123_loss: 0.2266 - 124_loss: 0.5516 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9172 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8870 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6719 - 34_categorical_accuracy: 0.5343 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9368 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7693 - 103_categorical_accuracy: 0.9289 - 104_categorical_accuracy: 0.7768 - 113_categorical_accuracy: 0.9297 - 114_categorical_accuracy: 0.7746 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7967 - val_loss: 15.6699 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4517 - val_14_loss: 0.5517 - val_23_loss: 0.6494 - val_24_loss: 1.0554 - val_33_loss: 0.9247 - val_34_loss: 1.3038 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3687 - val_74_loss: 1.1442 - val_83_loss: 0.2969 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3545 - val_94_loss: 1.7148 - val_103_loss: 0.3562 - val_104_loss: 2.1732 - val_113_loss: 0.3393 - val_114_loss: 2.1003 - val_123_loss: 0.3566 - val_124_loss: 1.5284 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9134 - val_14_categorical_accuracy: 0.9563 - val_23_categorical_accuracy: 0.8847 - val_24_categorical_accuracy: 0.8622 - val_33_categorical_accuracy: 0.6448 - val_34_categorical_accuracy: 0.4609 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9423 - val_74_categorical_accuracy: 0.9282 - val_83_categorical_accuracy: 0.9398 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9259 - val_94_categorical_accuracy: 0.7461 - val_103_categorical_accuracy: 0.9278 - val_104_categorical_accuracy: 0.7638 - val_113_categorical_accuracy: 0.9286 - val_114_categorical_accuracy: 0.7574 - val_123_categorical_accuracy: 0.9303 - val_124_categorical_accuracy: 0.8224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 6.6806 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2673 - 14_loss: 0.1275 - 23_loss: 0.3490 - 24_loss: 0.3988 - 33_loss: 0.7401 - 34_loss: 0.9382 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2059 - 74_loss: 0.1943 - 83_loss: 0.2069 - 84_loss: 0.0000e+00 - 93_loss: 0.2227 - 94_loss: 0.6133 - 103_loss: 0.2296 - 104_loss: 0.6004 - 113_loss: 0.2232 - 114_loss: 0.5859 - 123_loss: 0.2256 - 124_loss: 0.5520 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6718 - 34_categorical_accuracy: 0.5355 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9400 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9368 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9315 - 94_categorical_accuracy: 0.7694 - 103_categorical_accuracy: 0.9287 - 104_categorical_accuracy: 0.7770 - 113_categorical_accuracy: 0.9299 - 114_categorical_accuracy: 0.7747 - 123_categorical_accuracy: 0.9288 - 124_categorical_accuracy: 0.7965 - val_loss: 15.8588 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4481 - val_14_loss: 0.5627 - val_23_loss: 0.6783 - val_24_loss: 1.0612 - val_33_loss: 0.9225 - val_34_loss: 1.3023 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3899 - val_74_loss: 1.2002 - val_83_loss: 0.3075 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3557 - val_94_loss: 1.7428 - val_103_loss: 0.3537 - val_104_loss: 2.0941 - val_113_loss: 0.3245 - val_114_loss: 2.1549 - val_123_loss: 0.3760 - val_124_loss: 1.5842 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9139 - val_14_categorical_accuracy: 0.9562 - val_23_categorical_accuracy: 0.8836 - val_24_categorical_accuracy: 0.8611 - val_33_categorical_accuracy: 0.6392 - val_34_categorical_accuracy: 0.4610 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9423 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9387 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9280 - val_94_categorical_accuracy: 0.7486 - val_103_categorical_accuracy: 0.9282 - val_104_categorical_accuracy: 0.7586 - val_113_categorical_accuracy: 0.9298 - val_114_categorical_accuracy: 0.7527 - val_123_categorical_accuracy: 0.9290 - val_124_categorical_accuracy: 0.8269\n",
      "Epoch 104/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.6817 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2668 - 14_loss: 0.1274 - 23_loss: 0.3486 - 24_loss: 0.3992 - 33_loss: 0.7400 - 34_loss: 0.9377 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2066 - 74_loss: 0.1941 - 83_loss: 0.2073 - 84_loss: 0.0000e+00 - 93_loss: 0.2226 - 94_loss: 0.6134 - 103_loss: 0.2303 - 104_loss: 0.6010 - 113_loss: 0.2229 - 114_loss: 0.5859 - 123_loss: 0.2262 - 124_loss: 0.5519 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9596 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6716 - 34_categorical_accuracy: 0.5351 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9400 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7691 - 103_categorical_accuracy: 0.9287 - 104_categorical_accuracy: 0.7773 - 113_categorical_accuracy: 0.9296 - 114_categorical_accuracy: 0.7745 - 123_categorical_accuracy: 0.9287 - 124_categorical_accuracy: 0.7971 - val_loss: 15.6425 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4513 - val_14_loss: 0.5706 - val_23_loss: 0.6755 - val_24_loss: 1.0520 - val_33_loss: 0.9183 - val_34_loss: 1.3236 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3646 - val_74_loss: 1.1689 - val_83_loss: 0.2885 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3535 - val_94_loss: 1.7807 - val_103_loss: 0.3482 - val_104_loss: 2.0493 - val_113_loss: 0.3291 - val_114_loss: 2.0532 - val_123_loss: 0.3575 - val_124_loss: 1.5577 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9139 - val_14_categorical_accuracy: 0.9563 - val_23_categorical_accuracy: 0.8846 - val_24_categorical_accuracy: 0.8624 - val_33_categorical_accuracy: 0.6405 - val_34_categorical_accuracy: 0.4627 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9429 - val_74_categorical_accuracy: 0.9290 - val_83_categorical_accuracy: 0.9399 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9279 - val_94_categorical_accuracy: 0.7416 - val_103_categorical_accuracy: 0.9290 - val_104_categorical_accuracy: 0.7559 - val_113_categorical_accuracy: 0.9299 - val_114_categorical_accuracy: 0.7623 - val_123_categorical_accuracy: 0.9285 - val_124_categorical_accuracy: 0.8210\n",
      "Epoch 105/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.6801 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2672 - 14_loss: 0.1274 - 23_loss: 0.3492 - 24_loss: 0.3985 - 33_loss: 0.7401 - 34_loss: 0.9389 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2061 - 74_loss: 0.1942 - 83_loss: 0.2073 - 84_loss: 0.0000e+00 - 93_loss: 0.2230 - 94_loss: 0.6129 - 103_loss: 0.2295 - 104_loss: 0.6007 - 113_loss: 0.2222 - 114_loss: 0.5862 - 123_loss: 0.2257 - 124_loss: 0.5510 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9169 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8870 - 24_categorical_accuracy: 0.8707 - 33_categorical_accuracy: 0.6715 - 34_categorical_accuracy: 0.5342 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9368 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9312 - 94_categorical_accuracy: 0.7694 - 103_categorical_accuracy: 0.9287 - 104_categorical_accuracy: 0.7770 - 113_categorical_accuracy: 0.9297 - 114_categorical_accuracy: 0.7745 - 123_categorical_accuracy: 0.9287 - 124_categorical_accuracy: 0.7967 - val_loss: 15.6086 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4527 - val_14_loss: 0.5202 - val_23_loss: 0.6618 - val_24_loss: 1.0534 - val_33_loss: 0.9210 - val_34_loss: 1.2888 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3738 - val_74_loss: 1.2038 - val_83_loss: 0.2989 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3458 - val_94_loss: 1.8399 - val_103_loss: 0.3518 - val_104_loss: 2.1087 - val_113_loss: 0.3317 - val_114_loss: 1.9828 - val_123_loss: 0.3449 - val_124_loss: 1.5286 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9130 - val_14_categorical_accuracy: 0.9557 - val_23_categorical_accuracy: 0.8867 - val_24_categorical_accuracy: 0.8629 - val_33_categorical_accuracy: 0.6422 - val_34_categorical_accuracy: 0.4573 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9412 - val_74_categorical_accuracy: 0.9290 - val_83_categorical_accuracy: 0.9393 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9281 - val_94_categorical_accuracy: 0.7451 - val_103_categorical_accuracy: 0.9268 - val_104_categorical_accuracy: 0.7547 - val_113_categorical_accuracy: 0.9289 - val_114_categorical_accuracy: 0.7631 - val_123_categorical_accuracy: 0.9312 - val_124_categorical_accuracy: 0.8311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 6.6785 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2668 - 14_loss: 0.1274 - 23_loss: 0.3486 - 24_loss: 0.3990 - 33_loss: 0.7398 - 34_loss: 0.9382 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2059 - 74_loss: 0.1937 - 83_loss: 0.2076 - 84_loss: 0.0000e+00 - 93_loss: 0.2227 - 94_loss: 0.6129 - 103_loss: 0.2294 - 104_loss: 0.6006 - 113_loss: 0.2223 - 114_loss: 0.5864 - 123_loss: 0.2260 - 124_loss: 0.5514 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8867 - 24_categorical_accuracy: 0.8707 - 33_categorical_accuracy: 0.6719 - 34_categorical_accuracy: 0.5354 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9400 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9368 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7694 - 103_categorical_accuracy: 0.9287 - 104_categorical_accuracy: 0.7770 - 113_categorical_accuracy: 0.9297 - 114_categorical_accuracy: 0.7744 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7968 - val_loss: 16.0034 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4636 - val_14_loss: 0.5746 - val_23_loss: 0.6744 - val_24_loss: 1.1442 - val_33_loss: 0.9246 - val_34_loss: 1.3100 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3749 - val_74_loss: 1.2824 - val_83_loss: 0.2951 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3598 - val_94_loss: 1.7831 - val_103_loss: 0.3632 - val_104_loss: 2.1517 - val_113_loss: 0.3384 - val_114_loss: 1.9748 - val_123_loss: 0.3560 - val_124_loss: 1.6324 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9148 - val_14_categorical_accuracy: 0.9559 - val_23_categorical_accuracy: 0.8852 - val_24_categorical_accuracy: 0.8613 - val_33_categorical_accuracy: 0.6372 - val_34_categorical_accuracy: 0.4607 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9419 - val_74_categorical_accuracy: 0.9279 - val_83_categorical_accuracy: 0.9392 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9248 - val_94_categorical_accuracy: 0.7484 - val_103_categorical_accuracy: 0.9286 - val_104_categorical_accuracy: 0.7645 - val_113_categorical_accuracy: 0.9303 - val_114_categorical_accuracy: 0.7650 - val_123_categorical_accuracy: 0.9299 - val_124_categorical_accuracy: 0.8009\n",
      "Epoch 107/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.6820 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2671 - 14_loss: 0.1274 - 23_loss: 0.3491 - 24_loss: 0.3993 - 33_loss: 0.7400 - 34_loss: 0.9384 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2059 - 74_loss: 0.1938 - 83_loss: 0.2075 - 84_loss: 0.0000e+00 - 93_loss: 0.2236 - 94_loss: 0.6128 - 103_loss: 0.2296 - 104_loss: 0.6007 - 113_loss: 0.2231 - 114_loss: 0.5860 - 123_loss: 0.2259 - 124_loss: 0.5518 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9172 - 14_categorical_accuracy: 0.9596 - 23_categorical_accuracy: 0.8868 - 24_categorical_accuracy: 0.8710 - 33_categorical_accuracy: 0.6726 - 34_categorical_accuracy: 0.5362 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9400 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9368 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7691 - 103_categorical_accuracy: 0.9287 - 104_categorical_accuracy: 0.7771 - 113_categorical_accuracy: 0.9299 - 114_categorical_accuracy: 0.7746 - 123_categorical_accuracy: 0.9288 - 124_categorical_accuracy: 0.7969 - val_loss: 15.4909 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4557 - val_14_loss: 0.5123 - val_23_loss: 0.6324 - val_24_loss: 1.0413 - val_33_loss: 0.9191 - val_34_loss: 1.2828 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3654 - val_74_loss: 1.1897 - val_83_loss: 0.2948 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3501 - val_94_loss: 1.8006 - val_103_loss: 0.3509 - val_104_loss: 1.9438 - val_113_loss: 0.3268 - val_114_loss: 2.1056 - val_123_loss: 0.3409 - val_124_loss: 1.5788 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9136 - val_14_categorical_accuracy: 0.9567 - val_23_categorical_accuracy: 0.8860 - val_24_categorical_accuracy: 0.8612 - val_33_categorical_accuracy: 0.6452 - val_34_categorical_accuracy: 0.4607 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9424 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9386 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9286 - val_94_categorical_accuracy: 0.7444 - val_103_categorical_accuracy: 0.9285 - val_104_categorical_accuracy: 0.7563 - val_113_categorical_accuracy: 0.9304 - val_114_categorical_accuracy: 0.7647 - val_123_categorical_accuracy: 0.9283 - val_124_categorical_accuracy: 0.8244\n",
      "Epoch 108/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.6803 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2675 - 14_loss: 0.1272 - 23_loss: 0.3491 - 24_loss: 0.3990 - 33_loss: 0.7401 - 34_loss: 0.9380 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2058 - 74_loss: 0.1945 - 83_loss: 0.2070 - 84_loss: 0.0000e+00 - 93_loss: 0.2224 - 94_loss: 0.6129 - 103_loss: 0.2294 - 104_loss: 0.6013 - 113_loss: 0.2227 - 114_loss: 0.5864 - 123_loss: 0.2256 - 124_loss: 0.5514 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9172 - 14_categorical_accuracy: 0.9597 - 23_categorical_accuracy: 0.8872 - 24_categorical_accuracy: 0.8709 - 33_categorical_accuracy: 0.6723 - 34_categorical_accuracy: 0.5351 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9400 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9311 - 94_categorical_accuracy: 0.7691 - 103_categorical_accuracy: 0.9288 - 104_categorical_accuracy: 0.7771 - 113_categorical_accuracy: 0.9298 - 114_categorical_accuracy: 0.7746 - 123_categorical_accuracy: 0.9288 - 124_categorical_accuracy: 0.7969 - val_loss: 15.4893 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4508 - val_14_loss: 0.5257 - val_23_loss: 0.6548 - val_24_loss: 1.0650 - val_33_loss: 0.9225 - val_34_loss: 1.2846 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3749 - val_74_loss: 1.1952 - val_83_loss: 0.3023 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3780 - val_94_loss: 1.7765 - val_103_loss: 0.3601 - val_104_loss: 1.9475 - val_113_loss: 0.3286 - val_114_loss: 1.9846 - val_123_loss: 0.3554 - val_124_loss: 1.5828 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9152 - val_14_categorical_accuracy: 0.9564 - val_23_categorical_accuracy: 0.8853 - val_24_categorical_accuracy: 0.8620 - val_33_categorical_accuracy: 0.6398 - val_34_categorical_accuracy: 0.4565 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9425 - val_74_categorical_accuracy: 0.9293 - val_83_categorical_accuracy: 0.9395 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9286 - val_94_categorical_accuracy: 0.7514 - val_103_categorical_accuracy: 0.9280 - val_104_categorical_accuracy: 0.7522 - val_113_categorical_accuracy: 0.9277 - val_114_categorical_accuracy: 0.7558 - val_123_categorical_accuracy: 0.9295 - val_124_categorical_accuracy: 0.8262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 6.6771 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2675 - 14_loss: 0.1270 - 23_loss: 0.3485 - 24_loss: 0.3983 - 33_loss: 0.7393 - 34_loss: 0.9378 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2062 - 74_loss: 0.1935 - 83_loss: 0.2066 - 84_loss: 0.0000e+00 - 93_loss: 0.2230 - 94_loss: 0.6135 - 103_loss: 0.2297 - 104_loss: 0.6004 - 113_loss: 0.2227 - 114_loss: 0.5864 - 123_loss: 0.2255 - 124_loss: 0.5514 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9170 - 14_categorical_accuracy: 0.9596 - 23_categorical_accuracy: 0.8872 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6721 - 34_categorical_accuracy: 0.5358 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9400 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9311 - 94_categorical_accuracy: 0.7692 - 103_categorical_accuracy: 0.9286 - 104_categorical_accuracy: 0.7771 - 113_categorical_accuracy: 0.9297 - 114_categorical_accuracy: 0.7746 - 123_categorical_accuracy: 0.9288 - 124_categorical_accuracy: 0.7967 - val_loss: 15.7566 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4401 - val_14_loss: 0.5400 - val_23_loss: 0.6952 - val_24_loss: 1.1204 - val_33_loss: 0.9210 - val_34_loss: 1.2929 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3633 - val_74_loss: 1.2609 - val_83_loss: 0.3144 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3548 - val_94_loss: 1.7147 - val_103_loss: 0.3481 - val_104_loss: 2.0863 - val_113_loss: 0.3290 - val_114_loss: 2.0369 - val_123_loss: 0.3528 - val_124_loss: 1.5858 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9142 - val_14_categorical_accuracy: 0.9562 - val_23_categorical_accuracy: 0.8855 - val_24_categorical_accuracy: 0.8619 - val_33_categorical_accuracy: 0.6327 - val_34_categorical_accuracy: 0.4630 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9412 - val_74_categorical_accuracy: 0.9286 - val_83_categorical_accuracy: 0.9398 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9283 - val_94_categorical_accuracy: 0.7409 - val_103_categorical_accuracy: 0.9283 - val_104_categorical_accuracy: 0.7661 - val_113_categorical_accuracy: 0.9289 - val_114_categorical_accuracy: 0.7625 - val_123_categorical_accuracy: 0.9298 - val_124_categorical_accuracy: 0.8259\n",
      "Epoch 110/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.6893 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2681 - 14_loss: 0.1276 - 23_loss: 0.3495 - 24_loss: 0.4002 - 33_loss: 0.7397 - 34_loss: 0.9392 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2068 - 74_loss: 0.1943 - 83_loss: 0.2077 - 84_loss: 0.0000e+00 - 93_loss: 0.2228 - 94_loss: 0.6138 - 103_loss: 0.2299 - 104_loss: 0.6010 - 113_loss: 0.2234 - 114_loss: 0.5872 - 123_loss: 0.2258 - 124_loss: 0.5524 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9169 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8710 - 33_categorical_accuracy: 0.6722 - 34_categorical_accuracy: 0.5342 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9400 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9312 - 94_categorical_accuracy: 0.7693 - 103_categorical_accuracy: 0.9287 - 104_categorical_accuracy: 0.7769 - 113_categorical_accuracy: 0.9298 - 114_categorical_accuracy: 0.7745 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7968 - val_loss: 15.2717 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4539 - val_14_loss: 0.5607 - val_23_loss: 0.6281 - val_24_loss: 1.0443 - val_33_loss: 0.9271 - val_34_loss: 1.2935 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3490 - val_74_loss: 1.2831 - val_83_loss: 0.3036 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3481 - val_94_loss: 1.6378 - val_103_loss: 0.3474 - val_104_loss: 1.9444 - val_113_loss: 0.3312 - val_114_loss: 1.9110 - val_123_loss: 0.3643 - val_124_loss: 1.5442 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9142 - val_14_categorical_accuracy: 0.9560 - val_23_categorical_accuracy: 0.8855 - val_24_categorical_accuracy: 0.8631 - val_33_categorical_accuracy: 0.6416 - val_34_categorical_accuracy: 0.4606 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9429 - val_74_categorical_accuracy: 0.9286 - val_83_categorical_accuracy: 0.9394 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9283 - val_94_categorical_accuracy: 0.7514 - val_103_categorical_accuracy: 0.9269 - val_104_categorical_accuracy: 0.7649 - val_113_categorical_accuracy: 0.9286 - val_114_categorical_accuracy: 0.7631 - val_123_categorical_accuracy: 0.9303 - val_124_categorical_accuracy: 0.8160\n",
      "Epoch 111/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.6743 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2671 - 14_loss: 0.1272 - 23_loss: 0.3480 - 24_loss: 0.3981 - 33_loss: 0.7390 - 34_loss: 0.9379 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2058 - 74_loss: 0.1940 - 83_loss: 0.2068 - 84_loss: 0.0000e+00 - 93_loss: 0.2221 - 94_loss: 0.6124 - 103_loss: 0.2291 - 104_loss: 0.6002 - 113_loss: 0.2224 - 114_loss: 0.5859 - 123_loss: 0.2261 - 124_loss: 0.5521 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9172 - 14_categorical_accuracy: 0.9596 - 23_categorical_accuracy: 0.8870 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6721 - 34_categorical_accuracy: 0.5349 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9400 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9312 - 94_categorical_accuracy: 0.7694 - 103_categorical_accuracy: 0.9287 - 104_categorical_accuracy: 0.7769 - 113_categorical_accuracy: 0.9300 - 114_categorical_accuracy: 0.7743 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7962 - val_loss: 15.7013 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4514 - val_14_loss: 0.5811 - val_23_loss: 0.6686 - val_24_loss: 1.0501 - val_33_loss: 0.9289 - val_34_loss: 1.2917 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3634 - val_74_loss: 1.2430 - val_83_loss: 0.2990 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3535 - val_94_loss: 1.7292 - val_103_loss: 0.3506 - val_104_loss: 2.1189 - val_113_loss: 0.3250 - val_114_loss: 2.0500 - val_123_loss: 0.3560 - val_124_loss: 1.5409 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9146 - val_14_categorical_accuracy: 0.9561 - val_23_categorical_accuracy: 0.8832 - val_24_categorical_accuracy: 0.8624 - val_33_categorical_accuracy: 0.6354 - val_34_categorical_accuracy: 0.4630 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9407 - val_74_categorical_accuracy: 0.9289 - val_83_categorical_accuracy: 0.9393 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9281 - val_94_categorical_accuracy: 0.7495 - val_103_categorical_accuracy: 0.9293 - val_104_categorical_accuracy: 0.7649 - val_113_categorical_accuracy: 0.9304 - val_114_categorical_accuracy: 0.7638 - val_123_categorical_accuracy: 0.9284 - val_124_categorical_accuracy: 0.8009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.6715 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2661 - 14_loss: 0.1267 - 23_loss: 0.3483 - 24_loss: 0.3980 - 33_loss: 0.7391 - 34_loss: 0.9380 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2055 - 74_loss: 0.1938 - 83_loss: 0.2067 - 84_loss: 0.0000e+00 - 93_loss: 0.2226 - 94_loss: 0.6125 - 103_loss: 0.2290 - 104_loss: 0.6010 - 113_loss: 0.2221 - 114_loss: 0.5855 - 123_loss: 0.2253 - 124_loss: 0.5511 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9598 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8707 - 33_categorical_accuracy: 0.6725 - 34_categorical_accuracy: 0.5351 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9399 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9314 - 94_categorical_accuracy: 0.7693 - 103_categorical_accuracy: 0.9287 - 104_categorical_accuracy: 0.7768 - 113_categorical_accuracy: 0.9297 - 114_categorical_accuracy: 0.7747 - 123_categorical_accuracy: 0.9287 - 124_categorical_accuracy: 0.7966 - val_loss: 16.0986 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4690 - val_14_loss: 0.5719 - val_23_loss: 0.6899 - val_24_loss: 1.1495 - val_33_loss: 0.9171 - val_34_loss: 1.3021 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3782 - val_74_loss: 1.2834 - val_83_loss: 0.3052 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3736 - val_94_loss: 1.7984 - val_103_loss: 0.3597 - val_104_loss: 2.1265 - val_113_loss: 0.3379 - val_114_loss: 1.9949 - val_123_loss: 0.3689 - val_124_loss: 1.6722 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9129 - val_14_categorical_accuracy: 0.9560 - val_23_categorical_accuracy: 0.8847 - val_24_categorical_accuracy: 0.8603 - val_33_categorical_accuracy: 0.6425 - val_34_categorical_accuracy: 0.4628 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9419 - val_74_categorical_accuracy: 0.9285 - val_83_categorical_accuracy: 0.9384 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9287 - val_94_categorical_accuracy: 0.7418 - val_103_categorical_accuracy: 0.9281 - val_104_categorical_accuracy: 0.7557 - val_113_categorical_accuracy: 0.9282 - val_114_categorical_accuracy: 0.7620 - val_123_categorical_accuracy: 0.9302 - val_124_categorical_accuracy: 0.8219\n",
      "Epoch 113/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 6.6774 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2670 - 14_loss: 0.1271 - 23_loss: 0.3483 - 24_loss: 0.3982 - 33_loss: 0.7391 - 34_loss: 0.9384 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2056 - 74_loss: 0.1937 - 83_loss: 0.2066 - 84_loss: 0.0000e+00 - 93_loss: 0.2227 - 94_loss: 0.6131 - 103_loss: 0.2297 - 104_loss: 0.6008 - 113_loss: 0.2225 - 114_loss: 0.5867 - 123_loss: 0.2259 - 124_loss: 0.5519 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9172 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6723 - 34_categorical_accuracy: 0.5358 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9400 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9311 - 94_categorical_accuracy: 0.7696 - 103_categorical_accuracy: 0.9290 - 104_categorical_accuracy: 0.7770 - 113_categorical_accuracy: 0.9296 - 114_categorical_accuracy: 0.7744 - 123_categorical_accuracy: 0.9288 - 124_categorical_accuracy: 0.7966 - val_loss: 15.9447 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4609 - val_14_loss: 0.5834 - val_23_loss: 0.6921 - val_24_loss: 1.1667 - val_33_loss: 0.9266 - val_34_loss: 1.2952 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3793 - val_74_loss: 1.2226 - val_83_loss: 0.3098 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3615 - val_94_loss: 1.7152 - val_103_loss: 0.3649 - val_104_loss: 2.0993 - val_113_loss: 0.3414 - val_114_loss: 2.0242 - val_123_loss: 0.3645 - val_124_loss: 1.6373 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9145 - val_14_categorical_accuracy: 0.9557 - val_23_categorical_accuracy: 0.8855 - val_24_categorical_accuracy: 0.8618 - val_33_categorical_accuracy: 0.6325 - val_34_categorical_accuracy: 0.4634 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9422 - val_74_categorical_accuracy: 0.9289 - val_83_categorical_accuracy: 0.9390 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9269 - val_94_categorical_accuracy: 0.7440 - val_103_categorical_accuracy: 0.9274 - val_104_categorical_accuracy: 0.7685 - val_113_categorical_accuracy: 0.9295 - val_114_categorical_accuracy: 0.7630 - val_123_categorical_accuracy: 0.9310 - val_124_categorical_accuracy: 0.8160\n",
      "Epoch 114/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.6770 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2670 - 14_loss: 0.1275 - 23_loss: 0.3487 - 24_loss: 0.3991 - 33_loss: 0.7389 - 34_loss: 0.9379 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2058 - 74_loss: 0.1940 - 83_loss: 0.2070 - 84_loss: 0.0000e+00 - 93_loss: 0.2222 - 94_loss: 0.6123 - 103_loss: 0.2299 - 104_loss: 0.6009 - 113_loss: 0.2228 - 114_loss: 0.5860 - 123_loss: 0.2247 - 124_loss: 0.5522 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8705 - 33_categorical_accuracy: 0.6723 - 34_categorical_accuracy: 0.5351 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9399 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9368 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9312 - 94_categorical_accuracy: 0.7692 - 103_categorical_accuracy: 0.9287 - 104_categorical_accuracy: 0.7769 - 113_categorical_accuracy: 0.9298 - 114_categorical_accuracy: 0.7748 - 123_categorical_accuracy: 0.9287 - 124_categorical_accuracy: 0.7967 - val_loss: 15.8467 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4727 - val_14_loss: 0.5083 - val_23_loss: 0.6604 - val_24_loss: 1.0654 - val_33_loss: 0.9350 - val_34_loss: 1.2941 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3882 - val_74_loss: 1.2208 - val_83_loss: 0.3116 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3634 - val_94_loss: 1.7752 - val_103_loss: 0.3643 - val_104_loss: 2.2499 - val_113_loss: 0.3303 - val_114_loss: 1.9734 - val_123_loss: 0.3599 - val_124_loss: 1.5736 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9148 - val_14_categorical_accuracy: 0.9559 - val_23_categorical_accuracy: 0.8860 - val_24_categorical_accuracy: 0.8629 - val_33_categorical_accuracy: 0.6366 - val_34_categorical_accuracy: 0.4618 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9420 - val_74_categorical_accuracy: 0.9270 - val_83_categorical_accuracy: 0.9394 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9274 - val_94_categorical_accuracy: 0.7506 - val_103_categorical_accuracy: 0.9293 - val_104_categorical_accuracy: 0.7728 - val_113_categorical_accuracy: 0.9295 - val_114_categorical_accuracy: 0.7676 - val_123_categorical_accuracy: 0.9304 - val_124_categorical_accuracy: 0.8209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.7042 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2684 - 14_loss: 0.1275 - 23_loss: 0.3499 - 24_loss: 0.3988 - 33_loss: 0.7445 - 34_loss: 0.9417 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2060 - 74_loss: 0.1941 - 83_loss: 0.2083 - 84_loss: 0.0000e+00 - 93_loss: 0.2228 - 94_loss: 0.6173 - 103_loss: 0.2299 - 104_loss: 0.6021 - 113_loss: 0.2240 - 114_loss: 0.5894 - 123_loss: 0.2264 - 124_loss: 0.5530 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9169 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8707 - 33_categorical_accuracy: 0.6715 - 34_categorical_accuracy: 0.5343 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9400 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9367 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7692 - 103_categorical_accuracy: 0.9286 - 104_categorical_accuracy: 0.7771 - 113_categorical_accuracy: 0.9297 - 114_categorical_accuracy: 0.7749 - 123_categorical_accuracy: 0.9287 - 124_categorical_accuracy: 0.7967 - val_loss: 15.5818 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4542 - val_14_loss: 0.5489 - val_23_loss: 0.6587 - val_24_loss: 1.1275 - val_33_loss: 0.9284 - val_34_loss: 1.2971 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3795 - val_74_loss: 1.2362 - val_83_loss: 0.3038 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3580 - val_94_loss: 1.6895 - val_103_loss: 0.3561 - val_104_loss: 2.0563 - val_113_loss: 0.3283 - val_114_loss: 1.9341 - val_123_loss: 0.3704 - val_124_loss: 1.5549 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9144 - val_14_categorical_accuracy: 0.9561 - val_23_categorical_accuracy: 0.8835 - val_24_categorical_accuracy: 0.8619 - val_33_categorical_accuracy: 0.6381 - val_34_categorical_accuracy: 0.4682 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9420 - val_74_categorical_accuracy: 0.9289 - val_83_categorical_accuracy: 0.9402 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9275 - val_94_categorical_accuracy: 0.7467 - val_103_categorical_accuracy: 0.9283 - val_104_categorical_accuracy: 0.7656 - val_113_categorical_accuracy: 0.9298 - val_114_categorical_accuracy: 0.7666 - val_123_categorical_accuracy: 0.9307 - val_124_categorical_accuracy: 0.8217\n",
      "Epoch 116/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.6810 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2664 - 14_loss: 0.1272 - 23_loss: 0.3491 - 24_loss: 0.3992 - 33_loss: 0.7403 - 34_loss: 0.9396 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2064 - 74_loss: 0.1938 - 83_loss: 0.2072 - 84_loss: 0.0000e+00 - 93_loss: 0.2226 - 94_loss: 0.6135 - 103_loss: 0.2294 - 104_loss: 0.6010 - 113_loss: 0.2217 - 114_loss: 0.5859 - 123_loss: 0.2254 - 124_loss: 0.5525 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9593 - 23_categorical_accuracy: 0.8868 - 24_categorical_accuracy: 0.8705 - 33_categorical_accuracy: 0.6715 - 34_categorical_accuracy: 0.5347 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9367 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7691 - 103_categorical_accuracy: 0.9286 - 104_categorical_accuracy: 0.7769 - 113_categorical_accuracy: 0.9296 - 114_categorical_accuracy: 0.7749 - 123_categorical_accuracy: 0.9288 - 124_categorical_accuracy: 0.7962 - val_loss: 15.4117 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4564 - val_14_loss: 0.5784 - val_23_loss: 0.6396 - val_24_loss: 1.0413 - val_33_loss: 0.9091 - val_34_loss: 1.2875 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3740 - val_74_loss: 1.2196 - val_83_loss: 0.2951 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3581 - val_94_loss: 1.6861 - val_103_loss: 0.3677 - val_104_loss: 2.0396 - val_113_loss: 0.3451 - val_114_loss: 2.0123 - val_123_loss: 0.3608 - val_124_loss: 1.4412 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9136 - val_14_categorical_accuracy: 0.9561 - val_23_categorical_accuracy: 0.8842 - val_24_categorical_accuracy: 0.8619 - val_33_categorical_accuracy: 0.6386 - val_34_categorical_accuracy: 0.4665 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9429 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9405 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9261 - val_94_categorical_accuracy: 0.7457 - val_103_categorical_accuracy: 0.9266 - val_104_categorical_accuracy: 0.7502 - val_113_categorical_accuracy: 0.9284 - val_114_categorical_accuracy: 0.7623 - val_123_categorical_accuracy: 0.9307 - val_124_categorical_accuracy: 0.8204\n",
      "Epoch 117/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 6.6723 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2669 - 14_loss: 0.1271 - 23_loss: 0.3483 - 24_loss: 0.3979 - 33_loss: 0.7383 - 34_loss: 0.9381 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2056 - 74_loss: 0.1938 - 83_loss: 0.2066 - 84_loss: 0.0000e+00 - 93_loss: 0.2221 - 94_loss: 0.6136 - 103_loss: 0.2287 - 104_loss: 0.6006 - 113_loss: 0.2218 - 114_loss: 0.5855 - 123_loss: 0.2260 - 124_loss: 0.5514 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9169 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8705 - 33_categorical_accuracy: 0.6728 - 34_categorical_accuracy: 0.5364 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9399 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9312 - 94_categorical_accuracy: 0.7692 - 103_categorical_accuracy: 0.9286 - 104_categorical_accuracy: 0.7771 - 113_categorical_accuracy: 0.9297 - 114_categorical_accuracy: 0.7748 - 123_categorical_accuracy: 0.9287 - 124_categorical_accuracy: 0.7968 - val_loss: 15.9903 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4684 - val_14_loss: 0.5649 - val_23_loss: 0.6759 - val_24_loss: 1.0582 - val_33_loss: 0.9400 - val_34_loss: 1.3130 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3859 - val_74_loss: 1.2589 - val_83_loss: 0.3012 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3698 - val_94_loss: 1.7671 - val_103_loss: 0.3644 - val_104_loss: 2.1233 - val_113_loss: 0.3422 - val_114_loss: 2.0824 - val_123_loss: 0.3843 - val_124_loss: 1.5907 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9139 - val_14_categorical_accuracy: 0.9553 - val_23_categorical_accuracy: 0.8862 - val_24_categorical_accuracy: 0.8621 - val_33_categorical_accuracy: 0.6380 - val_34_categorical_accuracy: 0.4604 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9413 - val_74_categorical_accuracy: 0.9285 - val_83_categorical_accuracy: 0.9399 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9287 - val_94_categorical_accuracy: 0.7418 - val_103_categorical_accuracy: 0.9282 - val_104_categorical_accuracy: 0.7624 - val_113_categorical_accuracy: 0.9288 - val_114_categorical_accuracy: 0.7613 - val_123_categorical_accuracy: 0.9296 - val_124_categorical_accuracy: 0.8298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 6.6690 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2657 - 14_loss: 0.1268 - 23_loss: 0.3481 - 24_loss: 0.3983 - 33_loss: 0.7388 - 34_loss: 0.9375 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2050 - 74_loss: 0.1936 - 83_loss: 0.2063 - 84_loss: 0.0000e+00 - 93_loss: 0.2219 - 94_loss: 0.6127 - 103_loss: 0.2289 - 104_loss: 0.6001 - 113_loss: 0.2221 - 114_loss: 0.5867 - 123_loss: 0.2247 - 124_loss: 0.5519 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9170 - 14_categorical_accuracy: 0.9596 - 23_categorical_accuracy: 0.8868 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6719 - 34_categorical_accuracy: 0.5357 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9398 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9314 - 94_categorical_accuracy: 0.7695 - 103_categorical_accuracy: 0.9288 - 104_categorical_accuracy: 0.7768 - 113_categorical_accuracy: 0.9297 - 114_categorical_accuracy: 0.7746 - 123_categorical_accuracy: 0.9290 - 124_categorical_accuracy: 0.7966 - val_loss: 15.7919 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4502 - val_14_loss: 0.5760 - val_23_loss: 0.6733 - val_24_loss: 1.1242 - val_33_loss: 0.9252 - val_34_loss: 1.3233 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3680 - val_74_loss: 1.2845 - val_83_loss: 0.3067 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3671 - val_94_loss: 1.7739 - val_103_loss: 0.3585 - val_104_loss: 2.0357 - val_113_loss: 0.3362 - val_114_loss: 1.9478 - val_123_loss: 0.3728 - val_124_loss: 1.5685 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9141 - val_14_categorical_accuracy: 0.9560 - val_23_categorical_accuracy: 0.8855 - val_24_categorical_accuracy: 0.8615 - val_33_categorical_accuracy: 0.6382 - val_34_categorical_accuracy: 0.4616 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9417 - val_74_categorical_accuracy: 0.9288 - val_83_categorical_accuracy: 0.9390 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9276 - val_94_categorical_accuracy: 0.7473 - val_103_categorical_accuracy: 0.9279 - val_104_categorical_accuracy: 0.7591 - val_113_categorical_accuracy: 0.9279 - val_114_categorical_accuracy: 0.7576 - val_123_categorical_accuracy: 0.9289 - val_124_categorical_accuracy: 0.8289\n",
      "Epoch 119/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 6.6688 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2663 - 14_loss: 0.1267 - 23_loss: 0.3474 - 24_loss: 0.3978 - 33_loss: 0.7387 - 34_loss: 0.9380 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2052 - 74_loss: 0.1943 - 83_loss: 0.2059 - 84_loss: 0.0000e+00 - 93_loss: 0.2219 - 94_loss: 0.6126 - 103_loss: 0.2285 - 104_loss: 0.6010 - 113_loss: 0.2220 - 114_loss: 0.5863 - 123_loss: 0.2246 - 124_loss: 0.5516 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9170 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8706 - 33_categorical_accuracy: 0.6718 - 34_categorical_accuracy: 0.5347 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9400 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9312 - 94_categorical_accuracy: 0.7693 - 103_categorical_accuracy: 0.9287 - 104_categorical_accuracy: 0.7768 - 113_categorical_accuracy: 0.9297 - 114_categorical_accuracy: 0.7744 - 123_categorical_accuracy: 0.9291 - 124_categorical_accuracy: 0.7969 - val_loss: 16.1060 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4547 - val_14_loss: 0.5472 - val_23_loss: 0.6974 - val_24_loss: 1.1381 - val_33_loss: 0.9232 - val_34_loss: 1.3082 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3802 - val_74_loss: 1.2638 - val_83_loss: 0.3050 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3671 - val_94_loss: 1.8523 - val_103_loss: 0.3770 - val_104_loss: 2.1485 - val_113_loss: 0.3276 - val_114_loss: 2.0083 - val_123_loss: 0.3720 - val_124_loss: 1.6356 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9133 - val_14_categorical_accuracy: 0.9559 - val_23_categorical_accuracy: 0.8847 - val_24_categorical_accuracy: 0.8624 - val_33_categorical_accuracy: 0.6407 - val_34_categorical_accuracy: 0.4603 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9388 - val_74_categorical_accuracy: 0.9289 - val_83_categorical_accuracy: 0.9375 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9273 - val_94_categorical_accuracy: 0.7456 - val_103_categorical_accuracy: 0.9296 - val_104_categorical_accuracy: 0.7575 - val_113_categorical_accuracy: 0.9295 - val_114_categorical_accuracy: 0.7497 - val_123_categorical_accuracy: 0.9303 - val_124_categorical_accuracy: 0.8195\n",
      "Epoch 120/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.6761 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2667 - 14_loss: 0.1273 - 23_loss: 0.3483 - 24_loss: 0.3983 - 33_loss: 0.7390 - 34_loss: 0.9387 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2059 - 74_loss: 0.1945 - 83_loss: 0.2063 - 84_loss: 0.0000e+00 - 93_loss: 0.2226 - 94_loss: 0.6133 - 103_loss: 0.2291 - 104_loss: 0.6010 - 113_loss: 0.2223 - 114_loss: 0.5859 - 123_loss: 0.2252 - 124_loss: 0.5519 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9596 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8706 - 33_categorical_accuracy: 0.6717 - 34_categorical_accuracy: 0.5343 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9368 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9311 - 94_categorical_accuracy: 0.7693 - 103_categorical_accuracy: 0.9287 - 104_categorical_accuracy: 0.7772 - 113_categorical_accuracy: 0.9298 - 114_categorical_accuracy: 0.7744 - 123_categorical_accuracy: 0.9290 - 124_categorical_accuracy: 0.7969 - val_loss: 16.0900 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4683 - val_14_loss: 0.5837 - val_23_loss: 0.6884 - val_24_loss: 1.0939 - val_33_loss: 0.9249 - val_34_loss: 1.3070 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3820 - val_74_loss: 1.2272 - val_83_loss: 0.3070 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3561 - val_94_loss: 1.8152 - val_103_loss: 0.3795 - val_104_loss: 2.0889 - val_113_loss: 0.3463 - val_114_loss: 2.0584 - val_123_loss: 0.3739 - val_124_loss: 1.6895 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9137 - val_14_categorical_accuracy: 0.9554 - val_23_categorical_accuracy: 0.8862 - val_24_categorical_accuracy: 0.8616 - val_33_categorical_accuracy: 0.6387 - val_34_categorical_accuracy: 0.4580 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9424 - val_74_categorical_accuracy: 0.9288 - val_83_categorical_accuracy: 0.9396 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9281 - val_94_categorical_accuracy: 0.7405 - val_103_categorical_accuracy: 0.9279 - val_104_categorical_accuracy: 0.7589 - val_113_categorical_accuracy: 0.9287 - val_114_categorical_accuracy: 0.7638 - val_123_categorical_accuracy: 0.9296 - val_124_categorical_accuracy: 0.8299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.6712 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2664 - 14_loss: 0.1272 - 23_loss: 0.3484 - 24_loss: 0.3982 - 33_loss: 0.7375 - 34_loss: 0.9373 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2051 - 74_loss: 0.1940 - 83_loss: 0.2065 - 84_loss: 0.0000e+00 - 93_loss: 0.2223 - 94_loss: 0.6133 - 103_loss: 0.2291 - 104_loss: 0.6005 - 113_loss: 0.2224 - 114_loss: 0.5864 - 123_loss: 0.2244 - 124_loss: 0.5522 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9173 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8709 - 33_categorical_accuracy: 0.6720 - 34_categorical_accuracy: 0.5357 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9399 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9367 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9312 - 94_categorical_accuracy: 0.7694 - 103_categorical_accuracy: 0.9287 - 104_categorical_accuracy: 0.7770 - 113_categorical_accuracy: 0.9297 - 114_categorical_accuracy: 0.7745 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7968 - val_loss: 15.9965 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4626 - val_14_loss: 0.5821 - val_23_loss: 0.6787 - val_24_loss: 1.0876 - val_33_loss: 0.9148 - val_34_loss: 1.3152 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3729 - val_74_loss: 1.1858 - val_83_loss: 0.3039 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3487 - val_94_loss: 1.7384 - val_103_loss: 0.3624 - val_104_loss: 2.0717 - val_113_loss: 0.3495 - val_114_loss: 2.1865 - val_123_loss: 0.3807 - val_124_loss: 1.6549 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9143 - val_14_categorical_accuracy: 0.9562 - val_23_categorical_accuracy: 0.8854 - val_24_categorical_accuracy: 0.8614 - val_33_categorical_accuracy: 0.6444 - val_34_categorical_accuracy: 0.4614 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9427 - val_74_categorical_accuracy: 0.9289 - val_83_categorical_accuracy: 0.9397 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9264 - val_94_categorical_accuracy: 0.7320 - val_103_categorical_accuracy: 0.9269 - val_104_categorical_accuracy: 0.7542 - val_113_categorical_accuracy: 0.9283 - val_114_categorical_accuracy: 0.7658 - val_123_categorical_accuracy: 0.9290 - val_124_categorical_accuracy: 0.8142\n",
      "Epoch 122/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 6.6719 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2666 - 14_loss: 0.1272 - 23_loss: 0.3484 - 24_loss: 0.3976 - 33_loss: 0.7378 - 34_loss: 0.9375 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2049 - 74_loss: 0.1934 - 83_loss: 0.2067 - 84_loss: 0.0000e+00 - 93_loss: 0.2223 - 94_loss: 0.6134 - 103_loss: 0.2287 - 104_loss: 0.6010 - 113_loss: 0.2221 - 114_loss: 0.5864 - 123_loss: 0.2253 - 124_loss: 0.5524 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9175 - 14_categorical_accuracy: 0.9596 - 23_categorical_accuracy: 0.8871 - 24_categorical_accuracy: 0.8706 - 33_categorical_accuracy: 0.6719 - 34_categorical_accuracy: 0.5345 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9400 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7691 - 103_categorical_accuracy: 0.9287 - 104_categorical_accuracy: 0.7766 - 113_categorical_accuracy: 0.9298 - 114_categorical_accuracy: 0.7748 - 123_categorical_accuracy: 0.9290 - 124_categorical_accuracy: 0.7968 - val_loss: 16.2894 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4784 - val_14_loss: 0.5703 - val_23_loss: 0.6766 - val_24_loss: 1.1211 - val_33_loss: 0.9308 - val_34_loss: 1.3075 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3691 - val_74_loss: 1.2708 - val_83_loss: 0.3055 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3691 - val_94_loss: 1.8749 - val_103_loss: 0.3692 - val_104_loss: 2.1896 - val_113_loss: 0.3501 - val_114_loss: 2.1166 - val_123_loss: 0.3796 - val_124_loss: 1.6102 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9127 - val_14_categorical_accuracy: 0.9562 - val_23_categorical_accuracy: 0.8846 - val_24_categorical_accuracy: 0.8608 - val_33_categorical_accuracy: 0.6410 - val_34_categorical_accuracy: 0.4514 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9425 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9394 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9275 - val_94_categorical_accuracy: 0.7496 - val_103_categorical_accuracy: 0.9288 - val_104_categorical_accuracy: 0.7623 - val_113_categorical_accuracy: 0.9276 - val_114_categorical_accuracy: 0.7638 - val_123_categorical_accuracy: 0.9301 - val_124_categorical_accuracy: 0.8131\n",
      "Epoch 123/1000\n",
      "697/697 [==============================] - 28s 41ms/step - loss: 6.6742 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2660 - 14_loss: 0.1270 - 23_loss: 0.3480 - 24_loss: 0.3991 - 33_loss: 0.7383 - 34_loss: 0.9375 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2057 - 74_loss: 0.1944 - 83_loss: 0.2065 - 84_loss: 0.0000e+00 - 93_loss: 0.2224 - 94_loss: 0.6127 - 103_loss: 0.2288 - 104_loss: 0.6017 - 113_loss: 0.2219 - 114_loss: 0.5870 - 123_loss: 0.2251 - 124_loss: 0.5521 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8706 - 33_categorical_accuracy: 0.6724 - 34_categorical_accuracy: 0.5366 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9399 - 74_categorical_accuracy: 0.9428 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9312 - 94_categorical_accuracy: 0.7691 - 103_categorical_accuracy: 0.9288 - 104_categorical_accuracy: 0.7769 - 113_categorical_accuracy: 0.9297 - 114_categorical_accuracy: 0.7746 - 123_categorical_accuracy: 0.9288 - 124_categorical_accuracy: 0.7968 - val_loss: 15.1732 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4547 - val_14_loss: 0.5574 - val_23_loss: 0.6435 - val_24_loss: 1.0150 - val_33_loss: 0.9119 - val_34_loss: 1.2794 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3585 - val_74_loss: 1.0856 - val_83_loss: 0.3018 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3529 - val_94_loss: 1.8024 - val_103_loss: 0.3540 - val_104_loss: 1.9850 - val_113_loss: 0.3204 - val_114_loss: 1.8917 - val_123_loss: 0.3540 - val_124_loss: 1.5050 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9125 - val_14_categorical_accuracy: 0.9564 - val_23_categorical_accuracy: 0.8863 - val_24_categorical_accuracy: 0.8611 - val_33_categorical_accuracy: 0.6455 - val_34_categorical_accuracy: 0.4610 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9405 - val_74_categorical_accuracy: 0.9283 - val_83_categorical_accuracy: 0.9396 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9237 - val_94_categorical_accuracy: 0.7461 - val_103_categorical_accuracy: 0.9280 - val_104_categorical_accuracy: 0.7525 - val_113_categorical_accuracy: 0.9299 - val_114_categorical_accuracy: 0.7667 - val_123_categorical_accuracy: 0.9301 - val_124_categorical_accuracy: 0.8159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 6.7021 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2686 - 14_loss: 0.1290 - 23_loss: 0.3502 - 24_loss: 0.4011 - 33_loss: 0.7415 - 34_loss: 0.9407 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2074 - 74_loss: 0.1946 - 83_loss: 0.2074 - 84_loss: 0.0000e+00 - 93_loss: 0.2228 - 94_loss: 0.6146 - 103_loss: 0.2307 - 104_loss: 0.6025 - 113_loss: 0.2234 - 114_loss: 0.5878 - 123_loss: 0.2266 - 124_loss: 0.5533 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9592 - 23_categorical_accuracy: 0.8870 - 24_categorical_accuracy: 0.8707 - 33_categorical_accuracy: 0.6719 - 34_categorical_accuracy: 0.5350 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9400 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9310 - 94_categorical_accuracy: 0.7692 - 103_categorical_accuracy: 0.9285 - 104_categorical_accuracy: 0.7769 - 113_categorical_accuracy: 0.9298 - 114_categorical_accuracy: 0.7744 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7973 - val_loss: 15.8496 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4622 - val_14_loss: 0.5596 - val_23_loss: 0.6440 - val_24_loss: 1.1093 - val_33_loss: 0.9300 - val_34_loss: 1.3160 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3885 - val_74_loss: 1.2512 - val_83_loss: 0.2980 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3737 - val_94_loss: 1.7185 - val_103_loss: 0.3749 - val_104_loss: 2.1272 - val_113_loss: 0.3351 - val_114_loss: 2.0316 - val_123_loss: 0.3594 - val_124_loss: 1.5703 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9135 - val_14_categorical_accuracy: 0.9560 - val_23_categorical_accuracy: 0.8841 - val_24_categorical_accuracy: 0.8625 - val_33_categorical_accuracy: 0.6412 - val_34_categorical_accuracy: 0.4631 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9414 - val_74_categorical_accuracy: 0.9294 - val_83_categorical_accuracy: 0.9388 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9264 - val_94_categorical_accuracy: 0.7474 - val_103_categorical_accuracy: 0.9284 - val_104_categorical_accuracy: 0.7596 - val_113_categorical_accuracy: 0.9305 - val_114_categorical_accuracy: 0.7599 - val_123_categorical_accuracy: 0.9285 - val_124_categorical_accuracy: 0.8087\n",
      "Epoch 125/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.6692 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2664 - 14_loss: 0.1272 - 23_loss: 0.3482 - 24_loss: 0.3982 - 33_loss: 0.7383 - 34_loss: 0.9377 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2043 - 74_loss: 0.1942 - 83_loss: 0.2066 - 84_loss: 0.0000e+00 - 93_loss: 0.2212 - 94_loss: 0.6132 - 103_loss: 0.2289 - 104_loss: 0.6004 - 113_loss: 0.2215 - 114_loss: 0.5859 - 123_loss: 0.2254 - 124_loss: 0.5517 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9169 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8870 - 24_categorical_accuracy: 0.8705 - 33_categorical_accuracy: 0.6722 - 34_categorical_accuracy: 0.5354 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9401 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7690 - 103_categorical_accuracy: 0.9288 - 104_categorical_accuracy: 0.7770 - 113_categorical_accuracy: 0.9297 - 114_categorical_accuracy: 0.7747 - 123_categorical_accuracy: 0.9287 - 124_categorical_accuracy: 0.7967 - val_loss: 15.7653 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4625 - val_14_loss: 0.5319 - val_23_loss: 0.6474 - val_24_loss: 1.1057 - val_33_loss: 0.9228 - val_34_loss: 1.2813 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3928 - val_74_loss: 1.2061 - val_83_loss: 0.3017 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3692 - val_94_loss: 1.7761 - val_103_loss: 0.3610 - val_104_loss: 2.1100 - val_113_loss: 0.3313 - val_114_loss: 2.0587 - val_123_loss: 0.3580 - val_124_loss: 1.5487 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9146 - val_14_categorical_accuracy: 0.9564 - val_23_categorical_accuracy: 0.8862 - val_24_categorical_accuracy: 0.8629 - val_33_categorical_accuracy: 0.6445 - val_34_categorical_accuracy: 0.4601 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9404 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9396 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9280 - val_94_categorical_accuracy: 0.7399 - val_103_categorical_accuracy: 0.9284 - val_104_categorical_accuracy: 0.7449 - val_113_categorical_accuracy: 0.9288 - val_114_categorical_accuracy: 0.7641 - val_123_categorical_accuracy: 0.9298 - val_124_categorical_accuracy: 0.8293\n",
      "Epoch 126/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.6633 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2661 - 14_loss: 0.1265 - 23_loss: 0.3472 - 24_loss: 0.3983 - 33_loss: 0.7376 - 34_loss: 0.9369 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2047 - 74_loss: 0.1933 - 83_loss: 0.2062 - 84_loss: 0.0000e+00 - 93_loss: 0.2215 - 94_loss: 0.6130 - 103_loss: 0.2284 - 104_loss: 0.6003 - 113_loss: 0.2211 - 114_loss: 0.5859 - 123_loss: 0.2249 - 124_loss: 0.5512 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9172 - 14_categorical_accuracy: 0.9595 - 23_categorical_accuracy: 0.8867 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6719 - 34_categorical_accuracy: 0.5363 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9399 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9368 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9310 - 94_categorical_accuracy: 0.7694 - 103_categorical_accuracy: 0.9288 - 104_categorical_accuracy: 0.7769 - 113_categorical_accuracy: 0.9298 - 114_categorical_accuracy: 0.7747 - 123_categorical_accuracy: 0.9288 - 124_categorical_accuracy: 0.7967 - val_loss: 16.5787 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4865 - val_14_loss: 0.6008 - val_23_loss: 0.6875 - val_24_loss: 1.2355 - val_33_loss: 0.9336 - val_34_loss: 1.3023 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3968 - val_74_loss: 1.2745 - val_83_loss: 0.3115 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3892 - val_94_loss: 1.9037 - val_103_loss: 0.3719 - val_104_loss: 2.1143 - val_113_loss: 0.3502 - val_114_loss: 2.1422 - val_123_loss: 0.3855 - val_124_loss: 1.6927 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9099 - val_14_categorical_accuracy: 0.9556 - val_23_categorical_accuracy: 0.8836 - val_24_categorical_accuracy: 0.8626 - val_33_categorical_accuracy: 0.6441 - val_34_categorical_accuracy: 0.4672 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9393 - val_74_categorical_accuracy: 0.9288 - val_83_categorical_accuracy: 0.9390 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9276 - val_94_categorical_accuracy: 0.7439 - val_103_categorical_accuracy: 0.9276 - val_104_categorical_accuracy: 0.7608 - val_113_categorical_accuracy: 0.9289 - val_114_categorical_accuracy: 0.7651 - val_123_categorical_accuracy: 0.9285 - val_124_categorical_accuracy: 0.8157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 6.6688 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2656 - 14_loss: 0.1268 - 23_loss: 0.3475 - 24_loss: 0.3980 - 33_loss: 0.7381 - 34_loss: 0.9374 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2058 - 74_loss: 0.1939 - 83_loss: 0.2065 - 84_loss: 0.0000e+00 - 93_loss: 0.2222 - 94_loss: 0.6126 - 103_loss: 0.2292 - 104_loss: 0.6004 - 113_loss: 0.2219 - 114_loss: 0.5863 - 123_loss: 0.2249 - 124_loss: 0.5517 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9168 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8872 - 24_categorical_accuracy: 0.8703 - 33_categorical_accuracy: 0.6723 - 34_categorical_accuracy: 0.5350 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9399 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9368 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9310 - 94_categorical_accuracy: 0.7690 - 103_categorical_accuracy: 0.9287 - 104_categorical_accuracy: 0.7769 - 113_categorical_accuracy: 0.9297 - 114_categorical_accuracy: 0.7746 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7968 - val_loss: 15.2674 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4541 - val_14_loss: 0.5765 - val_23_loss: 0.6447 - val_24_loss: 1.0518 - val_33_loss: 0.9235 - val_34_loss: 1.2887 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3591 - val_74_loss: 1.1322 - val_83_loss: 0.3013 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3567 - val_94_loss: 1.7138 - val_103_loss: 0.3633 - val_104_loss: 1.9430 - val_113_loss: 0.3328 - val_114_loss: 2.0285 - val_123_loss: 0.3530 - val_124_loss: 1.4444 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9128 - val_14_categorical_accuracy: 0.9543 - val_23_categorical_accuracy: 0.8863 - val_24_categorical_accuracy: 0.8631 - val_33_categorical_accuracy: 0.6404 - val_34_categorical_accuracy: 0.4605 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9411 - val_74_categorical_accuracy: 0.9265 - val_83_categorical_accuracy: 0.9404 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9274 - val_94_categorical_accuracy: 0.7382 - val_103_categorical_accuracy: 0.9270 - val_104_categorical_accuracy: 0.7673 - val_113_categorical_accuracy: 0.9302 - val_114_categorical_accuracy: 0.7625 - val_123_categorical_accuracy: 0.9299 - val_124_categorical_accuracy: 0.8245\n",
      "Epoch 128/1000\n",
      "697/697 [==============================] - 29s 42ms/step - loss: 6.6807 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2667 - 14_loss: 0.1274 - 23_loss: 0.3486 - 24_loss: 0.3991 - 33_loss: 0.7390 - 34_loss: 0.9386 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2056 - 74_loss: 0.1944 - 83_loss: 0.2065 - 84_loss: 0.0000e+00 - 93_loss: 0.2219 - 94_loss: 0.6137 - 103_loss: 0.2294 - 104_loss: 0.6021 - 113_loss: 0.2224 - 114_loss: 0.5872 - 123_loss: 0.2255 - 124_loss: 0.5526 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9596 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6721 - 34_categorical_accuracy: 0.5352 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9399 - 74_categorical_accuracy: 0.9430 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9314 - 94_categorical_accuracy: 0.7692 - 103_categorical_accuracy: 0.9287 - 104_categorical_accuracy: 0.7771 - 113_categorical_accuracy: 0.9298 - 114_categorical_accuracy: 0.7745 - 123_categorical_accuracy: 0.9290 - 124_categorical_accuracy: 0.7967 - val_loss: 16.5186 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4666 - val_14_loss: 0.5823 - val_23_loss: 0.6847 - val_24_loss: 1.1719 - val_33_loss: 0.9479 - val_34_loss: 1.3192 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.4072 - val_74_loss: 1.2978 - val_83_loss: 0.3237 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3746 - val_94_loss: 1.9316 - val_103_loss: 0.3712 - val_104_loss: 2.1494 - val_113_loss: 0.3454 - val_114_loss: 2.1316 - val_123_loss: 0.3722 - val_124_loss: 1.6412 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9151 - val_14_categorical_accuracy: 0.9558 - val_23_categorical_accuracy: 0.8838 - val_24_categorical_accuracy: 0.8611 - val_33_categorical_accuracy: 0.6298 - val_34_categorical_accuracy: 0.4615 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9421 - val_74_categorical_accuracy: 0.9286 - val_83_categorical_accuracy: 0.9395 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9279 - val_94_categorical_accuracy: 0.7445 - val_103_categorical_accuracy: 0.9270 - val_104_categorical_accuracy: 0.7687 - val_113_categorical_accuracy: 0.9297 - val_114_categorical_accuracy: 0.7630 - val_123_categorical_accuracy: 0.9299 - val_124_categorical_accuracy: 0.8243\n",
      "Epoch 129/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.6692 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2660 - 14_loss: 0.1267 - 23_loss: 0.3476 - 24_loss: 0.3981 - 33_loss: 0.7382 - 34_loss: 0.9374 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2048 - 74_loss: 0.1943 - 83_loss: 0.2062 - 84_loss: 0.0000e+00 - 93_loss: 0.2218 - 94_loss: 0.6128 - 103_loss: 0.2285 - 104_loss: 0.6003 - 113_loss: 0.2221 - 114_loss: 0.5864 - 123_loss: 0.2256 - 124_loss: 0.5523 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9592 - 23_categorical_accuracy: 0.8867 - 24_categorical_accuracy: 0.8705 - 33_categorical_accuracy: 0.6727 - 34_categorical_accuracy: 0.5354 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9399 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9313 - 94_categorical_accuracy: 0.7691 - 103_categorical_accuracy: 0.9286 - 104_categorical_accuracy: 0.7770 - 113_categorical_accuracy: 0.9299 - 114_categorical_accuracy: 0.7745 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7966 - val_loss: 16.1468 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4696 - val_14_loss: 0.5363 - val_23_loss: 0.6938 - val_24_loss: 1.1372 - val_33_loss: 0.9265 - val_34_loss: 1.3415 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3977 - val_74_loss: 1.2914 - val_83_loss: 0.3139 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3835 - val_94_loss: 1.8643 - val_103_loss: 0.3756 - val_104_loss: 2.1696 - val_113_loss: 0.3473 - val_114_loss: 2.0201 - val_123_loss: 0.3616 - val_124_loss: 1.5168 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9111 - val_14_categorical_accuracy: 0.9565 - val_23_categorical_accuracy: 0.8851 - val_24_categorical_accuracy: 0.8622 - val_33_categorical_accuracy: 0.6403 - val_34_categorical_accuracy: 0.4649 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9420 - val_74_categorical_accuracy: 0.9288 - val_83_categorical_accuracy: 0.9383 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9272 - val_94_categorical_accuracy: 0.7448 - val_103_categorical_accuracy: 0.9290 - val_104_categorical_accuracy: 0.7672 - val_113_categorical_accuracy: 0.9279 - val_114_categorical_accuracy: 0.7631 - val_123_categorical_accuracy: 0.9306 - val_124_categorical_accuracy: 0.8092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 6.6646 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2652 - 14_loss: 0.1270 - 23_loss: 0.3465 - 24_loss: 0.3972 - 33_loss: 0.7376 - 34_loss: 0.9378 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2045 - 74_loss: 0.1938 - 83_loss: 0.2067 - 84_loss: 0.0000e+00 - 93_loss: 0.2212 - 94_loss: 0.6130 - 103_loss: 0.2287 - 104_loss: 0.6006 - 113_loss: 0.2215 - 114_loss: 0.5867 - 123_loss: 0.2247 - 124_loss: 0.5519 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9170 - 14_categorical_accuracy: 0.9593 - 23_categorical_accuracy: 0.8868 - 24_categorical_accuracy: 0.8709 - 33_categorical_accuracy: 0.6723 - 34_categorical_accuracy: 0.5365 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9399 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9370 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9312 - 94_categorical_accuracy: 0.7696 - 103_categorical_accuracy: 0.9288 - 104_categorical_accuracy: 0.7767 - 113_categorical_accuracy: 0.9297 - 114_categorical_accuracy: 0.7747 - 123_categorical_accuracy: 0.9286 - 124_categorical_accuracy: 0.7967 - val_loss: 15.5652 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4627 - val_14_loss: 0.5472 - val_23_loss: 0.6678 - val_24_loss: 1.1394 - val_33_loss: 0.9235 - val_34_loss: 1.3082 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3665 - val_74_loss: 1.2141 - val_83_loss: 0.3107 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3642 - val_94_loss: 1.7425 - val_103_loss: 0.3599 - val_104_loss: 2.0279 - val_113_loss: 0.3358 - val_114_loss: 1.9308 - val_123_loss: 0.3600 - val_124_loss: 1.5041 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9149 - val_14_categorical_accuracy: 0.9552 - val_23_categorical_accuracy: 0.8856 - val_24_categorical_accuracy: 0.8617 - val_33_categorical_accuracy: 0.6417 - val_34_categorical_accuracy: 0.4596 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9423 - val_74_categorical_accuracy: 0.9284 - val_83_categorical_accuracy: 0.9395 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9280 - val_94_categorical_accuracy: 0.7480 - val_103_categorical_accuracy: 0.9286 - val_104_categorical_accuracy: 0.7678 - val_113_categorical_accuracy: 0.9275 - val_114_categorical_accuracy: 0.7449 - val_123_categorical_accuracy: 0.9303 - val_124_categorical_accuracy: 0.8309\n",
      "Epoch 131/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.6794 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2668 - 14_loss: 0.1270 - 23_loss: 0.3479 - 24_loss: 0.3987 - 33_loss: 0.7389 - 34_loss: 0.9379 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2054 - 74_loss: 0.1946 - 83_loss: 0.2064 - 84_loss: 0.0000e+00 - 93_loss: 0.2223 - 94_loss: 0.6142 - 103_loss: 0.2292 - 104_loss: 0.6018 - 113_loss: 0.2230 - 114_loss: 0.5871 - 123_loss: 0.2258 - 124_loss: 0.5524 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9594 - 23_categorical_accuracy: 0.8870 - 24_categorical_accuracy: 0.8708 - 33_categorical_accuracy: 0.6723 - 34_categorical_accuracy: 0.5355 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9399 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9368 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9311 - 94_categorical_accuracy: 0.7689 - 103_categorical_accuracy: 0.9287 - 104_categorical_accuracy: 0.7765 - 113_categorical_accuracy: 0.9294 - 114_categorical_accuracy: 0.7748 - 123_categorical_accuracy: 0.9288 - 124_categorical_accuracy: 0.7965 - val_loss: 16.4150 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4647 - val_14_loss: 0.6007 - val_23_loss: 0.6763 - val_24_loss: 1.1418 - val_33_loss: 0.9338 - val_34_loss: 1.3307 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3871 - val_74_loss: 1.3572 - val_83_loss: 0.3222 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3761 - val_94_loss: 1.8041 - val_103_loss: 0.3828 - val_104_loss: 2.2648 - val_113_loss: 0.3444 - val_114_loss: 2.0020 - val_123_loss: 0.3796 - val_124_loss: 1.6465 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9123 - val_14_categorical_accuracy: 0.9560 - val_23_categorical_accuracy: 0.8840 - val_24_categorical_accuracy: 0.8620 - val_33_categorical_accuracy: 0.6393 - val_34_categorical_accuracy: 0.4564 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9410 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9395 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9274 - val_94_categorical_accuracy: 0.7456 - val_103_categorical_accuracy: 0.9264 - val_104_categorical_accuracy: 0.7461 - val_113_categorical_accuracy: 0.9286 - val_114_categorical_accuracy: 0.7645 - val_123_categorical_accuracy: 0.9304 - val_124_categorical_accuracy: 0.8011\n",
      "Epoch 132/1000\n",
      "697/697 [==============================] - 29s 41ms/step - loss: 6.6672 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2658 - 14_loss: 0.1270 - 23_loss: 0.3468 - 24_loss: 0.3978 - 33_loss: 0.7381 - 34_loss: 0.9376 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2048 - 74_loss: 0.1937 - 83_loss: 0.2060 - 84_loss: 0.0000e+00 - 93_loss: 0.2216 - 94_loss: 0.6139 - 103_loss: 0.2282 - 104_loss: 0.6008 - 113_loss: 0.2215 - 114_loss: 0.5865 - 123_loss: 0.2249 - 124_loss: 0.5521 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9597 - 23_categorical_accuracy: 0.8869 - 24_categorical_accuracy: 0.8706 - 33_categorical_accuracy: 0.6722 - 34_categorical_accuracy: 0.5356 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9400 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9368 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9312 - 94_categorical_accuracy: 0.7693 - 103_categorical_accuracy: 0.9288 - 104_categorical_accuracy: 0.7771 - 113_categorical_accuracy: 0.9299 - 114_categorical_accuracy: 0.7747 - 123_categorical_accuracy: 0.9287 - 124_categorical_accuracy: 0.7965 - val_loss: 15.8674 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4540 - val_14_loss: 0.5587 - val_23_loss: 0.6681 - val_24_loss: 1.1109 - val_33_loss: 0.9272 - val_34_loss: 1.3087 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3688 - val_74_loss: 1.2711 - val_83_loss: 0.3105 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3762 - val_94_loss: 1.7969 - val_103_loss: 0.3751 - val_104_loss: 2.0389 - val_113_loss: 0.3535 - val_114_loss: 1.9694 - val_123_loss: 0.3656 - val_124_loss: 1.6140 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9142 - val_14_categorical_accuracy: 0.9548 - val_23_categorical_accuracy: 0.8855 - val_24_categorical_accuracy: 0.8607 - val_33_categorical_accuracy: 0.6380 - val_34_categorical_accuracy: 0.4584 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9431 - val_74_categorical_accuracy: 0.9291 - val_83_categorical_accuracy: 0.9390 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9277 - val_94_categorical_accuracy: 0.7489 - val_103_categorical_accuracy: 0.9282 - val_104_categorical_accuracy: 0.7721 - val_113_categorical_accuracy: 0.9290 - val_114_categorical_accuracy: 0.7685 - val_123_categorical_accuracy: 0.9261 - val_124_categorical_accuracy: 0.8197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/1000\n",
      "697/697 [==============================] - 28s 40ms/step - loss: 6.6669 - 03_loss: 0.0000e+00 - 04_loss: 0.0000e+00 - 13_loss: 0.2651 - 14_loss: 0.1270 - 23_loss: 0.3474 - 24_loss: 0.3980 - 33_loss: 0.7371 - 34_loss: 0.9376 - 43_loss: 0.0000e+00 - 44_loss: 0.0000e+00 - 53_loss: 0.0000e+00 - 54_loss: 0.0000e+00 - 63_loss: 0.0000e+00 - 64_loss: 0.0000e+00 - 73_loss: 0.2048 - 74_loss: 0.1938 - 83_loss: 0.2058 - 84_loss: 0.0000e+00 - 93_loss: 0.2216 - 94_loss: 0.6136 - 103_loss: 0.2280 - 104_loss: 0.6010 - 113_loss: 0.2214 - 114_loss: 0.5867 - 123_loss: 0.2253 - 124_loss: 0.5527 - 03_categorical_accuracy: 1.0000 - 04_categorical_accuracy: 1.0000 - 13_categorical_accuracy: 0.9171 - 14_categorical_accuracy: 0.9596 - 23_categorical_accuracy: 0.8868 - 24_categorical_accuracy: 0.8705 - 33_categorical_accuracy: 0.6720 - 34_categorical_accuracy: 0.5366 - 43_categorical_accuracy: 1.0000 - 44_categorical_accuracy: 1.0000 - 53_categorical_accuracy: 1.0000 - 54_categorical_accuracy: 1.0000 - 63_categorical_accuracy: 1.0000 - 64_categorical_accuracy: 1.0000 - 73_categorical_accuracy: 0.9398 - 74_categorical_accuracy: 0.9429 - 83_categorical_accuracy: 0.9369 - 84_categorical_accuracy: 1.0000 - 93_categorical_accuracy: 0.9315 - 94_categorical_accuracy: 0.7690 - 103_categorical_accuracy: 0.9287 - 104_categorical_accuracy: 0.7769 - 113_categorical_accuracy: 0.9297 - 114_categorical_accuracy: 0.7745 - 123_categorical_accuracy: 0.9289 - 124_categorical_accuracy: 0.7963 - val_loss: 16.2533 - val_03_loss: 0.0000e+00 - val_04_loss: 0.0000e+00 - val_13_loss: 0.4969 - val_14_loss: 0.5638 - val_23_loss: 0.6882 - val_24_loss: 1.1290 - val_33_loss: 0.9428 - val_34_loss: 1.3044 - val_43_loss: 0.0000e+00 - val_44_loss: 0.0000e+00 - val_53_loss: 0.0000e+00 - val_54_loss: 0.0000e+00 - val_63_loss: 0.0000e+00 - val_64_loss: 0.0000e+00 - val_73_loss: 0.3878 - val_74_loss: 1.2630 - val_83_loss: 0.3133 - val_84_loss: 0.0000e+00 - val_93_loss: 0.3662 - val_94_loss: 1.8001 - val_103_loss: 0.3751 - val_104_loss: 2.1807 - val_113_loss: 0.3329 - val_114_loss: 2.1696 - val_123_loss: 0.3908 - val_124_loss: 1.5488 - val_03_categorical_accuracy: 1.0000 - val_04_categorical_accuracy: 1.0000 - val_13_categorical_accuracy: 0.9145 - val_14_categorical_accuracy: 0.9561 - val_23_categorical_accuracy: 0.8856 - val_24_categorical_accuracy: 0.8621 - val_33_categorical_accuracy: 0.6293 - val_34_categorical_accuracy: 0.4601 - val_43_categorical_accuracy: 1.0000 - val_44_categorical_accuracy: 1.0000 - val_53_categorical_accuracy: 1.0000 - val_54_categorical_accuracy: 1.0000 - val_63_categorical_accuracy: 1.0000 - val_64_categorical_accuracy: 1.0000 - val_73_categorical_accuracy: 0.9420 - val_74_categorical_accuracy: 0.9289 - val_83_categorical_accuracy: 0.9390 - val_84_categorical_accuracy: 1.0000 - val_93_categorical_accuracy: 0.9254 - val_94_categorical_accuracy: 0.7327 - val_103_categorical_accuracy: 0.9284 - val_104_categorical_accuracy: 0.7503 - val_113_categorical_accuracy: 0.9296 - val_114_categorical_accuracy: 0.7651 - val_123_categorical_accuracy: 0.9309 - val_124_categorical_accuracy: 0.8147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7f082b4fa0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM, Input, GRU\n",
    "from keras.layers import Bidirectional\n",
    "from keras.models import Model\n",
    "\n",
    "NUM_NODES = 13\n",
    "NODE_CLASSES = [3, 4]\n",
    "\n",
    "data_map = {}\n",
    "losses = []\n",
    "index = 0\n",
    "for i in range(NUM_NODES):\n",
    "    for n in NODE_CLASSES:\n",
    "        data_map[str(i)+str(n)] = next_states[:,index:index+n]\n",
    "        losses.append(tf.keras.losses.CategoricalCrossentropy())\n",
    "        index += n\n",
    "        \n",
    "input_ = Input(shape=(10,STATE_LEN+ACTION_LEN,))\n",
    "#x = Bidirectional(LSTM(64, activation='relu', return_sequences=True))(input_)\n",
    "#x = Bidirectional(GRU(64))(input_)\n",
    "x = Bidirectional(LSTM(256))(input_)\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "\n",
    "outs = []\n",
    "for i in range(NUM_NODES):\n",
    "    for n in NODE_CLASSES:\n",
    "        x_ = Dense(256, activation='relu')(x)\n",
    "        outs.append(Dense(n, activation='softmax', name=str(i)+str(n))(x_))\n",
    "\n",
    "model = Model(input_, outs)\n",
    "model.compile(optimizer='adam', loss=losses, metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=7)\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_value(model.optimizer.learning_rate, 0.005)\n",
    "\n",
    "#model.fit(train_dataset,epochs=250, verbose=1, callbacks=[callback])\n",
    "\n",
    "model.fit(states_actions_seq_10, data_map, epochs=1000, validation_split=0.1, verbose=1, callbacks=[callback], batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('NextStateModel_MulitLabel_rnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mfit(states_actions_seq_10, data_map, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[callback], batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(states_actions_seq_10, data_map, epochs=100, validation_split=0.1, verbose=1, callbacks=[callback], batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "697/697 [==============================] - 32s 28ms/step - loss: 4.3925 - 03_loss: 0.6321 - 04_loss: 0.1746 - 13_loss: 0.7745 - 14_loss: 0.6850 - 23_loss: 0.0075 - 24_loss: 0.0088 - 33_loss: 0.0069 - 34_loss: 0.0112 - 43_loss: 0.2902 - 44_loss: 1.1840 - 53_loss: 0.2869 - 54_loss: 0.3309 - 03_categorical_accuracy: 0.6734 - 04_categorical_accuracy: 0.9531 - 13_categorical_accuracy: 0.6536 - 14_categorical_accuracy: 0.6531 - 23_categorical_accuracy: 0.9997 - 24_categorical_accuracy: 0.9998 - 33_categorical_accuracy: 0.9996 - 34_categorical_accuracy: 0.9986 - 43_categorical_accuracy: 0.9182 - 44_categorical_accuracy: 0.4848 - 53_categorical_accuracy: 0.9147 - 54_categorical_accuracy: 0.9054 - val_loss: 4.2576 - val_03_loss: 0.6201 - val_04_loss: 0.1571 - val_13_loss: 0.7662 - val_14_loss: 0.6684 - val_23_loss: 1.2516e-07 - val_24_loss: 3.7638e-07 - val_33_loss: 1.2050e-07 - val_34_loss: 1.7278e-07 - val_43_loss: 0.2729 - val_44_loss: 1.1825 - val_53_loss: 0.2771 - val_54_loss: 0.3134 - val_03_categorical_accuracy: 0.6774 - val_04_categorical_accuracy: 0.9573 - val_13_categorical_accuracy: 0.6521 - val_14_categorical_accuracy: 0.6572 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9215 - val_44_categorical_accuracy: 0.4834 - val_53_categorical_accuracy: 0.9152 - val_54_categorical_accuracy: 0.9095\n",
      "Epoch 2/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 4.2045 - 03_loss: 0.6190 - 04_loss: 0.1499 - 13_loss: 0.7642 - 14_loss: 0.6676 - 23_loss: 1.5467e-07 - 24_loss: 4.1810e-07 - 33_loss: 1.5957e-07 - 34_loss: 1.9799e-07 - 43_loss: 0.2759 - 44_loss: 1.1549 - 53_loss: 0.2723 - 54_loss: 0.3006 - 03_categorical_accuracy: 0.6755 - 04_categorical_accuracy: 0.9593 - 13_categorical_accuracy: 0.6541 - 14_categorical_accuracy: 0.6609 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9195 - 44_categorical_accuracy: 0.4971 - 53_categorical_accuracy: 0.9163 - 54_categorical_accuracy: 0.9100 - val_loss: 4.2326 - val_03_loss: 0.6157 - val_04_loss: 0.1538 - val_13_loss: 0.7623 - val_14_loss: 0.6614 - val_23_loss: 1.2778e-07 - val_24_loss: 2.2050e-07 - val_33_loss: 1.2906e-07 - val_34_loss: 1.3736e-07 - val_43_loss: 0.2685 - val_44_loss: 1.1861 - val_53_loss: 0.2739 - val_54_loss: 0.3108 - val_03_categorical_accuracy: 0.6783 - val_04_categorical_accuracy: 0.9592 - val_13_categorical_accuracy: 0.6529 - val_14_categorical_accuracy: 0.6607 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9218 - val_44_categorical_accuracy: 0.4895 - val_53_categorical_accuracy: 0.9157 - val_54_categorical_accuracy: 0.9090\n",
      "Epoch 3/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 4.1603 - 03_loss: 0.6170 - 04_loss: 0.1459 - 13_loss: 0.7624 - 14_loss: 0.6636 - 23_loss: 5.7596e-08 - 24_loss: 1.0422e-07 - 33_loss: 5.7982e-08 - 34_loss: 6.7379e-08 - 43_loss: 0.2734 - 44_loss: 1.1382 - 53_loss: 0.2705 - 54_loss: 0.2894 - 03_categorical_accuracy: 0.6755 - 04_categorical_accuracy: 0.9599 - 13_categorical_accuracy: 0.6546 - 14_categorical_accuracy: 0.6624 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9197 - 44_categorical_accuracy: 0.5029 - 53_categorical_accuracy: 0.9165 - 54_categorical_accuracy: 0.9121 - val_loss: 4.2398 - val_03_loss: 0.6152 - val_04_loss: 0.1531 - val_13_loss: 0.7616 - val_14_loss: 0.6606 - val_23_loss: 5.2326e-08 - val_24_loss: 8.7270e-08 - val_33_loss: 5.5739e-08 - val_34_loss: 5.7889e-08 - val_43_loss: 0.2674 - val_44_loss: 1.1905 - val_53_loss: 0.2729 - val_54_loss: 0.3186 - val_03_categorical_accuracy: 0.6792 - val_04_categorical_accuracy: 0.9590 - val_13_categorical_accuracy: 0.6523 - val_14_categorical_accuracy: 0.6604 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9211 - val_44_categorical_accuracy: 0.4944 - val_53_categorical_accuracy: 0.9157 - val_54_categorical_accuracy: 0.9062\n",
      "Epoch 4/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 4.1128 - 03_loss: 0.6148 - 04_loss: 0.1422 - 13_loss: 0.7605 - 14_loss: 0.6595 - 23_loss: 2.6288e-08 - 24_loss: 4.0010e-08 - 33_loss: 2.6378e-08 - 34_loss: 2.9521e-08 - 43_loss: 0.2718 - 44_loss: 1.1184 - 53_loss: 0.2696 - 54_loss: 0.2759 - 03_categorical_accuracy: 0.6761 - 04_categorical_accuracy: 0.9612 - 13_categorical_accuracy: 0.6551 - 14_categorical_accuracy: 0.6645 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9197 - 44_categorical_accuracy: 0.5112 - 53_categorical_accuracy: 0.9166 - 54_categorical_accuracy: 0.9146 - val_loss: 4.2556 - val_03_loss: 0.6129 - val_04_loss: 0.1488 - val_13_loss: 0.7596 - val_14_loss: 0.6593 - val_23_loss: 1.4281e-08 - val_24_loss: 1.6208e-08 - val_33_loss: 1.4727e-08 - val_34_loss: 1.5274e-08 - val_43_loss: 0.2656 - val_44_loss: 1.2075 - val_53_loss: 0.2720 - val_54_loss: 0.3299 - val_03_categorical_accuracy: 0.6758 - val_04_categorical_accuracy: 0.9611 - val_13_categorical_accuracy: 0.6530 - val_14_categorical_accuracy: 0.6618 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9216 - val_44_categorical_accuracy: 0.4926 - val_53_categorical_accuracy: 0.9153 - val_54_categorical_accuracy: 0.9035\n",
      "Epoch 5/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 4.0578 - 03_loss: 0.6123 - 04_loss: 0.1375 - 13_loss: 0.7586 - 14_loss: 0.6550 - 23_loss: 1.5565e-08 - 24_loss: 2.0248e-08 - 33_loss: 1.5435e-08 - 34_loss: 1.6886e-08 - 43_loss: 0.2704 - 44_loss: 1.0946 - 53_loss: 0.2686 - 54_loss: 0.2608 - 03_categorical_accuracy: 0.6770 - 04_categorical_accuracy: 0.9627 - 13_categorical_accuracy: 0.6557 - 14_categorical_accuracy: 0.6665 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9200 - 44_categorical_accuracy: 0.5222 - 53_categorical_accuracy: 0.9175 - 54_categorical_accuracy: 0.9183 - val_loss: 4.2670 - val_03_loss: 0.6126 - val_04_loss: 0.1505 - val_13_loss: 0.7611 - val_14_loss: 0.6599 - val_23_loss: 1.3860e-08 - val_24_loss: 1.7388e-08 - val_33_loss: 1.3860e-08 - val_34_loss: 1.4263e-08 - val_43_loss: 0.2669 - val_44_loss: 1.2116 - val_53_loss: 0.2727 - val_54_loss: 0.3317 - val_03_categorical_accuracy: 0.6772 - val_04_categorical_accuracy: 0.9607 - val_13_categorical_accuracy: 0.6536 - val_14_categorical_accuracy: 0.6630 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9221 - val_44_categorical_accuracy: 0.4963 - val_53_categorical_accuracy: 0.9160 - val_54_categorical_accuracy: 0.9042\n",
      "Epoch 6/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 3.9966 - 03_loss: 0.6096 - 04_loss: 0.1324 - 13_loss: 0.7571 - 14_loss: 0.6491 - 23_loss: 9.2765e-09 - 24_loss: 1.2392e-08 - 33_loss: 9.6839e-09 - 34_loss: 1.0112e-08 - 43_loss: 0.2687 - 44_loss: 1.0679 - 53_loss: 0.2672 - 54_loss: 0.2448 - 03_categorical_accuracy: 0.6780 - 04_categorical_accuracy: 0.9638 - 13_categorical_accuracy: 0.6564 - 14_categorical_accuracy: 0.6687 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9204 - 44_categorical_accuracy: 0.5333 - 53_categorical_accuracy: 0.9175 - 54_categorical_accuracy: 0.9223 - val_loss: 4.3420 - val_03_loss: 0.6120 - val_04_loss: 0.1535 - val_13_loss: 0.7600 - val_14_loss: 0.6638 - val_23_loss: 6.6227e-11 - val_24_loss: 1.3522e-08 - val_33_loss: 7.2248e-11 - val_34_loss: 1.5052e-10 - val_43_loss: 0.2658 - val_44_loss: 1.2514 - val_53_loss: 0.2728 - val_54_loss: 0.3627 - val_03_categorical_accuracy: 0.6788 - val_04_categorical_accuracy: 0.9607 - val_13_categorical_accuracy: 0.6538 - val_14_categorical_accuracy: 0.6612 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9228 - val_44_categorical_accuracy: 0.4858 - val_53_categorical_accuracy: 0.9163 - val_54_categorical_accuracy: 0.8980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 3.9325 - 03_loss: 0.6065 - 04_loss: 0.1270 - 13_loss: 0.7547 - 14_loss: 0.6422 - 23_loss: 5.6581e-09 - 24_loss: 7.4636e-09 - 33_loss: 5.7243e-09 - 34_loss: 6.0782e-09 - 43_loss: 0.2671 - 44_loss: 1.0405 - 53_loss: 0.2657 - 54_loss: 0.2289 - 03_categorical_accuracy: 0.6796 - 04_categorical_accuracy: 0.9648 - 13_categorical_accuracy: 0.6575 - 14_categorical_accuracy: 0.6712 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9209 - 44_categorical_accuracy: 0.5459 - 53_categorical_accuracy: 0.9180 - 54_categorical_accuracy: 0.9264 - val_loss: 4.3855 - val_03_loss: 0.6122 - val_04_loss: 0.1547 - val_13_loss: 0.7617 - val_14_loss: 0.6675 - val_23_loss: 1.3264e-08 - val_24_loss: 1.3516e-08 - val_33_loss: 1.3270e-08 - val_34_loss: 1.3288e-08 - val_43_loss: 0.2665 - val_44_loss: 1.2742 - val_53_loss: 0.2731 - val_54_loss: 0.3757 - val_03_categorical_accuracy: 0.6751 - val_04_categorical_accuracy: 0.9615 - val_13_categorical_accuracy: 0.6545 - val_14_categorical_accuracy: 0.6612 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9225 - val_44_categorical_accuracy: 0.4901 - val_53_categorical_accuracy: 0.9165 - val_54_categorical_accuracy: 0.8982\n",
      "Epoch 8/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 3.8650 - 03_loss: 0.6030 - 04_loss: 0.1215 - 13_loss: 0.7519 - 14_loss: 0.6350 - 23_loss: 4.0927e-09 - 24_loss: 6.6448e-09 - 33_loss: 4.3489e-09 - 34_loss: 4.6359e-09 - 43_loss: 0.2645 - 44_loss: 1.0111 - 53_loss: 0.2636 - 54_loss: 0.2144 - 03_categorical_accuracy: 0.6813 - 04_categorical_accuracy: 0.9659 - 13_categorical_accuracy: 0.6583 - 14_categorical_accuracy: 0.6737 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9213 - 44_categorical_accuracy: 0.5583 - 53_categorical_accuracy: 0.9184 - 54_categorical_accuracy: 0.9303 - val_loss: 4.4653 - val_03_loss: 0.6141 - val_04_loss: 0.1618 - val_13_loss: 0.7606 - val_14_loss: 0.6743 - val_23_loss: 0.0000e+00 - val_24_loss: 1.8062e-11 - val_33_loss: 0.0000e+00 - val_34_loss: 6.0207e-12 - val_43_loss: 0.2679 - val_44_loss: 1.3153 - val_53_loss: 0.2736 - val_54_loss: 0.3976 - val_03_categorical_accuracy: 0.6751 - val_04_categorical_accuracy: 0.9613 - val_13_categorical_accuracy: 0.6561 - val_14_categorical_accuracy: 0.6575 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9224 - val_44_categorical_accuracy: 0.4827 - val_53_categorical_accuracy: 0.9157 - val_54_categorical_accuracy: 0.8958\n",
      "Epoch 9/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 3.7984 - 03_loss: 0.5984 - 04_loss: 0.1162 - 13_loss: 0.7490 - 14_loss: 0.6282 - 23_loss: 3.1709e-09 - 24_loss: 4.8634e-09 - 33_loss: 3.0511e-09 - 34_loss: 3.6385e-09 - 43_loss: 0.2618 - 44_loss: 0.9827 - 53_loss: 0.2610 - 54_loss: 0.2012 - 03_categorical_accuracy: 0.6841 - 04_categorical_accuracy: 0.9668 - 13_categorical_accuracy: 0.6593 - 14_categorical_accuracy: 0.6759 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9216 - 44_categorical_accuracy: 0.5698 - 53_categorical_accuracy: 0.9197 - 54_categorical_accuracy: 0.9333 - val_loss: 4.5406 - val_03_loss: 0.6170 - val_04_loss: 0.1682 - val_13_loss: 0.7630 - val_14_loss: 0.6784 - val_23_loss: 1.3245e-08 - val_24_loss: 1.3258e-08 - val_33_loss: 1.3251e-08 - val_34_loss: 1.3251e-08 - val_43_loss: 0.2691 - val_44_loss: 1.3545 - val_53_loss: 0.2762 - val_54_loss: 0.4143 - val_03_categorical_accuracy: 0.6739 - val_04_categorical_accuracy: 0.9591 - val_13_categorical_accuracy: 0.6556 - val_14_categorical_accuracy: 0.6591 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9224 - val_44_categorical_accuracy: 0.4900 - val_53_categorical_accuracy: 0.9166 - val_54_categorical_accuracy: 0.8940\n",
      "Epoch 10/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 3.7324 - 03_loss: 0.5936 - 04_loss: 0.1114 - 13_loss: 0.7456 - 14_loss: 0.6209 - 23_loss: 3.1722e-09 - 24_loss: 4.7610e-09 - 33_loss: 3.1047e-09 - 34_loss: 3.7709e-09 - 43_loss: 0.2581 - 44_loss: 0.9560 - 53_loss: 0.2582 - 54_loss: 0.1887 - 03_categorical_accuracy: 0.6877 - 04_categorical_accuracy: 0.9677 - 13_categorical_accuracy: 0.6597 - 14_categorical_accuracy: 0.6796 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9222 - 44_categorical_accuracy: 0.5819 - 53_categorical_accuracy: 0.9206 - 54_categorical_accuracy: 0.9363 - val_loss: 4.6509 - val_03_loss: 0.6182 - val_04_loss: 0.1716 - val_13_loss: 0.7656 - val_14_loss: 0.6838 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.2727 - val_44_loss: 1.4146 - val_53_loss: 0.2797 - val_54_loss: 0.4447 - val_03_categorical_accuracy: 0.6720 - val_04_categorical_accuracy: 0.9611 - val_13_categorical_accuracy: 0.6549 - val_14_categorical_accuracy: 0.6577 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9219 - val_44_categorical_accuracy: 0.4839 - val_53_categorical_accuracy: 0.9161 - val_54_categorical_accuracy: 0.8932\n",
      "Epoch 11/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 3.6691 - 03_loss: 0.5883 - 04_loss: 0.1066 - 13_loss: 0.7415 - 14_loss: 0.6140 - 23_loss: 2.0704e-09 - 24_loss: 3.2090e-09 - 33_loss: 1.6316e-09 - 34_loss: 2.6210e-09 - 43_loss: 0.2548 - 44_loss: 0.9317 - 53_loss: 0.2549 - 54_loss: 0.1773 - 03_categorical_accuracy: 0.6908 - 04_categorical_accuracy: 0.9686 - 13_categorical_accuracy: 0.6607 - 14_categorical_accuracy: 0.6822 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9230 - 44_categorical_accuracy: 0.5905 - 53_categorical_accuracy: 0.9212 - 54_categorical_accuracy: 0.9395 - val_loss: 4.7230 - val_03_loss: 0.6231 - val_04_loss: 0.1714 - val_13_loss: 0.7676 - val_14_loss: 0.6964 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.2737 - val_44_loss: 1.4522 - val_53_loss: 0.2823 - val_54_loss: 0.4562 - val_03_categorical_accuracy: 0.6702 - val_04_categorical_accuracy: 0.9601 - val_13_categorical_accuracy: 0.6551 - val_14_categorical_accuracy: 0.6549 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9217 - val_44_categorical_accuracy: 0.4875 - val_53_categorical_accuracy: 0.9157 - val_54_categorical_accuracy: 0.8952\n",
      "Epoch 12/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 3.6083 - 03_loss: 0.5826 - 04_loss: 0.1024 - 13_loss: 0.7368 - 14_loss: 0.6073 - 23_loss: 1.4985e-09 - 24_loss: 3.1241e-09 - 33_loss: 1.7513e-09 - 34_loss: 2.3287e-09 - 43_loss: 0.2505 - 44_loss: 0.9089 - 53_loss: 0.2514 - 54_loss: 0.1684 - 03_categorical_accuracy: 0.6943 - 04_categorical_accuracy: 0.9696 - 13_categorical_accuracy: 0.6615 - 14_categorical_accuracy: 0.6849 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9235 - 44_categorical_accuracy: 0.6011 - 53_categorical_accuracy: 0.9218 - 54_categorical_accuracy: 0.9417 - val_loss: 4.8346 - val_03_loss: 0.6295 - val_04_loss: 0.1797 - val_13_loss: 0.7726 - val_14_loss: 0.7050 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.2779 - val_44_loss: 1.4989 - val_53_loss: 0.2858 - val_54_loss: 0.4852 - val_03_categorical_accuracy: 0.6697 - val_04_categorical_accuracy: 0.9583 - val_13_categorical_accuracy: 0.6536 - val_14_categorical_accuracy: 0.6503 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9220 - val_44_categorical_accuracy: 0.4836 - val_53_categorical_accuracy: 0.9155 - val_54_categorical_accuracy: 0.8886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 3.5486 - 03_loss: 0.5763 - 04_loss: 0.0987 - 13_loss: 0.7320 - 14_loss: 0.6009 - 23_loss: 6.1411e-10 - 24_loss: 8.2751e-10 - 33_loss: 7.1847e-10 - 34_loss: 7.5860e-10 - 43_loss: 0.2463 - 44_loss: 0.8873 - 53_loss: 0.2474 - 54_loss: 0.1598 - 03_categorical_accuracy: 0.6986 - 04_categorical_accuracy: 0.9699 - 13_categorical_accuracy: 0.6626 - 14_categorical_accuracy: 0.6879 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9243 - 44_categorical_accuracy: 0.6109 - 53_categorical_accuracy: 0.9225 - 54_categorical_accuracy: 0.9441 - val_loss: 4.9405 - val_03_loss: 0.6374 - val_04_loss: 0.1833 - val_13_loss: 0.7783 - val_14_loss: 0.7121 - val_23_loss: 0.0000e+00 - val_24_loss: 1.3245e-08 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.2841 - val_44_loss: 1.5606 - val_53_loss: 0.2905 - val_54_loss: 0.4941 - val_03_categorical_accuracy: 0.6673 - val_04_categorical_accuracy: 0.9585 - val_13_categorical_accuracy: 0.6536 - val_14_categorical_accuracy: 0.6540 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9195 - val_44_categorical_accuracy: 0.4828 - val_53_categorical_accuracy: 0.9152 - val_54_categorical_accuracy: 0.8948\n",
      "Epoch 14/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 3.4921 - 03_loss: 0.5697 - 04_loss: 0.0950 - 13_loss: 0.7269 - 14_loss: 0.5947 - 23_loss: 6.2816e-10 - 24_loss: 1.2837e-09 - 33_loss: 7.1378e-10 - 34_loss: 9.2384e-10 - 43_loss: 0.2416 - 44_loss: 0.8684 - 53_loss: 0.2434 - 54_loss: 0.1524 - 03_categorical_accuracy: 0.7022 - 04_categorical_accuracy: 0.9707 - 13_categorical_accuracy: 0.6635 - 14_categorical_accuracy: 0.6909 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9250 - 44_categorical_accuracy: 0.6187 - 53_categorical_accuracy: 0.9232 - 54_categorical_accuracy: 0.9452 - val_loss: 5.0209 - val_03_loss: 0.6439 - val_04_loss: 0.1901 - val_13_loss: 0.7812 - val_14_loss: 0.7271 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.2878 - val_44_loss: 1.5796 - val_53_loss: 0.2952 - val_54_loss: 0.5160 - val_03_categorical_accuracy: 0.6654 - val_04_categorical_accuracy: 0.9596 - val_13_categorical_accuracy: 0.6531 - val_14_categorical_accuracy: 0.6518 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9183 - val_44_categorical_accuracy: 0.4786 - val_53_categorical_accuracy: 0.9151 - val_54_categorical_accuracy: 0.8898\n",
      "Epoch 15/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 3.4344 - 03_loss: 0.5633 - 04_loss: 0.0918 - 13_loss: 0.7204 - 14_loss: 0.5888 - 23_loss: 1.6015e-09 - 24_loss: 2.4785e-09 - 33_loss: 1.6242e-09 - 34_loss: 2.1842e-09 - 43_loss: 0.2367 - 44_loss: 0.8484 - 53_loss: 0.2388 - 54_loss: 0.1462 - 03_categorical_accuracy: 0.7060 - 04_categorical_accuracy: 0.9714 - 13_categorical_accuracy: 0.6648 - 14_categorical_accuracy: 0.6937 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9258 - 44_categorical_accuracy: 0.6265 - 53_categorical_accuracy: 0.9243 - 54_categorical_accuracy: 0.9469 - val_loss: 5.0779 - val_03_loss: 0.6555 - val_04_loss: 0.1950 - val_13_loss: 0.7903 - val_14_loss: 0.7280 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.2945 - val_44_loss: 1.5926 - val_53_loss: 0.2987 - val_54_loss: 0.5233 - val_03_categorical_accuracy: 0.6595 - val_04_categorical_accuracy: 0.9561 - val_13_categorical_accuracy: 0.6506 - val_14_categorical_accuracy: 0.6505 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9174 - val_44_categorical_accuracy: 0.4771 - val_53_categorical_accuracy: 0.9147 - val_54_categorical_accuracy: 0.8845\n",
      "Epoch 16/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 3.3820 - 03_loss: 0.5567 - 04_loss: 0.0894 - 13_loss: 0.7139 - 14_loss: 0.5839 - 23_loss: 1.0349e-09 - 24_loss: 2.1066e-09 - 33_loss: 1.3600e-09 - 34_loss: 1.6938e-09 - 43_loss: 0.2324 - 44_loss: 0.8320 - 53_loss: 0.2342 - 54_loss: 0.1393 - 03_categorical_accuracy: 0.7106 - 04_categorical_accuracy: 0.9717 - 13_categorical_accuracy: 0.6659 - 14_categorical_accuracy: 0.6959 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9266 - 44_categorical_accuracy: 0.6341 - 53_categorical_accuracy: 0.9252 - 54_categorical_accuracy: 0.9486 - val_loss: 5.2248 - val_03_loss: 0.6637 - val_04_loss: 0.2033 - val_13_loss: 0.7936 - val_14_loss: 0.7374 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.2977 - val_44_loss: 1.6750 - val_53_loss: 0.3052 - val_54_loss: 0.5488 - val_03_categorical_accuracy: 0.6606 - val_04_categorical_accuracy: 0.9577 - val_13_categorical_accuracy: 0.6494 - val_14_categorical_accuracy: 0.6494 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9162 - val_44_categorical_accuracy: 0.4768 - val_53_categorical_accuracy: 0.9130 - val_54_categorical_accuracy: 0.8870\n",
      "Epoch 17/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 3.3284 - 03_loss: 0.5497 - 04_loss: 0.0867 - 13_loss: 0.7076 - 14_loss: 0.5779 - 23_loss: 1.2202e-09 - 24_loss: 2.1079e-09 - 33_loss: 1.2958e-09 - 34_loss: 1.4864e-09 - 43_loss: 0.2273 - 44_loss: 0.8152 - 53_loss: 0.2292 - 54_loss: 0.1347 - 03_categorical_accuracy: 0.7154 - 04_categorical_accuracy: 0.9720 - 13_categorical_accuracy: 0.6681 - 14_categorical_accuracy: 0.6987 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9275 - 44_categorical_accuracy: 0.6420 - 53_categorical_accuracy: 0.9262 - 54_categorical_accuracy: 0.9490 - val_loss: 5.2863 - val_03_loss: 0.6697 - val_04_loss: 0.2084 - val_13_loss: 0.8023 - val_14_loss: 0.7519 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3054 - val_44_loss: 1.6675 - val_53_loss: 0.3117 - val_54_loss: 0.5694 - val_03_categorical_accuracy: 0.6574 - val_04_categorical_accuracy: 0.9545 - val_13_categorical_accuracy: 0.6445 - val_14_categorical_accuracy: 0.6485 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9164 - val_44_categorical_accuracy: 0.4816 - val_53_categorical_accuracy: 0.9132 - val_54_categorical_accuracy: 0.8880\n",
      "Epoch 18/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 3.2783 - 03_loss: 0.5426 - 04_loss: 0.0849 - 13_loss: 0.7005 - 14_loss: 0.5730 - 23_loss: 6.2682e-10 - 24_loss: 1.5152e-09 - 33_loss: 7.7065e-10 - 34_loss: 8.3955e-10 - 43_loss: 0.2221 - 44_loss: 0.8009 - 53_loss: 0.2246 - 54_loss: 0.1298 - 03_categorical_accuracy: 0.7198 - 04_categorical_accuracy: 0.9724 - 13_categorical_accuracy: 0.6693 - 14_categorical_accuracy: 0.7013 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9284 - 44_categorical_accuracy: 0.6475 - 53_categorical_accuracy: 0.9266 - 54_categorical_accuracy: 0.9506 - val_loss: 5.3975 - val_03_loss: 0.6829 - val_04_loss: 0.2130 - val_13_loss: 0.8135 - val_14_loss: 0.7570 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3123 - val_44_loss: 1.7148 - val_53_loss: 0.3207 - val_54_loss: 0.5834 - val_03_categorical_accuracy: 0.6573 - val_04_categorical_accuracy: 0.9554 - val_13_categorical_accuracy: 0.6398 - val_14_categorical_accuracy: 0.6460 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9156 - val_44_categorical_accuracy: 0.4713 - val_53_categorical_accuracy: 0.9114 - val_54_categorical_accuracy: 0.8885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 3.2270 - 03_loss: 0.5352 - 04_loss: 0.0823 - 13_loss: 0.6934 - 14_loss: 0.5675 - 23_loss: 5.9003e-10 - 24_loss: 9.8806e-10 - 33_loss: 6.1009e-10 - 34_loss: 7.3987e-10 - 43_loss: 0.2179 - 44_loss: 0.7849 - 53_loss: 0.2201 - 54_loss: 0.1257 - 03_categorical_accuracy: 0.7243 - 04_categorical_accuracy: 0.9729 - 13_categorical_accuracy: 0.6717 - 14_categorical_accuracy: 0.7037 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9289 - 44_categorical_accuracy: 0.6548 - 53_categorical_accuracy: 0.9279 - 54_categorical_accuracy: 0.9515 - val_loss: 5.4896 - val_03_loss: 0.6924 - val_04_loss: 0.2118 - val_13_loss: 0.8204 - val_14_loss: 0.7711 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3202 - val_44_loss: 1.7568 - val_53_loss: 0.3294 - val_54_loss: 0.5876 - val_03_categorical_accuracy: 0.6579 - val_04_categorical_accuracy: 0.9566 - val_13_categorical_accuracy: 0.6390 - val_14_categorical_accuracy: 0.6436 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9143 - val_44_categorical_accuracy: 0.4683 - val_53_categorical_accuracy: 0.9108 - val_54_categorical_accuracy: 0.8838\n",
      "Epoch 20/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 3.1791 - 03_loss: 0.5282 - 04_loss: 0.0806 - 13_loss: 0.6859 - 14_loss: 0.5626 - 23_loss: 3.7863e-10 - 24_loss: 6.0407e-10 - 33_loss: 3.6124e-10 - 34_loss: 5.5256e-10 - 43_loss: 0.2128 - 44_loss: 0.7709 - 53_loss: 0.2156 - 54_loss: 0.1225 - 03_categorical_accuracy: 0.7292 - 04_categorical_accuracy: 0.9732 - 13_categorical_accuracy: 0.6742 - 14_categorical_accuracy: 0.7065 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9300 - 44_categorical_accuracy: 0.6607 - 53_categorical_accuracy: 0.9289 - 54_categorical_accuracy: 0.9522 - val_loss: 5.5813 - val_03_loss: 0.6972 - val_04_loss: 0.2149 - val_13_loss: 0.8306 - val_14_loss: 0.7750 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3271 - val_44_loss: 1.7902 - val_53_loss: 0.3314 - val_54_loss: 0.6148 - val_03_categorical_accuracy: 0.6494 - val_04_categorical_accuracy: 0.9546 - val_13_categorical_accuracy: 0.6379 - val_14_categorical_accuracy: 0.6462 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9109 - val_44_categorical_accuracy: 0.4629 - val_53_categorical_accuracy: 0.9084 - val_54_categorical_accuracy: 0.8840\n",
      "Epoch 21/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 3.1324 - 03_loss: 0.5222 - 04_loss: 0.0793 - 13_loss: 0.6784 - 14_loss: 0.5576 - 23_loss: 1.4115e-09 - 24_loss: 2.3420e-09 - 33_loss: 1.3955e-09 - 34_loss: 1.7614e-09 - 43_loss: 0.2080 - 44_loss: 0.7579 - 53_loss: 0.2107 - 54_loss: 0.1182 - 03_categorical_accuracy: 0.7319 - 04_categorical_accuracy: 0.9737 - 13_categorical_accuracy: 0.6772 - 14_categorical_accuracy: 0.7094 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9311 - 44_categorical_accuracy: 0.6663 - 53_categorical_accuracy: 0.9297 - 54_categorical_accuracy: 0.9525 - val_loss: 5.6754 - val_03_loss: 0.7112 - val_04_loss: 0.2223 - val_13_loss: 0.8414 - val_14_loss: 0.7898 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3363 - val_44_loss: 1.8195 - val_53_loss: 0.3360 - val_54_loss: 0.6189 - val_03_categorical_accuracy: 0.6507 - val_04_categorical_accuracy: 0.9563 - val_13_categorical_accuracy: 0.6330 - val_14_categorical_accuracy: 0.6444 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9079 - val_44_categorical_accuracy: 0.4644 - val_53_categorical_accuracy: 0.9088 - val_54_categorical_accuracy: 0.8808\n",
      "Epoch 22/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 3.0869 - 03_loss: 0.5151 - 04_loss: 0.0778 - 13_loss: 0.6712 - 14_loss: 0.5529 - 23_loss: 1.0249e-09 - 24_loss: 1.9467e-09 - 33_loss: 1.1339e-09 - 34_loss: 1.7794e-09 - 43_loss: 0.2033 - 44_loss: 0.7454 - 53_loss: 0.2056 - 54_loss: 0.1156 - 03_categorical_accuracy: 0.7363 - 04_categorical_accuracy: 0.9738 - 13_categorical_accuracy: 0.6808 - 14_categorical_accuracy: 0.7120 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9315 - 44_categorical_accuracy: 0.6721 - 53_categorical_accuracy: 0.9307 - 54_categorical_accuracy: 0.9535 - val_loss: 5.7211 - val_03_loss: 0.7202 - val_04_loss: 0.2224 - val_13_loss: 0.8488 - val_14_loss: 0.7959 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3432 - val_44_loss: 1.8228 - val_53_loss: 0.3412 - val_54_loss: 0.6265 - val_03_categorical_accuracy: 0.6481 - val_04_categorical_accuracy: 0.9555 - val_13_categorical_accuracy: 0.6289 - val_14_categorical_accuracy: 0.6392 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9078 - val_44_categorical_accuracy: 0.4696 - val_53_categorical_accuracy: 0.9037 - val_54_categorical_accuracy: 0.8804\n",
      "Epoch 23/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 3.0443 - 03_loss: 0.5090 - 04_loss: 0.0767 - 13_loss: 0.6634 - 14_loss: 0.5483 - 23_loss: 7.8670e-10 - 24_loss: 1.1459e-09 - 33_loss: 8.2684e-10 - 34_loss: 9.9809e-10 - 43_loss: 0.1989 - 44_loss: 0.7338 - 53_loss: 0.2018 - 54_loss: 0.1124 - 03_categorical_accuracy: 0.7411 - 04_categorical_accuracy: 0.9742 - 13_categorical_accuracy: 0.6830 - 14_categorical_accuracy: 0.7141 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9324 - 44_categorical_accuracy: 0.6754 - 53_categorical_accuracy: 0.9315 - 54_categorical_accuracy: 0.9543 - val_loss: 5.8785 - val_03_loss: 0.7317 - val_04_loss: 0.2231 - val_13_loss: 0.8672 - val_14_loss: 0.8076 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3479 - val_44_loss: 1.8802 - val_53_loss: 0.3564 - val_54_loss: 0.6645 - val_03_categorical_accuracy: 0.6444 - val_04_categorical_accuracy: 0.9523 - val_13_categorical_accuracy: 0.6239 - val_14_categorical_accuracy: 0.6385 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9053 - val_44_categorical_accuracy: 0.4633 - val_53_categorical_accuracy: 0.9057 - val_54_categorical_accuracy: 0.8799\n",
      "Epoch 24/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 3.0001 - 03_loss: 0.5014 - 04_loss: 0.0752 - 13_loss: 0.6558 - 14_loss: 0.5430 - 23_loss: 5.4587e-10 - 24_loss: 1.2630e-09 - 33_loss: 6.1612e-10 - 34_loss: 8.7500e-10 - 43_loss: 0.1949 - 44_loss: 0.7215 - 53_loss: 0.1976 - 54_loss: 0.1106 - 03_categorical_accuracy: 0.7445 - 04_categorical_accuracy: 0.9744 - 13_categorical_accuracy: 0.6865 - 14_categorical_accuracy: 0.7165 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9333 - 44_categorical_accuracy: 0.6814 - 53_categorical_accuracy: 0.9324 - 54_categorical_accuracy: 0.9547 - val_loss: 5.8934 - val_03_loss: 0.7397 - val_04_loss: 0.2311 - val_13_loss: 0.8744 - val_14_loss: 0.8073 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3598 - val_44_loss: 1.8772 - val_53_loss: 0.3598 - val_54_loss: 0.6441 - val_03_categorical_accuracy: 0.6472 - val_04_categorical_accuracy: 0.9545 - val_13_categorical_accuracy: 0.6293 - val_14_categorical_accuracy: 0.6331 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9051 - val_44_categorical_accuracy: 0.4601 - val_53_categorical_accuracy: 0.9048 - val_54_categorical_accuracy: 0.8819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 2.9590 - 03_loss: 0.4950 - 04_loss: 0.0742 - 13_loss: 0.6478 - 14_loss: 0.5380 - 23_loss: 1.7962e-09 - 24_loss: 2.3795e-09 - 33_loss: 2.0216e-09 - 34_loss: 2.1748e-09 - 43_loss: 0.1915 - 44_loss: 0.7111 - 53_loss: 0.1933 - 54_loss: 0.1081 - 03_categorical_accuracy: 0.7482 - 04_categorical_accuracy: 0.9744 - 13_categorical_accuracy: 0.6890 - 14_categorical_accuracy: 0.7193 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9338 - 44_categorical_accuracy: 0.6859 - 53_categorical_accuracy: 0.9332 - 54_categorical_accuracy: 0.9548 - val_loss: 5.9889 - val_03_loss: 0.7594 - val_04_loss: 0.2366 - val_13_loss: 0.8893 - val_14_loss: 0.8190 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3650 - val_44_loss: 1.8814 - val_53_loss: 0.3691 - val_54_loss: 0.6691 - val_03_categorical_accuracy: 0.6440 - val_04_categorical_accuracy: 0.9528 - val_13_categorical_accuracy: 0.6221 - val_14_categorical_accuracy: 0.6297 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9047 - val_44_categorical_accuracy: 0.4685 - val_53_categorical_accuracy: 0.9028 - val_54_categorical_accuracy: 0.8785\n",
      "Epoch 26/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 2.9191 - 03_loss: 0.4887 - 04_loss: 0.0731 - 13_loss: 0.6402 - 14_loss: 0.5336 - 23_loss: 3.5455e-10 - 24_loss: 1.0369e-09 - 33_loss: 5.3852e-10 - 34_loss: 6.7699e-10 - 43_loss: 0.1877 - 44_loss: 0.6997 - 53_loss: 0.1900 - 54_loss: 0.1061 - 03_categorical_accuracy: 0.7523 - 04_categorical_accuracy: 0.9747 - 13_categorical_accuracy: 0.6925 - 14_categorical_accuracy: 0.7216 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9346 - 44_categorical_accuracy: 0.6902 - 53_categorical_accuracy: 0.9335 - 54_categorical_accuracy: 0.9552 - val_loss: 6.1456 - val_03_loss: 0.7766 - val_04_loss: 0.2367 - val_13_loss: 0.9035 - val_14_loss: 0.8397 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3729 - val_44_loss: 1.9701 - val_53_loss: 0.3776 - val_54_loss: 0.6685 - val_03_categorical_accuracy: 0.6332 - val_04_categorical_accuracy: 0.9511 - val_13_categorical_accuracy: 0.6187 - val_14_categorical_accuracy: 0.6332 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9065 - val_44_categorical_accuracy: 0.4586 - val_53_categorical_accuracy: 0.8972 - val_54_categorical_accuracy: 0.8794\n",
      "Epoch 27/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 2.8788 - 03_loss: 0.4810 - 04_loss: 0.0725 - 13_loss: 0.6319 - 14_loss: 0.5275 - 23_loss: 1.1580e-09 - 24_loss: 1.4610e-09 - 33_loss: 1.1118e-09 - 34_loss: 1.3921e-09 - 43_loss: 0.1838 - 44_loss: 0.6914 - 53_loss: 0.1863 - 54_loss: 0.1045 - 03_categorical_accuracy: 0.7569 - 04_categorical_accuracy: 0.9747 - 13_categorical_accuracy: 0.6973 - 14_categorical_accuracy: 0.7252 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9355 - 44_categorical_accuracy: 0.6932 - 53_categorical_accuracy: 0.9346 - 54_categorical_accuracy: 0.9552 - val_loss: 6.1887 - val_03_loss: 0.7771 - val_04_loss: 0.2392 - val_13_loss: 0.9102 - val_14_loss: 0.8460 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3804 - val_44_loss: 1.9684 - val_53_loss: 0.3849 - val_54_loss: 0.6824 - val_03_categorical_accuracy: 0.6429 - val_04_categorical_accuracy: 0.9534 - val_13_categorical_accuracy: 0.6135 - val_14_categorical_accuracy: 0.6358 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9033 - val_44_categorical_accuracy: 0.4644 - val_53_categorical_accuracy: 0.9030 - val_54_categorical_accuracy: 0.8777\n",
      "Epoch 28/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 2.8420 - 03_loss: 0.4762 - 04_loss: 0.0715 - 13_loss: 0.6233 - 14_loss: 0.5225 - 23_loss: 3.5923e-10 - 24_loss: 6.3418e-10 - 33_loss: 3.5923e-10 - 34_loss: 5.7263e-10 - 43_loss: 0.1803 - 44_loss: 0.6828 - 53_loss: 0.1825 - 54_loss: 0.1029 - 03_categorical_accuracy: 0.7594 - 04_categorical_accuracy: 0.9749 - 13_categorical_accuracy: 0.7023 - 14_categorical_accuracy: 0.7280 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9361 - 44_categorical_accuracy: 0.6979 - 53_categorical_accuracy: 0.9354 - 54_categorical_accuracy: 0.9558 - val_loss: 6.2946 - val_03_loss: 0.7923 - val_04_loss: 0.2509 - val_13_loss: 0.9280 - val_14_loss: 0.8605 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3872 - val_44_loss: 1.9892 - val_53_loss: 0.3916 - val_54_loss: 0.6949 - val_03_categorical_accuracy: 0.6411 - val_04_categorical_accuracy: 0.9509 - val_13_categorical_accuracy: 0.6053 - val_14_categorical_accuracy: 0.6276 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8949 - val_44_categorical_accuracy: 0.4645 - val_53_categorical_accuracy: 0.9043 - val_54_categorical_accuracy: 0.8788\n",
      "Epoch 29/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 2.8025 - 03_loss: 0.4696 - 04_loss: 0.0708 - 13_loss: 0.6161 - 14_loss: 0.5178 - 23_loss: 2.0537e-10 - 24_loss: 5.7865e-10 - 33_loss: 2.4283e-10 - 34_loss: 3.7328e-10 - 43_loss: 0.1761 - 44_loss: 0.6723 - 53_loss: 0.1791 - 54_loss: 0.1007 - 03_categorical_accuracy: 0.7625 - 04_categorical_accuracy: 0.9753 - 13_categorical_accuracy: 0.7054 - 14_categorical_accuracy: 0.7317 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9371 - 44_categorical_accuracy: 0.7018 - 53_categorical_accuracy: 0.9354 - 54_categorical_accuracy: 0.9562 - val_loss: 6.3514 - val_03_loss: 0.8018 - val_04_loss: 0.2435 - val_13_loss: 0.9409 - val_14_loss: 0.8667 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3935 - val_44_loss: 2.0140 - val_53_loss: 0.3949 - val_54_loss: 0.6962 - val_03_categorical_accuracy: 0.6355 - val_04_categorical_accuracy: 0.9526 - val_13_categorical_accuracy: 0.6080 - val_14_categorical_accuracy: 0.6281 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8931 - val_44_categorical_accuracy: 0.4609 - val_53_categorical_accuracy: 0.8976 - val_54_categorical_accuracy: 0.8848\n",
      "Epoch 30/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 2.7673 - 03_loss: 0.4631 - 04_loss: 0.0700 - 13_loss: 0.6075 - 14_loss: 0.5123 - 23_loss: 2.5889e-10 - 24_loss: 7.5125e-10 - 33_loss: 2.8163e-10 - 34_loss: 5.1778e-10 - 43_loss: 0.1736 - 44_loss: 0.6655 - 53_loss: 0.1754 - 54_loss: 0.0997 - 03_categorical_accuracy: 0.7670 - 04_categorical_accuracy: 0.9753 - 13_categorical_accuracy: 0.7092 - 14_categorical_accuracy: 0.7344 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9374 - 44_categorical_accuracy: 0.7047 - 53_categorical_accuracy: 0.9368 - 54_categorical_accuracy: 0.9560 - val_loss: 6.4454 - val_03_loss: 0.8128 - val_04_loss: 0.2462 - val_13_loss: 0.9529 - val_14_loss: 0.8804 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 1.3245e-08 - val_43_loss: 0.3976 - val_44_loss: 2.0355 - val_53_loss: 0.4094 - val_54_loss: 0.7106 - val_03_categorical_accuracy: 0.6392 - val_04_categorical_accuracy: 0.9540 - val_13_categorical_accuracy: 0.6039 - val_14_categorical_accuracy: 0.6290 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8996 - val_44_categorical_accuracy: 0.4617 - val_53_categorical_accuracy: 0.8995 - val_54_categorical_accuracy: 0.8756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 2.7338 - 03_loss: 0.4582 - 04_loss: 0.0695 - 13_loss: 0.6006 - 14_loss: 0.5074 - 23_loss: 4.4954e-10 - 24_loss: 1.0168e-09 - 33_loss: 6.2615e-10 - 34_loss: 9.9943e-10 - 43_loss: 0.1704 - 44_loss: 0.6568 - 53_loss: 0.1727 - 54_loss: 0.0982 - 03_categorical_accuracy: 0.7699 - 04_categorical_accuracy: 0.9753 - 13_categorical_accuracy: 0.7134 - 14_categorical_accuracy: 0.7373 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9378 - 44_categorical_accuracy: 0.7080 - 53_categorical_accuracy: 0.9374 - 54_categorical_accuracy: 0.9565 - val_loss: 6.4261 - val_03_loss: 0.8263 - val_04_loss: 0.2538 - val_13_loss: 0.9698 - val_14_loss: 0.8852 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4066 - val_44_loss: 1.9769 - val_53_loss: 0.4048 - val_54_loss: 0.7026 - val_03_categorical_accuracy: 0.6245 - val_04_categorical_accuracy: 0.9521 - val_13_categorical_accuracy: 0.5997 - val_14_categorical_accuracy: 0.6217 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8953 - val_44_categorical_accuracy: 0.4558 - val_53_categorical_accuracy: 0.8976 - val_54_categorical_accuracy: 0.8792\n",
      "Epoch 32/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 2.6973 - 03_loss: 0.4524 - 04_loss: 0.0688 - 13_loss: 0.5914 - 14_loss: 0.5021 - 23_loss: 3.5121e-10 - 24_loss: 7.3385e-10 - 33_loss: 4.9905e-10 - 34_loss: 1.0175e-09 - 43_loss: 0.1672 - 44_loss: 0.6496 - 53_loss: 0.1694 - 54_loss: 0.0966 - 03_categorical_accuracy: 0.7729 - 04_categorical_accuracy: 0.9757 - 13_categorical_accuracy: 0.7175 - 14_categorical_accuracy: 0.7407 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9388 - 44_categorical_accuracy: 0.7113 - 53_categorical_accuracy: 0.9384 - 54_categorical_accuracy: 0.9569 - val_loss: 6.6656 - val_03_loss: 0.8439 - val_04_loss: 0.2523 - val_13_loss: 0.9818 - val_14_loss: 0.9039 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4161 - val_44_loss: 2.1235 - val_53_loss: 0.4203 - val_54_loss: 0.7238 - val_03_categorical_accuracy: 0.6318 - val_04_categorical_accuracy: 0.9525 - val_13_categorical_accuracy: 0.5899 - val_14_categorical_accuracy: 0.6118 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8947 - val_44_categorical_accuracy: 0.4533 - val_53_categorical_accuracy: 0.8944 - val_54_categorical_accuracy: 0.8801\n",
      "Epoch 33/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 2.6661 - 03_loss: 0.4473 - 04_loss: 0.0683 - 13_loss: 0.5841 - 14_loss: 0.4967 - 23_loss: 9.1180e-10 - 24_loss: 1.2663e-09 - 33_loss: 9.0377e-10 - 34_loss: 1.2737e-09 - 43_loss: 0.1644 - 44_loss: 0.6429 - 53_loss: 0.1671 - 54_loss: 0.0954 - 03_categorical_accuracy: 0.7758 - 04_categorical_accuracy: 0.9757 - 13_categorical_accuracy: 0.7211 - 14_categorical_accuracy: 0.7432 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9393 - 44_categorical_accuracy: 0.7133 - 53_categorical_accuracy: 0.9384 - 54_categorical_accuracy: 0.9571 - val_loss: 6.7196 - val_03_loss: 0.8492 - val_04_loss: 0.2569 - val_13_loss: 1.0006 - val_14_loss: 0.9113 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4228 - val_44_loss: 2.1294 - val_53_loss: 0.4246 - val_54_loss: 0.7246 - val_03_categorical_accuracy: 0.6321 - val_04_categorical_accuracy: 0.9530 - val_13_categorical_accuracy: 0.6001 - val_14_categorical_accuracy: 0.6163 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8976 - val_44_categorical_accuracy: 0.4607 - val_53_categorical_accuracy: 0.8865 - val_54_categorical_accuracy: 0.8732\n",
      "Epoch 34/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 2.6340 - 03_loss: 0.4413 - 04_loss: 0.0680 - 13_loss: 0.5767 - 14_loss: 0.4916 - 23_loss: 4.2278e-10 - 24_loss: 6.9907e-10 - 33_loss: 4.2278e-10 - 34_loss: 5.3383e-10 - 43_loss: 0.1616 - 44_loss: 0.6362 - 53_loss: 0.1641 - 54_loss: 0.0945 - 03_categorical_accuracy: 0.7790 - 04_categorical_accuracy: 0.9756 - 13_categorical_accuracy: 0.7249 - 14_categorical_accuracy: 0.7465 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9397 - 44_categorical_accuracy: 0.7160 - 53_categorical_accuracy: 0.9392 - 54_categorical_accuracy: 0.9571 - val_loss: 6.7696 - val_03_loss: 0.8664 - val_04_loss: 0.2631 - val_13_loss: 1.0147 - val_14_loss: 0.9274 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4245 - val_44_loss: 2.1289 - val_53_loss: 0.4247 - val_54_loss: 0.7199 - val_03_categorical_accuracy: 0.6277 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5919 - val_14_categorical_accuracy: 0.6187 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8961 - val_44_categorical_accuracy: 0.4505 - val_53_categorical_accuracy: 0.8883 - val_54_categorical_accuracy: 0.8736\n",
      "Epoch 35/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 2.6024 - 03_loss: 0.4369 - 04_loss: 0.0675 - 13_loss: 0.5693 - 14_loss: 0.4860 - 23_loss: 2.3012e-10 - 24_loss: 4.5690e-10 - 33_loss: 2.4685e-10 - 34_loss: 4.0138e-10 - 43_loss: 0.1594 - 44_loss: 0.6281 - 53_loss: 0.1618 - 54_loss: 0.0935 - 03_categorical_accuracy: 0.7826 - 04_categorical_accuracy: 0.9758 - 13_categorical_accuracy: 0.7290 - 14_categorical_accuracy: 0.7501 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9402 - 44_categorical_accuracy: 0.7190 - 53_categorical_accuracy: 0.9398 - 54_categorical_accuracy: 0.9571 - val_loss: 6.8544 - val_03_loss: 0.8712 - val_04_loss: 0.2574 - val_13_loss: 1.0304 - val_14_loss: 0.9424 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4298 - val_44_loss: 2.1739 - val_53_loss: 0.4259 - val_54_loss: 0.7234 - val_03_categorical_accuracy: 0.6297 - val_04_categorical_accuracy: 0.9531 - val_13_categorical_accuracy: 0.5913 - val_14_categorical_accuracy: 0.6196 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8966 - val_44_categorical_accuracy: 0.4580 - val_53_categorical_accuracy: 0.8930 - val_54_categorical_accuracy: 0.8769\n",
      "Epoch 36/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 2.5712 - 03_loss: 0.4313 - 04_loss: 0.0672 - 13_loss: 0.5615 - 14_loss: 0.4807 - 23_loss: 1.2510e-10 - 24_loss: 3.5723e-10 - 33_loss: 1.2510e-10 - 34_loss: 2.2276e-10 - 43_loss: 0.1567 - 44_loss: 0.6227 - 53_loss: 0.1587 - 54_loss: 0.0925 - 03_categorical_accuracy: 0.7845 - 04_categorical_accuracy: 0.9759 - 13_categorical_accuracy: 0.7323 - 14_categorical_accuracy: 0.7529 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9409 - 44_categorical_accuracy: 0.7216 - 53_categorical_accuracy: 0.9405 - 54_categorical_accuracy: 0.9579 - val_loss: 6.8978 - val_03_loss: 0.8760 - val_04_loss: 0.2572 - val_13_loss: 1.0410 - val_14_loss: 0.9404 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4362 - val_44_loss: 2.1703 - val_53_loss: 0.4321 - val_54_loss: 0.7446 - val_03_categorical_accuracy: 0.6238 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5845 - val_14_categorical_accuracy: 0.6098 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8867 - val_44_categorical_accuracy: 0.4545 - val_53_categorical_accuracy: 0.8897 - val_54_categorical_accuracy: 0.8778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 2.5428 - 03_loss: 0.4272 - 04_loss: 0.0664 - 13_loss: 0.5554 - 14_loss: 0.4760 - 23_loss: 4.2345e-10 - 24_loss: 8.6831e-10 - 33_loss: 4.2345e-10 - 34_loss: 7.1445e-10 - 43_loss: 0.1538 - 44_loss: 0.6157 - 53_loss: 0.1563 - 54_loss: 0.0919 - 03_categorical_accuracy: 0.7873 - 04_categorical_accuracy: 0.9762 - 13_categorical_accuracy: 0.7358 - 14_categorical_accuracy: 0.7570 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9419 - 44_categorical_accuracy: 0.7240 - 53_categorical_accuracy: 0.9415 - 54_categorical_accuracy: 0.9574 - val_loss: 6.9797 - val_03_loss: 0.8950 - val_04_loss: 0.2609 - val_13_loss: 1.0581 - val_14_loss: 0.9675 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4387 - val_44_loss: 2.1764 - val_53_loss: 0.4422 - val_54_loss: 0.7408 - val_03_categorical_accuracy: 0.6238 - val_04_categorical_accuracy: 0.9531 - val_13_categorical_accuracy: 0.5835 - val_14_categorical_accuracy: 0.6103 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8930 - val_44_categorical_accuracy: 0.4601 - val_53_categorical_accuracy: 0.8924 - val_54_categorical_accuracy: 0.8770\n",
      "Epoch 38/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 2.5140 - 03_loss: 0.4220 - 04_loss: 0.0662 - 13_loss: 0.5476 - 14_loss: 0.4701 - 23_loss: 3.3916e-10 - 24_loss: 8.8972e-10 - 33_loss: 3.2311e-10 - 34_loss: 7.8670e-10 - 43_loss: 0.1522 - 44_loss: 0.6108 - 53_loss: 0.1544 - 54_loss: 0.0906 - 03_categorical_accuracy: 0.7896 - 04_categorical_accuracy: 0.9760 - 13_categorical_accuracy: 0.7398 - 14_categorical_accuracy: 0.7596 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9415 - 44_categorical_accuracy: 0.7265 - 53_categorical_accuracy: 0.9412 - 54_categorical_accuracy: 0.9580 - val_loss: 6.9995 - val_03_loss: 0.8986 - val_04_loss: 0.2639 - val_13_loss: 1.0732 - val_14_loss: 0.9622 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4447 - val_44_loss: 2.1677 - val_53_loss: 0.4424 - val_54_loss: 0.7468 - val_03_categorical_accuracy: 0.6192 - val_04_categorical_accuracy: 0.9520 - val_13_categorical_accuracy: 0.5804 - val_14_categorical_accuracy: 0.6055 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8926 - val_44_categorical_accuracy: 0.4457 - val_53_categorical_accuracy: 0.8891 - val_54_categorical_accuracy: 0.8704\n",
      "Epoch 39/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 2.4864 - 03_loss: 0.4173 - 04_loss: 0.0659 - 13_loss: 0.5405 - 14_loss: 0.4656 - 23_loss: 2.3414e-10 - 24_loss: 5.8668e-10 - 33_loss: 2.5488e-10 - 34_loss: 6.4421e-10 - 43_loss: 0.1499 - 44_loss: 0.6048 - 53_loss: 0.1521 - 54_loss: 0.0904 - 03_categorical_accuracy: 0.7930 - 04_categorical_accuracy: 0.9764 - 13_categorical_accuracy: 0.7434 - 14_categorical_accuracy: 0.7630 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9422 - 44_categorical_accuracy: 0.7296 - 53_categorical_accuracy: 0.9415 - 54_categorical_accuracy: 0.9578 - val_loss: 7.0461 - val_03_loss: 0.9189 - val_04_loss: 0.2638 - val_13_loss: 1.0838 - val_14_loss: 0.9721 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4491 - val_44_loss: 2.1812 - val_53_loss: 0.4486 - val_54_loss: 0.7286 - val_03_categorical_accuracy: 0.6135 - val_04_categorical_accuracy: 0.9523 - val_13_categorical_accuracy: 0.5811 - val_14_categorical_accuracy: 0.6148 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8943 - val_44_categorical_accuracy: 0.4518 - val_53_categorical_accuracy: 0.8886 - val_54_categorical_accuracy: 0.8776\n",
      "Epoch 40/1000\n",
      "697/697 [==============================] - 17s 25ms/step - loss: 2.4600 - 03_loss: 0.4126 - 04_loss: 0.0654 - 13_loss: 0.5346 - 14_loss: 0.4608 - 23_loss: 3.3314e-10 - 24_loss: 6.6027e-10 - 33_loss: 2.3347e-10 - 34_loss: 6.4020e-10 - 43_loss: 0.1472 - 44_loss: 0.5999 - 53_loss: 0.1501 - 54_loss: 0.0895 - 03_categorical_accuracy: 0.7952 - 04_categorical_accuracy: 0.9764 - 13_categorical_accuracy: 0.7471 - 14_categorical_accuracy: 0.7661 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9432 - 44_categorical_accuracy: 0.7307 - 53_categorical_accuracy: 0.9423 - 54_categorical_accuracy: 0.9581 - val_loss: 7.1749 - val_03_loss: 0.9287 - val_04_loss: 0.2746 - val_13_loss: 1.1023 - val_14_loss: 0.9892 - val_23_loss: 1.3245e-08 - val_24_loss: 1.3245e-08 - val_33_loss: 1.3245e-08 - val_34_loss: 1.3245e-08 - val_43_loss: 0.4557 - val_44_loss: 2.2053 - val_53_loss: 0.4511 - val_54_loss: 0.7679 - val_03_categorical_accuracy: 0.6160 - val_04_categorical_accuracy: 0.9545 - val_13_categorical_accuracy: 0.5740 - val_14_categorical_accuracy: 0.6010 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8841 - val_44_categorical_accuracy: 0.4493 - val_53_categorical_accuracy: 0.8905 - val_54_categorical_accuracy: 0.8761\n",
      "Epoch 41/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 2.4362 - 03_loss: 0.4088 - 04_loss: 0.0654 - 13_loss: 0.5274 - 14_loss: 0.4561 - 23_loss: 4.2814e-11 - 24_loss: 6.4889e-11 - 33_loss: 4.2814e-11 - 34_loss: 4.2814e-11 - 43_loss: 0.1457 - 44_loss: 0.5951 - 53_loss: 0.1489 - 54_loss: 0.0890 - 03_categorical_accuracy: 0.7970 - 04_categorical_accuracy: 0.9764 - 13_categorical_accuracy: 0.7510 - 14_categorical_accuracy: 0.7678 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9432 - 44_categorical_accuracy: 0.7314 - 53_categorical_accuracy: 0.9421 - 54_categorical_accuracy: 0.9578 - val_loss: 7.2300 - val_03_loss: 0.9335 - val_04_loss: 0.2670 - val_13_loss: 1.1102 - val_14_loss: 0.9968 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4656 - val_44_loss: 2.2336 - val_53_loss: 0.4604 - val_54_loss: 0.7630 - val_03_categorical_accuracy: 0.6221 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5775 - val_14_categorical_accuracy: 0.6084 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8849 - val_44_categorical_accuracy: 0.4588 - val_53_categorical_accuracy: 0.8871 - val_54_categorical_accuracy: 0.8755\n",
      "Epoch 42/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 2.4113 - 03_loss: 0.4059 - 04_loss: 0.0651 - 13_loss: 0.5209 - 14_loss: 0.4513 - 23_loss: 2.6156e-10 - 24_loss: 4.5824e-10 - 33_loss: 2.9769e-10 - 34_loss: 4.5824e-10 - 43_loss: 0.1441 - 44_loss: 0.5898 - 53_loss: 0.1465 - 54_loss: 0.0878 - 03_categorical_accuracy: 0.7989 - 04_categorical_accuracy: 0.9763 - 13_categorical_accuracy: 0.7537 - 14_categorical_accuracy: 0.7713 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9437 - 44_categorical_accuracy: 0.7336 - 53_categorical_accuracy: 0.9429 - 54_categorical_accuracy: 0.9583 - val_loss: 7.3838 - val_03_loss: 0.9478 - val_04_loss: 0.2684 - val_13_loss: 1.1420 - val_14_loss: 1.0115 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4659 - val_44_loss: 2.3150 - val_53_loss: 0.4685 - val_54_loss: 0.7646 - val_03_categorical_accuracy: 0.6196 - val_04_categorical_accuracy: 0.9506 - val_13_categorical_accuracy: 0.5805 - val_14_categorical_accuracy: 0.6109 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8847 - val_44_categorical_accuracy: 0.4472 - val_53_categorical_accuracy: 0.8889 - val_54_categorical_accuracy: 0.8787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 2.3842 - 03_loss: 0.4018 - 04_loss: 0.0646 - 13_loss: 0.5143 - 14_loss: 0.4462 - 23_loss: 1.5119e-10 - 24_loss: 6.0742e-10 - 33_loss: 1.3446e-10 - 34_loss: 4.6025e-10 - 43_loss: 0.1424 - 44_loss: 0.5842 - 53_loss: 0.1439 - 54_loss: 0.0868 - 03_categorical_accuracy: 0.8007 - 04_categorical_accuracy: 0.9764 - 13_categorical_accuracy: 0.7572 - 14_categorical_accuracy: 0.7746 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9437 - 44_categorical_accuracy: 0.7364 - 53_categorical_accuracy: 0.9439 - 54_categorical_accuracy: 0.9589 - val_loss: 7.3169 - val_03_loss: 0.9371 - val_04_loss: 0.2714 - val_13_loss: 1.1313 - val_14_loss: 1.0189 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4618 - val_44_loss: 2.2813 - val_53_loss: 0.4658 - val_54_loss: 0.7492 - val_03_categorical_accuracy: 0.6196 - val_04_categorical_accuracy: 0.9508 - val_13_categorical_accuracy: 0.5789 - val_14_categorical_accuracy: 0.6028 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8831 - val_44_categorical_accuracy: 0.4558 - val_53_categorical_accuracy: 0.8895 - val_54_categorical_accuracy: 0.8754\n",
      "Epoch 44/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 2.3661 - 03_loss: 0.3983 - 04_loss: 0.0644 - 13_loss: 0.5090 - 14_loss: 0.4429 - 23_loss: 6.4220e-11 - 24_loss: 3.6793e-10 - 33_loss: 1.1372e-10 - 34_loss: 3.6124e-10 - 43_loss: 0.1407 - 44_loss: 0.5806 - 53_loss: 0.1432 - 54_loss: 0.0869 - 03_categorical_accuracy: 0.8018 - 04_categorical_accuracy: 0.9763 - 13_categorical_accuracy: 0.7592 - 14_categorical_accuracy: 0.7753 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9446 - 44_categorical_accuracy: 0.7384 - 53_categorical_accuracy: 0.9440 - 54_categorical_accuracy: 0.9585 - val_loss: 7.4309 - val_03_loss: 0.9604 - val_04_loss: 0.2729 - val_13_loss: 1.1621 - val_14_loss: 1.0307 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4698 - val_44_loss: 2.2917 - val_53_loss: 0.4742 - val_54_loss: 0.7690 - val_03_categorical_accuracy: 0.6152 - val_04_categorical_accuracy: 0.9529 - val_13_categorical_accuracy: 0.5809 - val_14_categorical_accuracy: 0.5994 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8933 - val_44_categorical_accuracy: 0.4505 - val_53_categorical_accuracy: 0.8861 - val_54_categorical_accuracy: 0.8762\n",
      "Epoch 45/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 2.3395 - 03_loss: 0.3934 - 04_loss: 0.0641 - 13_loss: 0.5018 - 14_loss: 0.4372 - 23_loss: 1.5252e-10 - 24_loss: 4.0272e-10 - 33_loss: 1.6858e-10 - 34_loss: 2.8765e-10 - 43_loss: 0.1398 - 44_loss: 0.5756 - 53_loss: 0.1411 - 54_loss: 0.0864 - 03_categorical_accuracy: 0.8059 - 04_categorical_accuracy: 0.9764 - 13_categorical_accuracy: 0.7631 - 14_categorical_accuracy: 0.7789 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9449 - 44_categorical_accuracy: 0.7395 - 53_categorical_accuracy: 0.9447 - 54_categorical_accuracy: 0.9586 - val_loss: 7.4909 - val_03_loss: 0.9704 - val_04_loss: 0.2778 - val_13_loss: 1.1721 - val_14_loss: 1.0385 - val_23_loss: 0.0000e+00 - val_24_loss: 1.3245e-08 - val_33_loss: 0.0000e+00 - val_34_loss: 1.3245e-08 - val_43_loss: 0.4755 - val_44_loss: 2.3100 - val_53_loss: 0.4741 - val_54_loss: 0.7724 - val_03_categorical_accuracy: 0.6094 - val_04_categorical_accuracy: 0.9512 - val_13_categorical_accuracy: 0.5877 - val_14_categorical_accuracy: 0.6091 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8861 - val_44_categorical_accuracy: 0.4465 - val_53_categorical_accuracy: 0.8837 - val_54_categorical_accuracy: 0.8763\n",
      "Epoch 46/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 2.3223 - 03_loss: 0.3914 - 04_loss: 0.0640 - 13_loss: 0.4979 - 14_loss: 0.4334 - 23_loss: 7.9607e-11 - 24_loss: 2.9836e-10 - 33_loss: 7.9607e-11 - 34_loss: 2.8030e-10 - 43_loss: 0.1377 - 44_loss: 0.5723 - 53_loss: 0.1401 - 54_loss: 0.0855 - 03_categorical_accuracy: 0.8062 - 04_categorical_accuracy: 0.9766 - 13_categorical_accuracy: 0.7652 - 14_categorical_accuracy: 0.7811 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9453 - 44_categorical_accuracy: 0.7418 - 53_categorical_accuracy: 0.9448 - 54_categorical_accuracy: 0.9590 - val_loss: 7.6003 - val_03_loss: 0.9697 - val_04_loss: 0.2795 - val_13_loss: 1.1859 - val_14_loss: 1.0496 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4847 - val_44_loss: 2.3510 - val_53_loss: 0.4857 - val_54_loss: 0.7942 - val_03_categorical_accuracy: 0.6153 - val_04_categorical_accuracy: 0.9512 - val_13_categorical_accuracy: 0.5805 - val_14_categorical_accuracy: 0.6086 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8920 - val_44_categorical_accuracy: 0.4553 - val_53_categorical_accuracy: 0.8834 - val_54_categorical_accuracy: 0.8763\n",
      "Epoch 47/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 2.3005 - 03_loss: 0.3873 - 04_loss: 0.0638 - 13_loss: 0.4920 - 14_loss: 0.4288 - 23_loss: 4.0338e-10 - 24_loss: 6.6629e-10 - 33_loss: 3.7328e-10 - 34_loss: 6.5625e-10 - 43_loss: 0.1368 - 44_loss: 0.5677 - 53_loss: 0.1388 - 54_loss: 0.0851 - 03_categorical_accuracy: 0.8083 - 04_categorical_accuracy: 0.9763 - 13_categorical_accuracy: 0.7680 - 14_categorical_accuracy: 0.7838 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9455 - 44_categorical_accuracy: 0.7415 - 53_categorical_accuracy: 0.9448 - 54_categorical_accuracy: 0.9590 - val_loss: 7.5792 - val_03_loss: 0.9802 - val_04_loss: 0.2765 - val_13_loss: 1.1993 - val_14_loss: 1.0614 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4811 - val_44_loss: 2.2876 - val_53_loss: 0.4813 - val_54_loss: 0.8119 - val_03_categorical_accuracy: 0.6095 - val_04_categorical_accuracy: 0.9495 - val_13_categorical_accuracy: 0.5721 - val_14_categorical_accuracy: 0.5987 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8836 - val_44_categorical_accuracy: 0.4571 - val_53_categorical_accuracy: 0.8824 - val_54_categorical_accuracy: 0.8783\n",
      "Epoch 48/1000\n",
      "697/697 [==============================] - 16s 22ms/step - loss: 2.2832 - 03_loss: 0.3851 - 04_loss: 0.0634 - 13_loss: 0.4866 - 14_loss: 0.4250 - 23_loss: 5.5524e-11 - 24_loss: 3.3247e-10 - 33_loss: 7.0241e-11 - 34_loss: 2.3949e-10 - 43_loss: 0.1355 - 44_loss: 0.5653 - 53_loss: 0.1378 - 54_loss: 0.0844 - 03_categorical_accuracy: 0.8099 - 04_categorical_accuracy: 0.9768 - 13_categorical_accuracy: 0.7712 - 14_categorical_accuracy: 0.7867 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9459 - 44_categorical_accuracy: 0.7433 - 53_categorical_accuracy: 0.9452 - 54_categorical_accuracy: 0.9593 - val_loss: 7.6579 - val_03_loss: 1.0023 - val_04_loss: 0.2826 - val_13_loss: 1.2089 - val_14_loss: 1.0723 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4904 - val_44_loss: 2.3278 - val_53_loss: 0.4902 - val_54_loss: 0.7835 - val_03_categorical_accuracy: 0.6055 - val_04_categorical_accuracy: 0.9538 - val_13_categorical_accuracy: 0.5767 - val_14_categorical_accuracy: 0.6068 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8794 - val_44_categorical_accuracy: 0.4541 - val_53_categorical_accuracy: 0.8874 - val_54_categorical_accuracy: 0.8771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/1000\n",
      "697/697 [==============================] - 16s 22ms/step - loss: 2.2633 - 03_loss: 0.3816 - 04_loss: 0.0636 - 13_loss: 0.4820 - 14_loss: 0.4205 - 23_loss: 5.9538e-11 - 24_loss: 1.2844e-10 - 33_loss: 5.9538e-11 - 34_loss: 1.7259e-10 - 43_loss: 0.1341 - 44_loss: 0.5605 - 53_loss: 0.1363 - 54_loss: 0.0847 - 03_categorical_accuracy: 0.8111 - 04_categorical_accuracy: 0.9765 - 13_categorical_accuracy: 0.7734 - 14_categorical_accuracy: 0.7879 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9459 - 44_categorical_accuracy: 0.7450 - 53_categorical_accuracy: 0.9452 - 54_categorical_accuracy: 0.9589 - val_loss: 7.7123 - val_03_loss: 0.9968 - val_04_loss: 0.2798 - val_13_loss: 1.2275 - val_14_loss: 1.0952 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4898 - val_44_loss: 2.3512 - val_53_loss: 0.4873 - val_54_loss: 0.7847 - val_03_categorical_accuracy: 0.6147 - val_04_categorical_accuracy: 0.9511 - val_13_categorical_accuracy: 0.5741 - val_14_categorical_accuracy: 0.5996 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8820 - val_44_categorical_accuracy: 0.4522 - val_53_categorical_accuracy: 0.8814 - val_54_categorical_accuracy: 0.8728\n",
      "Epoch 50/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 2.2435 - 03_loss: 0.3783 - 04_loss: 0.0629 - 13_loss: 0.4770 - 14_loss: 0.4167 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1324 - 44_loss: 0.5576 - 53_loss: 0.1343 - 54_loss: 0.0843 - 03_categorical_accuracy: 0.8124 - 04_categorical_accuracy: 0.9768 - 13_categorical_accuracy: 0.7758 - 14_categorical_accuracy: 0.7908 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9463 - 44_categorical_accuracy: 0.7466 - 53_categorical_accuracy: 0.9462 - 54_categorical_accuracy: 0.9587 - val_loss: 7.8169 - val_03_loss: 1.0082 - val_04_loss: 0.2817 - val_13_loss: 1.2397 - val_14_loss: 1.0982 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4930 - val_44_loss: 2.3690 - val_53_loss: 0.5011 - val_54_loss: 0.8259 - val_03_categorical_accuracy: 0.6114 - val_04_categorical_accuracy: 0.9513 - val_13_categorical_accuracy: 0.5721 - val_14_categorical_accuracy: 0.6026 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8749 - val_44_categorical_accuracy: 0.4520 - val_53_categorical_accuracy: 0.8832 - val_54_categorical_accuracy: 0.8764\n",
      "Epoch 51/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 2.2272 - 03_loss: 0.3765 - 04_loss: 0.0630 - 13_loss: 0.4723 - 14_loss: 0.4136 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1305 - 44_loss: 0.5538 - 53_loss: 0.1343 - 54_loss: 0.0831 - 03_categorical_accuracy: 0.8129 - 04_categorical_accuracy: 0.9768 - 13_categorical_accuracy: 0.7782 - 14_categorical_accuracy: 0.7932 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9467 - 44_categorical_accuracy: 0.7475 - 53_categorical_accuracy: 0.9457 - 54_categorical_accuracy: 0.9593 - val_loss: 7.8508 - val_03_loss: 1.0156 - val_04_loss: 0.2835 - val_13_loss: 1.2391 - val_14_loss: 1.0973 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4893 - val_44_loss: 2.4010 - val_53_loss: 0.4971 - val_54_loss: 0.8277 - val_03_categorical_accuracy: 0.6143 - val_04_categorical_accuracy: 0.9531 - val_13_categorical_accuracy: 0.5708 - val_14_categorical_accuracy: 0.6019 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8837 - val_44_categorical_accuracy: 0.4483 - val_53_categorical_accuracy: 0.8861 - val_54_categorical_accuracy: 0.8794\n",
      "Epoch 52/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 2.2101 - 03_loss: 0.3729 - 04_loss: 0.0627 - 13_loss: 0.4678 - 14_loss: 0.4101 - 23_loss: 0.0000e+00 - 24_loss: 1.0971e-10 - 33_loss: 0.0000e+00 - 34_loss: 7.5593e-11 - 43_loss: 0.1298 - 44_loss: 0.5505 - 53_loss: 0.1330 - 54_loss: 0.0832 - 03_categorical_accuracy: 0.8155 - 04_categorical_accuracy: 0.9768 - 13_categorical_accuracy: 0.7806 - 14_categorical_accuracy: 0.7946 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9465 - 44_categorical_accuracy: 0.7488 - 53_categorical_accuracy: 0.9462 - 54_categorical_accuracy: 0.9591 - val_loss: 7.8579 - val_03_loss: 1.0186 - val_04_loss: 0.2834 - val_13_loss: 1.2487 - val_14_loss: 1.1157 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4990 - val_44_loss: 2.3996 - val_53_loss: 0.4996 - val_54_loss: 0.7934 - val_03_categorical_accuracy: 0.6078 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5677 - val_14_categorical_accuracy: 0.5998 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8821 - val_44_categorical_accuracy: 0.4518 - val_53_categorical_accuracy: 0.8866 - val_54_categorical_accuracy: 0.8764\n",
      "Epoch 53/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 2.1965 - 03_loss: 0.3711 - 04_loss: 0.0625 - 13_loss: 0.4645 - 14_loss: 0.4066 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1290 - 44_loss: 0.5483 - 53_loss: 0.1313 - 54_loss: 0.0831 - 03_categorical_accuracy: 0.8158 - 04_categorical_accuracy: 0.9768 - 13_categorical_accuracy: 0.7814 - 14_categorical_accuracy: 0.7969 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9473 - 44_categorical_accuracy: 0.7498 - 53_categorical_accuracy: 0.9467 - 54_categorical_accuracy: 0.9591 - val_loss: 7.9333 - val_03_loss: 1.0222 - val_04_loss: 0.2829 - val_13_loss: 1.2660 - val_14_loss: 1.1230 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5008 - val_44_loss: 2.3986 - val_53_loss: 0.5054 - val_54_loss: 0.8344 - val_03_categorical_accuracy: 0.6053 - val_04_categorical_accuracy: 0.9506 - val_13_categorical_accuracy: 0.5658 - val_14_categorical_accuracy: 0.5915 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8824 - val_44_categorical_accuracy: 0.4491 - val_53_categorical_accuracy: 0.8878 - val_54_categorical_accuracy: 0.8768\n",
      "Epoch 54/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 2.1814 - 03_loss: 0.3690 - 04_loss: 0.0626 - 13_loss: 0.4601 - 14_loss: 0.4029 - 23_loss: 0.0000e+00 - 24_loss: 1.5988e-10 - 33_loss: 0.0000e+00 - 34_loss: 5.5524e-11 - 43_loss: 0.1285 - 44_loss: 0.5447 - 53_loss: 0.1311 - 54_loss: 0.0825 - 03_categorical_accuracy: 0.8170 - 04_categorical_accuracy: 0.9766 - 13_categorical_accuracy: 0.7830 - 14_categorical_accuracy: 0.7989 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9476 - 44_categorical_accuracy: 0.7505 - 53_categorical_accuracy: 0.9464 - 54_categorical_accuracy: 0.9592 - val_loss: 7.9379 - val_03_loss: 1.0246 - val_04_loss: 0.2834 - val_13_loss: 1.2615 - val_14_loss: 1.1364 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5013 - val_44_loss: 2.4082 - val_53_loss: 0.5085 - val_54_loss: 0.8140 - val_03_categorical_accuracy: 0.6143 - val_04_categorical_accuracy: 0.9530 - val_13_categorical_accuracy: 0.5719 - val_14_categorical_accuracy: 0.5951 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8832 - val_44_categorical_accuracy: 0.4549 - val_53_categorical_accuracy: 0.8880 - val_54_categorical_accuracy: 0.8773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 2.1667 - 03_loss: 0.3668 - 04_loss: 0.0623 - 13_loss: 0.4559 - 14_loss: 0.4000 - 23_loss: 0.0000e+00 - 24_loss: 5.9538e-11 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1271 - 44_loss: 0.5426 - 53_loss: 0.1299 - 54_loss: 0.0821 - 03_categorical_accuracy: 0.8181 - 04_categorical_accuracy: 0.9770 - 13_categorical_accuracy: 0.7860 - 14_categorical_accuracy: 0.8001 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9478 - 44_categorical_accuracy: 0.7511 - 53_categorical_accuracy: 0.9470 - 54_categorical_accuracy: 0.9592 - val_loss: 8.0048 - val_03_loss: 1.0299 - val_04_loss: 0.2790 - val_13_loss: 1.2725 - val_14_loss: 1.1272 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5021 - val_44_loss: 2.4566 - val_53_loss: 0.5102 - val_54_loss: 0.8272 - val_03_categorical_accuracy: 0.6156 - val_04_categorical_accuracy: 0.9520 - val_13_categorical_accuracy: 0.5631 - val_14_categorical_accuracy: 0.5932 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8817 - val_44_categorical_accuracy: 0.4455 - val_53_categorical_accuracy: 0.8819 - val_54_categorical_accuracy: 0.8740\n",
      "Epoch 56/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 2.1508 - 03_loss: 0.3640 - 04_loss: 0.0621 - 13_loss: 0.4519 - 14_loss: 0.3967 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1268 - 44_loss: 0.5386 - 53_loss: 0.1292 - 54_loss: 0.0815 - 03_categorical_accuracy: 0.8189 - 04_categorical_accuracy: 0.9769 - 13_categorical_accuracy: 0.7874 - 14_categorical_accuracy: 0.8015 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9479 - 44_categorical_accuracy: 0.7531 - 53_categorical_accuracy: 0.9472 - 54_categorical_accuracy: 0.9598 - val_loss: 8.1519 - val_03_loss: 1.0451 - val_04_loss: 0.2873 - val_13_loss: 1.3020 - val_14_loss: 1.1533 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5104 - val_44_loss: 2.5014 - val_53_loss: 0.5125 - val_54_loss: 0.8401 - val_03_categorical_accuracy: 0.6163 - val_04_categorical_accuracy: 0.9507 - val_13_categorical_accuracy: 0.5624 - val_14_categorical_accuracy: 0.6007 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8823 - val_44_categorical_accuracy: 0.4479 - val_53_categorical_accuracy: 0.8812 - val_54_categorical_accuracy: 0.8741\n",
      "Epoch 57/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 2.1351 - 03_loss: 0.3611 - 04_loss: 0.0620 - 13_loss: 0.4478 - 14_loss: 0.3927 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1256 - 44_loss: 0.5367 - 53_loss: 0.1277 - 54_loss: 0.0815 - 03_categorical_accuracy: 0.8208 - 04_categorical_accuracy: 0.9770 - 13_categorical_accuracy: 0.7891 - 14_categorical_accuracy: 0.8039 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9480 - 44_categorical_accuracy: 0.7535 - 53_categorical_accuracy: 0.9478 - 54_categorical_accuracy: 0.9601 - val_loss: 8.1717 - val_03_loss: 1.0433 - val_04_loss: 0.2858 - val_13_loss: 1.3157 - val_14_loss: 1.1654 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5115 - val_44_loss: 2.5047 - val_53_loss: 0.5097 - val_54_loss: 0.8357 - val_03_categorical_accuracy: 0.6153 - val_04_categorical_accuracy: 0.9512 - val_13_categorical_accuracy: 0.5630 - val_14_categorical_accuracy: 0.5955 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8817 - val_44_categorical_accuracy: 0.4518 - val_53_categorical_accuracy: 0.8839 - val_54_categorical_accuracy: 0.8743\n",
      "Epoch 58/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 2.1250 - 03_loss: 0.3595 - 04_loss: 0.0619 - 13_loss: 0.4445 - 14_loss: 0.3912 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1249 - 44_loss: 0.5348 - 53_loss: 0.1274 - 54_loss: 0.0809 - 03_categorical_accuracy: 0.8215 - 04_categorical_accuracy: 0.9771 - 13_categorical_accuracy: 0.7912 - 14_categorical_accuracy: 0.8046 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9479 - 44_categorical_accuracy: 0.7546 - 53_categorical_accuracy: 0.9476 - 54_categorical_accuracy: 0.9598 - val_loss: 8.0190 - val_03_loss: 1.0390 - val_04_loss: 0.2853 - val_13_loss: 1.2999 - val_14_loss: 1.1424 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5090 - val_44_loss: 2.4178 - val_53_loss: 0.5070 - val_54_loss: 0.8186 - val_03_categorical_accuracy: 0.6083 - val_04_categorical_accuracy: 0.9510 - val_13_categorical_accuracy: 0.5650 - val_14_categorical_accuracy: 0.5994 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8904 - val_44_categorical_accuracy: 0.4534 - val_53_categorical_accuracy: 0.8827 - val_54_categorical_accuracy: 0.8743\n",
      "Epoch 59/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 2.1115 - 03_loss: 0.3572 - 04_loss: 0.0616 - 13_loss: 0.4415 - 14_loss: 0.3885 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1243 - 44_loss: 0.5316 - 53_loss: 0.1264 - 54_loss: 0.0804 - 03_categorical_accuracy: 0.8228 - 04_categorical_accuracy: 0.9770 - 13_categorical_accuracy: 0.7928 - 14_categorical_accuracy: 0.8054 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9482 - 44_categorical_accuracy: 0.7547 - 53_categorical_accuracy: 0.9479 - 54_categorical_accuracy: 0.9597 - val_loss: 8.2487 - val_03_loss: 1.0591 - val_04_loss: 0.2937 - val_13_loss: 1.3277 - val_14_loss: 1.1618 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5242 - val_44_loss: 2.5040 - val_53_loss: 0.5145 - val_54_loss: 0.8638 - val_03_categorical_accuracy: 0.6068 - val_04_categorical_accuracy: 0.9527 - val_13_categorical_accuracy: 0.5690 - val_14_categorical_accuracy: 0.5989 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8894 - val_44_categorical_accuracy: 0.4549 - val_53_categorical_accuracy: 0.8795 - val_54_categorical_accuracy: 0.8762\n",
      "Epoch 60/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 2.0994 - 03_loss: 0.3559 - 04_loss: 0.0616 - 13_loss: 0.4383 - 14_loss: 0.3846 - 23_loss: 4.9503e-11 - 24_loss: 1.4650e-10 - 33_loss: 4.9503e-11 - 34_loss: 1.1105e-10 - 43_loss: 0.1235 - 44_loss: 0.5294 - 53_loss: 0.1257 - 54_loss: 0.0806 - 03_categorical_accuracy: 0.8231 - 04_categorical_accuracy: 0.9771 - 13_categorical_accuracy: 0.7937 - 14_categorical_accuracy: 0.8079 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9483 - 44_categorical_accuracy: 0.7565 - 53_categorical_accuracy: 0.9481 - 54_categorical_accuracy: 0.9597 - val_loss: 8.1975 - val_03_loss: 1.0487 - val_04_loss: 0.2929 - val_13_loss: 1.3242 - val_14_loss: 1.1660 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5155 - val_44_loss: 2.4945 - val_53_loss: 0.5111 - val_54_loss: 0.8447 - val_03_categorical_accuracy: 0.6142 - val_04_categorical_accuracy: 0.9512 - val_13_categorical_accuracy: 0.5646 - val_14_categorical_accuracy: 0.5941 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8886 - val_44_categorical_accuracy: 0.4479 - val_53_categorical_accuracy: 0.8821 - val_54_categorical_accuracy: 0.8772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 2.0883 - 03_loss: 0.3543 - 04_loss: 0.0615 - 13_loss: 0.4356 - 14_loss: 0.3831 - 23_loss: 0.0000e+00 - 24_loss: 2.3481e-10 - 33_loss: 0.0000e+00 - 34_loss: 1.1707e-10 - 43_loss: 0.1224 - 44_loss: 0.5271 - 53_loss: 0.1246 - 54_loss: 0.0798 - 03_categorical_accuracy: 0.8240 - 04_categorical_accuracy: 0.9772 - 13_categorical_accuracy: 0.7958 - 14_categorical_accuracy: 0.8090 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9491 - 44_categorical_accuracy: 0.7569 - 53_categorical_accuracy: 0.9482 - 54_categorical_accuracy: 0.9601 - val_loss: 8.2525 - val_03_loss: 1.0615 - val_04_loss: 0.2883 - val_13_loss: 1.3294 - val_14_loss: 1.1755 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5173 - val_44_loss: 2.5268 - val_53_loss: 0.5164 - val_54_loss: 0.8372 - val_03_categorical_accuracy: 0.6135 - val_04_categorical_accuracy: 0.9521 - val_13_categorical_accuracy: 0.5535 - val_14_categorical_accuracy: 0.5867 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8783 - val_44_categorical_accuracy: 0.4513 - val_53_categorical_accuracy: 0.8809 - val_54_categorical_accuracy: 0.8782\n",
      "Epoch 62/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 2.0796 - 03_loss: 0.3528 - 04_loss: 0.0613 - 13_loss: 0.4325 - 14_loss: 0.3819 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1227 - 44_loss: 0.5241 - 53_loss: 0.1243 - 54_loss: 0.0799 - 03_categorical_accuracy: 0.8246 - 04_categorical_accuracy: 0.9772 - 13_categorical_accuracy: 0.7962 - 14_categorical_accuracy: 0.8099 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9487 - 44_categorical_accuracy: 0.7579 - 53_categorical_accuracy: 0.9485 - 54_categorical_accuracy: 0.9598 - val_loss: 8.1602 - val_03_loss: 1.0491 - val_04_loss: 0.2822 - val_13_loss: 1.3233 - val_14_loss: 1.1618 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5164 - val_44_loss: 2.4439 - val_53_loss: 0.5231 - val_54_loss: 0.8604 - val_03_categorical_accuracy: 0.6189 - val_04_categorical_accuracy: 0.9524 - val_13_categorical_accuracy: 0.5612 - val_14_categorical_accuracy: 0.5902 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8842 - val_44_categorical_accuracy: 0.4516 - val_53_categorical_accuracy: 0.8743 - val_54_categorical_accuracy: 0.8793\n",
      "Epoch 63/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 2.0665 - 03_loss: 0.3503 - 04_loss: 0.0612 - 13_loss: 0.4297 - 14_loss: 0.3776 - 23_loss: 0.0000e+00 - 24_loss: 6.0876e-11 - 33_loss: 0.0000e+00 - 34_loss: 4.5490e-11 - 43_loss: 0.1219 - 44_loss: 0.5227 - 53_loss: 0.1234 - 54_loss: 0.0797 - 03_categorical_accuracy: 0.8267 - 04_categorical_accuracy: 0.9768 - 13_categorical_accuracy: 0.7971 - 14_categorical_accuracy: 0.8116 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9493 - 44_categorical_accuracy: 0.7590 - 53_categorical_accuracy: 0.9483 - 54_categorical_accuracy: 0.9597 - val_loss: 8.3579 - val_03_loss: 1.0707 - val_04_loss: 0.2914 - val_13_loss: 1.3617 - val_14_loss: 1.1920 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5203 - val_44_loss: 2.5246 - val_53_loss: 0.5280 - val_54_loss: 0.8693 - val_03_categorical_accuracy: 0.6109 - val_04_categorical_accuracy: 0.9524 - val_13_categorical_accuracy: 0.5696 - val_14_categorical_accuracy: 0.5958 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8787 - val_44_categorical_accuracy: 0.4569 - val_53_categorical_accuracy: 0.8798 - val_54_categorical_accuracy: 0.8731\n",
      "Epoch 64/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 2.0599 - 03_loss: 0.3500 - 04_loss: 0.0609 - 13_loss: 0.4284 - 14_loss: 0.3769 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1211 - 44_loss: 0.5206 - 53_loss: 0.1226 - 54_loss: 0.0794 - 03_categorical_accuracy: 0.8260 - 04_categorical_accuracy: 0.9773 - 13_categorical_accuracy: 0.7979 - 14_categorical_accuracy: 0.8111 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9489 - 44_categorical_accuracy: 0.7583 - 53_categorical_accuracy: 0.9489 - 54_categorical_accuracy: 0.9601 - val_loss: 8.3326 - val_03_loss: 1.0755 - val_04_loss: 0.2935 - val_13_loss: 1.3675 - val_14_loss: 1.2049 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5200 - val_44_loss: 2.4958 - val_53_loss: 0.5311 - val_54_loss: 0.8443 - val_03_categorical_accuracy: 0.6040 - val_04_categorical_accuracy: 0.9509 - val_13_categorical_accuracy: 0.5647 - val_14_categorical_accuracy: 0.5950 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8814 - val_44_categorical_accuracy: 0.4533 - val_53_categorical_accuracy: 0.8803 - val_54_categorical_accuracy: 0.8761\n",
      "Epoch 65/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 2.0478 - 03_loss: 0.3468 - 04_loss: 0.0612 - 13_loss: 0.4247 - 14_loss: 0.3739 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1200 - 44_loss: 0.5197 - 53_loss: 0.1223 - 54_loss: 0.0791 - 03_categorical_accuracy: 0.8270 - 04_categorical_accuracy: 0.9772 - 13_categorical_accuracy: 0.7995 - 14_categorical_accuracy: 0.8129 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9493 - 44_categorical_accuracy: 0.7595 - 53_categorical_accuracy: 0.9488 - 54_categorical_accuracy: 0.9603 - val_loss: 8.4223 - val_03_loss: 1.0885 - val_04_loss: 0.2900 - val_13_loss: 1.3783 - val_14_loss: 1.2006 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5253 - val_44_loss: 2.5558 - val_53_loss: 0.5254 - val_54_loss: 0.8584 - val_03_categorical_accuracy: 0.6108 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5645 - val_14_categorical_accuracy: 0.5947 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8861 - val_44_categorical_accuracy: 0.4496 - val_53_categorical_accuracy: 0.8821 - val_54_categorical_accuracy: 0.8783\n",
      "Epoch 66/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 2.0354 - 03_loss: 0.3453 - 04_loss: 0.0610 - 13_loss: 0.4222 - 14_loss: 0.3718 - 23_loss: 0.0000e+00 - 24_loss: 1.4650e-10 - 33_loss: 0.0000e+00 - 34_loss: 1.2978e-10 - 43_loss: 0.1197 - 44_loss: 0.5154 - 53_loss: 0.1214 - 54_loss: 0.0787 - 03_categorical_accuracy: 0.8277 - 04_categorical_accuracy: 0.9772 - 13_categorical_accuracy: 0.8004 - 14_categorical_accuracy: 0.8141 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9497 - 44_categorical_accuracy: 0.7604 - 53_categorical_accuracy: 0.9493 - 54_categorical_accuracy: 0.9603 - val_loss: 8.3416 - val_03_loss: 1.0736 - val_04_loss: 0.2945 - val_13_loss: 1.3637 - val_14_loss: 1.1911 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5224 - val_44_loss: 2.4967 - val_53_loss: 0.5312 - val_54_loss: 0.8682 - val_03_categorical_accuracy: 0.6147 - val_04_categorical_accuracy: 0.9506 - val_13_categorical_accuracy: 0.5610 - val_14_categorical_accuracy: 0.5955 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8816 - val_44_categorical_accuracy: 0.4480 - val_53_categorical_accuracy: 0.8811 - val_54_categorical_accuracy: 0.8781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 2.0297 - 03_loss: 0.3451 - 04_loss: 0.0612 - 13_loss: 0.4198 - 14_loss: 0.3705 - 23_loss: 0.0000e+00 - 24_loss: 9.4993e-11 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1192 - 44_loss: 0.5137 - 53_loss: 0.1213 - 54_loss: 0.0790 - 03_categorical_accuracy: 0.8272 - 04_categorical_accuracy: 0.9770 - 13_categorical_accuracy: 0.8010 - 14_categorical_accuracy: 0.8148 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9496 - 44_categorical_accuracy: 0.7607 - 53_categorical_accuracy: 0.9490 - 54_categorical_accuracy: 0.9601 - val_loss: 8.4777 - val_03_loss: 1.0840 - val_04_loss: 0.2973 - val_13_loss: 1.3915 - val_14_loss: 1.2159 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5221 - val_44_loss: 2.5894 - val_53_loss: 0.5290 - val_54_loss: 0.8485 - val_03_categorical_accuracy: 0.6048 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5667 - val_14_categorical_accuracy: 0.6014 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8833 - val_44_categorical_accuracy: 0.4485 - val_53_categorical_accuracy: 0.8754 - val_54_categorical_accuracy: 0.8748\n",
      "Epoch 68/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 2.0181 - 03_loss: 0.3428 - 04_loss: 0.0607 - 13_loss: 0.4163 - 14_loss: 0.3675 - 23_loss: 0.0000e+00 - 24_loss: 1.3312e-10 - 33_loss: 0.0000e+00 - 34_loss: 8.2951e-11 - 43_loss: 0.1186 - 44_loss: 0.5134 - 53_loss: 0.1207 - 54_loss: 0.0780 - 03_categorical_accuracy: 0.8281 - 04_categorical_accuracy: 0.9770 - 13_categorical_accuracy: 0.8027 - 14_categorical_accuracy: 0.8157 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9493 - 44_categorical_accuracy: 0.7605 - 53_categorical_accuracy: 0.9488 - 54_categorical_accuracy: 0.9604 - val_loss: 8.4976 - val_03_loss: 1.0958 - val_04_loss: 0.2930 - val_13_loss: 1.3882 - val_14_loss: 1.2167 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5290 - val_44_loss: 2.5559 - val_53_loss: 0.5343 - val_54_loss: 0.8848 - val_03_categorical_accuracy: 0.6097 - val_04_categorical_accuracy: 0.9511 - val_13_categorical_accuracy: 0.5587 - val_14_categorical_accuracy: 0.5890 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8797 - val_44_categorical_accuracy: 0.4491 - val_53_categorical_accuracy: 0.8761 - val_54_categorical_accuracy: 0.8806\n",
      "Epoch 69/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 2.0106 - 03_loss: 0.3420 - 04_loss: 0.0606 - 13_loss: 0.4150 - 14_loss: 0.3654 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1182 - 44_loss: 0.5117 - 53_loss: 0.1195 - 54_loss: 0.0781 - 03_categorical_accuracy: 0.8285 - 04_categorical_accuracy: 0.9772 - 13_categorical_accuracy: 0.8037 - 14_categorical_accuracy: 0.8163 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9495 - 44_categorical_accuracy: 0.7608 - 53_categorical_accuracy: 0.9494 - 54_categorical_accuracy: 0.9604 - val_loss: 8.6104 - val_03_loss: 1.0998 - val_04_loss: 0.2983 - val_13_loss: 1.4071 - val_14_loss: 1.2323 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5334 - val_44_loss: 2.6173 - val_53_loss: 0.5355 - val_54_loss: 0.8866 - val_03_categorical_accuracy: 0.6108 - val_04_categorical_accuracy: 0.9506 - val_13_categorical_accuracy: 0.5630 - val_14_categorical_accuracy: 0.5911 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8802 - val_44_categorical_accuracy: 0.4467 - val_53_categorical_accuracy: 0.8840 - val_54_categorical_accuracy: 0.8761\n",
      "Epoch 70/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 2.0010 - 03_loss: 0.3404 - 04_loss: 0.0606 - 13_loss: 0.4130 - 14_loss: 0.3635 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1175 - 44_loss: 0.5087 - 53_loss: 0.1194 - 54_loss: 0.0781 - 03_categorical_accuracy: 0.8289 - 04_categorical_accuracy: 0.9774 - 13_categorical_accuracy: 0.8038 - 14_categorical_accuracy: 0.8170 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9502 - 44_categorical_accuracy: 0.7618 - 53_categorical_accuracy: 0.9492 - 54_categorical_accuracy: 0.9606 - val_loss: 8.5466 - val_03_loss: 1.0991 - val_04_loss: 0.2972 - val_13_loss: 1.3980 - val_14_loss: 1.2327 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5266 - val_44_loss: 2.5724 - val_53_loss: 0.5330 - val_54_loss: 0.8876 - val_03_categorical_accuracy: 0.6094 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5574 - val_14_categorical_accuracy: 0.5985 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8760 - val_44_categorical_accuracy: 0.4494 - val_53_categorical_accuracy: 0.8832 - val_54_categorical_accuracy: 0.8765\n",
      "Epoch 71/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.9963 - 03_loss: 0.3391 - 04_loss: 0.0605 - 13_loss: 0.4112 - 14_loss: 0.3621 - 23_loss: 0.0000e+00 - 24_loss: 9.1648e-11 - 33_loss: 0.0000e+00 - 34_loss: 5.5524e-11 - 43_loss: 0.1173 - 44_loss: 0.5088 - 53_loss: 0.1195 - 54_loss: 0.0778 - 03_categorical_accuracy: 0.8294 - 04_categorical_accuracy: 0.9772 - 13_categorical_accuracy: 0.8047 - 14_categorical_accuracy: 0.8182 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9503 - 44_categorical_accuracy: 0.7616 - 53_categorical_accuracy: 0.9498 - 54_categorical_accuracy: 0.9604 - val_loss: 8.4988 - val_03_loss: 1.0917 - val_04_loss: 0.2874 - val_13_loss: 1.3968 - val_14_loss: 1.2333 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5243 - val_44_loss: 2.5589 - val_53_loss: 0.5315 - val_54_loss: 0.8750 - val_03_categorical_accuracy: 0.6136 - val_04_categorical_accuracy: 0.9512 - val_13_categorical_accuracy: 0.5602 - val_14_categorical_accuracy: 0.5865 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8735 - val_44_categorical_accuracy: 0.4485 - val_53_categorical_accuracy: 0.8803 - val_54_categorical_accuracy: 0.8756\n",
      "Epoch 72/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.9845 - 03_loss: 0.3382 - 04_loss: 0.0603 - 13_loss: 0.4083 - 14_loss: 0.3604 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1166 - 44_loss: 0.5053 - 53_loss: 0.1183 - 54_loss: 0.0771 - 03_categorical_accuracy: 0.8305 - 04_categorical_accuracy: 0.9775 - 13_categorical_accuracy: 0.8063 - 14_categorical_accuracy: 0.8187 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9504 - 44_categorical_accuracy: 0.7633 - 53_categorical_accuracy: 0.9499 - 54_categorical_accuracy: 0.9605 - val_loss: 8.6258 - val_03_loss: 1.0986 - val_04_loss: 0.2994 - val_13_loss: 1.4233 - val_14_loss: 1.2435 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5368 - val_44_loss: 2.6033 - val_53_loss: 0.5333 - val_54_loss: 0.8876 - val_03_categorical_accuracy: 0.6056 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5667 - val_14_categorical_accuracy: 0.5959 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8847 - val_44_categorical_accuracy: 0.4508 - val_53_categorical_accuracy: 0.8774 - val_54_categorical_accuracy: 0.8757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 1.9795 - 03_loss: 0.3363 - 04_loss: 0.0604 - 13_loss: 0.4071 - 14_loss: 0.3592 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1170 - 44_loss: 0.5043 - 53_loss: 0.1181 - 54_loss: 0.0773 - 03_categorical_accuracy: 0.8311 - 04_categorical_accuracy: 0.9772 - 13_categorical_accuracy: 0.8066 - 14_categorical_accuracy: 0.8200 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9498 - 44_categorical_accuracy: 0.7632 - 53_categorical_accuracy: 0.9501 - 54_categorical_accuracy: 0.9605 - val_loss: 8.6779 - val_03_loss: 1.1097 - val_04_loss: 0.2964 - val_13_loss: 1.4244 - val_14_loss: 1.2523 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5352 - val_44_loss: 2.6161 - val_53_loss: 0.5349 - val_54_loss: 0.9089 - val_03_categorical_accuracy: 0.6112 - val_04_categorical_accuracy: 0.9522 - val_13_categorical_accuracy: 0.5633 - val_14_categorical_accuracy: 0.5928 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8776 - val_44_categorical_accuracy: 0.4523 - val_53_categorical_accuracy: 0.8713 - val_54_categorical_accuracy: 0.8747\n",
      "Epoch 74/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.9716 - 03_loss: 0.3358 - 04_loss: 0.0601 - 13_loss: 0.4047 - 14_loss: 0.3571 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1160 - 44_loss: 0.5023 - 53_loss: 0.1184 - 54_loss: 0.0771 - 03_categorical_accuracy: 0.8308 - 04_categorical_accuracy: 0.9773 - 13_categorical_accuracy: 0.8071 - 14_categorical_accuracy: 0.8202 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9503 - 44_categorical_accuracy: 0.7648 - 53_categorical_accuracy: 0.9494 - 54_categorical_accuracy: 0.9605 - val_loss: 8.7754 - val_03_loss: 1.1193 - val_04_loss: 0.3089 - val_13_loss: 1.4401 - val_14_loss: 1.2488 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5377 - val_44_loss: 2.6695 - val_53_loss: 0.5393 - val_54_loss: 0.9118 - val_03_categorical_accuracy: 0.6082 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5571 - val_14_categorical_accuracy: 0.5898 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8836 - val_44_categorical_accuracy: 0.4589 - val_53_categorical_accuracy: 0.8740 - val_54_categorical_accuracy: 0.8736\n",
      "Epoch 75/1000\n",
      "697/697 [==============================] - 16s 22ms/step - loss: 1.9648 - 03_loss: 0.3339 - 04_loss: 0.0602 - 13_loss: 0.4024 - 14_loss: 0.3548 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1161 - 44_loss: 0.5030 - 53_loss: 0.1177 - 54_loss: 0.0767 - 03_categorical_accuracy: 0.8316 - 04_categorical_accuracy: 0.9775 - 13_categorical_accuracy: 0.8082 - 14_categorical_accuracy: 0.8208 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9502 - 44_categorical_accuracy: 0.7632 - 53_categorical_accuracy: 0.9497 - 54_categorical_accuracy: 0.9602 - val_loss: 8.7735 - val_03_loss: 1.1127 - val_04_loss: 0.3032 - val_13_loss: 1.4380 - val_14_loss: 1.2557 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5377 - val_44_loss: 2.6829 - val_53_loss: 0.5430 - val_54_loss: 0.9003 - val_03_categorical_accuracy: 0.6077 - val_04_categorical_accuracy: 0.9507 - val_13_categorical_accuracy: 0.5653 - val_14_categorical_accuracy: 0.5951 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8799 - val_44_categorical_accuracy: 0.4446 - val_53_categorical_accuracy: 0.8777 - val_54_categorical_accuracy: 0.8734\n",
      "Epoch 76/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 1.9574 - 03_loss: 0.3325 - 04_loss: 0.0601 - 13_loss: 0.4019 - 14_loss: 0.3536 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1153 - 44_loss: 0.5000 - 53_loss: 0.1173 - 54_loss: 0.0766 - 03_categorical_accuracy: 0.8333 - 04_categorical_accuracy: 0.9773 - 13_categorical_accuracy: 0.8083 - 14_categorical_accuracy: 0.8218 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9504 - 44_categorical_accuracy: 0.7651 - 53_categorical_accuracy: 0.9502 - 54_categorical_accuracy: 0.9606 - val_loss: 8.7812 - val_03_loss: 1.1139 - val_04_loss: 0.3090 - val_13_loss: 1.4446 - val_14_loss: 1.2723 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5354 - val_44_loss: 2.6513 - val_53_loss: 0.5382 - val_54_loss: 0.9163 - val_03_categorical_accuracy: 0.6098 - val_04_categorical_accuracy: 0.9506 - val_13_categorical_accuracy: 0.5562 - val_14_categorical_accuracy: 0.5885 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8768 - val_44_categorical_accuracy: 0.4501 - val_53_categorical_accuracy: 0.8760 - val_54_categorical_accuracy: 0.8763\n",
      "Epoch 77/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 1.9530 - 03_loss: 0.3323 - 04_loss: 0.0601 - 13_loss: 0.3994 - 14_loss: 0.3532 - 23_loss: 0.0000e+00 - 24_loss: 8.4289e-11 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1150 - 44_loss: 0.4996 - 53_loss: 0.1165 - 54_loss: 0.0768 - 03_categorical_accuracy: 0.8323 - 04_categorical_accuracy: 0.9773 - 13_categorical_accuracy: 0.8088 - 14_categorical_accuracy: 0.8220 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9502 - 44_categorical_accuracy: 0.7654 - 53_categorical_accuracy: 0.9502 - 54_categorical_accuracy: 0.9604 - val_loss: 8.6935 - val_03_loss: 1.1064 - val_04_loss: 0.2981 - val_13_loss: 1.4295 - val_14_loss: 1.2604 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5347 - val_44_loss: 2.6168 - val_53_loss: 0.5386 - val_54_loss: 0.9089 - val_03_categorical_accuracy: 0.6116 - val_04_categorical_accuracy: 0.9510 - val_13_categorical_accuracy: 0.5566 - val_14_categorical_accuracy: 0.5905 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8831 - val_44_categorical_accuracy: 0.4510 - val_53_categorical_accuracy: 0.8793 - val_54_categorical_accuracy: 0.8749\n",
      "Epoch 78/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.9420 - 03_loss: 0.3300 - 04_loss: 0.0599 - 13_loss: 0.3978 - 14_loss: 0.3504 - 23_loss: 0.0000e+00 - 24_loss: 1.6055e-11 - 33_loss: 0.0000e+00 - 34_loss: 3.0103e-11 - 43_loss: 0.1142 - 44_loss: 0.4977 - 53_loss: 0.1157 - 54_loss: 0.0764 - 03_categorical_accuracy: 0.8340 - 04_categorical_accuracy: 0.9775 - 13_categorical_accuracy: 0.8102 - 14_categorical_accuracy: 0.8236 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9512 - 44_categorical_accuracy: 0.7650 - 53_categorical_accuracy: 0.9507 - 54_categorical_accuracy: 0.9604 - val_loss: 8.6980 - val_03_loss: 1.1228 - val_04_loss: 0.2997 - val_13_loss: 1.4227 - val_14_loss: 1.2576 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5307 - val_44_loss: 2.6352 - val_53_loss: 0.5413 - val_54_loss: 0.8881 - val_03_categorical_accuracy: 0.6075 - val_04_categorical_accuracy: 0.9511 - val_13_categorical_accuracy: 0.5614 - val_14_categorical_accuracy: 0.5877 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8851 - val_44_categorical_accuracy: 0.4502 - val_53_categorical_accuracy: 0.8781 - val_54_categorical_accuracy: 0.8740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.9369 - 03_loss: 0.3300 - 04_loss: 0.0597 - 13_loss: 0.3957 - 14_loss: 0.3493 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1139 - 44_loss: 0.4958 - 53_loss: 0.1163 - 54_loss: 0.0763 - 03_categorical_accuracy: 0.8333 - 04_categorical_accuracy: 0.9775 - 13_categorical_accuracy: 0.8103 - 14_categorical_accuracy: 0.8233 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9509 - 44_categorical_accuracy: 0.7663 - 53_categorical_accuracy: 0.9497 - 54_categorical_accuracy: 0.9609 - val_loss: 8.8648 - val_03_loss: 1.1270 - val_04_loss: 0.3072 - val_13_loss: 1.4647 - val_14_loss: 1.2761 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5370 - val_44_loss: 2.6947 - val_53_loss: 0.5474 - val_54_loss: 0.9108 - val_03_categorical_accuracy: 0.6095 - val_04_categorical_accuracy: 0.9506 - val_13_categorical_accuracy: 0.5541 - val_14_categorical_accuracy: 0.5899 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8798 - val_44_categorical_accuracy: 0.4512 - val_53_categorical_accuracy: 0.8806 - val_54_categorical_accuracy: 0.8748\n",
      "Epoch 80/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.9322 - 03_loss: 0.3285 - 04_loss: 0.0600 - 13_loss: 0.3948 - 14_loss: 0.3472 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1140 - 44_loss: 0.4957 - 53_loss: 0.1157 - 54_loss: 0.0763 - 03_categorical_accuracy: 0.8342 - 04_categorical_accuracy: 0.9772 - 13_categorical_accuracy: 0.8113 - 14_categorical_accuracy: 0.8246 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9506 - 44_categorical_accuracy: 0.7657 - 53_categorical_accuracy: 0.9501 - 54_categorical_accuracy: 0.9605 - val_loss: 8.7319 - val_03_loss: 1.1196 - val_04_loss: 0.3092 - val_13_loss: 1.4463 - val_14_loss: 1.2568 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5359 - val_44_loss: 2.6034 - val_53_loss: 0.5463 - val_54_loss: 0.9144 - val_03_categorical_accuracy: 0.6091 - val_04_categorical_accuracy: 0.9501 - val_13_categorical_accuracy: 0.5586 - val_14_categorical_accuracy: 0.5940 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8810 - val_44_categorical_accuracy: 0.4488 - val_53_categorical_accuracy: 0.8805 - val_54_categorical_accuracy: 0.8738\n",
      "Epoch 81/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.9257 - 03_loss: 0.3268 - 04_loss: 0.0596 - 13_loss: 0.3930 - 14_loss: 0.3476 - 23_loss: 0.0000e+00 - 24_loss: 7.5593e-11 - 33_loss: 0.0000e+00 - 34_loss: 7.5593e-11 - 43_loss: 0.1137 - 44_loss: 0.4936 - 53_loss: 0.1154 - 54_loss: 0.0761 - 03_categorical_accuracy: 0.8346 - 04_categorical_accuracy: 0.9773 - 13_categorical_accuracy: 0.8112 - 14_categorical_accuracy: 0.8238 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9507 - 44_categorical_accuracy: 0.7668 - 53_categorical_accuracy: 0.9501 - 54_categorical_accuracy: 0.9609 - val_loss: 8.8846 - val_03_loss: 1.1290 - val_04_loss: 0.3083 - val_13_loss: 1.4529 - val_14_loss: 1.2870 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5443 - val_44_loss: 2.6831 - val_53_loss: 0.5386 - val_54_loss: 0.9414 - val_03_categorical_accuracy: 0.6049 - val_04_categorical_accuracy: 0.9526 - val_13_categorical_accuracy: 0.5561 - val_14_categorical_accuracy: 0.5922 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8770 - val_44_categorical_accuracy: 0.4518 - val_53_categorical_accuracy: 0.8802 - val_54_categorical_accuracy: 0.8761\n",
      "Epoch 82/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 1.9185 - 03_loss: 0.3268 - 04_loss: 0.0595 - 13_loss: 0.3904 - 14_loss: 0.3453 - 23_loss: 0.0000e+00 - 24_loss: 1.6390e-10 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1136 - 44_loss: 0.4924 - 53_loss: 0.1148 - 54_loss: 0.0759 - 03_categorical_accuracy: 0.8348 - 04_categorical_accuracy: 0.9774 - 13_categorical_accuracy: 0.8130 - 14_categorical_accuracy: 0.8255 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9508 - 44_categorical_accuracy: 0.7666 - 53_categorical_accuracy: 0.9505 - 54_categorical_accuracy: 0.9608 - val_loss: 8.7570 - val_03_loss: 1.1190 - val_04_loss: 0.3085 - val_13_loss: 1.4423 - val_14_loss: 1.2582 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5345 - val_44_loss: 2.6140 - val_53_loss: 0.5383 - val_54_loss: 0.9422 - val_03_categorical_accuracy: 0.6084 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5649 - val_14_categorical_accuracy: 0.5915 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8817 - val_44_categorical_accuracy: 0.4441 - val_53_categorical_accuracy: 0.8766 - val_54_categorical_accuracy: 0.8754\n",
      "Epoch 83/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.9139 - 03_loss: 0.3255 - 04_loss: 0.0596 - 13_loss: 0.3898 - 14_loss: 0.3445 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1127 - 44_loss: 0.4921 - 53_loss: 0.1142 - 54_loss: 0.0755 - 03_categorical_accuracy: 0.8347 - 04_categorical_accuracy: 0.9774 - 13_categorical_accuracy: 0.8131 - 14_categorical_accuracy: 0.8256 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9512 - 44_categorical_accuracy: 0.7667 - 53_categorical_accuracy: 0.9506 - 54_categorical_accuracy: 0.9610 - val_loss: 8.8878 - val_03_loss: 1.1363 - val_04_loss: 0.3157 - val_13_loss: 1.4801 - val_14_loss: 1.2783 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5437 - val_44_loss: 2.6623 - val_53_loss: 0.5513 - val_54_loss: 0.9202 - val_03_categorical_accuracy: 0.6028 - val_04_categorical_accuracy: 0.9521 - val_13_categorical_accuracy: 0.5564 - val_14_categorical_accuracy: 0.5953 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8772 - val_44_categorical_accuracy: 0.4512 - val_53_categorical_accuracy: 0.8790 - val_54_categorical_accuracy: 0.8732\n",
      "Epoch 84/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.9069 - 03_loss: 0.3245 - 04_loss: 0.0595 - 13_loss: 0.3887 - 14_loss: 0.3427 - 23_loss: 0.0000e+00 - 24_loss: 1.5854e-10 - 33_loss: 0.0000e+00 - 34_loss: 1.1974e-10 - 43_loss: 0.1125 - 44_loss: 0.4899 - 53_loss: 0.1137 - 54_loss: 0.0754 - 03_categorical_accuracy: 0.8359 - 04_categorical_accuracy: 0.9775 - 13_categorical_accuracy: 0.8123 - 14_categorical_accuracy: 0.8253 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9517 - 44_categorical_accuracy: 0.7676 - 53_categorical_accuracy: 0.9508 - 54_categorical_accuracy: 0.9610 - val_loss: 8.8497 - val_03_loss: 1.1220 - val_04_loss: 0.3103 - val_13_loss: 1.4633 - val_14_loss: 1.2871 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5379 - val_44_loss: 2.6666 - val_53_loss: 0.5414 - val_54_loss: 0.9212 - val_03_categorical_accuracy: 0.6112 - val_04_categorical_accuracy: 0.9520 - val_13_categorical_accuracy: 0.5677 - val_14_categorical_accuracy: 0.5926 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8786 - val_44_categorical_accuracy: 0.4489 - val_53_categorical_accuracy: 0.8803 - val_54_categorical_accuracy: 0.8723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.9045 - 03_loss: 0.3237 - 04_loss: 0.0595 - 13_loss: 0.3873 - 14_loss: 0.3420 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1126 - 44_loss: 0.4901 - 53_loss: 0.1139 - 54_loss: 0.0752 - 03_categorical_accuracy: 0.8351 - 04_categorical_accuracy: 0.9775 - 13_categorical_accuracy: 0.8130 - 14_categorical_accuracy: 0.8261 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9509 - 44_categorical_accuracy: 0.7669 - 53_categorical_accuracy: 0.9506 - 54_categorical_accuracy: 0.9608 - val_loss: 8.9471 - val_03_loss: 1.1302 - val_04_loss: 0.3107 - val_13_loss: 1.4718 - val_14_loss: 1.2928 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5444 - val_44_loss: 2.7195 - val_53_loss: 0.5432 - val_54_loss: 0.9344 - val_03_categorical_accuracy: 0.6147 - val_04_categorical_accuracy: 0.9504 - val_13_categorical_accuracy: 0.5622 - val_14_categorical_accuracy: 0.5864 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8779 - val_44_categorical_accuracy: 0.4508 - val_53_categorical_accuracy: 0.8757 - val_54_categorical_accuracy: 0.8770\n",
      "Epoch 86/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 1.8984 - 03_loss: 0.3234 - 04_loss: 0.0593 - 13_loss: 0.3860 - 14_loss: 0.3404 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1117 - 44_loss: 0.4890 - 53_loss: 0.1135 - 54_loss: 0.0752 - 03_categorical_accuracy: 0.8360 - 04_categorical_accuracy: 0.9777 - 13_categorical_accuracy: 0.8136 - 14_categorical_accuracy: 0.8266 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9514 - 44_categorical_accuracy: 0.7673 - 53_categorical_accuracy: 0.9509 - 54_categorical_accuracy: 0.9612 - val_loss: 8.9416 - val_03_loss: 1.1314 - val_04_loss: 0.3232 - val_13_loss: 1.4618 - val_14_loss: 1.2783 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5468 - val_44_loss: 2.6782 - val_53_loss: 0.5542 - val_54_loss: 0.9677 - val_03_categorical_accuracy: 0.6103 - val_04_categorical_accuracy: 0.9523 - val_13_categorical_accuracy: 0.5568 - val_14_categorical_accuracy: 0.5907 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8757 - val_44_categorical_accuracy: 0.4487 - val_53_categorical_accuracy: 0.8720 - val_54_categorical_accuracy: 0.8739\n",
      "Epoch 87/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 1.8933 - 03_loss: 0.3222 - 04_loss: 0.0592 - 13_loss: 0.3843 - 14_loss: 0.3390 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1119 - 44_loss: 0.4882 - 53_loss: 0.1134 - 54_loss: 0.0750 - 03_categorical_accuracy: 0.8361 - 04_categorical_accuracy: 0.9778 - 13_categorical_accuracy: 0.8148 - 14_categorical_accuracy: 0.8276 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9513 - 44_categorical_accuracy: 0.7679 - 53_categorical_accuracy: 0.9509 - 54_categorical_accuracy: 0.9611 - val_loss: 9.0328 - val_03_loss: 1.1450 - val_04_loss: 0.3253 - val_13_loss: 1.4872 - val_14_loss: 1.3039 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5393 - val_44_loss: 2.7443 - val_53_loss: 0.5503 - val_54_loss: 0.9375 - val_03_categorical_accuracy: 0.6093 - val_04_categorical_accuracy: 0.9520 - val_13_categorical_accuracy: 0.5604 - val_14_categorical_accuracy: 0.5920 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8764 - val_44_categorical_accuracy: 0.4468 - val_53_categorical_accuracy: 0.8788 - val_54_categorical_accuracy: 0.8767\n",
      "Epoch 88/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 1.8862 - 03_loss: 0.3214 - 04_loss: 0.0593 - 13_loss: 0.3826 - 14_loss: 0.3381 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1119 - 44_loss: 0.4855 - 53_loss: 0.1125 - 54_loss: 0.0750 - 03_categorical_accuracy: 0.8356 - 04_categorical_accuracy: 0.9774 - 13_categorical_accuracy: 0.8150 - 14_categorical_accuracy: 0.8274 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9511 - 44_categorical_accuracy: 0.7686 - 53_categorical_accuracy: 0.9510 - 54_categorical_accuracy: 0.9608 - val_loss: 8.9879 - val_03_loss: 1.1298 - val_04_loss: 0.3182 - val_13_loss: 1.4849 - val_14_loss: 1.3079 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5436 - val_44_loss: 2.7178 - val_53_loss: 0.5519 - val_54_loss: 0.9339 - val_03_categorical_accuracy: 0.6081 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5631 - val_14_categorical_accuracy: 0.5915 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8771 - val_44_categorical_accuracy: 0.4529 - val_53_categorical_accuracy: 0.8777 - val_54_categorical_accuracy: 0.8732\n",
      "Epoch 89/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.8817 - 03_loss: 0.3204 - 04_loss: 0.0591 - 13_loss: 0.3813 - 14_loss: 0.3378 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1114 - 44_loss: 0.4847 - 53_loss: 0.1128 - 54_loss: 0.0742 - 03_categorical_accuracy: 0.8368 - 04_categorical_accuracy: 0.9776 - 13_categorical_accuracy: 0.8154 - 14_categorical_accuracy: 0.8278 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9515 - 44_categorical_accuracy: 0.7699 - 53_categorical_accuracy: 0.9508 - 54_categorical_accuracy: 0.9614 - val_loss: 8.9434 - val_03_loss: 1.1391 - val_04_loss: 0.3164 - val_13_loss: 1.4739 - val_14_loss: 1.3062 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5477 - val_44_loss: 2.6797 - val_53_loss: 0.5481 - val_54_loss: 0.9323 - val_03_categorical_accuracy: 0.6034 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5656 - val_14_categorical_accuracy: 0.5967 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8832 - val_44_categorical_accuracy: 0.4497 - val_53_categorical_accuracy: 0.8739 - val_54_categorical_accuracy: 0.8761\n",
      "Epoch 90/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.8795 - 03_loss: 0.3199 - 04_loss: 0.0593 - 13_loss: 0.3815 - 14_loss: 0.3363 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1107 - 44_loss: 0.4850 - 53_loss: 0.1125 - 54_loss: 0.0743 - 03_categorical_accuracy: 0.8369 - 04_categorical_accuracy: 0.9776 - 13_categorical_accuracy: 0.8145 - 14_categorical_accuracy: 0.8283 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9517 - 44_categorical_accuracy: 0.7687 - 53_categorical_accuracy: 0.9513 - 54_categorical_accuracy: 0.9614 - val_loss: 8.9408 - val_03_loss: 1.1460 - val_04_loss: 0.3111 - val_13_loss: 1.4832 - val_14_loss: 1.2995 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5508 - val_44_loss: 2.6479 - val_53_loss: 0.5457 - val_54_loss: 0.9565 - val_03_categorical_accuracy: 0.6143 - val_04_categorical_accuracy: 0.9522 - val_13_categorical_accuracy: 0.5640 - val_14_categorical_accuracy: 0.5923 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8729 - val_44_categorical_accuracy: 0.4490 - val_53_categorical_accuracy: 0.8767 - val_54_categorical_accuracy: 0.8734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.8739 - 03_loss: 0.3187 - 04_loss: 0.0589 - 13_loss: 0.3799 - 14_loss: 0.3357 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1103 - 44_loss: 0.4843 - 53_loss: 0.1118 - 54_loss: 0.0744 - 03_categorical_accuracy: 0.8374 - 04_categorical_accuracy: 0.9776 - 13_categorical_accuracy: 0.8162 - 14_categorical_accuracy: 0.8286 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9518 - 44_categorical_accuracy: 0.7685 - 53_categorical_accuracy: 0.9511 - 54_categorical_accuracy: 0.9612 - val_loss: 9.0301 - val_03_loss: 1.1487 - val_04_loss: 0.3218 - val_13_loss: 1.4842 - val_14_loss: 1.3085 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5445 - val_44_loss: 2.7257 - val_53_loss: 0.5522 - val_54_loss: 0.9446 - val_03_categorical_accuracy: 0.6051 - val_04_categorical_accuracy: 0.9513 - val_13_categorical_accuracy: 0.5618 - val_14_categorical_accuracy: 0.5916 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8742 - val_44_categorical_accuracy: 0.4544 - val_53_categorical_accuracy: 0.8757 - val_54_categorical_accuracy: 0.8766\n",
      "Epoch 92/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.8672 - 03_loss: 0.3178 - 04_loss: 0.0589 - 13_loss: 0.3785 - 14_loss: 0.3343 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1098 - 44_loss: 0.4822 - 53_loss: 0.1116 - 54_loss: 0.0740 - 03_categorical_accuracy: 0.8376 - 04_categorical_accuracy: 0.9775 - 13_categorical_accuracy: 0.8154 - 14_categorical_accuracy: 0.8287 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9514 - 44_categorical_accuracy: 0.7688 - 53_categorical_accuracy: 0.9515 - 54_categorical_accuracy: 0.9612 - val_loss: 9.0131 - val_03_loss: 1.1560 - val_04_loss: 0.3185 - val_13_loss: 1.5005 - val_14_loss: 1.3047 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5476 - val_44_loss: 2.6943 - val_53_loss: 0.5456 - val_54_loss: 0.9458 - val_03_categorical_accuracy: 0.6054 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5626 - val_14_categorical_accuracy: 0.5932 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8757 - val_44_categorical_accuracy: 0.4479 - val_53_categorical_accuracy: 0.8781 - val_54_categorical_accuracy: 0.8742\n",
      "Epoch 93/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 1.8637 - 03_loss: 0.3171 - 04_loss: 0.0589 - 13_loss: 0.3773 - 14_loss: 0.3336 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1106 - 44_loss: 0.4812 - 53_loss: 0.1111 - 54_loss: 0.0738 - 03_categorical_accuracy: 0.8373 - 04_categorical_accuracy: 0.9776 - 13_categorical_accuracy: 0.8160 - 14_categorical_accuracy: 0.8290 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9514 - 44_categorical_accuracy: 0.7702 - 53_categorical_accuracy: 0.9513 - 54_categorical_accuracy: 0.9612 - val_loss: 9.0544 - val_03_loss: 1.1486 - val_04_loss: 0.3153 - val_13_loss: 1.5001 - val_14_loss: 1.3130 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5434 - val_44_loss: 2.7276 - val_53_loss: 0.5494 - val_54_loss: 0.9571 - val_03_categorical_accuracy: 0.6087 - val_04_categorical_accuracy: 0.9522 - val_13_categorical_accuracy: 0.5613 - val_14_categorical_accuracy: 0.5937 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8775 - val_44_categorical_accuracy: 0.4454 - val_53_categorical_accuracy: 0.8814 - val_54_categorical_accuracy: 0.8777\n",
      "Epoch 94/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 1.8591 - 03_loss: 0.3165 - 04_loss: 0.0589 - 13_loss: 0.3770 - 14_loss: 0.3320 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1101 - 44_loss: 0.4795 - 53_loss: 0.1114 - 54_loss: 0.0738 - 03_categorical_accuracy: 0.8380 - 04_categorical_accuracy: 0.9777 - 13_categorical_accuracy: 0.8165 - 14_categorical_accuracy: 0.8293 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9514 - 44_categorical_accuracy: 0.7707 - 53_categorical_accuracy: 0.9509 - 54_categorical_accuracy: 0.9613 - val_loss: 9.0323 - val_03_loss: 1.1554 - val_04_loss: 0.3139 - val_13_loss: 1.5038 - val_14_loss: 1.3143 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5442 - val_44_loss: 2.6883 - val_53_loss: 0.5470 - val_54_loss: 0.9654 - val_03_categorical_accuracy: 0.6141 - val_04_categorical_accuracy: 0.9505 - val_13_categorical_accuracy: 0.5600 - val_14_categorical_accuracy: 0.5914 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8762 - val_44_categorical_accuracy: 0.4496 - val_53_categorical_accuracy: 0.8830 - val_54_categorical_accuracy: 0.8740\n",
      "Epoch 95/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.8546 - 03_loss: 0.3163 - 04_loss: 0.0587 - 13_loss: 0.3749 - 14_loss: 0.3317 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1093 - 44_loss: 0.4792 - 53_loss: 0.1109 - 54_loss: 0.0736 - 03_categorical_accuracy: 0.8374 - 04_categorical_accuracy: 0.9776 - 13_categorical_accuracy: 0.8170 - 14_categorical_accuracy: 0.8295 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9514 - 44_categorical_accuracy: 0.7708 - 53_categorical_accuracy: 0.9515 - 54_categorical_accuracy: 0.9614 - val_loss: 9.1442 - val_03_loss: 1.1614 - val_04_loss: 0.3279 - val_13_loss: 1.5188 - val_14_loss: 1.3419 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5459 - val_44_loss: 2.7191 - val_53_loss: 0.5532 - val_54_loss: 0.9758 - val_03_categorical_accuracy: 0.6126 - val_04_categorical_accuracy: 0.9541 - val_13_categorical_accuracy: 0.5641 - val_14_categorical_accuracy: 0.5963 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8802 - val_44_categorical_accuracy: 0.4439 - val_53_categorical_accuracy: 0.8763 - val_54_categorical_accuracy: 0.8744\n",
      "Epoch 96/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.8532 - 03_loss: 0.3159 - 04_loss: 0.0588 - 13_loss: 0.3740 - 14_loss: 0.3316 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1095 - 44_loss: 0.4792 - 53_loss: 0.1107 - 54_loss: 0.0734 - 03_categorical_accuracy: 0.8371 - 04_categorical_accuracy: 0.9775 - 13_categorical_accuracy: 0.8180 - 14_categorical_accuracy: 0.8290 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9516 - 44_categorical_accuracy: 0.7704 - 53_categorical_accuracy: 0.9515 - 54_categorical_accuracy: 0.9613 - val_loss: 9.1109 - val_03_loss: 1.1444 - val_04_loss: 0.3236 - val_13_loss: 1.5024 - val_14_loss: 1.3168 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5445 - val_44_loss: 2.7296 - val_53_loss: 0.5559 - val_54_loss: 0.9936 - val_03_categorical_accuracy: 0.6070 - val_04_categorical_accuracy: 0.9509 - val_13_categorical_accuracy: 0.5595 - val_14_categorical_accuracy: 0.5869 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8741 - val_44_categorical_accuracy: 0.4499 - val_53_categorical_accuracy: 0.8808 - val_54_categorical_accuracy: 0.8735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.8478 - 03_loss: 0.3151 - 04_loss: 0.0586 - 13_loss: 0.3733 - 14_loss: 0.3298 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1095 - 44_loss: 0.4774 - 53_loss: 0.1104 - 54_loss: 0.0737 - 03_categorical_accuracy: 0.8379 - 04_categorical_accuracy: 0.9778 - 13_categorical_accuracy: 0.8177 - 14_categorical_accuracy: 0.8301 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9515 - 44_categorical_accuracy: 0.7704 - 53_categorical_accuracy: 0.9515 - 54_categorical_accuracy: 0.9612 - val_loss: 9.1181 - val_03_loss: 1.1396 - val_04_loss: 0.3193 - val_13_loss: 1.5072 - val_14_loss: 1.3224 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5471 - val_44_loss: 2.7956 - val_53_loss: 0.5503 - val_54_loss: 0.9365 - val_03_categorical_accuracy: 0.6086 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5562 - val_14_categorical_accuracy: 0.5908 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8757 - val_44_categorical_accuracy: 0.4453 - val_53_categorical_accuracy: 0.8773 - val_54_categorical_accuracy: 0.8743\n",
      "Epoch 98/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 1.8424 - 03_loss: 0.3143 - 04_loss: 0.0588 - 13_loss: 0.3720 - 14_loss: 0.3285 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1088 - 44_loss: 0.4768 - 53_loss: 0.1099 - 54_loss: 0.0734 - 03_categorical_accuracy: 0.8381 - 04_categorical_accuracy: 0.9777 - 13_categorical_accuracy: 0.8182 - 14_categorical_accuracy: 0.8307 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9519 - 44_categorical_accuracy: 0.7706 - 53_categorical_accuracy: 0.9516 - 54_categorical_accuracy: 0.9615 - val_loss: 9.0621 - val_03_loss: 1.1508 - val_04_loss: 0.3262 - val_13_loss: 1.5056 - val_14_loss: 1.3079 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5495 - val_44_loss: 2.7208 - val_53_loss: 0.5538 - val_54_loss: 0.9475 - val_03_categorical_accuracy: 0.6105 - val_04_categorical_accuracy: 0.9514 - val_13_categorical_accuracy: 0.5577 - val_14_categorical_accuracy: 0.5828 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8788 - val_44_categorical_accuracy: 0.4490 - val_53_categorical_accuracy: 0.8799 - val_54_categorical_accuracy: 0.8734\n",
      "Epoch 99/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 1.8399 - 03_loss: 0.3128 - 04_loss: 0.0588 - 13_loss: 0.3705 - 14_loss: 0.3288 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1090 - 44_loss: 0.4764 - 53_loss: 0.1103 - 54_loss: 0.0733 - 03_categorical_accuracy: 0.8390 - 04_categorical_accuracy: 0.9776 - 13_categorical_accuracy: 0.8188 - 14_categorical_accuracy: 0.8304 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9517 - 44_categorical_accuracy: 0.7708 - 53_categorical_accuracy: 0.9512 - 54_categorical_accuracy: 0.9615 - val_loss: 9.1839 - val_03_loss: 1.1566 - val_04_loss: 0.3256 - val_13_loss: 1.5147 - val_14_loss: 1.3343 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5511 - val_44_loss: 2.7838 - val_53_loss: 0.5533 - val_54_loss: 0.9645 - val_03_categorical_accuracy: 0.6068 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5586 - val_14_categorical_accuracy: 0.5939 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8735 - val_44_categorical_accuracy: 0.4483 - val_53_categorical_accuracy: 0.8744 - val_54_categorical_accuracy: 0.8736\n",
      "Epoch 100/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.8379 - 03_loss: 0.3126 - 04_loss: 0.0585 - 13_loss: 0.3714 - 14_loss: 0.3275 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1092 - 44_loss: 0.4761 - 53_loss: 0.1095 - 54_loss: 0.0730 - 03_categorical_accuracy: 0.8390 - 04_categorical_accuracy: 0.9776 - 13_categorical_accuracy: 0.8178 - 14_categorical_accuracy: 0.8312 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9516 - 44_categorical_accuracy: 0.7714 - 53_categorical_accuracy: 0.9512 - 54_categorical_accuracy: 0.9615 - val_loss: 9.2204 - val_03_loss: 1.1626 - val_04_loss: 0.3356 - val_13_loss: 1.5223 - val_14_loss: 1.3347 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5503 - val_44_loss: 2.7864 - val_53_loss: 0.5592 - val_54_loss: 0.9693 - val_03_categorical_accuracy: 0.6039 - val_04_categorical_accuracy: 0.9512 - val_13_categorical_accuracy: 0.5597 - val_14_categorical_accuracy: 0.5961 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8771 - val_44_categorical_accuracy: 0.4485 - val_53_categorical_accuracy: 0.8769 - val_54_categorical_accuracy: 0.8726\n",
      "Epoch 101/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.8338 - 03_loss: 0.3124 - 04_loss: 0.0585 - 13_loss: 0.3703 - 14_loss: 0.3268 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1086 - 44_loss: 0.4747 - 53_loss: 0.1097 - 54_loss: 0.0729 - 03_categorical_accuracy: 0.8385 - 04_categorical_accuracy: 0.9777 - 13_categorical_accuracy: 0.8184 - 14_categorical_accuracy: 0.8308 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9517 - 44_categorical_accuracy: 0.7708 - 53_categorical_accuracy: 0.9518 - 54_categorical_accuracy: 0.9612 - val_loss: 9.2612 - val_03_loss: 1.1679 - val_04_loss: 0.3270 - val_13_loss: 1.5252 - val_14_loss: 1.3305 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5575 - val_44_loss: 2.7980 - val_53_loss: 0.5551 - val_54_loss: 0.9999 - val_03_categorical_accuracy: 0.6141 - val_04_categorical_accuracy: 0.9511 - val_13_categorical_accuracy: 0.5560 - val_14_categorical_accuracy: 0.5906 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8828 - val_44_categorical_accuracy: 0.4479 - val_53_categorical_accuracy: 0.8797 - val_54_categorical_accuracy: 0.8752\n",
      "Epoch 102/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.8277 - 03_loss: 0.3114 - 04_loss: 0.0583 - 13_loss: 0.3690 - 14_loss: 0.3263 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1083 - 44_loss: 0.4729 - 53_loss: 0.1089 - 54_loss: 0.0726 - 03_categorical_accuracy: 0.8389 - 04_categorical_accuracy: 0.9777 - 13_categorical_accuracy: 0.8187 - 14_categorical_accuracy: 0.8306 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9522 - 44_categorical_accuracy: 0.7716 - 53_categorical_accuracy: 0.9518 - 54_categorical_accuracy: 0.9615 - val_loss: 9.1751 - val_03_loss: 1.1609 - val_04_loss: 0.3285 - val_13_loss: 1.5178 - val_14_loss: 1.3226 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5470 - val_44_loss: 2.7761 - val_53_loss: 0.5538 - val_54_loss: 0.9684 - val_03_categorical_accuracy: 0.6053 - val_04_categorical_accuracy: 0.9513 - val_13_categorical_accuracy: 0.5574 - val_14_categorical_accuracy: 0.5893 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8731 - val_44_categorical_accuracy: 0.4548 - val_53_categorical_accuracy: 0.8803 - val_54_categorical_accuracy: 0.8753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 1.8276 - 03_loss: 0.3109 - 04_loss: 0.0584 - 13_loss: 0.3689 - 14_loss: 0.3254 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1085 - 44_loss: 0.4736 - 53_loss: 0.1092 - 54_loss: 0.0727 - 03_categorical_accuracy: 0.8394 - 04_categorical_accuracy: 0.9779 - 13_categorical_accuracy: 0.8195 - 14_categorical_accuracy: 0.8321 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9514 - 44_categorical_accuracy: 0.7718 - 53_categorical_accuracy: 0.9517 - 54_categorical_accuracy: 0.9619 - val_loss: 9.1723 - val_03_loss: 1.1588 - val_04_loss: 0.3350 - val_13_loss: 1.5142 - val_14_loss: 1.3367 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5436 - val_44_loss: 2.7449 - val_53_loss: 0.5562 - val_54_loss: 0.9830 - val_03_categorical_accuracy: 0.6059 - val_04_categorical_accuracy: 0.9527 - val_13_categorical_accuracy: 0.5658 - val_14_categorical_accuracy: 0.5959 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8780 - val_44_categorical_accuracy: 0.4482 - val_53_categorical_accuracy: 0.8814 - val_54_categorical_accuracy: 0.8737\n",
      "Epoch 104/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 1.8214 - 03_loss: 0.3094 - 04_loss: 0.0583 - 13_loss: 0.3668 - 14_loss: 0.3243 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1081 - 44_loss: 0.4727 - 53_loss: 0.1091 - 54_loss: 0.0726 - 03_categorical_accuracy: 0.8402 - 04_categorical_accuracy: 0.9777 - 13_categorical_accuracy: 0.8194 - 14_categorical_accuracy: 0.8312 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9520 - 44_categorical_accuracy: 0.7722 - 53_categorical_accuracy: 0.9516 - 54_categorical_accuracy: 0.9621 - val_loss: 9.2250 - val_03_loss: 1.1693 - val_04_loss: 0.3298 - val_13_loss: 1.5294 - val_14_loss: 1.3293 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5512 - val_44_loss: 2.7558 - val_53_loss: 0.5574 - val_54_loss: 1.0027 - val_03_categorical_accuracy: 0.6118 - val_04_categorical_accuracy: 0.9507 - val_13_categorical_accuracy: 0.5524 - val_14_categorical_accuracy: 0.5845 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8799 - val_44_categorical_accuracy: 0.4487 - val_53_categorical_accuracy: 0.8743 - val_54_categorical_accuracy: 0.8756\n",
      "Epoch 105/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.8174 - 03_loss: 0.3101 - 04_loss: 0.0582 - 13_loss: 0.3662 - 14_loss: 0.3237 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1073 - 44_loss: 0.4711 - 53_loss: 0.1085 - 54_loss: 0.0724 - 03_categorical_accuracy: 0.8388 - 04_categorical_accuracy: 0.9778 - 13_categorical_accuracy: 0.8196 - 14_categorical_accuracy: 0.8316 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9521 - 44_categorical_accuracy: 0.7718 - 53_categorical_accuracy: 0.9517 - 54_categorical_accuracy: 0.9618 - val_loss: 9.3190 - val_03_loss: 1.1658 - val_04_loss: 0.3335 - val_13_loss: 1.5389 - val_14_loss: 1.3549 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5485 - val_44_loss: 2.7960 - val_53_loss: 0.5648 - val_54_loss: 1.0167 - val_03_categorical_accuracy: 0.6109 - val_04_categorical_accuracy: 0.9511 - val_13_categorical_accuracy: 0.5592 - val_14_categorical_accuracy: 0.5903 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8732 - val_44_categorical_accuracy: 0.4491 - val_53_categorical_accuracy: 0.8784 - val_54_categorical_accuracy: 0.8700\n",
      "Epoch 106/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.8159 - 03_loss: 0.3096 - 04_loss: 0.0581 - 13_loss: 0.3662 - 14_loss: 0.3227 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1074 - 44_loss: 0.4709 - 53_loss: 0.1084 - 54_loss: 0.0725 - 03_categorical_accuracy: 0.8390 - 04_categorical_accuracy: 0.9777 - 13_categorical_accuracy: 0.8193 - 14_categorical_accuracy: 0.8323 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9517 - 44_categorical_accuracy: 0.7732 - 53_categorical_accuracy: 0.9518 - 54_categorical_accuracy: 0.9615 - val_loss: 9.1490 - val_03_loss: 1.1618 - val_04_loss: 0.3323 - val_13_loss: 1.5040 - val_14_loss: 1.3230 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5520 - val_44_loss: 2.7339 - val_53_loss: 0.5555 - val_54_loss: 0.9865 - val_03_categorical_accuracy: 0.6148 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5629 - val_14_categorical_accuracy: 0.5946 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8765 - val_44_categorical_accuracy: 0.4497 - val_53_categorical_accuracy: 0.8782 - val_54_categorical_accuracy: 0.8727\n",
      "Epoch 107/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.8098 - 03_loss: 0.3087 - 04_loss: 0.0582 - 13_loss: 0.3643 - 14_loss: 0.3213 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1073 - 44_loss: 0.4702 - 53_loss: 0.1079 - 54_loss: 0.0720 - 03_categorical_accuracy: 0.8400 - 04_categorical_accuracy: 0.9778 - 13_categorical_accuracy: 0.8202 - 14_categorical_accuracy: 0.8318 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9520 - 44_categorical_accuracy: 0.7717 - 53_categorical_accuracy: 0.9522 - 54_categorical_accuracy: 0.9619 - val_loss: 9.2559 - val_03_loss: 1.1580 - val_04_loss: 0.3333 - val_13_loss: 1.5350 - val_14_loss: 1.3394 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5549 - val_44_loss: 2.7712 - val_53_loss: 0.5591 - val_54_loss: 1.0049 - val_03_categorical_accuracy: 0.6088 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5643 - val_14_categorical_accuracy: 0.5945 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8791 - val_44_categorical_accuracy: 0.4508 - val_53_categorical_accuracy: 0.8747 - val_54_categorical_accuracy: 0.8738\n",
      "Epoch 108/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.8078 - 03_loss: 0.3081 - 04_loss: 0.0580 - 13_loss: 0.3637 - 14_loss: 0.3214 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1068 - 44_loss: 0.4693 - 53_loss: 0.1083 - 54_loss: 0.0722 - 03_categorical_accuracy: 0.8404 - 04_categorical_accuracy: 0.9780 - 13_categorical_accuracy: 0.8205 - 14_categorical_accuracy: 0.8330 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9528 - 44_categorical_accuracy: 0.7732 - 53_categorical_accuracy: 0.9521 - 54_categorical_accuracy: 0.9617 - val_loss: 9.3345 - val_03_loss: 1.1519 - val_04_loss: 0.3326 - val_13_loss: 1.5317 - val_14_loss: 1.3553 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5526 - val_44_loss: 2.8077 - val_53_loss: 0.5625 - val_54_loss: 1.0402 - val_03_categorical_accuracy: 0.6022 - val_04_categorical_accuracy: 0.9517 - val_13_categorical_accuracy: 0.5589 - val_14_categorical_accuracy: 0.5888 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8776 - val_44_categorical_accuracy: 0.4476 - val_53_categorical_accuracy: 0.8770 - val_54_categorical_accuracy: 0.8783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.8057 - 03_loss: 0.3064 - 04_loss: 0.0580 - 13_loss: 0.3632 - 14_loss: 0.3210 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1075 - 44_loss: 0.4694 - 53_loss: 0.1083 - 54_loss: 0.0719 - 03_categorical_accuracy: 0.8400 - 04_categorical_accuracy: 0.9778 - 13_categorical_accuracy: 0.8199 - 14_categorical_accuracy: 0.8325 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9516 - 44_categorical_accuracy: 0.7720 - 53_categorical_accuracy: 0.9516 - 54_categorical_accuracy: 0.9618 - val_loss: 9.3142 - val_03_loss: 1.1724 - val_04_loss: 0.3356 - val_13_loss: 1.5430 - val_14_loss: 1.3603 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5554 - val_44_loss: 2.7967 - val_53_loss: 0.5533 - val_54_loss: 0.9974 - val_03_categorical_accuracy: 0.6049 - val_04_categorical_accuracy: 0.9513 - val_13_categorical_accuracy: 0.5648 - val_14_categorical_accuracy: 0.5945 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8802 - val_44_categorical_accuracy: 0.4495 - val_53_categorical_accuracy: 0.8754 - val_54_categorical_accuracy: 0.8751\n",
      "Epoch 110/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.8000 - 03_loss: 0.3067 - 04_loss: 0.0581 - 13_loss: 0.3618 - 14_loss: 0.3203 - 23_loss: 0.0000e+00 - 24_loss: 4.4152e-11 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1066 - 44_loss: 0.4673 - 53_loss: 0.1076 - 54_loss: 0.0716 - 03_categorical_accuracy: 0.8398 - 04_categorical_accuracy: 0.9781 - 13_categorical_accuracy: 0.8204 - 14_categorical_accuracy: 0.8323 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9524 - 44_categorical_accuracy: 0.7728 - 53_categorical_accuracy: 0.9522 - 54_categorical_accuracy: 0.9620 - val_loss: 9.2527 - val_03_loss: 1.1742 - val_04_loss: 0.3314 - val_13_loss: 1.5230 - val_14_loss: 1.3367 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5466 - val_44_loss: 2.7738 - val_53_loss: 0.5548 - val_54_loss: 1.0121 - val_03_categorical_accuracy: 0.6061 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5563 - val_14_categorical_accuracy: 0.5909 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8782 - val_44_categorical_accuracy: 0.4515 - val_53_categorical_accuracy: 0.8785 - val_54_categorical_accuracy: 0.8763\n",
      "Epoch 111/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7992 - 03_loss: 0.3068 - 04_loss: 0.0580 - 13_loss: 0.3611 - 14_loss: 0.3196 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1063 - 44_loss: 0.4680 - 53_loss: 0.1076 - 54_loss: 0.0718 - 03_categorical_accuracy: 0.8404 - 04_categorical_accuracy: 0.9780 - 13_categorical_accuracy: 0.8213 - 14_categorical_accuracy: 0.8330 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9523 - 44_categorical_accuracy: 0.7727 - 53_categorical_accuracy: 0.9519 - 54_categorical_accuracy: 0.9623 - val_loss: 9.3750 - val_03_loss: 1.1726 - val_04_loss: 0.3456 - val_13_loss: 1.5396 - val_14_loss: 1.3617 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5516 - val_44_loss: 2.8251 - val_53_loss: 0.5601 - val_54_loss: 1.0186 - val_03_categorical_accuracy: 0.6077 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5605 - val_14_categorical_accuracy: 0.5929 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8799 - val_44_categorical_accuracy: 0.4482 - val_53_categorical_accuracy: 0.8775 - val_54_categorical_accuracy: 0.8731\n",
      "Epoch 112/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7950 - 03_loss: 0.3063 - 04_loss: 0.0579 - 13_loss: 0.3606 - 14_loss: 0.3185 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1062 - 44_loss: 0.4667 - 53_loss: 0.1077 - 54_loss: 0.0713 - 03_categorical_accuracy: 0.8406 - 04_categorical_accuracy: 0.9781 - 13_categorical_accuracy: 0.8214 - 14_categorical_accuracy: 0.8336 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9521 - 44_categorical_accuracy: 0.7738 - 53_categorical_accuracy: 0.9517 - 54_categorical_accuracy: 0.9624 - val_loss: 9.4237 - val_03_loss: 1.1675 - val_04_loss: 0.3411 - val_13_loss: 1.5435 - val_14_loss: 1.3638 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5586 - val_44_loss: 2.8582 - val_53_loss: 0.5649 - val_54_loss: 1.0262 - val_03_categorical_accuracy: 0.6105 - val_04_categorical_accuracy: 0.9512 - val_13_categorical_accuracy: 0.5581 - val_14_categorical_accuracy: 0.5884 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8755 - val_44_categorical_accuracy: 0.4462 - val_53_categorical_accuracy: 0.8822 - val_54_categorical_accuracy: 0.8732\n",
      "Epoch 113/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7901 - 03_loss: 0.3052 - 04_loss: 0.0578 - 13_loss: 0.3590 - 14_loss: 0.3176 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1062 - 44_loss: 0.4657 - 53_loss: 0.1075 - 54_loss: 0.0711 - 03_categorical_accuracy: 0.8413 - 04_categorical_accuracy: 0.9781 - 13_categorical_accuracy: 0.8212 - 14_categorical_accuracy: 0.8342 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9525 - 44_categorical_accuracy: 0.7737 - 53_categorical_accuracy: 0.9522 - 54_categorical_accuracy: 0.9619 - val_loss: 9.4515 - val_03_loss: 1.1788 - val_04_loss: 0.3429 - val_13_loss: 1.5581 - val_14_loss: 1.3783 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5563 - val_44_loss: 2.8451 - val_53_loss: 0.5627 - val_54_loss: 1.0293 - val_03_categorical_accuracy: 0.6072 - val_04_categorical_accuracy: 0.9509 - val_13_categorical_accuracy: 0.5640 - val_14_categorical_accuracy: 0.5886 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8813 - val_44_categorical_accuracy: 0.4433 - val_53_categorical_accuracy: 0.8730 - val_54_categorical_accuracy: 0.8721\n",
      "Epoch 114/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7882 - 03_loss: 0.3043 - 04_loss: 0.0579 - 13_loss: 0.3592 - 14_loss: 0.3174 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1059 - 44_loss: 0.4657 - 53_loss: 0.1065 - 54_loss: 0.0713 - 03_categorical_accuracy: 0.8410 - 04_categorical_accuracy: 0.9779 - 13_categorical_accuracy: 0.8218 - 14_categorical_accuracy: 0.8336 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9526 - 44_categorical_accuracy: 0.7738 - 53_categorical_accuracy: 0.9523 - 54_categorical_accuracy: 0.9625 - val_loss: 9.3499 - val_03_loss: 1.1676 - val_04_loss: 0.3370 - val_13_loss: 1.5402 - val_14_loss: 1.3464 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5586 - val_44_loss: 2.8217 - val_53_loss: 0.5646 - val_54_loss: 1.0138 - val_03_categorical_accuracy: 0.6055 - val_04_categorical_accuracy: 0.9521 - val_13_categorical_accuracy: 0.5620 - val_14_categorical_accuracy: 0.5908 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8849 - val_44_categorical_accuracy: 0.4466 - val_53_categorical_accuracy: 0.8847 - val_54_categorical_accuracy: 0.8765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7864 - 03_loss: 0.3048 - 04_loss: 0.0577 - 13_loss: 0.3577 - 14_loss: 0.3165 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1060 - 44_loss: 0.4657 - 53_loss: 0.1066 - 54_loss: 0.0712 - 03_categorical_accuracy: 0.8406 - 04_categorical_accuracy: 0.9780 - 13_categorical_accuracy: 0.8217 - 14_categorical_accuracy: 0.8347 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9521 - 44_categorical_accuracy: 0.7738 - 53_categorical_accuracy: 0.9525 - 54_categorical_accuracy: 0.9622 - val_loss: 9.3249 - val_03_loss: 1.1555 - val_04_loss: 0.3448 - val_13_loss: 1.5504 - val_14_loss: 1.3491 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5550 - val_44_loss: 2.8015 - val_53_loss: 0.5632 - val_54_loss: 1.0055 - val_03_categorical_accuracy: 0.6064 - val_04_categorical_accuracy: 0.9522 - val_13_categorical_accuracy: 0.5602 - val_14_categorical_accuracy: 0.5918 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8776 - val_44_categorical_accuracy: 0.4501 - val_53_categorical_accuracy: 0.8786 - val_54_categorical_accuracy: 0.8728\n",
      "Epoch 116/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 1.7838 - 03_loss: 0.3038 - 04_loss: 0.0579 - 13_loss: 0.3574 - 14_loss: 0.3169 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1057 - 44_loss: 0.4642 - 53_loss: 0.1068 - 54_loss: 0.0712 - 03_categorical_accuracy: 0.8420 - 04_categorical_accuracy: 0.9780 - 13_categorical_accuracy: 0.8213 - 14_categorical_accuracy: 0.8332 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9524 - 44_categorical_accuracy: 0.7741 - 53_categorical_accuracy: 0.9519 - 54_categorical_accuracy: 0.9623 - val_loss: 9.4768 - val_03_loss: 1.1890 - val_04_loss: 0.3443 - val_13_loss: 1.5563 - val_14_loss: 1.3758 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5614 - val_44_loss: 2.8320 - val_53_loss: 0.5690 - val_54_loss: 1.0489 - val_03_categorical_accuracy: 0.6067 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5553 - val_14_categorical_accuracy: 0.5891 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8776 - val_44_categorical_accuracy: 0.4518 - val_53_categorical_accuracy: 0.8779 - val_54_categorical_accuracy: 0.8751\n",
      "Epoch 117/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7793 - 03_loss: 0.3032 - 04_loss: 0.0576 - 13_loss: 0.3563 - 14_loss: 0.3159 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1048 - 44_loss: 0.4642 - 53_loss: 0.1061 - 54_loss: 0.0711 - 03_categorical_accuracy: 0.8412 - 04_categorical_accuracy: 0.9781 - 13_categorical_accuracy: 0.8221 - 14_categorical_accuracy: 0.8340 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9528 - 44_categorical_accuracy: 0.7735 - 53_categorical_accuracy: 0.9522 - 54_categorical_accuracy: 0.9625 - val_loss: 9.3816 - val_03_loss: 1.1663 - val_04_loss: 0.3435 - val_13_loss: 1.5311 - val_14_loss: 1.3419 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5514 - val_44_loss: 2.8554 - val_53_loss: 0.5572 - val_54_loss: 1.0347 - val_03_categorical_accuracy: 0.6109 - val_04_categorical_accuracy: 0.9513 - val_13_categorical_accuracy: 0.5612 - val_14_categorical_accuracy: 0.5911 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8812 - val_44_categorical_accuracy: 0.4453 - val_53_categorical_accuracy: 0.8766 - val_54_categorical_accuracy: 0.8748\n",
      "Epoch 118/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7766 - 03_loss: 0.3035 - 04_loss: 0.0577 - 13_loss: 0.3555 - 14_loss: 0.3140 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1051 - 44_loss: 0.4634 - 53_loss: 0.1061 - 54_loss: 0.0712 - 03_categorical_accuracy: 0.8411 - 04_categorical_accuracy: 0.9779 - 13_categorical_accuracy: 0.8229 - 14_categorical_accuracy: 0.8349 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9526 - 44_categorical_accuracy: 0.7739 - 53_categorical_accuracy: 0.9523 - 54_categorical_accuracy: 0.9623 - val_loss: 9.5435 - val_03_loss: 1.1923 - val_04_loss: 0.3368 - val_13_loss: 1.5655 - val_14_loss: 1.3911 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5638 - val_44_loss: 2.8786 - val_53_loss: 0.5683 - val_54_loss: 1.0473 - val_03_categorical_accuracy: 0.6080 - val_04_categorical_accuracy: 0.9510 - val_13_categorical_accuracy: 0.5593 - val_14_categorical_accuracy: 0.5843 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8794 - val_44_categorical_accuracy: 0.4444 - val_53_categorical_accuracy: 0.8773 - val_54_categorical_accuracy: 0.8733\n",
      "Epoch 119/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7767 - 03_loss: 0.3027 - 04_loss: 0.0578 - 13_loss: 0.3566 - 14_loss: 0.3149 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1051 - 44_loss: 0.4626 - 53_loss: 0.1062 - 54_loss: 0.0708 - 03_categorical_accuracy: 0.8417 - 04_categorical_accuracy: 0.9780 - 13_categorical_accuracy: 0.8209 - 14_categorical_accuracy: 0.8339 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9528 - 44_categorical_accuracy: 0.7739 - 53_categorical_accuracy: 0.9527 - 54_categorical_accuracy: 0.9621 - val_loss: 9.3426 - val_03_loss: 1.1690 - val_04_loss: 0.3436 - val_13_loss: 1.5473 - val_14_loss: 1.3436 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5581 - val_44_loss: 2.8231 - val_53_loss: 0.5517 - val_54_loss: 1.0062 - val_03_categorical_accuracy: 0.5981 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5622 - val_14_categorical_accuracy: 0.5909 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8841 - val_44_categorical_accuracy: 0.4489 - val_53_categorical_accuracy: 0.8789 - val_54_categorical_accuracy: 0.8718\n",
      "Epoch 120/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7727 - 03_loss: 0.3022 - 04_loss: 0.0576 - 13_loss: 0.3545 - 14_loss: 0.3133 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1049 - 44_loss: 0.4626 - 53_loss: 0.1065 - 54_loss: 0.0710 - 03_categorical_accuracy: 0.8415 - 04_categorical_accuracy: 0.9782 - 13_categorical_accuracy: 0.8228 - 14_categorical_accuracy: 0.8347 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9525 - 44_categorical_accuracy: 0.7736 - 53_categorical_accuracy: 0.9524 - 54_categorical_accuracy: 0.9619 - val_loss: 9.4573 - val_03_loss: 1.1837 - val_04_loss: 0.3428 - val_13_loss: 1.5498 - val_14_loss: 1.3629 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5595 - val_44_loss: 2.8560 - val_53_loss: 0.5639 - val_54_loss: 1.0387 - val_03_categorical_accuracy: 0.6126 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5555 - val_14_categorical_accuracy: 0.5907 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8753 - val_44_categorical_accuracy: 0.4487 - val_53_categorical_accuracy: 0.8775 - val_54_categorical_accuracy: 0.8739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 1.7687 - 03_loss: 0.3020 - 04_loss: 0.0576 - 13_loss: 0.3538 - 14_loss: 0.3131 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1046 - 44_loss: 0.4613 - 53_loss: 0.1055 - 54_loss: 0.0706 - 03_categorical_accuracy: 0.8415 - 04_categorical_accuracy: 0.9782 - 13_categorical_accuracy: 0.8227 - 14_categorical_accuracy: 0.8344 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9525 - 44_categorical_accuracy: 0.7740 - 53_categorical_accuracy: 0.9527 - 54_categorical_accuracy: 0.9619 - val_loss: 9.4273 - val_03_loss: 1.1831 - val_04_loss: 0.3491 - val_13_loss: 1.5658 - val_14_loss: 1.3749 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5592 - val_44_loss: 2.8124 - val_53_loss: 0.5639 - val_54_loss: 1.0189 - val_03_categorical_accuracy: 0.6089 - val_04_categorical_accuracy: 0.9512 - val_13_categorical_accuracy: 0.5584 - val_14_categorical_accuracy: 0.5902 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8785 - val_44_categorical_accuracy: 0.4527 - val_53_categorical_accuracy: 0.8693 - val_54_categorical_accuracy: 0.8737\n",
      "Epoch 122/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7666 - 03_loss: 0.3009 - 04_loss: 0.0576 - 13_loss: 0.3533 - 14_loss: 0.3129 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1047 - 44_loss: 0.4608 - 53_loss: 0.1059 - 54_loss: 0.0705 - 03_categorical_accuracy: 0.8417 - 04_categorical_accuracy: 0.9781 - 13_categorical_accuracy: 0.8228 - 14_categorical_accuracy: 0.8351 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9529 - 44_categorical_accuracy: 0.7743 - 53_categorical_accuracy: 0.9524 - 54_categorical_accuracy: 0.9625 - val_loss: 9.4801 - val_03_loss: 1.1827 - val_04_loss: 0.3455 - val_13_loss: 1.5497 - val_14_loss: 1.3721 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5556 - val_44_loss: 2.8543 - val_53_loss: 0.5623 - val_54_loss: 1.0579 - val_03_categorical_accuracy: 0.6103 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5604 - val_14_categorical_accuracy: 0.5898 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8784 - val_44_categorical_accuracy: 0.4467 - val_53_categorical_accuracy: 0.8742 - val_54_categorical_accuracy: 0.8717\n",
      "Epoch 123/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7637 - 03_loss: 0.2999 - 04_loss: 0.0576 - 13_loss: 0.3527 - 14_loss: 0.3119 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1044 - 44_loss: 0.4609 - 53_loss: 0.1058 - 54_loss: 0.0705 - 03_categorical_accuracy: 0.8428 - 04_categorical_accuracy: 0.9780 - 13_categorical_accuracy: 0.8232 - 14_categorical_accuracy: 0.8353 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9528 - 44_categorical_accuracy: 0.7744 - 53_categorical_accuracy: 0.9523 - 54_categorical_accuracy: 0.9626 - val_loss: 9.4828 - val_03_loss: 1.1765 - val_04_loss: 0.3443 - val_13_loss: 1.5652 - val_14_loss: 1.3835 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5590 - val_44_loss: 2.8433 - val_53_loss: 0.5591 - val_54_loss: 1.0520 - val_03_categorical_accuracy: 0.6044 - val_04_categorical_accuracy: 0.9509 - val_13_categorical_accuracy: 0.5619 - val_14_categorical_accuracy: 0.5924 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8771 - val_44_categorical_accuracy: 0.4431 - val_53_categorical_accuracy: 0.8719 - val_54_categorical_accuracy: 0.8744\n",
      "Epoch 124/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 1.7608 - 03_loss: 0.2998 - 04_loss: 0.0574 - 13_loss: 0.3519 - 14_loss: 0.3116 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1041 - 44_loss: 0.4604 - 53_loss: 0.1054 - 54_loss: 0.0702 - 03_categorical_accuracy: 0.8423 - 04_categorical_accuracy: 0.9782 - 13_categorical_accuracy: 0.8226 - 14_categorical_accuracy: 0.8353 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9525 - 44_categorical_accuracy: 0.7735 - 53_categorical_accuracy: 0.9525 - 54_categorical_accuracy: 0.9628 - val_loss: 9.5643 - val_03_loss: 1.1873 - val_04_loss: 0.3506 - val_13_loss: 1.5902 - val_14_loss: 1.3862 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5688 - val_44_loss: 2.8551 - val_53_loss: 0.5709 - val_54_loss: 1.0553 - val_03_categorical_accuracy: 0.6033 - val_04_categorical_accuracy: 0.9510 - val_13_categorical_accuracy: 0.5637 - val_14_categorical_accuracy: 0.5892 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8807 - val_44_categorical_accuracy: 0.4488 - val_53_categorical_accuracy: 0.8767 - val_54_categorical_accuracy: 0.8728\n",
      "Epoch 125/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 1.7597 - 03_loss: 0.3003 - 04_loss: 0.0574 - 13_loss: 0.3517 - 14_loss: 0.3113 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1045 - 44_loss: 0.4588 - 53_loss: 0.1053 - 54_loss: 0.0703 - 03_categorical_accuracy: 0.8416 - 04_categorical_accuracy: 0.9780 - 13_categorical_accuracy: 0.8228 - 14_categorical_accuracy: 0.8347 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9528 - 44_categorical_accuracy: 0.7747 - 53_categorical_accuracy: 0.9526 - 54_categorical_accuracy: 0.9622 - val_loss: 9.6676 - val_03_loss: 1.1915 - val_04_loss: 0.3512 - val_13_loss: 1.5901 - val_14_loss: 1.4056 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5618 - val_44_loss: 2.9169 - val_53_loss: 0.5717 - val_54_loss: 1.0788 - val_03_categorical_accuracy: 0.6084 - val_04_categorical_accuracy: 0.9509 - val_13_categorical_accuracy: 0.5614 - val_14_categorical_accuracy: 0.5891 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8775 - val_44_categorical_accuracy: 0.4497 - val_53_categorical_accuracy: 0.8742 - val_54_categorical_accuracy: 0.8755\n",
      "Epoch 126/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7550 - 03_loss: 0.2989 - 04_loss: 0.0574 - 13_loss: 0.3508 - 14_loss: 0.3106 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1034 - 44_loss: 0.4591 - 53_loss: 0.1047 - 54_loss: 0.0701 - 03_categorical_accuracy: 0.8423 - 04_categorical_accuracy: 0.9780 - 13_categorical_accuracy: 0.8231 - 14_categorical_accuracy: 0.8355 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9528 - 44_categorical_accuracy: 0.7740 - 53_categorical_accuracy: 0.9526 - 54_categorical_accuracy: 0.9627 - val_loss: 9.5568 - val_03_loss: 1.1761 - val_04_loss: 0.3502 - val_13_loss: 1.5652 - val_14_loss: 1.3870 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5752 - val_44_loss: 2.8641 - val_53_loss: 0.5716 - val_54_loss: 1.0674 - val_03_categorical_accuracy: 0.6043 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5604 - val_14_categorical_accuracy: 0.5940 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8822 - val_44_categorical_accuracy: 0.4510 - val_53_categorical_accuracy: 0.8772 - val_54_categorical_accuracy: 0.8723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7524 - 03_loss: 0.2988 - 04_loss: 0.0574 - 13_loss: 0.3497 - 14_loss: 0.3096 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1043 - 44_loss: 0.4578 - 53_loss: 0.1046 - 54_loss: 0.0701 - 03_categorical_accuracy: 0.8416 - 04_categorical_accuracy: 0.9783 - 13_categorical_accuracy: 0.8240 - 14_categorical_accuracy: 0.8353 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9525 - 44_categorical_accuracy: 0.7751 - 53_categorical_accuracy: 0.9525 - 54_categorical_accuracy: 0.9627 - val_loss: 9.5879 - val_03_loss: 1.1940 - val_04_loss: 0.3480 - val_13_loss: 1.5765 - val_14_loss: 1.3913 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5645 - val_44_loss: 2.8691 - val_53_loss: 0.5688 - val_54_loss: 1.0759 - val_03_categorical_accuracy: 0.6073 - val_04_categorical_accuracy: 0.9506 - val_13_categorical_accuracy: 0.5603 - val_14_categorical_accuracy: 0.5904 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8798 - val_44_categorical_accuracy: 0.4519 - val_53_categorical_accuracy: 0.8766 - val_54_categorical_accuracy: 0.8744\n",
      "Epoch 128/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7518 - 03_loss: 0.2990 - 04_loss: 0.0573 - 13_loss: 0.3501 - 14_loss: 0.3094 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1037 - 44_loss: 0.4577 - 53_loss: 0.1046 - 54_loss: 0.0700 - 03_categorical_accuracy: 0.8428 - 04_categorical_accuracy: 0.9783 - 13_categorical_accuracy: 0.8235 - 14_categorical_accuracy: 0.8352 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9528 - 44_categorical_accuracy: 0.7748 - 53_categorical_accuracy: 0.9524 - 54_categorical_accuracy: 0.9626 - val_loss: 9.6611 - val_03_loss: 1.1934 - val_04_loss: 0.3475 - val_13_loss: 1.5838 - val_14_loss: 1.4080 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5737 - val_44_loss: 2.9250 - val_53_loss: 0.5684 - val_54_loss: 1.0614 - val_03_categorical_accuracy: 0.6151 - val_04_categorical_accuracy: 0.9505 - val_13_categorical_accuracy: 0.5573 - val_14_categorical_accuracy: 0.5848 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8804 - val_44_categorical_accuracy: 0.4497 - val_53_categorical_accuracy: 0.8748 - val_54_categorical_accuracy: 0.8753\n",
      "Epoch 129/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7484 - 03_loss: 0.2984 - 04_loss: 0.0572 - 13_loss: 0.3484 - 14_loss: 0.3092 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1036 - 44_loss: 0.4573 - 53_loss: 0.1046 - 54_loss: 0.0698 - 03_categorical_accuracy: 0.8425 - 04_categorical_accuracy: 0.9782 - 13_categorical_accuracy: 0.8243 - 14_categorical_accuracy: 0.8358 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9527 - 44_categorical_accuracy: 0.7756 - 53_categorical_accuracy: 0.9527 - 54_categorical_accuracy: 0.9627 - val_loss: 9.6126 - val_03_loss: 1.1923 - val_04_loss: 0.3487 - val_13_loss: 1.5810 - val_14_loss: 1.3888 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5666 - val_44_loss: 2.8884 - val_53_loss: 0.5658 - val_54_loss: 1.0810 - val_03_categorical_accuracy: 0.6030 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5568 - val_14_categorical_accuracy: 0.5889 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8803 - val_44_categorical_accuracy: 0.4475 - val_53_categorical_accuracy: 0.8754 - val_54_categorical_accuracy: 0.8747\n",
      "Epoch 130/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7466 - 03_loss: 0.2981 - 04_loss: 0.0573 - 13_loss: 0.3481 - 14_loss: 0.3084 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1039 - 44_loss: 0.4559 - 53_loss: 0.1048 - 54_loss: 0.0700 - 03_categorical_accuracy: 0.8415 - 04_categorical_accuracy: 0.9783 - 13_categorical_accuracy: 0.8244 - 14_categorical_accuracy: 0.8360 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9526 - 44_categorical_accuracy: 0.7752 - 53_categorical_accuracy: 0.9525 - 54_categorical_accuracy: 0.9625 - val_loss: 9.7517 - val_03_loss: 1.1975 - val_04_loss: 0.3592 - val_13_loss: 1.6127 - val_14_loss: 1.4150 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5603 - val_44_loss: 2.9450 - val_53_loss: 0.5691 - val_54_loss: 1.0931 - val_03_categorical_accuracy: 0.6022 - val_04_categorical_accuracy: 0.9521 - val_13_categorical_accuracy: 0.5582 - val_14_categorical_accuracy: 0.5930 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8803 - val_44_categorical_accuracy: 0.4488 - val_53_categorical_accuracy: 0.8773 - val_54_categorical_accuracy: 0.8735\n",
      "Epoch 131/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7436 - 03_loss: 0.2970 - 04_loss: 0.0574 - 13_loss: 0.3484 - 14_loss: 0.3074 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1035 - 44_loss: 0.4560 - 53_loss: 0.1039 - 54_loss: 0.0699 - 03_categorical_accuracy: 0.8424 - 04_categorical_accuracy: 0.9783 - 13_categorical_accuracy: 0.8237 - 14_categorical_accuracy: 0.8368 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9524 - 44_categorical_accuracy: 0.7755 - 53_categorical_accuracy: 0.9529 - 54_categorical_accuracy: 0.9630 - val_loss: 9.6021 - val_03_loss: 1.1839 - val_04_loss: 0.3613 - val_13_loss: 1.5766 - val_14_loss: 1.4045 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5608 - val_44_loss: 2.8920 - val_53_loss: 0.5727 - val_54_loss: 1.0504 - val_03_categorical_accuracy: 0.6109 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5607 - val_14_categorical_accuracy: 0.5867 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8778 - val_44_categorical_accuracy: 0.4478 - val_53_categorical_accuracy: 0.8759 - val_54_categorical_accuracy: 0.8763\n",
      "Epoch 132/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7386 - 03_loss: 0.2968 - 04_loss: 0.0572 - 13_loss: 0.3466 - 14_loss: 0.3071 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1032 - 44_loss: 0.4545 - 53_loss: 0.1037 - 54_loss: 0.0695 - 03_categorical_accuracy: 0.8431 - 04_categorical_accuracy: 0.9783 - 13_categorical_accuracy: 0.8242 - 14_categorical_accuracy: 0.8365 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9530 - 44_categorical_accuracy: 0.7761 - 53_categorical_accuracy: 0.9529 - 54_categorical_accuracy: 0.9630 - val_loss: 9.6066 - val_03_loss: 1.1805 - val_04_loss: 0.3502 - val_13_loss: 1.5721 - val_14_loss: 1.4041 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5626 - val_44_loss: 2.9080 - val_53_loss: 0.5691 - val_54_loss: 1.0601 - val_03_categorical_accuracy: 0.6078 - val_04_categorical_accuracy: 0.9521 - val_13_categorical_accuracy: 0.5628 - val_14_categorical_accuracy: 0.5931 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8799 - val_44_categorical_accuracy: 0.4439 - val_53_categorical_accuracy: 0.8795 - val_54_categorical_accuracy: 0.8747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7384 - 03_loss: 0.2964 - 04_loss: 0.0571 - 13_loss: 0.3468 - 14_loss: 0.3067 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1028 - 44_loss: 0.4549 - 53_loss: 0.1041 - 54_loss: 0.0695 - 03_categorical_accuracy: 0.8425 - 04_categorical_accuracy: 0.9783 - 13_categorical_accuracy: 0.8246 - 14_categorical_accuracy: 0.8370 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9532 - 44_categorical_accuracy: 0.7751 - 53_categorical_accuracy: 0.9523 - 54_categorical_accuracy: 0.9632 - val_loss: 9.7273 - val_03_loss: 1.2064 - val_04_loss: 0.3666 - val_13_loss: 1.5986 - val_14_loss: 1.4103 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5739 - val_44_loss: 2.9473 - val_53_loss: 0.5654 - val_54_loss: 1.0587 - val_03_categorical_accuracy: 0.6086 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5584 - val_14_categorical_accuracy: 0.5912 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8790 - val_44_categorical_accuracy: 0.4469 - val_53_categorical_accuracy: 0.8805 - val_54_categorical_accuracy: 0.8738\n",
      "Epoch 134/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7382 - 03_loss: 0.2964 - 04_loss: 0.0573 - 13_loss: 0.3463 - 14_loss: 0.3068 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1033 - 44_loss: 0.4547 - 53_loss: 0.1039 - 54_loss: 0.0696 - 03_categorical_accuracy: 0.8427 - 04_categorical_accuracy: 0.9782 - 13_categorical_accuracy: 0.8240 - 14_categorical_accuracy: 0.8365 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9529 - 44_categorical_accuracy: 0.7753 - 53_categorical_accuracy: 0.9530 - 54_categorical_accuracy: 0.9627 - val_loss: 9.7615 - val_03_loss: 1.1860 - val_04_loss: 0.3673 - val_13_loss: 1.5938 - val_14_loss: 1.4062 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5739 - val_44_loss: 2.9695 - val_53_loss: 0.5793 - val_54_loss: 1.0856 - val_03_categorical_accuracy: 0.6103 - val_04_categorical_accuracy: 0.9512 - val_13_categorical_accuracy: 0.5560 - val_14_categorical_accuracy: 0.5902 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8764 - val_44_categorical_accuracy: 0.4494 - val_53_categorical_accuracy: 0.8742 - val_54_categorical_accuracy: 0.8754\n",
      "Epoch 135/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 1.7356 - 03_loss: 0.2961 - 04_loss: 0.0571 - 13_loss: 0.3460 - 14_loss: 0.3060 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1034 - 44_loss: 0.4543 - 53_loss: 0.1033 - 54_loss: 0.0694 - 03_categorical_accuracy: 0.8426 - 04_categorical_accuracy: 0.9783 - 13_categorical_accuracy: 0.8247 - 14_categorical_accuracy: 0.8369 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9526 - 44_categorical_accuracy: 0.7756 - 53_categorical_accuracy: 0.9531 - 54_categorical_accuracy: 0.9627 - val_loss: 9.8288 - val_03_loss: 1.2133 - val_04_loss: 0.3682 - val_13_loss: 1.6026 - val_14_loss: 1.4224 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5720 - val_44_loss: 2.9514 - val_53_loss: 0.5848 - val_54_loss: 1.1140 - val_03_categorical_accuracy: 0.6090 - val_04_categorical_accuracy: 0.9512 - val_13_categorical_accuracy: 0.5571 - val_14_categorical_accuracy: 0.5877 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8774 - val_44_categorical_accuracy: 0.4497 - val_53_categorical_accuracy: 0.8805 - val_54_categorical_accuracy: 0.8717\n",
      "Epoch 136/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7315 - 03_loss: 0.2952 - 04_loss: 0.0571 - 13_loss: 0.3454 - 14_loss: 0.3060 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1024 - 44_loss: 0.4527 - 53_loss: 0.1036 - 54_loss: 0.0691 - 03_categorical_accuracy: 0.8434 - 04_categorical_accuracy: 0.9782 - 13_categorical_accuracy: 0.8241 - 14_categorical_accuracy: 0.8366 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9533 - 44_categorical_accuracy: 0.7766 - 53_categorical_accuracy: 0.9528 - 54_categorical_accuracy: 0.9632 - val_loss: 9.7263 - val_03_loss: 1.1837 - val_04_loss: 0.3601 - val_13_loss: 1.5957 - val_14_loss: 1.4004 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5718 - val_44_loss: 2.9399 - val_53_loss: 0.5790 - val_54_loss: 1.0957 - val_03_categorical_accuracy: 0.6022 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5554 - val_14_categorical_accuracy: 0.5902 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8799 - val_44_categorical_accuracy: 0.4512 - val_53_categorical_accuracy: 0.8785 - val_54_categorical_accuracy: 0.8737\n",
      "Epoch 137/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7302 - 03_loss: 0.2953 - 04_loss: 0.0570 - 13_loss: 0.3444 - 14_loss: 0.3052 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1028 - 44_loss: 0.4530 - 53_loss: 0.1030 - 54_loss: 0.0695 - 03_categorical_accuracy: 0.8430 - 04_categorical_accuracy: 0.9782 - 13_categorical_accuracy: 0.8249 - 14_categorical_accuracy: 0.8373 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9526 - 44_categorical_accuracy: 0.7760 - 53_categorical_accuracy: 0.9529 - 54_categorical_accuracy: 0.9631 - val_loss: 9.7915 - val_03_loss: 1.1981 - val_04_loss: 0.3685 - val_13_loss: 1.6101 - val_14_loss: 1.4023 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5742 - val_44_loss: 2.9655 - val_53_loss: 0.5724 - val_54_loss: 1.1006 - val_03_categorical_accuracy: 0.6075 - val_04_categorical_accuracy: 0.9520 - val_13_categorical_accuracy: 0.5565 - val_14_categorical_accuracy: 0.5855 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8807 - val_44_categorical_accuracy: 0.4491 - val_53_categorical_accuracy: 0.8740 - val_54_categorical_accuracy: 0.8721\n",
      "Epoch 138/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7283 - 03_loss: 0.2946 - 04_loss: 0.0572 - 13_loss: 0.3434 - 14_loss: 0.3045 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1023 - 44_loss: 0.4538 - 53_loss: 0.1034 - 54_loss: 0.0691 - 03_categorical_accuracy: 0.8434 - 04_categorical_accuracy: 0.9783 - 13_categorical_accuracy: 0.8254 - 14_categorical_accuracy: 0.8373 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9530 - 44_categorical_accuracy: 0.7757 - 53_categorical_accuracy: 0.9530 - 54_categorical_accuracy: 0.9630 - val_loss: 9.8756 - val_03_loss: 1.2095 - val_04_loss: 0.3654 - val_13_loss: 1.6174 - val_14_loss: 1.4276 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5741 - val_44_loss: 2.9548 - val_53_loss: 0.5774 - val_54_loss: 1.1494 - val_03_categorical_accuracy: 0.6082 - val_04_categorical_accuracy: 0.9517 - val_13_categorical_accuracy: 0.5570 - val_14_categorical_accuracy: 0.5876 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8737 - val_44_categorical_accuracy: 0.4478 - val_53_categorical_accuracy: 0.8768 - val_54_categorical_accuracy: 0.8756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 1.7267 - 03_loss: 0.2947 - 04_loss: 0.0571 - 13_loss: 0.3447 - 14_loss: 0.3047 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1021 - 44_loss: 0.4513 - 53_loss: 0.1030 - 54_loss: 0.0690 - 03_categorical_accuracy: 0.8434 - 04_categorical_accuracy: 0.9784 - 13_categorical_accuracy: 0.8250 - 14_categorical_accuracy: 0.8369 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9532 - 44_categorical_accuracy: 0.7762 - 53_categorical_accuracy: 0.9526 - 54_categorical_accuracy: 0.9630 - val_loss: 9.8883 - val_03_loss: 1.2043 - val_04_loss: 0.3628 - val_13_loss: 1.6154 - val_14_loss: 1.4371 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5713 - val_44_loss: 2.9941 - val_53_loss: 0.5822 - val_54_loss: 1.1212 - val_03_categorical_accuracy: 0.6051 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5556 - val_14_categorical_accuracy: 0.5901 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8786 - val_44_categorical_accuracy: 0.4506 - val_53_categorical_accuracy: 0.8780 - val_54_categorical_accuracy: 0.8728\n",
      "Epoch 140/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 1.7221 - 03_loss: 0.2937 - 04_loss: 0.0568 - 13_loss: 0.3426 - 14_loss: 0.3035 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1016 - 44_loss: 0.4515 - 53_loss: 0.1031 - 54_loss: 0.0691 - 03_categorical_accuracy: 0.8434 - 04_categorical_accuracy: 0.9785 - 13_categorical_accuracy: 0.8255 - 14_categorical_accuracy: 0.8377 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9536 - 44_categorical_accuracy: 0.7765 - 53_categorical_accuracy: 0.9529 - 54_categorical_accuracy: 0.9629 - val_loss: 9.8603 - val_03_loss: 1.2033 - val_04_loss: 0.3616 - val_13_loss: 1.6000 - val_14_loss: 1.4281 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5790 - val_44_loss: 2.9872 - val_53_loss: 0.5726 - val_54_loss: 1.1284 - val_03_categorical_accuracy: 0.6065 - val_04_categorical_accuracy: 0.9513 - val_13_categorical_accuracy: 0.5620 - val_14_categorical_accuracy: 0.5897 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8786 - val_44_categorical_accuracy: 0.4496 - val_53_categorical_accuracy: 0.8732 - val_54_categorical_accuracy: 0.8768\n",
      "Epoch 141/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7228 - 03_loss: 0.2946 - 04_loss: 0.0569 - 13_loss: 0.3428 - 14_loss: 0.3029 - 23_loss: 0.0000e+00 - 24_loss: 1.7928e-10 - 33_loss: 0.0000e+00 - 34_loss: 3.9469e-11 - 43_loss: 0.1022 - 44_loss: 0.4515 - 53_loss: 0.1028 - 54_loss: 0.0690 - 03_categorical_accuracy: 0.8432 - 04_categorical_accuracy: 0.9785 - 13_categorical_accuracy: 0.8257 - 14_categorical_accuracy: 0.8378 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9530 - 44_categorical_accuracy: 0.7760 - 53_categorical_accuracy: 0.9529 - 54_categorical_accuracy: 0.9630 - val_loss: 9.8565 - val_03_loss: 1.2005 - val_04_loss: 0.3679 - val_13_loss: 1.6126 - val_14_loss: 1.4207 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5694 - val_44_loss: 3.0195 - val_53_loss: 0.5712 - val_54_loss: 1.0946 - val_03_categorical_accuracy: 0.6089 - val_04_categorical_accuracy: 0.9517 - val_13_categorical_accuracy: 0.5635 - val_14_categorical_accuracy: 0.5916 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8807 - val_44_categorical_accuracy: 0.4428 - val_53_categorical_accuracy: 0.8731 - val_54_categorical_accuracy: 0.8725\n",
      "Epoch 142/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7176 - 03_loss: 0.2932 - 04_loss: 0.0568 - 13_loss: 0.3409 - 14_loss: 0.3028 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1018 - 44_loss: 0.4512 - 53_loss: 0.1027 - 54_loss: 0.0683 - 03_categorical_accuracy: 0.8436 - 04_categorical_accuracy: 0.9782 - 13_categorical_accuracy: 0.8259 - 14_categorical_accuracy: 0.8366 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9531 - 44_categorical_accuracy: 0.7763 - 53_categorical_accuracy: 0.9533 - 54_categorical_accuracy: 0.9636 - val_loss: 9.8390 - val_03_loss: 1.1925 - val_04_loss: 0.3676 - val_13_loss: 1.6124 - val_14_loss: 1.4256 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5778 - val_44_loss: 2.9625 - val_53_loss: 0.5742 - val_54_loss: 1.1263 - val_03_categorical_accuracy: 0.6142 - val_04_categorical_accuracy: 0.9517 - val_13_categorical_accuracy: 0.5556 - val_14_categorical_accuracy: 0.5851 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8811 - val_44_categorical_accuracy: 0.4496 - val_53_categorical_accuracy: 0.8784 - val_54_categorical_accuracy: 0.8741\n",
      "Epoch 143/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7186 - 03_loss: 0.2933 - 04_loss: 0.0568 - 13_loss: 0.3420 - 14_loss: 0.3023 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1021 - 44_loss: 0.4505 - 53_loss: 0.1028 - 54_loss: 0.0688 - 03_categorical_accuracy: 0.8441 - 04_categorical_accuracy: 0.9784 - 13_categorical_accuracy: 0.8257 - 14_categorical_accuracy: 0.8380 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9529 - 44_categorical_accuracy: 0.7771 - 53_categorical_accuracy: 0.9528 - 54_categorical_accuracy: 0.9631 - val_loss: 9.8560 - val_03_loss: 1.1968 - val_04_loss: 0.3712 - val_13_loss: 1.6144 - val_14_loss: 1.4287 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5726 - val_44_loss: 2.9778 - val_53_loss: 0.5808 - val_54_loss: 1.1138 - val_03_categorical_accuracy: 0.6114 - val_04_categorical_accuracy: 0.9511 - val_13_categorical_accuracy: 0.5591 - val_14_categorical_accuracy: 0.5852 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8764 - val_44_categorical_accuracy: 0.4465 - val_53_categorical_accuracy: 0.8752 - val_54_categorical_accuracy: 0.8759\n",
      "Epoch 144/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7158 - 03_loss: 0.2928 - 04_loss: 0.0568 - 13_loss: 0.3412 - 14_loss: 0.3021 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1016 - 44_loss: 0.4495 - 53_loss: 0.1029 - 54_loss: 0.0689 - 03_categorical_accuracy: 0.8438 - 04_categorical_accuracy: 0.9786 - 13_categorical_accuracy: 0.8257 - 14_categorical_accuracy: 0.8381 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9532 - 44_categorical_accuracy: 0.7773 - 53_categorical_accuracy: 0.9533 - 54_categorical_accuracy: 0.9631 - val_loss: 9.7244 - val_03_loss: 1.1884 - val_04_loss: 0.3751 - val_13_loss: 1.6007 - val_14_loss: 1.4087 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5680 - val_44_loss: 2.9224 - val_53_loss: 0.5681 - val_54_loss: 1.0930 - val_03_categorical_accuracy: 0.6090 - val_04_categorical_accuracy: 0.9523 - val_13_categorical_accuracy: 0.5592 - val_14_categorical_accuracy: 0.5903 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8775 - val_44_categorical_accuracy: 0.4449 - val_53_categorical_accuracy: 0.8813 - val_54_categorical_accuracy: 0.8734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7143 - 03_loss: 0.2926 - 04_loss: 0.0569 - 13_loss: 0.3410 - 14_loss: 0.3014 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1014 - 44_loss: 0.4496 - 53_loss: 0.1025 - 54_loss: 0.0689 - 03_categorical_accuracy: 0.8428 - 04_categorical_accuracy: 0.9783 - 13_categorical_accuracy: 0.8258 - 14_categorical_accuracy: 0.8370 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9535 - 44_categorical_accuracy: 0.7764 - 53_categorical_accuracy: 0.9531 - 54_categorical_accuracy: 0.9632 - val_loss: 9.9018 - val_03_loss: 1.1974 - val_04_loss: 0.3767 - val_13_loss: 1.6023 - val_14_loss: 1.4310 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5798 - val_44_loss: 3.0097 - val_53_loss: 0.5742 - val_54_loss: 1.1306 - val_03_categorical_accuracy: 0.6120 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5599 - val_14_categorical_accuracy: 0.5888 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8781 - val_44_categorical_accuracy: 0.4458 - val_53_categorical_accuracy: 0.8775 - val_54_categorical_accuracy: 0.8732\n",
      "Epoch 146/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7114 - 03_loss: 0.2925 - 04_loss: 0.0570 - 13_loss: 0.3395 - 14_loss: 0.3009 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1015 - 44_loss: 0.4489 - 53_loss: 0.1025 - 54_loss: 0.0686 - 03_categorical_accuracy: 0.8443 - 04_categorical_accuracy: 0.9784 - 13_categorical_accuracy: 0.8264 - 14_categorical_accuracy: 0.8377 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9534 - 44_categorical_accuracy: 0.7773 - 53_categorical_accuracy: 0.9532 - 54_categorical_accuracy: 0.9631 - val_loss: 10.0431 - val_03_loss: 1.2095 - val_04_loss: 0.3758 - val_13_loss: 1.6366 - val_14_loss: 1.4724 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5803 - val_44_loss: 3.0307 - val_53_loss: 0.5904 - val_54_loss: 1.1474 - val_03_categorical_accuracy: 0.6074 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5572 - val_14_categorical_accuracy: 0.5866 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8786 - val_44_categorical_accuracy: 0.4472 - val_53_categorical_accuracy: 0.8746 - val_54_categorical_accuracy: 0.8735\n",
      "Epoch 147/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7084 - 03_loss: 0.2915 - 04_loss: 0.0567 - 13_loss: 0.3396 - 14_loss: 0.3009 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1010 - 44_loss: 0.4481 - 53_loss: 0.1023 - 54_loss: 0.0684 - 03_categorical_accuracy: 0.8438 - 04_categorical_accuracy: 0.9784 - 13_categorical_accuracy: 0.8257 - 14_categorical_accuracy: 0.8381 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9536 - 44_categorical_accuracy: 0.7774 - 53_categorical_accuracy: 0.9528 - 54_categorical_accuracy: 0.9632 - val_loss: 10.1242 - val_03_loss: 1.2325 - val_04_loss: 0.3932 - val_13_loss: 1.6614 - val_14_loss: 1.4639 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5836 - val_44_loss: 3.0199 - val_53_loss: 0.5885 - val_54_loss: 1.1812 - val_03_categorical_accuracy: 0.6113 - val_04_categorical_accuracy: 0.9522 - val_13_categorical_accuracy: 0.5585 - val_14_categorical_accuracy: 0.5861 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8763 - val_44_categorical_accuracy: 0.4497 - val_53_categorical_accuracy: 0.8806 - val_54_categorical_accuracy: 0.8740\n",
      "Epoch 148/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7067 - 03_loss: 0.2908 - 04_loss: 0.0566 - 13_loss: 0.3391 - 14_loss: 0.3007 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1014 - 44_loss: 0.4478 - 53_loss: 0.1019 - 54_loss: 0.0683 - 03_categorical_accuracy: 0.8444 - 04_categorical_accuracy: 0.9784 - 13_categorical_accuracy: 0.8263 - 14_categorical_accuracy: 0.8381 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9531 - 44_categorical_accuracy: 0.7767 - 53_categorical_accuracy: 0.9533 - 54_categorical_accuracy: 0.9634 - val_loss: 9.9862 - val_03_loss: 1.1985 - val_04_loss: 0.3861 - val_13_loss: 1.6075 - val_14_loss: 1.4400 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5654 - val_44_loss: 3.0439 - val_53_loss: 0.5695 - val_54_loss: 1.1752 - val_03_categorical_accuracy: 0.6051 - val_04_categorical_accuracy: 0.9514 - val_13_categorical_accuracy: 0.5635 - val_14_categorical_accuracy: 0.5918 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8797 - val_44_categorical_accuracy: 0.4481 - val_53_categorical_accuracy: 0.8773 - val_54_categorical_accuracy: 0.8740\n",
      "Epoch 149/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7058 - 03_loss: 0.2909 - 04_loss: 0.0569 - 13_loss: 0.3388 - 14_loss: 0.3005 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1009 - 44_loss: 0.4479 - 53_loss: 0.1019 - 54_loss: 0.0681 - 03_categorical_accuracy: 0.8442 - 04_categorical_accuracy: 0.9785 - 13_categorical_accuracy: 0.8253 - 14_categorical_accuracy: 0.8381 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9531 - 44_categorical_accuracy: 0.7771 - 53_categorical_accuracy: 0.9530 - 54_categorical_accuracy: 0.9632 - val_loss: 10.0267 - val_03_loss: 1.2131 - val_04_loss: 0.3836 - val_13_loss: 1.6534 - val_14_loss: 1.4568 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5802 - val_44_loss: 3.0077 - val_53_loss: 0.5755 - val_54_loss: 1.1565 - val_03_categorical_accuracy: 0.6094 - val_04_categorical_accuracy: 0.9512 - val_13_categorical_accuracy: 0.5634 - val_14_categorical_accuracy: 0.5911 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8730 - val_44_categorical_accuracy: 0.4499 - val_53_categorical_accuracy: 0.8756 - val_54_categorical_accuracy: 0.8719\n",
      "Epoch 150/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7032 - 03_loss: 0.2902 - 04_loss: 0.0568 - 13_loss: 0.3382 - 14_loss: 0.2993 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1008 - 44_loss: 0.4478 - 53_loss: 0.1014 - 54_loss: 0.0687 - 03_categorical_accuracy: 0.8443 - 04_categorical_accuracy: 0.9784 - 13_categorical_accuracy: 0.8256 - 14_categorical_accuracy: 0.8380 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9535 - 44_categorical_accuracy: 0.7774 - 53_categorical_accuracy: 0.9531 - 54_categorical_accuracy: 0.9629 - val_loss: 9.7974 - val_03_loss: 1.1821 - val_04_loss: 0.3776 - val_13_loss: 1.5978 - val_14_loss: 1.4278 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5681 - val_44_loss: 2.9381 - val_53_loss: 0.5726 - val_54_loss: 1.1332 - val_03_categorical_accuracy: 0.6073 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5642 - val_14_categorical_accuracy: 0.5907 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8727 - val_44_categorical_accuracy: 0.4464 - val_53_categorical_accuracy: 0.8772 - val_54_categorical_accuracy: 0.8730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7008 - 03_loss: 0.2900 - 04_loss: 0.0565 - 13_loss: 0.3381 - 14_loss: 0.2990 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1009 - 44_loss: 0.4470 - 53_loss: 0.1015 - 54_loss: 0.0680 - 03_categorical_accuracy: 0.8441 - 04_categorical_accuracy: 0.9784 - 13_categorical_accuracy: 0.8264 - 14_categorical_accuracy: 0.8392 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9533 - 44_categorical_accuracy: 0.7771 - 53_categorical_accuracy: 0.9534 - 54_categorical_accuracy: 0.9637 - val_loss: 10.0475 - val_03_loss: 1.2142 - val_04_loss: 0.3863 - val_13_loss: 1.6334 - val_14_loss: 1.4496 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5907 - val_44_loss: 3.0285 - val_53_loss: 0.5866 - val_54_loss: 1.1581 - val_03_categorical_accuracy: 0.6094 - val_04_categorical_accuracy: 0.9512 - val_13_categorical_accuracy: 0.5562 - val_14_categorical_accuracy: 0.5922 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8832 - val_44_categorical_accuracy: 0.4469 - val_53_categorical_accuracy: 0.8745 - val_54_categorical_accuracy: 0.8749\n",
      "Epoch 152/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7004 - 03_loss: 0.2905 - 04_loss: 0.0566 - 13_loss: 0.3377 - 14_loss: 0.2989 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1005 - 44_loss: 0.4463 - 53_loss: 0.1018 - 54_loss: 0.0681 - 03_categorical_accuracy: 0.8441 - 04_categorical_accuracy: 0.9785 - 13_categorical_accuracy: 0.8267 - 14_categorical_accuracy: 0.8379 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9538 - 44_categorical_accuracy: 0.7779 - 53_categorical_accuracy: 0.9532 - 54_categorical_accuracy: 0.9633 - val_loss: 10.0344 - val_03_loss: 1.2110 - val_04_loss: 0.3886 - val_13_loss: 1.6423 - val_14_loss: 1.4562 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5761 - val_44_loss: 3.0404 - val_53_loss: 0.5798 - val_54_loss: 1.1402 - val_03_categorical_accuracy: 0.6035 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5558 - val_14_categorical_accuracy: 0.5845 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8842 - val_44_categorical_accuracy: 0.4512 - val_53_categorical_accuracy: 0.8795 - val_54_categorical_accuracy: 0.8764\n",
      "Epoch 153/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.7012 - 03_loss: 0.2899 - 04_loss: 0.0570 - 13_loss: 0.3377 - 14_loss: 0.2993 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1008 - 44_loss: 0.4464 - 53_loss: 0.1017 - 54_loss: 0.0683 - 03_categorical_accuracy: 0.8453 - 04_categorical_accuracy: 0.9787 - 13_categorical_accuracy: 0.8267 - 14_categorical_accuracy: 0.8380 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9533 - 44_categorical_accuracy: 0.7780 - 53_categorical_accuracy: 0.9530 - 54_categorical_accuracy: 0.9630 - val_loss: 10.0775 - val_03_loss: 1.2146 - val_04_loss: 0.3863 - val_13_loss: 1.6218 - val_14_loss: 1.4589 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5880 - val_44_loss: 3.0166 - val_53_loss: 0.5879 - val_54_loss: 1.2034 - val_03_categorical_accuracy: 0.6034 - val_04_categorical_accuracy: 0.9517 - val_13_categorical_accuracy: 0.5607 - val_14_categorical_accuracy: 0.5937 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8806 - val_44_categorical_accuracy: 0.4482 - val_53_categorical_accuracy: 0.8759 - val_54_categorical_accuracy: 0.8737\n",
      "Epoch 154/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.6964 - 03_loss: 0.2896 - 04_loss: 0.0567 - 13_loss: 0.3361 - 14_loss: 0.2984 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1004 - 44_loss: 0.4457 - 53_loss: 0.1014 - 54_loss: 0.0682 - 03_categorical_accuracy: 0.8439 - 04_categorical_accuracy: 0.9785 - 13_categorical_accuracy: 0.8267 - 14_categorical_accuracy: 0.8379 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9539 - 44_categorical_accuracy: 0.7770 - 53_categorical_accuracy: 0.9532 - 54_categorical_accuracy: 0.9633 - val_loss: 9.9019 - val_03_loss: 1.2011 - val_04_loss: 0.3759 - val_13_loss: 1.6153 - val_14_loss: 1.4226 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5756 - val_44_loss: 2.9784 - val_53_loss: 0.5827 - val_54_loss: 1.1504 - val_03_categorical_accuracy: 0.6059 - val_04_categorical_accuracy: 0.9510 - val_13_categorical_accuracy: 0.5600 - val_14_categorical_accuracy: 0.5900 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8761 - val_44_categorical_accuracy: 0.4475 - val_53_categorical_accuracy: 0.8765 - val_54_categorical_accuracy: 0.8751\n",
      "Epoch 155/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.6938 - 03_loss: 0.2892 - 04_loss: 0.0566 - 13_loss: 0.3361 - 14_loss: 0.2974 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1002 - 44_loss: 0.4455 - 53_loss: 0.1012 - 54_loss: 0.0676 - 03_categorical_accuracy: 0.8445 - 04_categorical_accuracy: 0.9786 - 13_categorical_accuracy: 0.8263 - 14_categorical_accuracy: 0.8381 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9536 - 44_categorical_accuracy: 0.7769 - 53_categorical_accuracy: 0.9532 - 54_categorical_accuracy: 0.9637 - val_loss: 10.1944 - val_03_loss: 1.2273 - val_04_loss: 0.3822 - val_13_loss: 1.6573 - val_14_loss: 1.4785 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5877 - val_44_loss: 3.0799 - val_53_loss: 0.5910 - val_54_loss: 1.1905 - val_03_categorical_accuracy: 0.6085 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5601 - val_14_categorical_accuracy: 0.5913 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8807 - val_44_categorical_accuracy: 0.4489 - val_53_categorical_accuracy: 0.8776 - val_54_categorical_accuracy: 0.8740\n",
      "Epoch 156/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 1.6922 - 03_loss: 0.2885 - 04_loss: 0.0567 - 13_loss: 0.3356 - 14_loss: 0.2964 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1006 - 44_loss: 0.4454 - 53_loss: 0.1012 - 54_loss: 0.0678 - 03_categorical_accuracy: 0.8456 - 04_categorical_accuracy: 0.9786 - 13_categorical_accuracy: 0.8275 - 14_categorical_accuracy: 0.8390 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9534 - 44_categorical_accuracy: 0.7771 - 53_categorical_accuracy: 0.9532 - 54_categorical_accuracy: 0.9637 - val_loss: 10.2014 - val_03_loss: 1.2250 - val_04_loss: 0.3865 - val_13_loss: 1.6681 - val_14_loss: 1.4731 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5923 - val_44_loss: 3.0824 - val_53_loss: 0.5919 - val_54_loss: 1.1822 - val_03_categorical_accuracy: 0.6121 - val_04_categorical_accuracy: 0.9517 - val_13_categorical_accuracy: 0.5582 - val_14_categorical_accuracy: 0.5856 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8757 - val_44_categorical_accuracy: 0.4501 - val_53_categorical_accuracy: 0.8747 - val_54_categorical_accuracy: 0.8720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 1.6900 - 03_loss: 0.2891 - 04_loss: 0.0565 - 13_loss: 0.3347 - 14_loss: 0.2969 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1004 - 44_loss: 0.4438 - 53_loss: 0.1010 - 54_loss: 0.0676 - 03_categorical_accuracy: 0.8443 - 04_categorical_accuracy: 0.9785 - 13_categorical_accuracy: 0.8269 - 14_categorical_accuracy: 0.8392 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9536 - 44_categorical_accuracy: 0.7779 - 53_categorical_accuracy: 0.9531 - 54_categorical_accuracy: 0.9639 - val_loss: 10.2523 - val_03_loss: 1.2205 - val_04_loss: 0.3981 - val_13_loss: 1.6761 - val_14_loss: 1.4948 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5902 - val_44_loss: 3.0755 - val_53_loss: 0.5864 - val_54_loss: 1.2106 - val_03_categorical_accuracy: 0.6065 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5608 - val_14_categorical_accuracy: 0.5911 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8770 - val_44_categorical_accuracy: 0.4541 - val_53_categorical_accuracy: 0.8731 - val_54_categorical_accuracy: 0.8732\n",
      "Epoch 158/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.6896 - 03_loss: 0.2881 - 04_loss: 0.0566 - 13_loss: 0.3349 - 14_loss: 0.2963 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1006 - 44_loss: 0.4442 - 53_loss: 0.1010 - 54_loss: 0.0679 - 03_categorical_accuracy: 0.8452 - 04_categorical_accuracy: 0.9786 - 13_categorical_accuracy: 0.8273 - 14_categorical_accuracy: 0.8392 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9536 - 44_categorical_accuracy: 0.7779 - 53_categorical_accuracy: 0.9536 - 54_categorical_accuracy: 0.9634 - val_loss: 10.2132 - val_03_loss: 1.2314 - val_04_loss: 0.3891 - val_13_loss: 1.6682 - val_14_loss: 1.4710 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5808 - val_44_loss: 3.0802 - val_53_loss: 0.5862 - val_54_loss: 1.2063 - val_03_categorical_accuracy: 0.6108 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5578 - val_14_categorical_accuracy: 0.5906 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8819 - val_44_categorical_accuracy: 0.4470 - val_53_categorical_accuracy: 0.8781 - val_54_categorical_accuracy: 0.8739\n",
      "Epoch 159/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.6872 - 03_loss: 0.2886 - 04_loss: 0.0567 - 13_loss: 0.3341 - 14_loss: 0.2961 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0999 - 44_loss: 0.4438 - 53_loss: 0.1007 - 54_loss: 0.0673 - 03_categorical_accuracy: 0.8441 - 04_categorical_accuracy: 0.9785 - 13_categorical_accuracy: 0.8279 - 14_categorical_accuracy: 0.8391 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9536 - 44_categorical_accuracy: 0.7782 - 53_categorical_accuracy: 0.9529 - 54_categorical_accuracy: 0.9637 - val_loss: 10.3319 - val_03_loss: 1.2386 - val_04_loss: 0.3939 - val_13_loss: 1.6839 - val_14_loss: 1.4878 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5917 - val_44_loss: 3.1110 - val_53_loss: 0.5922 - val_54_loss: 1.2328 - val_03_categorical_accuracy: 0.6096 - val_04_categorical_accuracy: 0.9512 - val_13_categorical_accuracy: 0.5580 - val_14_categorical_accuracy: 0.5852 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8738 - val_44_categorical_accuracy: 0.4469 - val_53_categorical_accuracy: 0.8720 - val_54_categorical_accuracy: 0.8736\n",
      "Epoch 160/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.6849 - 03_loss: 0.2877 - 04_loss: 0.0563 - 13_loss: 0.3336 - 14_loss: 0.2954 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0994 - 44_loss: 0.4441 - 53_loss: 0.1007 - 54_loss: 0.0677 - 03_categorical_accuracy: 0.8453 - 04_categorical_accuracy: 0.9787 - 13_categorical_accuracy: 0.8272 - 14_categorical_accuracy: 0.8397 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9540 - 44_categorical_accuracy: 0.7774 - 53_categorical_accuracy: 0.9533 - 54_categorical_accuracy: 0.9639 - val_loss: 10.0845 - val_03_loss: 1.2158 - val_04_loss: 0.3905 - val_13_loss: 1.6319 - val_14_loss: 1.4691 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5766 - val_44_loss: 3.0161 - val_53_loss: 0.5900 - val_54_loss: 1.1945 - val_03_categorical_accuracy: 0.6094 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5549 - val_14_categorical_accuracy: 0.5878 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8770 - val_44_categorical_accuracy: 0.4495 - val_53_categorical_accuracy: 0.8841 - val_54_categorical_accuracy: 0.8732\n",
      "Epoch 161/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.6835 - 03_loss: 0.2866 - 04_loss: 0.0565 - 13_loss: 0.3335 - 14_loss: 0.2957 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0998 - 44_loss: 0.4432 - 53_loss: 0.1007 - 54_loss: 0.0676 - 03_categorical_accuracy: 0.8448 - 04_categorical_accuracy: 0.9785 - 13_categorical_accuracy: 0.8275 - 14_categorical_accuracy: 0.8392 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9535 - 44_categorical_accuracy: 0.7779 - 53_categorical_accuracy: 0.9531 - 54_categorical_accuracy: 0.9636 - val_loss: 10.4440 - val_03_loss: 1.2498 - val_04_loss: 0.3978 - val_13_loss: 1.6993 - val_14_loss: 1.5192 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5926 - val_44_loss: 3.1622 - val_53_loss: 0.5959 - val_54_loss: 1.2272 - val_03_categorical_accuracy: 0.6109 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5646 - val_14_categorical_accuracy: 0.5867 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8762 - val_44_categorical_accuracy: 0.4503 - val_53_categorical_accuracy: 0.8735 - val_54_categorical_accuracy: 0.8742\n",
      "Epoch 162/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.6838 - 03_loss: 0.2876 - 04_loss: 0.0565 - 13_loss: 0.3331 - 14_loss: 0.2954 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1000 - 44_loss: 0.4432 - 53_loss: 0.1005 - 54_loss: 0.0675 - 03_categorical_accuracy: 0.8453 - 04_categorical_accuracy: 0.9786 - 13_categorical_accuracy: 0.8277 - 14_categorical_accuracy: 0.8402 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9535 - 44_categorical_accuracy: 0.7774 - 53_categorical_accuracy: 0.9536 - 54_categorical_accuracy: 0.9640 - val_loss: 10.1484 - val_03_loss: 1.2227 - val_04_loss: 0.3807 - val_13_loss: 1.6598 - val_14_loss: 1.4611 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5860 - val_44_loss: 3.0439 - val_53_loss: 0.5857 - val_54_loss: 1.2086 - val_03_categorical_accuracy: 0.6090 - val_04_categorical_accuracy: 0.9517 - val_13_categorical_accuracy: 0.5569 - val_14_categorical_accuracy: 0.5886 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8782 - val_44_categorical_accuracy: 0.4489 - val_53_categorical_accuracy: 0.8789 - val_54_categorical_accuracy: 0.8731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.6798 - 03_loss: 0.2868 - 04_loss: 0.0564 - 13_loss: 0.3325 - 14_loss: 0.2940 - 23_loss: 0.0000e+00 - 24_loss: 8.2282e-11 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0997 - 44_loss: 0.4424 - 53_loss: 0.1005 - 54_loss: 0.0675 - 03_categorical_accuracy: 0.8449 - 04_categorical_accuracy: 0.9785 - 13_categorical_accuracy: 0.8282 - 14_categorical_accuracy: 0.8397 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9536 - 44_categorical_accuracy: 0.7783 - 53_categorical_accuracy: 0.9530 - 54_categorical_accuracy: 0.9636 - val_loss: 10.2232 - val_03_loss: 1.2316 - val_04_loss: 0.4063 - val_13_loss: 1.6631 - val_14_loss: 1.4721 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5874 - val_44_loss: 3.1095 - val_53_loss: 0.5774 - val_54_loss: 1.1758 - val_03_categorical_accuracy: 0.6043 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5627 - val_14_categorical_accuracy: 0.5940 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8735 - val_44_categorical_accuracy: 0.4510 - val_53_categorical_accuracy: 0.8773 - val_54_categorical_accuracy: 0.8732\n",
      "Epoch 164/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.6783 - 03_loss: 0.2866 - 04_loss: 0.0563 - 13_loss: 0.3322 - 14_loss: 0.2945 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0995 - 44_loss: 0.4419 - 53_loss: 0.1001 - 54_loss: 0.0672 - 03_categorical_accuracy: 0.8449 - 04_categorical_accuracy: 0.9786 - 13_categorical_accuracy: 0.8277 - 14_categorical_accuracy: 0.8399 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9540 - 44_categorical_accuracy: 0.7783 - 53_categorical_accuracy: 0.9534 - 54_categorical_accuracy: 0.9637 - val_loss: 10.3504 - val_03_loss: 1.2462 - val_04_loss: 0.4032 - val_13_loss: 1.6917 - val_14_loss: 1.5156 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5852 - val_44_loss: 3.1047 - val_53_loss: 0.5980 - val_54_loss: 1.2059 - val_03_categorical_accuracy: 0.6090 - val_04_categorical_accuracy: 0.9511 - val_13_categorical_accuracy: 0.5574 - val_14_categorical_accuracy: 0.5882 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8752 - val_44_categorical_accuracy: 0.4489 - val_53_categorical_accuracy: 0.8756 - val_54_categorical_accuracy: 0.8752\n",
      "Epoch 165/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.6785 - 03_loss: 0.2864 - 04_loss: 0.0564 - 13_loss: 0.3320 - 14_loss: 0.2945 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0998 - 44_loss: 0.4415 - 53_loss: 0.1004 - 54_loss: 0.0675 - 03_categorical_accuracy: 0.8446 - 04_categorical_accuracy: 0.9789 - 13_categorical_accuracy: 0.8273 - 14_categorical_accuracy: 0.8390 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9534 - 44_categorical_accuracy: 0.7776 - 53_categorical_accuracy: 0.9533 - 54_categorical_accuracy: 0.9635 - val_loss: 10.3238 - val_03_loss: 1.2352 - val_04_loss: 0.4109 - val_13_loss: 1.6810 - val_14_loss: 1.5014 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5864 - val_44_loss: 3.1234 - val_53_loss: 0.5830 - val_54_loss: 1.2025 - val_03_categorical_accuracy: 0.6071 - val_04_categorical_accuracy: 0.9507 - val_13_categorical_accuracy: 0.5592 - val_14_categorical_accuracy: 0.5904 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8777 - val_44_categorical_accuracy: 0.4479 - val_53_categorical_accuracy: 0.8735 - val_54_categorical_accuracy: 0.8738\n",
      "Epoch 166/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.6753 - 03_loss: 0.2853 - 04_loss: 0.0562 - 13_loss: 0.3309 - 14_loss: 0.2936 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0999 - 44_loss: 0.4421 - 53_loss: 0.1003 - 54_loss: 0.0670 - 03_categorical_accuracy: 0.8460 - 04_categorical_accuracy: 0.9787 - 13_categorical_accuracy: 0.8272 - 14_categorical_accuracy: 0.8395 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9534 - 44_categorical_accuracy: 0.7783 - 53_categorical_accuracy: 0.9533 - 54_categorical_accuracy: 0.9639 - val_loss: 10.2734 - val_03_loss: 1.2282 - val_04_loss: 0.4061 - val_13_loss: 1.6694 - val_14_loss: 1.4827 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5852 - val_44_loss: 3.0798 - val_53_loss: 0.5849 - val_54_loss: 1.2373 - val_03_categorical_accuracy: 0.6068 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5584 - val_14_categorical_accuracy: 0.5875 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8752 - val_44_categorical_accuracy: 0.4515 - val_53_categorical_accuracy: 0.8788 - val_54_categorical_accuracy: 0.8738\n",
      "Epoch 167/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 1.6742 - 03_loss: 0.2854 - 04_loss: 0.0562 - 13_loss: 0.3309 - 14_loss: 0.2932 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0996 - 44_loss: 0.4413 - 53_loss: 0.1003 - 54_loss: 0.0674 - 03_categorical_accuracy: 0.8457 - 04_categorical_accuracy: 0.9787 - 13_categorical_accuracy: 0.8282 - 14_categorical_accuracy: 0.8395 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9538 - 44_categorical_accuracy: 0.7780 - 53_categorical_accuracy: 0.9531 - 54_categorical_accuracy: 0.9633 - val_loss: 10.4614 - val_03_loss: 1.2464 - val_04_loss: 0.4056 - val_13_loss: 1.7088 - val_14_loss: 1.5257 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5860 - val_44_loss: 3.1468 - val_53_loss: 0.5951 - val_54_loss: 1.2471 - val_03_categorical_accuracy: 0.6053 - val_04_categorical_accuracy: 0.9512 - val_13_categorical_accuracy: 0.5532 - val_14_categorical_accuracy: 0.5863 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8766 - val_44_categorical_accuracy: 0.4481 - val_53_categorical_accuracy: 0.8784 - val_54_categorical_accuracy: 0.8741\n",
      "Epoch 168/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 1.6710 - 03_loss: 0.2854 - 04_loss: 0.0563 - 13_loss: 0.3302 - 14_loss: 0.2927 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0993 - 44_loss: 0.4398 - 53_loss: 0.1002 - 54_loss: 0.0671 - 03_categorical_accuracy: 0.8454 - 04_categorical_accuracy: 0.9787 - 13_categorical_accuracy: 0.8288 - 14_categorical_accuracy: 0.8406 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9533 - 44_categorical_accuracy: 0.7794 - 53_categorical_accuracy: 0.9532 - 54_categorical_accuracy: 0.9636 - val_loss: 10.3050 - val_03_loss: 1.2216 - val_04_loss: 0.3862 - val_13_loss: 1.6662 - val_14_loss: 1.4857 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5836 - val_44_loss: 3.1307 - val_53_loss: 0.5753 - val_54_loss: 1.2557 - val_03_categorical_accuracy: 0.6063 - val_04_categorical_accuracy: 0.9509 - val_13_categorical_accuracy: 0.5571 - val_14_categorical_accuracy: 0.5865 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8772 - val_44_categorical_accuracy: 0.4466 - val_53_categorical_accuracy: 0.8758 - val_54_categorical_accuracy: 0.8725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.6696 - 03_loss: 0.2848 - 04_loss: 0.0563 - 13_loss: 0.3299 - 14_loss: 0.2924 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0990 - 44_loss: 0.4403 - 53_loss: 0.0998 - 54_loss: 0.0671 - 03_categorical_accuracy: 0.8459 - 04_categorical_accuracy: 0.9789 - 13_categorical_accuracy: 0.8281 - 14_categorical_accuracy: 0.8399 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9539 - 44_categorical_accuracy: 0.7780 - 53_categorical_accuracy: 0.9533 - 54_categorical_accuracy: 0.9637 - val_loss: 10.3398 - val_03_loss: 1.2187 - val_04_loss: 0.4106 - val_13_loss: 1.6781 - val_14_loss: 1.4924 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5977 - val_44_loss: 3.1269 - val_53_loss: 0.5775 - val_54_loss: 1.2381 - val_03_categorical_accuracy: 0.6095 - val_04_categorical_accuracy: 0.9511 - val_13_categorical_accuracy: 0.5584 - val_14_categorical_accuracy: 0.5897 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8845 - val_44_categorical_accuracy: 0.4460 - val_53_categorical_accuracy: 0.8712 - val_54_categorical_accuracy: 0.8724\n",
      "Epoch 170/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.6680 - 03_loss: 0.2848 - 04_loss: 0.0562 - 13_loss: 0.3288 - 14_loss: 0.2919 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0996 - 44_loss: 0.4398 - 53_loss: 0.1001 - 54_loss: 0.0668 - 03_categorical_accuracy: 0.8455 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8288 - 14_categorical_accuracy: 0.8401 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9538 - 44_categorical_accuracy: 0.7793 - 53_categorical_accuracy: 0.9535 - 54_categorical_accuracy: 0.9638 - val_loss: 10.3468 - val_03_loss: 1.2360 - val_04_loss: 0.4087 - val_13_loss: 1.6902 - val_14_loss: 1.5016 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5859 - val_44_loss: 3.1186 - val_53_loss: 0.5944 - val_54_loss: 1.2116 - val_03_categorical_accuracy: 0.6061 - val_04_categorical_accuracy: 0.9509 - val_13_categorical_accuracy: 0.5563 - val_14_categorical_accuracy: 0.5892 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8773 - val_44_categorical_accuracy: 0.4512 - val_53_categorical_accuracy: 0.8798 - val_54_categorical_accuracy: 0.8727\n",
      "Epoch 171/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.6670 - 03_loss: 0.2849 - 04_loss: 0.0559 - 13_loss: 0.3291 - 14_loss: 0.2925 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0991 - 44_loss: 0.4396 - 53_loss: 0.0992 - 54_loss: 0.0667 - 03_categorical_accuracy: 0.8452 - 04_categorical_accuracy: 0.9790 - 13_categorical_accuracy: 0.8288 - 14_categorical_accuracy: 0.8403 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9539 - 44_categorical_accuracy: 0.7782 - 53_categorical_accuracy: 0.9536 - 54_categorical_accuracy: 0.9642 - val_loss: 10.2991 - val_03_loss: 1.2205 - val_04_loss: 0.3995 - val_13_loss: 1.6802 - val_14_loss: 1.4790 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5787 - val_44_loss: 3.1342 - val_53_loss: 0.5826 - val_54_loss: 1.2244 - val_03_categorical_accuracy: 0.6000 - val_04_categorical_accuracy: 0.9513 - val_13_categorical_accuracy: 0.5629 - val_14_categorical_accuracy: 0.5930 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8771 - val_44_categorical_accuracy: 0.4521 - val_53_categorical_accuracy: 0.8771 - val_54_categorical_accuracy: 0.8738\n",
      "Epoch 172/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 1.6650 - 03_loss: 0.2840 - 04_loss: 0.0564 - 13_loss: 0.3282 - 14_loss: 0.2913 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0992 - 44_loss: 0.4398 - 53_loss: 0.0993 - 54_loss: 0.0669 - 03_categorical_accuracy: 0.8465 - 04_categorical_accuracy: 0.9787 - 13_categorical_accuracy: 0.8288 - 14_categorical_accuracy: 0.8402 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9537 - 44_categorical_accuracy: 0.7788 - 53_categorical_accuracy: 0.9541 - 54_categorical_accuracy: 0.9639 - val_loss: 10.4907 - val_03_loss: 1.2338 - val_04_loss: 0.4022 - val_13_loss: 1.7089 - val_14_loss: 1.5256 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5894 - val_44_loss: 3.1655 - val_53_loss: 0.6049 - val_54_loss: 1.2604 - val_03_categorical_accuracy: 0.6088 - val_04_categorical_accuracy: 0.9512 - val_13_categorical_accuracy: 0.5562 - val_14_categorical_accuracy: 0.5880 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8765 - val_44_categorical_accuracy: 0.4480 - val_53_categorical_accuracy: 0.8799 - val_54_categorical_accuracy: 0.8745\n",
      "Epoch 173/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.6656 - 03_loss: 0.2842 - 04_loss: 0.0564 - 13_loss: 0.3291 - 14_loss: 0.2915 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0987 - 44_loss: 0.4390 - 53_loss: 0.0997 - 54_loss: 0.0669 - 03_categorical_accuracy: 0.8455 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8283 - 14_categorical_accuracy: 0.8396 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9537 - 44_categorical_accuracy: 0.7793 - 53_categorical_accuracy: 0.9532 - 54_categorical_accuracy: 0.9640 - val_loss: 10.5453 - val_03_loss: 1.2398 - val_04_loss: 0.4187 - val_13_loss: 1.7060 - val_14_loss: 1.5069 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5883 - val_44_loss: 3.2366 - val_53_loss: 0.5969 - val_54_loss: 1.2522 - val_03_categorical_accuracy: 0.6072 - val_04_categorical_accuracy: 0.9517 - val_13_categorical_accuracy: 0.5620 - val_14_categorical_accuracy: 0.5910 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8766 - val_44_categorical_accuracy: 0.4471 - val_53_categorical_accuracy: 0.8770 - val_54_categorical_accuracy: 0.8746\n",
      "Epoch 174/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.6624 - 03_loss: 0.2832 - 04_loss: 0.0561 - 13_loss: 0.3286 - 14_loss: 0.2913 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0988 - 44_loss: 0.4384 - 53_loss: 0.0992 - 54_loss: 0.0668 - 03_categorical_accuracy: 0.8461 - 04_categorical_accuracy: 0.9789 - 13_categorical_accuracy: 0.8292 - 14_categorical_accuracy: 0.8405 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9538 - 44_categorical_accuracy: 0.7784 - 53_categorical_accuracy: 0.9539 - 54_categorical_accuracy: 0.9643 - val_loss: 10.5256 - val_03_loss: 1.2421 - val_04_loss: 0.4172 - val_13_loss: 1.7129 - val_14_loss: 1.5203 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5830 - val_44_loss: 3.1987 - val_53_loss: 0.5892 - val_54_loss: 1.2622 - val_03_categorical_accuracy: 0.6086 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5542 - val_14_categorical_accuracy: 0.5856 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8811 - val_44_categorical_accuracy: 0.4484 - val_53_categorical_accuracy: 0.8746 - val_54_categorical_accuracy: 0.8737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.6605 - 03_loss: 0.2834 - 04_loss: 0.0561 - 13_loss: 0.3271 - 14_loss: 0.2908 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0986 - 44_loss: 0.4390 - 53_loss: 0.0989 - 54_loss: 0.0666 - 03_categorical_accuracy: 0.8458 - 04_categorical_accuracy: 0.9789 - 13_categorical_accuracy: 0.8286 - 14_categorical_accuracy: 0.8404 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9537 - 44_categorical_accuracy: 0.7788 - 53_categorical_accuracy: 0.9538 - 54_categorical_accuracy: 0.9640 - val_loss: 10.4106 - val_03_loss: 1.2508 - val_04_loss: 0.4100 - val_13_loss: 1.6888 - val_14_loss: 1.5113 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5896 - val_44_loss: 3.1466 - val_53_loss: 0.5907 - val_54_loss: 1.2228 - val_03_categorical_accuracy: 0.6068 - val_04_categorical_accuracy: 0.9513 - val_13_categorical_accuracy: 0.5590 - val_14_categorical_accuracy: 0.5938 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8772 - val_44_categorical_accuracy: 0.4485 - val_53_categorical_accuracy: 0.8766 - val_54_categorical_accuracy: 0.8731\n",
      "Epoch 176/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.6591 - 03_loss: 0.2830 - 04_loss: 0.0560 - 13_loss: 0.3280 - 14_loss: 0.2900 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0986 - 44_loss: 0.4379 - 53_loss: 0.0991 - 54_loss: 0.0665 - 03_categorical_accuracy: 0.8459 - 04_categorical_accuracy: 0.9786 - 13_categorical_accuracy: 0.8286 - 14_categorical_accuracy: 0.8407 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9538 - 44_categorical_accuracy: 0.7802 - 53_categorical_accuracy: 0.9536 - 54_categorical_accuracy: 0.9641 - val_loss: 10.4122 - val_03_loss: 1.2465 - val_04_loss: 0.4020 - val_13_loss: 1.6987 - val_14_loss: 1.4898 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5893 - val_44_loss: 3.1326 - val_53_loss: 0.5945 - val_54_loss: 1.2587 - val_03_categorical_accuracy: 0.6044 - val_04_categorical_accuracy: 0.9511 - val_13_categorical_accuracy: 0.5634 - val_14_categorical_accuracy: 0.5928 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8773 - val_44_categorical_accuracy: 0.4487 - val_53_categorical_accuracy: 0.8768 - val_54_categorical_accuracy: 0.8733\n",
      "Epoch 177/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 1.6582 - 03_loss: 0.2834 - 04_loss: 0.0560 - 13_loss: 0.3264 - 14_loss: 0.2904 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0985 - 44_loss: 0.4375 - 53_loss: 0.0992 - 54_loss: 0.0669 - 03_categorical_accuracy: 0.8453 - 04_categorical_accuracy: 0.9789 - 13_categorical_accuracy: 0.8295 - 14_categorical_accuracy: 0.8396 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9538 - 44_categorical_accuracy: 0.7803 - 53_categorical_accuracy: 0.9537 - 54_categorical_accuracy: 0.9640 - val_loss: 10.5582 - val_03_loss: 1.2525 - val_04_loss: 0.4120 - val_13_loss: 1.7171 - val_14_loss: 1.5118 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5961 - val_44_loss: 3.1842 - val_53_loss: 0.6034 - val_54_loss: 1.2813 - val_03_categorical_accuracy: 0.6031 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5573 - val_14_categorical_accuracy: 0.5858 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8830 - val_44_categorical_accuracy: 0.4489 - val_53_categorical_accuracy: 0.8770 - val_54_categorical_accuracy: 0.8722\n",
      "Epoch 178/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.6580 - 03_loss: 0.2834 - 04_loss: 0.0561 - 13_loss: 0.3267 - 14_loss: 0.2903 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0980 - 44_loss: 0.4380 - 53_loss: 0.0991 - 54_loss: 0.0664 - 03_categorical_accuracy: 0.8460 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8290 - 14_categorical_accuracy: 0.8407 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9541 - 44_categorical_accuracy: 0.7786 - 53_categorical_accuracy: 0.9537 - 54_categorical_accuracy: 0.9643 - val_loss: 10.6699 - val_03_loss: 1.2438 - val_04_loss: 0.4147 - val_13_loss: 1.7377 - val_14_loss: 1.5302 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.6117 - val_44_loss: 3.2468 - val_53_loss: 0.6087 - val_54_loss: 1.2764 - val_03_categorical_accuracy: 0.6032 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5587 - val_14_categorical_accuracy: 0.5925 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8813 - val_44_categorical_accuracy: 0.4464 - val_53_categorical_accuracy: 0.8813 - val_54_categorical_accuracy: 0.8733\n",
      "Epoch 179/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.6551 - 03_loss: 0.2823 - 04_loss: 0.0560 - 13_loss: 0.3270 - 14_loss: 0.2899 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0983 - 44_loss: 0.4361 - 53_loss: 0.0993 - 54_loss: 0.0663 - 03_categorical_accuracy: 0.8463 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8293 - 14_categorical_accuracy: 0.8411 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9540 - 44_categorical_accuracy: 0.7792 - 53_categorical_accuracy: 0.9535 - 54_categorical_accuracy: 0.9642 - val_loss: 10.5354 - val_03_loss: 1.2594 - val_04_loss: 0.4136 - val_13_loss: 1.6932 - val_14_loss: 1.5053 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5890 - val_44_loss: 3.1975 - val_53_loss: 0.5916 - val_54_loss: 1.2859 - val_03_categorical_accuracy: 0.6086 - val_04_categorical_accuracy: 0.9513 - val_13_categorical_accuracy: 0.5566 - val_14_categorical_accuracy: 0.5883 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8751 - val_44_categorical_accuracy: 0.4499 - val_53_categorical_accuracy: 0.8782 - val_54_categorical_accuracy: 0.8728\n",
      "Epoch 180/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.6525 - 03_loss: 0.2827 - 04_loss: 0.0562 - 13_loss: 0.3260 - 14_loss: 0.2891 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0981 - 44_loss: 0.4356 - 53_loss: 0.0984 - 54_loss: 0.0665 - 03_categorical_accuracy: 0.8455 - 04_categorical_accuracy: 0.9786 - 13_categorical_accuracy: 0.8299 - 14_categorical_accuracy: 0.8406 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9538 - 44_categorical_accuracy: 0.7796 - 53_categorical_accuracy: 0.9538 - 54_categorical_accuracy: 0.9639 - val_loss: 10.4613 - val_03_loss: 1.2395 - val_04_loss: 0.4231 - val_13_loss: 1.7120 - val_14_loss: 1.4950 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5905 - val_44_loss: 3.1466 - val_53_loss: 0.5892 - val_54_loss: 1.2654 - val_03_categorical_accuracy: 0.6060 - val_04_categorical_accuracy: 0.9513 - val_13_categorical_accuracy: 0.5586 - val_14_categorical_accuracy: 0.5892 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8755 - val_44_categorical_accuracy: 0.4507 - val_53_categorical_accuracy: 0.8762 - val_54_categorical_accuracy: 0.8725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.6524 - 03_loss: 0.2818 - 04_loss: 0.0562 - 13_loss: 0.3261 - 14_loss: 0.2896 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0979 - 44_loss: 0.4357 - 53_loss: 0.0985 - 54_loss: 0.0666 - 03_categorical_accuracy: 0.8473 - 04_categorical_accuracy: 0.9789 - 13_categorical_accuracy: 0.8292 - 14_categorical_accuracy: 0.8406 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9542 - 44_categorical_accuracy: 0.7801 - 53_categorical_accuracy: 0.9538 - 54_categorical_accuracy: 0.9641 - val_loss: 10.6028 - val_03_loss: 1.2481 - val_04_loss: 0.4045 - val_13_loss: 1.7103 - val_14_loss: 1.5330 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5931 - val_44_loss: 3.2200 - val_53_loss: 0.5965 - val_54_loss: 1.2972 - val_03_categorical_accuracy: 0.6097 - val_04_categorical_accuracy: 0.9513 - val_13_categorical_accuracy: 0.5569 - val_14_categorical_accuracy: 0.5858 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8763 - val_44_categorical_accuracy: 0.4483 - val_53_categorical_accuracy: 0.8791 - val_54_categorical_accuracy: 0.8727\n",
      "Epoch 182/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.6498 - 03_loss: 0.2818 - 04_loss: 0.0560 - 13_loss: 0.3250 - 14_loss: 0.2880 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0984 - 44_loss: 0.4358 - 53_loss: 0.0985 - 54_loss: 0.0662 - 03_categorical_accuracy: 0.8472 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8298 - 14_categorical_accuracy: 0.8415 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9539 - 44_categorical_accuracy: 0.7800 - 53_categorical_accuracy: 0.9534 - 54_categorical_accuracy: 0.9641 - val_loss: 10.6223 - val_03_loss: 1.2396 - val_04_loss: 0.4158 - val_13_loss: 1.7055 - val_14_loss: 1.5089 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5875 - val_44_loss: 3.2434 - val_53_loss: 0.6025 - val_54_loss: 1.3190 - val_03_categorical_accuracy: 0.6071 - val_04_categorical_accuracy: 0.9513 - val_13_categorical_accuracy: 0.5567 - val_14_categorical_accuracy: 0.5839 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8774 - val_44_categorical_accuracy: 0.4495 - val_53_categorical_accuracy: 0.8807 - val_54_categorical_accuracy: 0.8736\n",
      "Epoch 183/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 1.6499 - 03_loss: 0.2816 - 04_loss: 0.0559 - 13_loss: 0.3253 - 14_loss: 0.2884 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0978 - 44_loss: 0.4357 - 53_loss: 0.0989 - 54_loss: 0.0663 - 03_categorical_accuracy: 0.8466 - 04_categorical_accuracy: 0.9786 - 13_categorical_accuracy: 0.8299 - 14_categorical_accuracy: 0.8418 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9538 - 44_categorical_accuracy: 0.7791 - 53_categorical_accuracy: 0.9537 - 54_categorical_accuracy: 0.9646 - val_loss: 10.8571 - val_03_loss: 1.2740 - val_04_loss: 0.4298 - val_13_loss: 1.7477 - val_14_loss: 1.5627 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5997 - val_44_loss: 3.2919 - val_53_loss: 0.6013 - val_54_loss: 1.3501 - val_03_categorical_accuracy: 0.6062 - val_04_categorical_accuracy: 0.9514 - val_13_categorical_accuracy: 0.5544 - val_14_categorical_accuracy: 0.5832 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8712 - val_44_categorical_accuracy: 0.4487 - val_53_categorical_accuracy: 0.8767 - val_54_categorical_accuracy: 0.8726\n",
      "Epoch 184/1000\n",
      "697/697 [==============================] - 16s 23ms/step - loss: 1.6495 - 03_loss: 0.2814 - 04_loss: 0.0559 - 13_loss: 0.3259 - 14_loss: 0.2886 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0977 - 44_loss: 0.4353 - 53_loss: 0.0986 - 54_loss: 0.0660 - 03_categorical_accuracy: 0.8460 - 04_categorical_accuracy: 0.9789 - 13_categorical_accuracy: 0.8294 - 14_categorical_accuracy: 0.8411 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9541 - 44_categorical_accuracy: 0.7806 - 53_categorical_accuracy: 0.9539 - 54_categorical_accuracy: 0.9643 - val_loss: 10.6734 - val_03_loss: 1.2641 - val_04_loss: 0.4244 - val_13_loss: 1.7346 - val_14_loss: 1.5467 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5972 - val_44_loss: 3.2042 - val_53_loss: 0.6011 - val_54_loss: 1.3012 - val_03_categorical_accuracy: 0.6076 - val_04_categorical_accuracy: 0.9512 - val_13_categorical_accuracy: 0.5579 - val_14_categorical_accuracy: 0.5887 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8793 - val_44_categorical_accuracy: 0.4465 - val_53_categorical_accuracy: 0.8781 - val_54_categorical_accuracy: 0.8751\n",
      "Epoch 185/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 1.6464 - 03_loss: 0.2815 - 04_loss: 0.0560 - 13_loss: 0.3245 - 14_loss: 0.2881 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0978 - 44_loss: 0.4345 - 53_loss: 0.0982 - 54_loss: 0.0658 - 03_categorical_accuracy: 0.8458 - 04_categorical_accuracy: 0.9787 - 13_categorical_accuracy: 0.8293 - 14_categorical_accuracy: 0.8414 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9536 - 44_categorical_accuracy: 0.7801 - 53_categorical_accuracy: 0.9540 - 54_categorical_accuracy: 0.9646 - val_loss: 10.7335 - val_03_loss: 1.2647 - val_04_loss: 0.4295 - val_13_loss: 1.7307 - val_14_loss: 1.5258 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5983 - val_44_loss: 3.2593 - val_53_loss: 0.6078 - val_54_loss: 1.3174 - val_03_categorical_accuracy: 0.6065 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5600 - val_14_categorical_accuracy: 0.5931 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8766 - val_44_categorical_accuracy: 0.4504 - val_53_categorical_accuracy: 0.8837 - val_54_categorical_accuracy: 0.8729\n",
      "Epoch 186/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 1.6459 - 03_loss: 0.2807 - 04_loss: 0.0562 - 13_loss: 0.3244 - 14_loss: 0.2873 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0977 - 44_loss: 0.4346 - 53_loss: 0.0986 - 54_loss: 0.0664 - 03_categorical_accuracy: 0.8465 - 04_categorical_accuracy: 0.9789 - 13_categorical_accuracy: 0.8293 - 14_categorical_accuracy: 0.8419 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9542 - 44_categorical_accuracy: 0.7803 - 53_categorical_accuracy: 0.9537 - 54_categorical_accuracy: 0.9642 - val_loss: 10.7434 - val_03_loss: 1.2508 - val_04_loss: 0.4328 - val_13_loss: 1.7238 - val_14_loss: 1.5197 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5946 - val_44_loss: 3.2868 - val_53_loss: 0.6001 - val_54_loss: 1.3348 - val_03_categorical_accuracy: 0.6124 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5577 - val_14_categorical_accuracy: 0.5843 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8796 - val_44_categorical_accuracy: 0.4528 - val_53_categorical_accuracy: 0.8785 - val_54_categorical_accuracy: 0.8746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 1.6436 - 03_loss: 0.2806 - 04_loss: 0.0559 - 13_loss: 0.3243 - 14_loss: 0.2868 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0975 - 44_loss: 0.4341 - 53_loss: 0.0984 - 54_loss: 0.0660 - 03_categorical_accuracy: 0.8462 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8292 - 14_categorical_accuracy: 0.8413 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9541 - 44_categorical_accuracy: 0.7807 - 53_categorical_accuracy: 0.9538 - 54_categorical_accuracy: 0.9642 - val_loss: 10.7346 - val_03_loss: 1.2458 - val_04_loss: 0.4301 - val_13_loss: 1.7058 - val_14_loss: 1.5301 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5967 - val_44_loss: 3.2698 - val_53_loss: 0.5959 - val_54_loss: 1.3604 - val_03_categorical_accuracy: 0.6054 - val_04_categorical_accuracy: 0.9517 - val_13_categorical_accuracy: 0.5601 - val_14_categorical_accuracy: 0.5911 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8772 - val_44_categorical_accuracy: 0.4516 - val_53_categorical_accuracy: 0.8753 - val_54_categorical_accuracy: 0.8733\n",
      "Epoch 188/1000\n",
      "697/697 [==============================] - 17s 24ms/step - loss: 1.6449 - 03_loss: 0.2807 - 04_loss: 0.0563 - 13_loss: 0.3240 - 14_loss: 0.2876 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0977 - 44_loss: 0.4341 - 53_loss: 0.0984 - 54_loss: 0.0662 - 03_categorical_accuracy: 0.8462 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8299 - 14_categorical_accuracy: 0.8419 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9540 - 44_categorical_accuracy: 0.7807 - 53_categorical_accuracy: 0.9538 - 54_categorical_accuracy: 0.9644 - val_loss: 10.8837 - val_03_loss: 1.2650 - val_04_loss: 0.4221 - val_13_loss: 1.7666 - val_14_loss: 1.5633 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.6215 - val_44_loss: 3.3071 - val_53_loss: 0.6046 - val_54_loss: 1.3335 - val_03_categorical_accuracy: 0.6082 - val_04_categorical_accuracy: 0.9517 - val_13_categorical_accuracy: 0.5605 - val_14_categorical_accuracy: 0.5895 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8858 - val_44_categorical_accuracy: 0.4523 - val_53_categorical_accuracy: 0.8760 - val_54_categorical_accuracy: 0.8730\n",
      "Epoch 189/1000\n",
      "697/697 [==============================] - 16s 24ms/step - loss: 1.6418 - 03_loss: 0.2802 - 04_loss: 0.0560 - 13_loss: 0.3231 - 14_loss: 0.2869 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0974 - 44_loss: 0.4340 - 53_loss: 0.0983 - 54_loss: 0.0660 - 03_categorical_accuracy: 0.8468 - 04_categorical_accuracy: 0.9790 - 13_categorical_accuracy: 0.8300 - 14_categorical_accuracy: 0.8416 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9541 - 44_categorical_accuracy: 0.7802 - 53_categorical_accuracy: 0.9539 - 54_categorical_accuracy: 0.9644 - val_loss: 10.8259 - val_03_loss: 1.2632 - val_04_loss: 0.4297 - val_13_loss: 1.7124 - val_14_loss: 1.5575 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.6076 - val_44_loss: 3.3101 - val_53_loss: 0.6071 - val_54_loss: 1.3383 - val_03_categorical_accuracy: 0.6122 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5587 - val_14_categorical_accuracy: 0.5889 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8760 - val_44_categorical_accuracy: 0.4495 - val_53_categorical_accuracy: 0.8741 - val_54_categorical_accuracy: 0.8732\n",
      "Epoch 190/1000\n",
      "425/697 [=================>............] - ETA: 5s - loss: 1.6067 - 03_loss: 0.2735 - 04_loss: 0.0556 - 13_loss: 0.3157 - 14_loss: 0.2812 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0933 - 44_loss: 0.4259 - 53_loss: 0.0950 - 54_loss: 0.0664 - 03_categorical_accuracy: 0.8507 - 04_categorical_accuracy: 0.9793 - 13_categorical_accuracy: 0.8355 - 14_categorical_accuracy: 0.8456 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9560 - 44_categorical_accuracy: 0.7847 - 53_categorical_accuracy: 0.9553 - 54_categorical_accuracy: 0.9644"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [30], line 42\u001b[0m\n\u001b[1;32m     38\u001b[0m K\u001b[38;5;241m.\u001b[39mset_value(model\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mlearning_rate, \u001b[38;5;241m0.0005\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#model.fit(train_dataset,epochs=250, verbose=1, callbacks=[callback])\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates_actions_seq_10\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM, Input, GRU\n",
    "from keras.layers import Bidirectional\n",
    "from keras.models import Model\n",
    "\n",
    "NUM_NODES = 6\n",
    "NODE_CLASSES = [3, 4]\n",
    "\n",
    "data_map = {}\n",
    "losses = []\n",
    "index = 0\n",
    "for i in range(NUM_NODES):\n",
    "    for n in NODE_CLASSES:\n",
    "        data_map[str(i)+str(n)] = next_states[:,index:index+n]\n",
    "        losses.append(tf.keras.losses.CategoricalCrossentropy())\n",
    "        index += n\n",
    "        \n",
    "input_ = Input(shape=(10,42+20,))\n",
    "#x = Bidirectional(LSTM(64, activation='relu', return_sequences=True))(input_)\n",
    "#x = Bidirectional(GRU(64))(input_)\n",
    "x = Bidirectional(LSTM(256))(input_)\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "\n",
    "outs = []\n",
    "for i in range(NUM_NODES):\n",
    "    for n in NODE_CLASSES:\n",
    "        x_ = Dense(256, activation='relu')(x)\n",
    "        outs.append(Dense(n, activation='softmax', name=str(i)+str(n))(x_))\n",
    "\n",
    "model = Model(input_, outs)\n",
    "model.compile(optimizer='adam', loss=losses, metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=7)\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_value(model.optimizer.learning_rate, 0.0005)\n",
    "\n",
    "#model.fit(train_dataset,epochs=250, verbose=1, callbacks=[callback])\n",
    "\n",
    "model.fit(states_actions_seq_10, data_map, epochs=1000, validation_split=0.1, verbose=1, callbacks=[callback], batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('NextStateModel_MulitLabel_rnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: -14.100000381469727,\n",
       " 1: -14.0,\n",
       " 2: -13.100000381469727,\n",
       " 3: -13.0,\n",
       " 4: -12.100000381469727,\n",
       " 5: -12.0,\n",
       " 6: -11.0,\n",
       " 7: -4.099999904632568,\n",
       " 8: -4.0,\n",
       " 9: -3.0999999046325684,\n",
       " 10: -3.0,\n",
       " 11: -2.0999999046325684,\n",
       " 12: -2.0,\n",
       " 13: -1.100000023841858,\n",
       " 14: -1.0,\n",
       " 15: -0.10000000149011612,\n",
       " 16: 0.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels, encoding, counts = np.unique(rewards, return_inverse=True, return_counts=True)\n",
    "reward_encoding = np.eye(labels.shape[0])[encoding]\n",
    "index_to_reward = {}; reward_to_index = {}\n",
    "for i in range(labels.shape[0]):\n",
    "    index_to_reward[i] = labels[i]\n",
    "    reward_to_index[labels[i]] = i\n",
    "reward_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_map[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16, 16, 15, ..., 13, 13, 15])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vectorize(reward_to_index.get)(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "697/697 [==============================] - 40s 32ms/step - loss: 5.4602 - 03_loss: 0.6317 - 04_loss: 0.1732 - 13_loss: 0.7735 - 14_loss: 0.6846 - 23_loss: 0.0096 - 24_loss: 0.0117 - 33_loss: 0.0084 - 34_loss: 0.0109 - 43_loss: 0.2901 - 44_loss: 1.1840 - 53_loss: 0.2879 - 54_loss: 0.3309 - reward_loss: 1.0636 - 03_categorical_accuracy: 0.6737 - 04_categorical_accuracy: 0.9542 - 13_categorical_accuracy: 0.6534 - 14_categorical_accuracy: 0.6525 - 23_categorical_accuracy: 0.9983 - 24_categorical_accuracy: 0.9984 - 33_categorical_accuracy: 0.9989 - 34_categorical_accuracy: 0.9991 - 43_categorical_accuracy: 0.9178 - 44_categorical_accuracy: 0.4848 - 53_categorical_accuracy: 0.9146 - 54_categorical_accuracy: 0.9051 - reward_categorical_accuracy: 0.5444 - val_loss: 5.3018 - val_03_loss: 0.6191 - val_04_loss: 0.1649 - val_13_loss: 0.7674 - val_14_loss: 0.6652 - val_23_loss: 3.0066e-07 - val_24_loss: 2.0759e-07 - val_33_loss: 1.9189e-07 - val_34_loss: 3.0028e-07 - val_43_loss: 0.2708 - val_44_loss: 1.1960 - val_53_loss: 0.2773 - val_54_loss: 0.3060 - val_reward_loss: 1.0350 - val_03_categorical_accuracy: 0.6786 - val_04_categorical_accuracy: 0.9529 - val_13_categorical_accuracy: 0.6512 - val_14_categorical_accuracy: 0.6591 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9212 - val_44_categorical_accuracy: 0.4798 - val_53_categorical_accuracy: 0.9154 - val_54_categorical_accuracy: 0.9084 - val_reward_categorical_accuracy: 0.5520\n",
      "Epoch 2/1000\n",
      "697/697 [==============================] - 18s 27ms/step - loss: 5.2313 - 03_loss: 0.6192 - 04_loss: 0.1499 - 13_loss: 0.7645 - 14_loss: 0.6671 - 23_loss: 3.4238e-07 - 24_loss: 2.2202e-07 - 33_loss: 1.9795e-07 - 34_loss: 3.0283e-07 - 43_loss: 0.2757 - 44_loss: 1.1553 - 53_loss: 0.2722 - 54_loss: 0.2977 - reward_loss: 1.0298 - 03_categorical_accuracy: 0.6754 - 04_categorical_accuracy: 0.9592 - 13_categorical_accuracy: 0.6540 - 14_categorical_accuracy: 0.6604 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9193 - 44_categorical_accuracy: 0.4959 - 53_categorical_accuracy: 0.9166 - 54_categorical_accuracy: 0.9104 - reward_categorical_accuracy: 0.5550 - val_loss: 5.2539 - val_03_loss: 0.6156 - val_04_loss: 0.1506 - val_13_loss: 0.7655 - val_14_loss: 0.6648 - val_23_loss: 1.4226e-07 - val_24_loss: 8.9852e-08 - val_33_loss: 8.9720e-08 - val_34_loss: 1.2041e-07 - val_43_loss: 0.2691 - val_44_loss: 1.1734 - val_53_loss: 0.2753 - val_54_loss: 0.3060 - val_reward_loss: 1.0335 - val_03_categorical_accuracy: 0.6786 - val_04_categorical_accuracy: 0.9591 - val_13_categorical_accuracy: 0.6516 - val_14_categorical_accuracy: 0.6573 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9214 - val_44_categorical_accuracy: 0.4941 - val_53_categorical_accuracy: 0.9156 - val_54_categorical_accuracy: 0.9096 - val_reward_categorical_accuracy: 0.5513\n",
      "Epoch 3/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 5.1775 - 03_loss: 0.6174 - 04_loss: 0.1456 - 13_loss: 0.7625 - 14_loss: 0.6633 - 23_loss: 1.1111e-07 - 24_loss: 7.2317e-08 - 33_loss: 5.9599e-08 - 34_loss: 8.9645e-08 - 43_loss: 0.2735 - 44_loss: 1.1399 - 53_loss: 0.2707 - 54_loss: 0.2858 - reward_loss: 1.0189 - 03_categorical_accuracy: 0.6753 - 04_categorical_accuracy: 0.9604 - 13_categorical_accuracy: 0.6548 - 14_categorical_accuracy: 0.6632 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9195 - 44_categorical_accuracy: 0.5018 - 53_categorical_accuracy: 0.9168 - 54_categorical_accuracy: 0.9123 - reward_categorical_accuracy: 0.5578 - val_loss: 5.2754 - val_03_loss: 0.6160 - val_04_loss: 0.1514 - val_13_loss: 0.7614 - val_14_loss: 0.6621 - val_23_loss: 2.9549e-08 - val_24_loss: 2.1283e-08 - val_33_loss: 2.0121e-08 - val_34_loss: 2.5287e-08 - val_43_loss: 0.2672 - val_44_loss: 1.1777 - val_53_loss: 0.2739 - val_54_loss: 0.3189 - val_reward_loss: 1.0468 - val_03_categorical_accuracy: 0.6781 - val_04_categorical_accuracy: 0.9591 - val_13_categorical_accuracy: 0.6523 - val_14_categorical_accuracy: 0.6612 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9216 - val_44_categorical_accuracy: 0.4956 - val_53_categorical_accuracy: 0.9156 - val_54_categorical_accuracy: 0.9046 - val_reward_categorical_accuracy: 0.5530\n",
      "Epoch 4/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 5.1188 - 03_loss: 0.6150 - 04_loss: 0.1420 - 13_loss: 0.7606 - 14_loss: 0.6585 - 23_loss: 4.4722e-08 - 24_loss: 3.0444e-08 - 33_loss: 2.4711e-08 - 34_loss: 3.6089e-08 - 43_loss: 0.2720 - 44_loss: 1.1223 - 53_loss: 0.2696 - 54_loss: 0.2723 - reward_loss: 1.0066 - 03_categorical_accuracy: 0.6755 - 04_categorical_accuracy: 0.9613 - 13_categorical_accuracy: 0.6554 - 14_categorical_accuracy: 0.6659 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9196 - 44_categorical_accuracy: 0.5088 - 53_categorical_accuracy: 0.9168 - 54_categorical_accuracy: 0.9161 - reward_categorical_accuracy: 0.5617 - val_loss: 5.3173 - val_03_loss: 0.6139 - val_04_loss: 0.1502 - val_13_loss: 0.7603 - val_14_loss: 0.6626 - val_23_loss: 4.7840e-08 - val_24_loss: 3.0392e-08 - val_33_loss: 2.9140e-08 - val_34_loss: 4.5841e-08 - val_43_loss: 0.2665 - val_44_loss: 1.2003 - val_53_loss: 0.2715 - val_54_loss: 0.3361 - val_reward_loss: 1.0560 - val_03_categorical_accuracy: 0.6789 - val_04_categorical_accuracy: 0.9598 - val_13_categorical_accuracy: 0.6541 - val_14_categorical_accuracy: 0.6614 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9220 - val_44_categorical_accuracy: 0.4906 - val_53_categorical_accuracy: 0.9165 - val_54_categorical_accuracy: 0.9061 - val_reward_categorical_accuracy: 0.5522\n",
      "Epoch 5/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 5.0533 - 03_loss: 0.6129 - 04_loss: 0.1378 - 13_loss: 0.7590 - 14_loss: 0.6536 - 23_loss: 2.4336e-08 - 24_loss: 1.7892e-08 - 33_loss: 1.3866e-08 - 34_loss: 2.0118e-08 - 43_loss: 0.2705 - 44_loss: 1.1006 - 53_loss: 0.2684 - 54_loss: 0.2573 - reward_loss: 0.9935 - 03_categorical_accuracy: 0.6765 - 04_categorical_accuracy: 0.9625 - 13_categorical_accuracy: 0.6562 - 14_categorical_accuracy: 0.6680 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9198 - 44_categorical_accuracy: 0.5194 - 53_categorical_accuracy: 0.9171 - 54_categorical_accuracy: 0.9192 - reward_categorical_accuracy: 0.5659 - val_loss: 5.3227 - val_03_loss: 0.6123 - val_04_loss: 0.1504 - val_13_loss: 0.7604 - val_14_loss: 0.6605 - val_23_loss: 1.4733e-08 - val_24_loss: 1.3697e-08 - val_33_loss: 1.3553e-08 - val_34_loss: 1.4486e-08 - val_43_loss: 0.2664 - val_44_loss: 1.1977 - val_53_loss: 0.2722 - val_54_loss: 0.3405 - val_reward_loss: 1.0621 - val_03_categorical_accuracy: 0.6775 - val_04_categorical_accuracy: 0.9620 - val_13_categorical_accuracy: 0.6549 - val_14_categorical_accuracy: 0.6628 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9228 - val_44_categorical_accuracy: 0.4957 - val_53_categorical_accuracy: 0.9163 - val_54_categorical_accuracy: 0.9012 - val_reward_categorical_accuracy: 0.5519\n",
      "Epoch 6/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 4.9771 - 03_loss: 0.6101 - 04_loss: 0.1327 - 13_loss: 0.7570 - 14_loss: 0.6472 - 23_loss: 1.5675e-08 - 24_loss: 1.2421e-08 - 33_loss: 9.1655e-09 - 34_loss: 1.3482e-08 - 43_loss: 0.2688 - 44_loss: 1.0746 - 53_loss: 0.2670 - 54_loss: 0.2415 - reward_loss: 0.9783 - 03_categorical_accuracy: 0.6774 - 04_categorical_accuracy: 0.9634 - 13_categorical_accuracy: 0.6565 - 14_categorical_accuracy: 0.6705 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9203 - 44_categorical_accuracy: 0.5311 - 53_categorical_accuracy: 0.9178 - 54_categorical_accuracy: 0.9239 - reward_categorical_accuracy: 0.5695 - val_loss: 5.3919 - val_03_loss: 0.6130 - val_04_loss: 0.1540 - val_13_loss: 0.7610 - val_14_loss: 0.6640 - val_23_loss: 1.5341e-08 - val_24_loss: 1.4058e-08 - val_33_loss: 1.3902e-08 - val_34_loss: 1.5016e-08 - val_43_loss: 0.2653 - val_44_loss: 1.2441 - val_53_loss: 0.2721 - val_54_loss: 0.3513 - val_reward_loss: 1.0671 - val_03_categorical_accuracy: 0.6775 - val_04_categorical_accuracy: 0.9592 - val_13_categorical_accuracy: 0.6543 - val_14_categorical_accuracy: 0.6605 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9224 - val_44_categorical_accuracy: 0.4866 - val_53_categorical_accuracy: 0.9160 - val_54_categorical_accuracy: 0.9009 - val_reward_categorical_accuracy: 0.5512\n",
      "Epoch 7/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 4.8968 - 03_loss: 0.6066 - 04_loss: 0.1272 - 13_loss: 0.7546 - 14_loss: 0.6407 - 23_loss: 8.3286e-09 - 24_loss: 6.0474e-09 - 33_loss: 4.4359e-09 - 34_loss: 6.9057e-09 - 43_loss: 0.2670 - 44_loss: 1.0472 - 53_loss: 0.2653 - 54_loss: 0.2253 - reward_loss: 0.9629 - 03_categorical_accuracy: 0.6790 - 04_categorical_accuracy: 0.9647 - 13_categorical_accuracy: 0.6575 - 14_categorical_accuracy: 0.6726 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9207 - 44_categorical_accuracy: 0.5424 - 53_categorical_accuracy: 0.9185 - 54_categorical_accuracy: 0.9280 - reward_categorical_accuracy: 0.5747 - val_loss: 5.4846 - val_03_loss: 0.6138 - val_04_loss: 0.1555 - val_13_loss: 0.7613 - val_14_loss: 0.6697 - val_23_loss: 9.6331e-11 - val_24_loss: 1.8062e-11 - val_33_loss: 3.6124e-11 - val_34_loss: 9.6331e-11 - val_43_loss: 0.2685 - val_44_loss: 1.2566 - val_53_loss: 0.2742 - val_54_loss: 0.3909 - val_reward_loss: 1.0942 - val_03_categorical_accuracy: 0.6776 - val_04_categorical_accuracy: 0.9620 - val_13_categorical_accuracy: 0.6542 - val_14_categorical_accuracy: 0.6613 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9216 - val_44_categorical_accuracy: 0.4969 - val_53_categorical_accuracy: 0.9164 - val_54_categorical_accuracy: 0.8980 - val_reward_categorical_accuracy: 0.5458\n",
      "Epoch 8/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 4.8145 - 03_loss: 0.6028 - 04_loss: 0.1217 - 13_loss: 0.7522 - 14_loss: 0.6333 - 23_loss: 5.4728e-09 - 24_loss: 3.6418e-09 - 33_loss: 2.5595e-09 - 34_loss: 4.6312e-09 - 43_loss: 0.2643 - 44_loss: 1.0189 - 53_loss: 0.2633 - 54_loss: 0.2109 - reward_loss: 0.9470 - 03_categorical_accuracy: 0.6817 - 04_categorical_accuracy: 0.9659 - 13_categorical_accuracy: 0.6580 - 14_categorical_accuracy: 0.6756 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9213 - 44_categorical_accuracy: 0.5552 - 53_categorical_accuracy: 0.9190 - 54_categorical_accuracy: 0.9314 - reward_categorical_accuracy: 0.5789 - val_loss: 5.6133 - val_03_loss: 0.6171 - val_04_loss: 0.1628 - val_13_loss: 0.7639 - val_14_loss: 0.6765 - val_23_loss: 6.0207e-12 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 6.0207e-12 - val_43_loss: 0.2689 - val_44_loss: 1.2984 - val_53_loss: 0.2756 - val_54_loss: 0.4227 - val_reward_loss: 1.1273 - val_03_categorical_accuracy: 0.6731 - val_04_categorical_accuracy: 0.9604 - val_13_categorical_accuracy: 0.6560 - val_14_categorical_accuracy: 0.6588 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9227 - val_44_categorical_accuracy: 0.4930 - val_53_categorical_accuracy: 0.9165 - val_54_categorical_accuracy: 0.8935 - val_reward_categorical_accuracy: 0.5488\n",
      "Epoch 9/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 4.7325 - 03_loss: 0.5989 - 04_loss: 0.1167 - 13_loss: 0.7493 - 14_loss: 0.6262 - 23_loss: 6.4107e-09 - 24_loss: 4.6908e-09 - 33_loss: 3.3288e-09 - 34_loss: 5.7410e-09 - 43_loss: 0.2619 - 44_loss: 0.9911 - 53_loss: 0.2605 - 54_loss: 0.1974 - reward_loss: 0.9305 - 03_categorical_accuracy: 0.6841 - 04_categorical_accuracy: 0.9668 - 13_categorical_accuracy: 0.6591 - 14_categorical_accuracy: 0.6783 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9221 - 44_categorical_accuracy: 0.5667 - 53_categorical_accuracy: 0.9196 - 54_categorical_accuracy: 0.9345 - reward_categorical_accuracy: 0.5838 - val_loss: 5.6552 - val_03_loss: 0.6177 - val_04_loss: 0.1617 - val_13_loss: 0.7644 - val_14_loss: 0.6809 - val_23_loss: 6.0207e-12 - val_24_loss: 6.0207e-12 - val_33_loss: 6.0207e-12 - val_34_loss: 6.0207e-12 - val_43_loss: 0.2716 - val_44_loss: 1.3469 - val_53_loss: 0.2779 - val_54_loss: 0.4115 - val_reward_loss: 1.1226 - val_03_categorical_accuracy: 0.6738 - val_04_categorical_accuracy: 0.9593 - val_13_categorical_accuracy: 0.6553 - val_14_categorical_accuracy: 0.6581 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9213 - val_44_categorical_accuracy: 0.4902 - val_53_categorical_accuracy: 0.9161 - val_54_categorical_accuracy: 0.8929 - val_reward_categorical_accuracy: 0.5465\n",
      "Epoch 10/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 4.6520 - 03_loss: 0.5944 - 04_loss: 0.1117 - 13_loss: 0.7457 - 14_loss: 0.6189 - 23_loss: 4.2258e-09 - 24_loss: 3.2498e-09 - 33_loss: 2.5374e-09 - 34_loss: 3.8465e-09 - 43_loss: 0.2587 - 44_loss: 0.9650 - 53_loss: 0.2575 - 54_loss: 0.1849 - reward_loss: 0.9151 - 03_categorical_accuracy: 0.6861 - 04_categorical_accuracy: 0.9677 - 13_categorical_accuracy: 0.6598 - 14_categorical_accuracy: 0.6814 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9222 - 44_categorical_accuracy: 0.5775 - 53_categorical_accuracy: 0.9205 - 54_categorical_accuracy: 0.9380 - reward_categorical_accuracy: 0.5888 - val_loss: 5.7486 - val_03_loss: 0.6205 - val_04_loss: 0.1688 - val_13_loss: 0.7668 - val_14_loss: 0.6893 - val_23_loss: 1.3245e-08 - val_24_loss: 1.3245e-08 - val_33_loss: 1.3245e-08 - val_34_loss: 1.3245e-08 - val_43_loss: 0.2732 - val_44_loss: 1.3856 - val_53_loss: 0.2801 - val_54_loss: 0.4347 - val_reward_loss: 1.1295 - val_03_categorical_accuracy: 0.6740 - val_04_categorical_accuracy: 0.9592 - val_13_categorical_accuracy: 0.6554 - val_14_categorical_accuracy: 0.6575 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9223 - val_44_categorical_accuracy: 0.4888 - val_53_categorical_accuracy: 0.9161 - val_54_categorical_accuracy: 0.8896 - val_reward_categorical_accuracy: 0.5445\n",
      "Epoch 11/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 19s 27ms/step - loss: 4.5737 - 03_loss: 0.5893 - 04_loss: 0.1067 - 13_loss: 0.7419 - 14_loss: 0.6122 - 23_loss: 3.1522e-09 - 24_loss: 2.6638e-09 - 33_loss: 2.0591e-09 - 34_loss: 3.2057e-09 - 43_loss: 0.2549 - 44_loss: 0.9402 - 53_loss: 0.2542 - 54_loss: 0.1746 - reward_loss: 0.8996 - 03_categorical_accuracy: 0.6900 - 04_categorical_accuracy: 0.9687 - 13_categorical_accuracy: 0.6605 - 14_categorical_accuracy: 0.6838 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9230 - 44_categorical_accuracy: 0.5879 - 53_categorical_accuracy: 0.9211 - 54_categorical_accuracy: 0.9404 - reward_categorical_accuracy: 0.5934 - val_loss: 5.8639 - val_03_loss: 0.6254 - val_04_loss: 0.1748 - val_13_loss: 0.7712 - val_14_loss: 0.6985 - val_23_loss: 6.0207e-11 - val_24_loss: 1.2041e-11 - val_33_loss: 1.2041e-11 - val_34_loss: 3.0103e-11 - val_43_loss: 0.2764 - val_44_loss: 1.4258 - val_53_loss: 0.2840 - val_54_loss: 0.4572 - val_reward_loss: 1.1506 - val_03_categorical_accuracy: 0.6730 - val_04_categorical_accuracy: 0.9586 - val_13_categorical_accuracy: 0.6553 - val_14_categorical_accuracy: 0.6552 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9216 - val_44_categorical_accuracy: 0.4848 - val_53_categorical_accuracy: 0.9155 - val_54_categorical_accuracy: 0.8955 - val_reward_categorical_accuracy: 0.5457\n",
      "Epoch 12/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 4.5007 - 03_loss: 0.5835 - 04_loss: 0.1027 - 13_loss: 0.7373 - 14_loss: 0.6059 - 23_loss: 3.1140e-09 - 24_loss: 2.6498e-09 - 33_loss: 2.1480e-09 - 34_loss: 3.5709e-09 - 43_loss: 0.2514 - 44_loss: 0.9186 - 53_loss: 0.2505 - 54_loss: 0.1657 - reward_loss: 0.8852 - 03_categorical_accuracy: 0.6934 - 04_categorical_accuracy: 0.9696 - 13_categorical_accuracy: 0.6617 - 14_categorical_accuracy: 0.6868 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9235 - 44_categorical_accuracy: 0.5969 - 53_categorical_accuracy: 0.9219 - 54_categorical_accuracy: 0.9429 - reward_categorical_accuracy: 0.5979 - val_loss: 5.9404 - val_03_loss: 0.6282 - val_04_loss: 0.1814 - val_13_loss: 0.7742 - val_14_loss: 0.7034 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.2796 - val_44_loss: 1.4323 - val_53_loss: 0.2873 - val_54_loss: 0.4631 - val_reward_loss: 1.1909 - val_03_categorical_accuracy: 0.6714 - val_04_categorical_accuracy: 0.9586 - val_13_categorical_accuracy: 0.6538 - val_14_categorical_accuracy: 0.6547 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9216 - val_44_categorical_accuracy: 0.4861 - val_53_categorical_accuracy: 0.9158 - val_54_categorical_accuracy: 0.8902 - val_reward_categorical_accuracy: 0.5423\n",
      "Epoch 13/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 4.4258 - 03_loss: 0.5772 - 04_loss: 0.0985 - 13_loss: 0.7324 - 14_loss: 0.5998 - 23_loss: 1.8042e-09 - 24_loss: 2.1929e-09 - 33_loss: 1.5941e-09 - 34_loss: 2.5247e-09 - 43_loss: 0.2470 - 44_loss: 0.8963 - 53_loss: 0.2461 - 54_loss: 0.1568 - reward_loss: 0.8717 - 03_categorical_accuracy: 0.6977 - 04_categorical_accuracy: 0.9702 - 13_categorical_accuracy: 0.6625 - 14_categorical_accuracy: 0.6893 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9242 - 44_categorical_accuracy: 0.6077 - 53_categorical_accuracy: 0.9227 - 54_categorical_accuracy: 0.9449 - reward_categorical_accuracy: 0.6032 - val_loss: 6.1001 - val_03_loss: 0.6358 - val_04_loss: 0.1922 - val_13_loss: 0.7770 - val_14_loss: 0.7112 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.2859 - val_44_loss: 1.4861 - val_53_loss: 0.2925 - val_54_loss: 0.5034 - val_reward_loss: 1.2159 - val_03_categorical_accuracy: 0.6646 - val_04_categorical_accuracy: 0.9597 - val_13_categorical_accuracy: 0.6531 - val_14_categorical_accuracy: 0.6533 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9197 - val_44_categorical_accuracy: 0.4819 - val_53_categorical_accuracy: 0.9145 - val_54_categorical_accuracy: 0.8933 - val_reward_categorical_accuracy: 0.5417\n",
      "Epoch 14/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 4.3608 - 03_loss: 0.5714 - 04_loss: 0.0955 - 13_loss: 0.7277 - 14_loss: 0.5943 - 23_loss: 2.0731e-09 - 24_loss: 1.9915e-09 - 33_loss: 1.5640e-09 - 34_loss: 2.1059e-09 - 43_loss: 0.2430 - 44_loss: 0.8784 - 53_loss: 0.2425 - 54_loss: 0.1498 - reward_loss: 0.8582 - 03_categorical_accuracy: 0.7013 - 04_categorical_accuracy: 0.9707 - 13_categorical_accuracy: 0.6631 - 14_categorical_accuracy: 0.6911 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9250 - 44_categorical_accuracy: 0.6147 - 53_categorical_accuracy: 0.9235 - 54_categorical_accuracy: 0.9467 - reward_categorical_accuracy: 0.6072 - val_loss: 6.2384 - val_03_loss: 0.6463 - val_04_loss: 0.1932 - val_13_loss: 0.7838 - val_14_loss: 0.7250 - val_23_loss: 1.3245e-08 - val_24_loss: 1.3245e-08 - val_33_loss: 0.0000e+00 - val_34_loss: 1.3245e-08 - val_43_loss: 0.2894 - val_44_loss: 1.5458 - val_53_loss: 0.2952 - val_54_loss: 0.5144 - val_reward_loss: 1.2453 - val_03_categorical_accuracy: 0.6630 - val_04_categorical_accuracy: 0.9567 - val_13_categorical_accuracy: 0.6521 - val_14_categorical_accuracy: 0.6506 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9183 - val_44_categorical_accuracy: 0.4837 - val_53_categorical_accuracy: 0.9148 - val_54_categorical_accuracy: 0.8842 - val_reward_categorical_accuracy: 0.5332\n",
      "Epoch 15/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 4.2921 - 03_loss: 0.5655 - 04_loss: 0.0924 - 13_loss: 0.7222 - 14_loss: 0.5887 - 23_loss: 9.3856e-10 - 24_loss: 9.8672e-10 - 33_loss: 7.6596e-10 - 34_loss: 9.9408e-10 - 43_loss: 0.2381 - 44_loss: 0.8595 - 53_loss: 0.2375 - 54_loss: 0.1424 - reward_loss: 0.8458 - 03_categorical_accuracy: 0.7057 - 04_categorical_accuracy: 0.9714 - 13_categorical_accuracy: 0.6646 - 14_categorical_accuracy: 0.6940 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9255 - 44_categorical_accuracy: 0.6228 - 53_categorical_accuracy: 0.9244 - 54_categorical_accuracy: 0.9485 - reward_categorical_accuracy: 0.6113 - val_loss: 6.3466 - val_03_loss: 0.6511 - val_04_loss: 0.2004 - val_13_loss: 0.7891 - val_14_loss: 0.7350 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.2952 - val_44_loss: 1.5489 - val_53_loss: 0.3011 - val_54_loss: 0.5424 - val_reward_loss: 1.2833 - val_03_categorical_accuracy: 0.6628 - val_04_categorical_accuracy: 0.9587 - val_13_categorical_accuracy: 0.6509 - val_14_categorical_accuracy: 0.6530 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9183 - val_44_categorical_accuracy: 0.4886 - val_53_categorical_accuracy: 0.9121 - val_54_categorical_accuracy: 0.8896 - val_reward_categorical_accuracy: 0.5339\n",
      "Epoch 16/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 4.2286 - 03_loss: 0.5588 - 04_loss: 0.0897 - 13_loss: 0.7164 - 14_loss: 0.5835 - 23_loss: 9.3922e-10 - 24_loss: 1.1239e-09 - 33_loss: 7.9540e-10 - 34_loss: 1.2884e-09 - 43_loss: 0.2336 - 44_loss: 0.8422 - 53_loss: 0.2332 - 54_loss: 0.1378 - reward_loss: 0.8333 - 03_categorical_accuracy: 0.7095 - 04_categorical_accuracy: 0.9717 - 13_categorical_accuracy: 0.6656 - 14_categorical_accuracy: 0.6962 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9265 - 44_categorical_accuracy: 0.6310 - 53_categorical_accuracy: 0.9248 - 54_categorical_accuracy: 0.9486 - reward_categorical_accuracy: 0.6162 - val_loss: 6.3663 - val_03_loss: 0.6590 - val_04_loss: 0.1972 - val_13_loss: 0.7930 - val_14_loss: 0.7393 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 1.3245e-08 - val_43_loss: 0.2987 - val_44_loss: 1.5650 - val_53_loss: 0.3067 - val_54_loss: 0.5330 - val_reward_loss: 1.2745 - val_03_categorical_accuracy: 0.6600 - val_04_categorical_accuracy: 0.9541 - val_13_categorical_accuracy: 0.6495 - val_14_categorical_accuracy: 0.6512 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9175 - val_44_categorical_accuracy: 0.4772 - val_53_categorical_accuracy: 0.9139 - val_54_categorical_accuracy: 0.8842 - val_reward_categorical_accuracy: 0.5260\n",
      "Epoch 17/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 4.1653 - 03_loss: 0.5522 - 04_loss: 0.0869 - 13_loss: 0.7104 - 14_loss: 0.5793 - 23_loss: 1.2001e-09 - 24_loss: 1.4443e-09 - 33_loss: 1.1419e-09 - 34_loss: 1.4811e-09 - 43_loss: 0.2288 - 44_loss: 0.8254 - 53_loss: 0.2289 - 54_loss: 0.1321 - reward_loss: 0.8213 - 03_categorical_accuracy: 0.7146 - 04_categorical_accuracy: 0.9725 - 13_categorical_accuracy: 0.6673 - 14_categorical_accuracy: 0.6981 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9269 - 44_categorical_accuracy: 0.6379 - 53_categorical_accuracy: 0.9261 - 54_categorical_accuracy: 0.9501 - reward_categorical_accuracy: 0.6202 - val_loss: 6.5244 - val_03_loss: 0.6717 - val_04_loss: 0.2101 - val_13_loss: 0.8003 - val_14_loss: 0.7458 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3061 - val_44_loss: 1.6194 - val_53_loss: 0.3132 - val_54_loss: 0.5523 - val_reward_loss: 1.3054 - val_03_categorical_accuracy: 0.6592 - val_04_categorical_accuracy: 0.9560 - val_13_categorical_accuracy: 0.6445 - val_14_categorical_accuracy: 0.6501 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9152 - val_44_categorical_accuracy: 0.4735 - val_53_categorical_accuracy: 0.9107 - val_54_categorical_accuracy: 0.8873 - val_reward_categorical_accuracy: 0.5296\n",
      "Epoch 18/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 4.1048 - 03_loss: 0.5449 - 04_loss: 0.0858 - 13_loss: 0.7039 - 14_loss: 0.5739 - 23_loss: 1.0275e-09 - 24_loss: 1.4269e-09 - 33_loss: 9.2451e-10 - 34_loss: 1.4115e-09 - 43_loss: 0.2247 - 44_loss: 0.8108 - 53_loss: 0.2243 - 54_loss: 0.1272 - reward_loss: 0.8093 - 03_categorical_accuracy: 0.7190 - 04_categorical_accuracy: 0.9723 - 13_categorical_accuracy: 0.6688 - 14_categorical_accuracy: 0.7005 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9279 - 44_categorical_accuracy: 0.6434 - 53_categorical_accuracy: 0.9266 - 54_categorical_accuracy: 0.9513 - reward_categorical_accuracy: 0.6248 - val_loss: 6.6884 - val_03_loss: 0.6847 - val_04_loss: 0.2087 - val_13_loss: 0.8075 - val_14_loss: 0.7582 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3165 - val_44_loss: 1.6571 - val_53_loss: 0.3201 - val_54_loss: 0.5905 - val_reward_loss: 1.3451 - val_03_categorical_accuracy: 0.6609 - val_04_categorical_accuracy: 0.9554 - val_13_categorical_accuracy: 0.6420 - val_14_categorical_accuracy: 0.6451 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9114 - val_44_categorical_accuracy: 0.4707 - val_53_categorical_accuracy: 0.9115 - val_54_categorical_accuracy: 0.8833 - val_reward_categorical_accuracy: 0.5261\n",
      "Epoch 19/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 4.0486 - 03_loss: 0.5381 - 04_loss: 0.0831 - 13_loss: 0.6977 - 14_loss: 0.5698 - 23_loss: 6.4354e-10 - 24_loss: 8.1145e-10 - 33_loss: 6.1210e-10 - 34_loss: 8.2282e-10 - 43_loss: 0.2206 - 44_loss: 0.7973 - 53_loss: 0.2196 - 54_loss: 0.1233 - reward_loss: 0.7991 - 03_categorical_accuracy: 0.7224 - 04_categorical_accuracy: 0.9728 - 13_categorical_accuracy: 0.6702 - 14_categorical_accuracy: 0.7019 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9287 - 44_categorical_accuracy: 0.6504 - 53_categorical_accuracy: 0.9277 - 54_categorical_accuracy: 0.9521 - reward_categorical_accuracy: 0.6277 - val_loss: 6.7452 - val_03_loss: 0.6979 - val_04_loss: 0.2178 - val_13_loss: 0.8164 - val_14_loss: 0.7627 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3204 - val_44_loss: 1.6639 - val_53_loss: 0.3266 - val_54_loss: 0.5824 - val_reward_loss: 1.3572 - val_03_categorical_accuracy: 0.6466 - val_04_categorical_accuracy: 0.9553 - val_13_categorical_accuracy: 0.6414 - val_14_categorical_accuracy: 0.6470 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9130 - val_44_categorical_accuracy: 0.4740 - val_53_categorical_accuracy: 0.9115 - val_54_categorical_accuracy: 0.8820 - val_reward_categorical_accuracy: 0.5244\n",
      "Epoch 20/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 3.9925 - 03_loss: 0.5320 - 04_loss: 0.0811 - 13_loss: 0.6910 - 14_loss: 0.5651 - 23_loss: 1.1198e-09 - 24_loss: 1.5172e-09 - 33_loss: 9.5193e-10 - 34_loss: 1.4925e-09 - 43_loss: 0.2161 - 44_loss: 0.7834 - 53_loss: 0.2158 - 54_loss: 0.1203 - reward_loss: 0.7878 - 03_categorical_accuracy: 0.7267 - 04_categorical_accuracy: 0.9734 - 13_categorical_accuracy: 0.6727 - 14_categorical_accuracy: 0.7051 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9296 - 44_categorical_accuracy: 0.6561 - 53_categorical_accuracy: 0.9284 - 54_categorical_accuracy: 0.9522 - reward_categorical_accuracy: 0.6319 - val_loss: 6.8092 - val_03_loss: 0.7012 - val_04_loss: 0.2192 - val_13_loss: 0.8276 - val_14_loss: 0.7727 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3236 - val_44_loss: 1.6753 - val_53_loss: 0.3321 - val_54_loss: 0.5933 - val_reward_loss: 1.3643 - val_03_categorical_accuracy: 0.6547 - val_04_categorical_accuracy: 0.9526 - val_13_categorical_accuracy: 0.6378 - val_14_categorical_accuracy: 0.6412 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9112 - val_44_categorical_accuracy: 0.4703 - val_53_categorical_accuracy: 0.9074 - val_54_categorical_accuracy: 0.8763 - val_reward_categorical_accuracy: 0.5166\n",
      "Epoch 21/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 19s 28ms/step - loss: 3.9384 - 03_loss: 0.5252 - 04_loss: 0.0800 - 13_loss: 0.6841 - 14_loss: 0.5608 - 23_loss: 1.3707e-09 - 24_loss: 1.5828e-09 - 33_loss: 1.2750e-09 - 34_loss: 1.7681e-09 - 43_loss: 0.2117 - 44_loss: 0.7712 - 53_loss: 0.2114 - 54_loss: 0.1167 - reward_loss: 0.7773 - 03_categorical_accuracy: 0.7302 - 04_categorical_accuracy: 0.9736 - 13_categorical_accuracy: 0.6749 - 14_categorical_accuracy: 0.7065 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9303 - 44_categorical_accuracy: 0.6608 - 53_categorical_accuracy: 0.9296 - 54_categorical_accuracy: 0.9531 - reward_categorical_accuracy: 0.6358 - val_loss: 6.8753 - val_03_loss: 0.7028 - val_04_loss: 0.2206 - val_13_loss: 0.8353 - val_14_loss: 0.7795 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3288 - val_44_loss: 1.6865 - val_53_loss: 0.3380 - val_54_loss: 0.5927 - val_reward_loss: 1.3911 - val_03_categorical_accuracy: 0.6543 - val_04_categorical_accuracy: 0.9567 - val_13_categorical_accuracy: 0.6399 - val_14_categorical_accuracy: 0.6411 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9108 - val_44_categorical_accuracy: 0.4721 - val_53_categorical_accuracy: 0.9073 - val_54_categorical_accuracy: 0.8816 - val_reward_categorical_accuracy: 0.5233\n",
      "Epoch 22/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 3.8869 - 03_loss: 0.5181 - 04_loss: 0.0788 - 13_loss: 0.6777 - 14_loss: 0.5561 - 23_loss: 1.3881e-09 - 24_loss: 1.5540e-09 - 33_loss: 1.1908e-09 - 34_loss: 1.7012e-09 - 43_loss: 0.2073 - 44_loss: 0.7598 - 53_loss: 0.2069 - 54_loss: 0.1139 - reward_loss: 0.7682 - 03_categorical_accuracy: 0.7355 - 04_categorical_accuracy: 0.9738 - 13_categorical_accuracy: 0.6776 - 14_categorical_accuracy: 0.7093 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9311 - 44_categorical_accuracy: 0.6659 - 53_categorical_accuracy: 0.9299 - 54_categorical_accuracy: 0.9536 - reward_categorical_accuracy: 0.6395 - val_loss: 7.1164 - val_03_loss: 0.7236 - val_04_loss: 0.2319 - val_13_loss: 0.8433 - val_14_loss: 0.7927 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3379 - val_44_loss: 1.7432 - val_53_loss: 0.3476 - val_54_loss: 0.6482 - val_reward_loss: 1.4481 - val_03_categorical_accuracy: 0.6505 - val_04_categorical_accuracy: 0.9536 - val_13_categorical_accuracy: 0.6291 - val_14_categorical_accuracy: 0.6390 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9098 - val_44_categorical_accuracy: 0.4714 - val_53_categorical_accuracy: 0.9031 - val_54_categorical_accuracy: 0.8794 - val_reward_categorical_accuracy: 0.5175\n",
      "Epoch 23/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 3.8360 - 03_loss: 0.5125 - 04_loss: 0.0771 - 13_loss: 0.6711 - 14_loss: 0.5519 - 23_loss: 9.5996e-10 - 24_loss: 1.2657e-09 - 33_loss: 8.8972e-10 - 34_loss: 1.3593e-09 - 43_loss: 0.2031 - 44_loss: 0.7480 - 53_loss: 0.2029 - 54_loss: 0.1106 - reward_loss: 0.7588 - 03_categorical_accuracy: 0.7379 - 04_categorical_accuracy: 0.9741 - 13_categorical_accuracy: 0.6797 - 14_categorical_accuracy: 0.7124 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9318 - 44_categorical_accuracy: 0.6702 - 53_categorical_accuracy: 0.9311 - 54_categorical_accuracy: 0.9545 - reward_categorical_accuracy: 0.6427 - val_loss: 7.1688 - val_03_loss: 0.7329 - val_04_loss: 0.2325 - val_13_loss: 0.8549 - val_14_loss: 0.7993 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3412 - val_44_loss: 1.7617 - val_53_loss: 0.3549 - val_54_loss: 0.6557 - val_reward_loss: 1.4358 - val_03_categorical_accuracy: 0.6372 - val_04_categorical_accuracy: 0.9553 - val_13_categorical_accuracy: 0.6306 - val_14_categorical_accuracy: 0.6424 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9106 - val_44_categorical_accuracy: 0.4649 - val_53_categorical_accuracy: 0.9080 - val_54_categorical_accuracy: 0.8829 - val_reward_categorical_accuracy: 0.5201\n",
      "Epoch 24/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 3.7848 - 03_loss: 0.5056 - 04_loss: 0.0760 - 13_loss: 0.6636 - 14_loss: 0.5473 - 23_loss: 7.9941e-10 - 24_loss: 1.0135e-09 - 33_loss: 7.3051e-10 - 34_loss: 1.0817e-09 - 43_loss: 0.1998 - 44_loss: 0.7361 - 53_loss: 0.1986 - 54_loss: 0.1083 - reward_loss: 0.7496 - 03_categorical_accuracy: 0.7417 - 04_categorical_accuracy: 0.9746 - 13_categorical_accuracy: 0.6823 - 14_categorical_accuracy: 0.7136 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9324 - 44_categorical_accuracy: 0.6765 - 53_categorical_accuracy: 0.9322 - 54_categorical_accuracy: 0.9549 - reward_categorical_accuracy: 0.6468 - val_loss: 7.3193 - val_03_loss: 0.7496 - val_04_loss: 0.2369 - val_13_loss: 0.8736 - val_14_loss: 0.8224 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3533 - val_44_loss: 1.7761 - val_53_loss: 0.3621 - val_54_loss: 0.6578 - val_reward_loss: 1.4875 - val_03_categorical_accuracy: 0.6429 - val_04_categorical_accuracy: 0.9525 - val_13_categorical_accuracy: 0.6275 - val_14_categorical_accuracy: 0.6404 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9057 - val_44_categorical_accuracy: 0.4699 - val_53_categorical_accuracy: 0.9033 - val_54_categorical_accuracy: 0.8806 - val_reward_categorical_accuracy: 0.5123\n",
      "Epoch 25/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 3.7348 - 03_loss: 0.4989 - 04_loss: 0.0749 - 13_loss: 0.6563 - 14_loss: 0.5422 - 23_loss: 6.0943e-10 - 24_loss: 9.4525e-10 - 33_loss: 4.6827e-10 - 34_loss: 1.0215e-09 - 43_loss: 0.1952 - 44_loss: 0.7266 - 53_loss: 0.1948 - 54_loss: 0.1061 - reward_loss: 0.7397 - 03_categorical_accuracy: 0.7464 - 04_categorical_accuracy: 0.9745 - 13_categorical_accuracy: 0.6859 - 14_categorical_accuracy: 0.7169 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9331 - 44_categorical_accuracy: 0.6803 - 53_categorical_accuracy: 0.9327 - 54_categorical_accuracy: 0.9552 - reward_categorical_accuracy: 0.6504 - val_loss: 7.4031 - val_03_loss: 0.7516 - val_04_loss: 0.2399 - val_13_loss: 0.8785 - val_14_loss: 0.8130 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3590 - val_44_loss: 1.8293 - val_53_loss: 0.3680 - val_54_loss: 0.6755 - val_reward_loss: 1.4883 - val_03_categorical_accuracy: 0.6415 - val_04_categorical_accuracy: 0.9529 - val_13_categorical_accuracy: 0.6267 - val_14_categorical_accuracy: 0.6356 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9055 - val_44_categorical_accuracy: 0.4631 - val_53_categorical_accuracy: 0.9014 - val_54_categorical_accuracy: 0.8781 - val_reward_categorical_accuracy: 0.5148\n",
      "Epoch 26/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 3.6886 - 03_loss: 0.4927 - 04_loss: 0.0740 - 13_loss: 0.6491 - 14_loss: 0.5380 - 23_loss: 6.8569e-10 - 24_loss: 8.1279e-10 - 33_loss: 6.0474e-10 - 34_loss: 7.6663e-10 - 43_loss: 0.1917 - 44_loss: 0.7170 - 53_loss: 0.1911 - 54_loss: 0.1035 - reward_loss: 0.7316 - 03_categorical_accuracy: 0.7489 - 04_categorical_accuracy: 0.9748 - 13_categorical_accuracy: 0.6888 - 14_categorical_accuracy: 0.7193 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9345 - 44_categorical_accuracy: 0.6842 - 53_categorical_accuracy: 0.9336 - 54_categorical_accuracy: 0.9556 - reward_categorical_accuracy: 0.6539 - val_loss: 7.4122 - val_03_loss: 0.7588 - val_04_loss: 0.2414 - val_13_loss: 0.8884 - val_14_loss: 0.8274 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3686 - val_44_loss: 1.7947 - val_53_loss: 0.3748 - val_54_loss: 0.6481 - val_reward_loss: 1.5101 - val_03_categorical_accuracy: 0.6413 - val_04_categorical_accuracy: 0.9552 - val_13_categorical_accuracy: 0.6268 - val_14_categorical_accuracy: 0.6349 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9078 - val_44_categorical_accuracy: 0.4660 - val_53_categorical_accuracy: 0.8996 - val_54_categorical_accuracy: 0.8797 - val_reward_categorical_accuracy: 0.5085\n",
      "Epoch 27/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 3.6448 - 03_loss: 0.4865 - 04_loss: 0.0734 - 13_loss: 0.6424 - 14_loss: 0.5335 - 23_loss: 9.0979e-10 - 24_loss: 1.1453e-09 - 33_loss: 7.7934e-10 - 34_loss: 1.1954e-09 - 43_loss: 0.1890 - 44_loss: 0.7068 - 53_loss: 0.1878 - 54_loss: 0.1019 - reward_loss: 0.7235 - 03_categorical_accuracy: 0.7534 - 04_categorical_accuracy: 0.9748 - 13_categorical_accuracy: 0.6916 - 14_categorical_accuracy: 0.7216 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9343 - 44_categorical_accuracy: 0.6886 - 53_categorical_accuracy: 0.9340 - 54_categorical_accuracy: 0.9559 - reward_categorical_accuracy: 0.6572 - val_loss: 7.6569 - val_03_loss: 0.7778 - val_04_loss: 0.2452 - val_13_loss: 0.9015 - val_14_loss: 0.8448 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3752 - val_44_loss: 1.8709 - val_53_loss: 0.3796 - val_54_loss: 0.6982 - val_reward_loss: 1.5637 - val_03_categorical_accuracy: 0.6451 - val_04_categorical_accuracy: 0.9526 - val_13_categorical_accuracy: 0.6152 - val_14_categorical_accuracy: 0.6277 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9062 - val_44_categorical_accuracy: 0.4678 - val_53_categorical_accuracy: 0.8961 - val_54_categorical_accuracy: 0.8815 - val_reward_categorical_accuracy: 0.5074\n",
      "Epoch 28/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 3.5991 - 03_loss: 0.4803 - 04_loss: 0.0724 - 13_loss: 0.6352 - 14_loss: 0.5295 - 23_loss: 2.0470e-10 - 24_loss: 2.6825e-10 - 33_loss: 1.2309e-10 - 34_loss: 3.1910e-10 - 43_loss: 0.1849 - 44_loss: 0.6978 - 53_loss: 0.1841 - 54_loss: 0.1000 - reward_loss: 0.7148 - 03_categorical_accuracy: 0.7567 - 04_categorical_accuracy: 0.9748 - 13_categorical_accuracy: 0.6943 - 14_categorical_accuracy: 0.7227 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9354 - 44_categorical_accuracy: 0.6928 - 53_categorical_accuracy: 0.9349 - 54_categorical_accuracy: 0.9564 - reward_categorical_accuracy: 0.6607 - val_loss: 7.7233 - val_03_loss: 0.7820 - val_04_loss: 0.2487 - val_13_loss: 0.9123 - val_14_loss: 0.8467 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3745 - val_44_loss: 1.8975 - val_53_loss: 0.3932 - val_54_loss: 0.6971 - val_reward_loss: 1.5714 - val_03_categorical_accuracy: 0.6342 - val_04_categorical_accuracy: 0.9531 - val_13_categorical_accuracy: 0.6162 - val_14_categorical_accuracy: 0.6360 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.9070 - val_44_categorical_accuracy: 0.4690 - val_53_categorical_accuracy: 0.8982 - val_54_categorical_accuracy: 0.8816 - val_reward_categorical_accuracy: 0.5085\n",
      "Epoch 29/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 3.5584 - 03_loss: 0.4738 - 04_loss: 0.0717 - 13_loss: 0.6290 - 14_loss: 0.5246 - 23_loss: 1.2938e-09 - 24_loss: 1.5045e-09 - 33_loss: 1.0764e-09 - 34_loss: 1.5165e-09 - 43_loss: 0.1818 - 44_loss: 0.6909 - 53_loss: 0.1813 - 54_loss: 0.0987 - reward_loss: 0.7067 - 03_categorical_accuracy: 0.7604 - 04_categorical_accuracy: 0.9750 - 13_categorical_accuracy: 0.6981 - 14_categorical_accuracy: 0.7259 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9362 - 44_categorical_accuracy: 0.6943 - 53_categorical_accuracy: 0.9356 - 54_categorical_accuracy: 0.9566 - reward_categorical_accuracy: 0.6652 - val_loss: 7.8312 - val_03_loss: 0.8011 - val_04_loss: 0.2496 - val_13_loss: 0.9272 - val_14_loss: 0.8582 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3826 - val_44_loss: 1.9373 - val_53_loss: 0.3956 - val_54_loss: 0.6912 - val_reward_loss: 1.5885 - val_03_categorical_accuracy: 0.6279 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.6136 - val_14_categorical_accuracy: 0.6353 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8984 - val_44_categorical_accuracy: 0.4633 - val_53_categorical_accuracy: 0.8979 - val_54_categorical_accuracy: 0.8794 - val_reward_categorical_accuracy: 0.5037\n",
      "Epoch 30/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 3.5150 - 03_loss: 0.4686 - 04_loss: 0.0707 - 13_loss: 0.6214 - 14_loss: 0.5195 - 23_loss: 1.0208e-09 - 24_loss: 1.1152e-09 - 33_loss: 8.7300e-10 - 34_loss: 1.3486e-09 - 43_loss: 0.1785 - 44_loss: 0.6817 - 53_loss: 0.1778 - 54_loss: 0.0973 - reward_loss: 0.6996 - 03_categorical_accuracy: 0.7637 - 04_categorical_accuracy: 0.9753 - 13_categorical_accuracy: 0.7019 - 14_categorical_accuracy: 0.7295 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9366 - 44_categorical_accuracy: 0.6993 - 53_categorical_accuracy: 0.9361 - 54_categorical_accuracy: 0.9568 - reward_categorical_accuracy: 0.6686 - val_loss: 7.8531 - val_03_loss: 0.8018 - val_04_loss: 0.2559 - val_13_loss: 0.9299 - val_14_loss: 0.8626 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3884 - val_44_loss: 1.9181 - val_53_loss: 0.4034 - val_54_loss: 0.6941 - val_reward_loss: 1.5990 - val_03_categorical_accuracy: 0.6360 - val_04_categorical_accuracy: 0.9533 - val_13_categorical_accuracy: 0.6129 - val_14_categorical_accuracy: 0.6285 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8958 - val_44_categorical_accuracy: 0.4570 - val_53_categorical_accuracy: 0.8914 - val_54_categorical_accuracy: 0.8784 - val_reward_categorical_accuracy: 0.4971\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 19s 27ms/step - loss: 3.4749 - 03_loss: 0.4629 - 04_loss: 0.0701 - 13_loss: 0.6142 - 14_loss: 0.5152 - 23_loss: 1.0369e-09 - 24_loss: 1.1493e-09 - 33_loss: 9.5260e-10 - 34_loss: 1.2115e-09 - 43_loss: 0.1753 - 44_loss: 0.6742 - 53_loss: 0.1750 - 54_loss: 0.0958 - reward_loss: 0.6922 - 03_categorical_accuracy: 0.7673 - 04_categorical_accuracy: 0.9752 - 13_categorical_accuracy: 0.7056 - 14_categorical_accuracy: 0.7322 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9373 - 44_categorical_accuracy: 0.7011 - 53_categorical_accuracy: 0.9369 - 54_categorical_accuracy: 0.9572 - reward_categorical_accuracy: 0.6708 - val_loss: 7.8959 - val_03_loss: 0.8208 - val_04_loss: 0.2566 - val_13_loss: 0.9469 - val_14_loss: 0.8691 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.3920 - val_44_loss: 1.8950 - val_53_loss: 0.3991 - val_54_loss: 0.7201 - val_reward_loss: 1.5964 - val_03_categorical_accuracy: 0.6329 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.6071 - val_14_categorical_accuracy: 0.6204 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8980 - val_44_categorical_accuracy: 0.4588 - val_53_categorical_accuracy: 0.8967 - val_54_categorical_accuracy: 0.8833 - val_reward_categorical_accuracy: 0.5037\n",
      "Epoch 32/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 3.4331 - 03_loss: 0.4575 - 04_loss: 0.0697 - 13_loss: 0.6070 - 14_loss: 0.5093 - 23_loss: 7.6931e-10 - 24_loss: 1.0228e-09 - 33_loss: 5.9872e-10 - 34_loss: 1.0222e-09 - 43_loss: 0.1725 - 44_loss: 0.6667 - 53_loss: 0.1722 - 54_loss: 0.0943 - reward_loss: 0.6839 - 03_categorical_accuracy: 0.7702 - 04_categorical_accuracy: 0.9753 - 13_categorical_accuracy: 0.7094 - 14_categorical_accuracy: 0.7354 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9379 - 44_categorical_accuracy: 0.7052 - 53_categorical_accuracy: 0.9373 - 54_categorical_accuracy: 0.9573 - reward_categorical_accuracy: 0.6750 - val_loss: 8.1333 - val_03_loss: 0.8297 - val_04_loss: 0.2610 - val_13_loss: 0.9622 - val_14_loss: 0.8967 - val_23_loss: 1.3245e-08 - val_24_loss: 1.3245e-08 - val_33_loss: 1.3245e-08 - val_34_loss: 1.3245e-08 - val_43_loss: 0.4038 - val_44_loss: 1.9795 - val_53_loss: 0.4149 - val_54_loss: 0.7378 - val_reward_loss: 1.6477 - val_03_categorical_accuracy: 0.6303 - val_04_categorical_accuracy: 0.9544 - val_13_categorical_accuracy: 0.6061 - val_14_categorical_accuracy: 0.6226 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8970 - val_44_categorical_accuracy: 0.4531 - val_53_categorical_accuracy: 0.8896 - val_54_categorical_accuracy: 0.8781 - val_reward_categorical_accuracy: 0.4970\n",
      "Epoch 33/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 3.3965 - 03_loss: 0.4520 - 04_loss: 0.0693 - 13_loss: 0.5998 - 14_loss: 0.5055 - 23_loss: 5.0038e-10 - 24_loss: 7.7332e-10 - 33_loss: 4.2278e-10 - 34_loss: 7.5459e-10 - 43_loss: 0.1696 - 44_loss: 0.6608 - 53_loss: 0.1692 - 54_loss: 0.0933 - reward_loss: 0.6771 - 03_categorical_accuracy: 0.7728 - 04_categorical_accuracy: 0.9756 - 13_categorical_accuracy: 0.7132 - 14_categorical_accuracy: 0.7380 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9381 - 44_categorical_accuracy: 0.7073 - 53_categorical_accuracy: 0.9382 - 54_categorical_accuracy: 0.9572 - reward_categorical_accuracy: 0.6779 - val_loss: 8.1880 - val_03_loss: 0.8370 - val_04_loss: 0.2614 - val_13_loss: 0.9722 - val_14_loss: 0.8982 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4049 - val_44_loss: 1.9948 - val_53_loss: 0.4169 - val_54_loss: 0.7323 - val_reward_loss: 1.6703 - val_03_categorical_accuracy: 0.6279 - val_04_categorical_accuracy: 0.9520 - val_13_categorical_accuracy: 0.6035 - val_14_categorical_accuracy: 0.6189 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8946 - val_44_categorical_accuracy: 0.4568 - val_53_categorical_accuracy: 0.8985 - val_54_categorical_accuracy: 0.8718 - val_reward_categorical_accuracy: 0.4934\n",
      "Epoch 34/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 3.3577 - 03_loss: 0.4466 - 04_loss: 0.0683 - 13_loss: 0.5922 - 14_loss: 0.5006 - 23_loss: 5.0707e-10 - 24_loss: 5.5925e-10 - 33_loss: 4.0673e-10 - 34_loss: 6.7498e-10 - 43_loss: 0.1671 - 44_loss: 0.6539 - 53_loss: 0.1668 - 54_loss: 0.0918 - reward_loss: 0.6705 - 03_categorical_accuracy: 0.7754 - 04_categorical_accuracy: 0.9758 - 13_categorical_accuracy: 0.7173 - 14_categorical_accuracy: 0.7406 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9388 - 44_categorical_accuracy: 0.7098 - 53_categorical_accuracy: 0.9382 - 54_categorical_accuracy: 0.9578 - reward_categorical_accuracy: 0.6801 - val_loss: 8.2614 - val_03_loss: 0.8636 - val_04_loss: 0.2623 - val_13_loss: 0.9875 - val_14_loss: 0.9094 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4089 - val_44_loss: 1.9897 - val_53_loss: 0.4221 - val_54_loss: 0.7434 - val_reward_loss: 1.6746 - val_03_categorical_accuracy: 0.6280 - val_04_categorical_accuracy: 0.9528 - val_13_categorical_accuracy: 0.6017 - val_14_categorical_accuracy: 0.6190 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8986 - val_44_categorical_accuracy: 0.4578 - val_53_categorical_accuracy: 0.8881 - val_54_categorical_accuracy: 0.8776 - val_reward_categorical_accuracy: 0.5007\n",
      "Epoch 35/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 3.3200 - 03_loss: 0.4416 - 04_loss: 0.0682 - 13_loss: 0.5850 - 14_loss: 0.4953 - 23_loss: 4.9838e-10 - 24_loss: 4.7630e-10 - 33_loss: 3.3983e-10 - 34_loss: 5.9738e-10 - 43_loss: 0.1643 - 44_loss: 0.6473 - 53_loss: 0.1637 - 54_loss: 0.0907 - reward_loss: 0.6639 - 03_categorical_accuracy: 0.7784 - 04_categorical_accuracy: 0.9757 - 13_categorical_accuracy: 0.7202 - 14_categorical_accuracy: 0.7445 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9394 - 44_categorical_accuracy: 0.7128 - 53_categorical_accuracy: 0.9392 - 54_categorical_accuracy: 0.9581 - reward_categorical_accuracy: 0.6844 - val_loss: 8.4385 - val_03_loss: 0.8702 - val_04_loss: 0.2704 - val_13_loss: 1.0033 - val_14_loss: 0.9281 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4158 - val_44_loss: 2.0411 - val_53_loss: 0.4272 - val_54_loss: 0.7758 - val_reward_loss: 1.7067 - val_03_categorical_accuracy: 0.6189 - val_04_categorical_accuracy: 0.9510 - val_13_categorical_accuracy: 0.5982 - val_14_categorical_accuracy: 0.6247 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8954 - val_44_categorical_accuracy: 0.4613 - val_53_categorical_accuracy: 0.8915 - val_54_categorical_accuracy: 0.8807 - val_reward_categorical_accuracy: 0.4915\n",
      "Epoch 36/1000\n",
      "697/697 [==============================] - 18s 25ms/step - loss: 3.2872 - 03_loss: 0.4378 - 04_loss: 0.0677 - 13_loss: 0.5785 - 14_loss: 0.4903 - 23_loss: 1.4383e-10 - 24_loss: 3.3047e-10 - 33_loss: 1.4383e-10 - 34_loss: 3.1241e-10 - 43_loss: 0.1627 - 44_loss: 0.6415 - 53_loss: 0.1610 - 54_loss: 0.0903 - reward_loss: 0.6575 - 03_categorical_accuracy: 0.7810 - 04_categorical_accuracy: 0.9756 - 13_categorical_accuracy: 0.7236 - 14_categorical_accuracy: 0.7473 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9394 - 44_categorical_accuracy: 0.7145 - 53_categorical_accuracy: 0.9400 - 54_categorical_accuracy: 0.9581 - reward_categorical_accuracy: 0.6862 - val_loss: 8.4946 - val_03_loss: 0.8769 - val_04_loss: 0.2663 - val_13_loss: 1.0153 - val_14_loss: 0.9289 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4205 - val_44_loss: 2.0268 - val_53_loss: 0.4394 - val_54_loss: 0.7781 - val_reward_loss: 1.7425 - val_03_categorical_accuracy: 0.6264 - val_04_categorical_accuracy: 0.9553 - val_13_categorical_accuracy: 0.5925 - val_14_categorical_accuracy: 0.6129 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8915 - val_44_categorical_accuracy: 0.4588 - val_53_categorical_accuracy: 0.8945 - val_54_categorical_accuracy: 0.8745 - val_reward_categorical_accuracy: 0.4988\n",
      "Epoch 37/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 3.2496 - 03_loss: 0.4319 - 04_loss: 0.0669 - 13_loss: 0.5715 - 14_loss: 0.4865 - 23_loss: 9.5996e-10 - 24_loss: 1.3941e-09 - 33_loss: 7.8336e-10 - 34_loss: 1.9828e-09 - 43_loss: 0.1597 - 44_loss: 0.6345 - 53_loss: 0.1592 - 54_loss: 0.0891 - reward_loss: 0.6502 - 03_categorical_accuracy: 0.7840 - 04_categorical_accuracy: 0.9760 - 13_categorical_accuracy: 0.7275 - 14_categorical_accuracy: 0.7492 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9404 - 44_categorical_accuracy: 0.7169 - 53_categorical_accuracy: 0.9402 - 54_categorical_accuracy: 0.9578 - reward_categorical_accuracy: 0.6896 - val_loss: 8.6680 - val_03_loss: 0.8925 - val_04_loss: 0.2689 - val_13_loss: 1.0335 - val_14_loss: 0.9455 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4279 - val_44_loss: 2.0941 - val_53_loss: 0.4413 - val_54_loss: 0.7852 - val_reward_loss: 1.7791 - val_03_categorical_accuracy: 0.6261 - val_04_categorical_accuracy: 0.9540 - val_13_categorical_accuracy: 0.5899 - val_14_categorical_accuracy: 0.6154 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8894 - val_44_categorical_accuracy: 0.4547 - val_53_categorical_accuracy: 0.8932 - val_54_categorical_accuracy: 0.8762 - val_reward_categorical_accuracy: 0.4890\n",
      "Epoch 38/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 3.2163 - 03_loss: 0.4272 - 04_loss: 0.0670 - 13_loss: 0.5644 - 14_loss: 0.4809 - 23_loss: 5.2647e-10 - 24_loss: 6.8034e-10 - 33_loss: 5.3785e-10 - 34_loss: 7.1378e-10 - 43_loss: 0.1573 - 44_loss: 0.6301 - 53_loss: 0.1570 - 54_loss: 0.0884 - reward_loss: 0.6440 - 03_categorical_accuracy: 0.7864 - 04_categorical_accuracy: 0.9759 - 13_categorical_accuracy: 0.7319 - 14_categorical_accuracy: 0.7536 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9404 - 44_categorical_accuracy: 0.7196 - 53_categorical_accuracy: 0.9410 - 54_categorical_accuracy: 0.9584 - reward_categorical_accuracy: 0.6936 - val_loss: 8.6536 - val_03_loss: 0.8921 - val_04_loss: 0.2711 - val_13_loss: 1.0371 - val_14_loss: 0.9471 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4363 - val_44_loss: 2.0695 - val_53_loss: 0.4468 - val_54_loss: 0.7896 - val_reward_loss: 1.7640 - val_03_categorical_accuracy: 0.6188 - val_04_categorical_accuracy: 0.9528 - val_13_categorical_accuracy: 0.5874 - val_14_categorical_accuracy: 0.6134 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8962 - val_44_categorical_accuracy: 0.4567 - val_53_categorical_accuracy: 0.8926 - val_54_categorical_accuracy: 0.8810 - val_reward_categorical_accuracy: 0.4936\n",
      "Epoch 39/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 3.1845 - 03_loss: 0.4234 - 04_loss: 0.0667 - 13_loss: 0.5578 - 14_loss: 0.4763 - 23_loss: 4.9704e-10 - 24_loss: 6.0675e-10 - 33_loss: 4.2212e-10 - 34_loss: 6.2414e-10 - 43_loss: 0.1554 - 44_loss: 0.6245 - 53_loss: 0.1551 - 54_loss: 0.0875 - reward_loss: 0.6377 - 03_categorical_accuracy: 0.7897 - 04_categorical_accuracy: 0.9759 - 13_categorical_accuracy: 0.7345 - 14_categorical_accuracy: 0.7559 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9413 - 44_categorical_accuracy: 0.7223 - 53_categorical_accuracy: 0.9409 - 54_categorical_accuracy: 0.9584 - reward_categorical_accuracy: 0.6960 - val_loss: 8.8378 - val_03_loss: 0.9025 - val_04_loss: 0.2740 - val_13_loss: 1.0587 - val_14_loss: 0.9693 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4405 - val_44_loss: 2.1359 - val_53_loss: 0.4536 - val_54_loss: 0.7997 - val_reward_loss: 1.8035 - val_03_categorical_accuracy: 0.6276 - val_04_categorical_accuracy: 0.9524 - val_13_categorical_accuracy: 0.5826 - val_14_categorical_accuracy: 0.6052 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8929 - val_44_categorical_accuracy: 0.4577 - val_53_categorical_accuracy: 0.8888 - val_54_categorical_accuracy: 0.8746 - val_reward_categorical_accuracy: 0.4912\n",
      "Epoch 40/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 3.1520 - 03_loss: 0.4185 - 04_loss: 0.0662 - 13_loss: 0.5515 - 14_loss: 0.4714 - 23_loss: 9.3722e-10 - 24_loss: 1.0844e-09 - 33_loss: 7.4121e-10 - 34_loss: 1.0683e-09 - 43_loss: 0.1537 - 44_loss: 0.6186 - 53_loss: 0.1539 - 54_loss: 0.0865 - reward_loss: 0.6318 - 03_categorical_accuracy: 0.7910 - 04_categorical_accuracy: 0.9759 - 13_categorical_accuracy: 0.7381 - 14_categorical_accuracy: 0.7596 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9419 - 44_categorical_accuracy: 0.7234 - 53_categorical_accuracy: 0.9414 - 54_categorical_accuracy: 0.9587 - reward_categorical_accuracy: 0.7001 - val_loss: 8.8516 - val_03_loss: 0.9145 - val_04_loss: 0.2699 - val_13_loss: 1.0728 - val_14_loss: 0.9757 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4421 - val_44_loss: 2.1167 - val_53_loss: 0.4553 - val_54_loss: 0.7969 - val_reward_loss: 1.8077 - val_03_categorical_accuracy: 0.6277 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5704 - val_14_categorical_accuracy: 0.6080 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8941 - val_44_categorical_accuracy: 0.4570 - val_53_categorical_accuracy: 0.8906 - val_54_categorical_accuracy: 0.8818 - val_reward_categorical_accuracy: 0.4814\n",
      "Epoch 41/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 18s 26ms/step - loss: 3.1211 - 03_loss: 0.4145 - 04_loss: 0.0655 - 13_loss: 0.5447 - 14_loss: 0.4670 - 23_loss: 2.8364e-10 - 24_loss: 3.7730e-10 - 33_loss: 2.1875e-10 - 34_loss: 3.8465e-10 - 43_loss: 0.1510 - 44_loss: 0.6147 - 53_loss: 0.1505 - 54_loss: 0.0861 - reward_loss: 0.6270 - 03_categorical_accuracy: 0.7935 - 04_categorical_accuracy: 0.9761 - 13_categorical_accuracy: 0.7414 - 14_categorical_accuracy: 0.7613 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9422 - 44_categorical_accuracy: 0.7261 - 53_categorical_accuracy: 0.9423 - 54_categorical_accuracy: 0.9588 - reward_categorical_accuracy: 0.7010 - val_loss: 9.0043 - val_03_loss: 0.9354 - val_04_loss: 0.2774 - val_13_loss: 1.0939 - val_14_loss: 0.9864 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4497 - val_44_loss: 2.1092 - val_53_loss: 0.4616 - val_54_loss: 0.8340 - val_reward_loss: 1.8565 - val_03_categorical_accuracy: 0.6166 - val_04_categorical_accuracy: 0.9524 - val_13_categorical_accuracy: 0.5886 - val_14_categorical_accuracy: 0.6101 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8864 - val_44_categorical_accuracy: 0.4518 - val_53_categorical_accuracy: 0.8857 - val_54_categorical_accuracy: 0.8770 - val_reward_categorical_accuracy: 0.4864\n",
      "Epoch 42/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 3.0900 - 03_loss: 0.4115 - 04_loss: 0.0656 - 13_loss: 0.5392 - 14_loss: 0.4619 - 23_loss: 1.6724e-10 - 24_loss: 2.6156e-10 - 33_loss: 1.5788e-10 - 34_loss: 3.0103e-10 - 43_loss: 0.1488 - 44_loss: 0.6089 - 53_loss: 0.1495 - 54_loss: 0.0853 - reward_loss: 0.6192 - 03_categorical_accuracy: 0.7949 - 04_categorical_accuracy: 0.9762 - 13_categorical_accuracy: 0.7438 - 14_categorical_accuracy: 0.7646 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9429 - 44_categorical_accuracy: 0.7279 - 53_categorical_accuracy: 0.9426 - 54_categorical_accuracy: 0.9591 - reward_categorical_accuracy: 0.7053 - val_loss: 9.0484 - val_03_loss: 0.9430 - val_04_loss: 0.2779 - val_13_loss: 1.0997 - val_14_loss: 0.9999 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4506 - val_44_loss: 2.1525 - val_53_loss: 0.4673 - val_54_loss: 0.7994 - val_reward_loss: 1.8581 - val_03_categorical_accuracy: 0.6119 - val_04_categorical_accuracy: 0.9524 - val_13_categorical_accuracy: 0.5862 - val_14_categorical_accuracy: 0.6118 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8896 - val_44_categorical_accuracy: 0.4542 - val_53_categorical_accuracy: 0.8854 - val_54_categorical_accuracy: 0.8740 - val_reward_categorical_accuracy: 0.4852\n",
      "Epoch 43/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 3.0623 - 03_loss: 0.4075 - 04_loss: 0.0652 - 13_loss: 0.5336 - 14_loss: 0.4572 - 23_loss: 3.3515e-10 - 24_loss: 4.4085e-10 - 33_loss: 2.9836e-10 - 34_loss: 4.7965e-10 - 43_loss: 0.1483 - 44_loss: 0.6037 - 53_loss: 0.1479 - 54_loss: 0.0850 - reward_loss: 0.6139 - 03_categorical_accuracy: 0.7973 - 04_categorical_accuracy: 0.9762 - 13_categorical_accuracy: 0.7476 - 14_categorical_accuracy: 0.7672 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9428 - 44_categorical_accuracy: 0.7297 - 53_categorical_accuracy: 0.9431 - 54_categorical_accuracy: 0.9591 - reward_categorical_accuracy: 0.7073 - val_loss: 9.1075 - val_03_loss: 0.9340 - val_04_loss: 0.2796 - val_13_loss: 1.1131 - val_14_loss: 1.0149 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4531 - val_44_loss: 2.1614 - val_53_loss: 0.4646 - val_54_loss: 0.8166 - val_reward_loss: 1.8702 - val_03_categorical_accuracy: 0.6232 - val_04_categorical_accuracy: 0.9506 - val_13_categorical_accuracy: 0.5777 - val_14_categorical_accuracy: 0.6105 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8861 - val_44_categorical_accuracy: 0.4576 - val_53_categorical_accuracy: 0.8865 - val_54_categorical_accuracy: 0.8773 - val_reward_categorical_accuracy: 0.4819\n",
      "Epoch 44/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 3.0340 - 03_loss: 0.4049 - 04_loss: 0.0649 - 13_loss: 0.5268 - 14_loss: 0.4527 - 23_loss: 4.6627e-10 - 24_loss: 4.8165e-10 - 33_loss: 3.0438e-10 - 34_loss: 5.5658e-10 - 43_loss: 0.1459 - 44_loss: 0.6009 - 53_loss: 0.1457 - 54_loss: 0.0837 - reward_loss: 0.6084 - 03_categorical_accuracy: 0.7983 - 04_categorical_accuracy: 0.9764 - 13_categorical_accuracy: 0.7510 - 14_categorical_accuracy: 0.7706 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9435 - 44_categorical_accuracy: 0.7304 - 53_categorical_accuracy: 0.9431 - 54_categorical_accuracy: 0.9593 - reward_categorical_accuracy: 0.7106 - val_loss: 9.1674 - val_03_loss: 0.9504 - val_04_loss: 0.2835 - val_13_loss: 1.1206 - val_14_loss: 1.0294 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4591 - val_44_loss: 2.1435 - val_53_loss: 0.4754 - val_54_loss: 0.8225 - val_reward_loss: 1.8829 - val_03_categorical_accuracy: 0.6242 - val_04_categorical_accuracy: 0.9521 - val_13_categorical_accuracy: 0.5762 - val_14_categorical_accuracy: 0.5973 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8875 - val_44_categorical_accuracy: 0.4550 - val_53_categorical_accuracy: 0.8851 - val_54_categorical_accuracy: 0.8771 - val_reward_categorical_accuracy: 0.4842\n",
      "Epoch 45/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 3.0067 - 03_loss: 0.4004 - 04_loss: 0.0648 - 13_loss: 0.5220 - 14_loss: 0.4485 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1443 - 44_loss: 0.5967 - 53_loss: 0.1441 - 54_loss: 0.0831 - reward_loss: 0.6027 - 03_categorical_accuracy: 0.8009 - 04_categorical_accuracy: 0.9766 - 13_categorical_accuracy: 0.7536 - 14_categorical_accuracy: 0.7721 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9440 - 44_categorical_accuracy: 0.7322 - 53_categorical_accuracy: 0.9441 - 54_categorical_accuracy: 0.9598 - reward_categorical_accuracy: 0.7123 - val_loss: 9.2156 - val_03_loss: 0.9549 - val_04_loss: 0.2774 - val_13_loss: 1.1375 - val_14_loss: 1.0288 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4645 - val_44_loss: 2.1788 - val_53_loss: 0.4778 - val_54_loss: 0.8052 - val_reward_loss: 1.8907 - val_03_categorical_accuracy: 0.6144 - val_04_categorical_accuracy: 0.9522 - val_13_categorical_accuracy: 0.5737 - val_14_categorical_accuracy: 0.6026 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8883 - val_44_categorical_accuracy: 0.4527 - val_53_categorical_accuracy: 0.8838 - val_54_categorical_accuracy: 0.8754 - val_reward_categorical_accuracy: 0.4794\n",
      "Epoch 46/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.9800 - 03_loss: 0.3973 - 04_loss: 0.0645 - 13_loss: 0.5161 - 14_loss: 0.4445 - 23_loss: 8.9641e-11 - 24_loss: 2.5889e-10 - 33_loss: 1.8062e-11 - 34_loss: 3.5254e-10 - 43_loss: 0.1429 - 44_loss: 0.5923 - 53_loss: 0.1423 - 54_loss: 0.0827 - reward_loss: 0.5975 - 03_categorical_accuracy: 0.8025 - 04_categorical_accuracy: 0.9764 - 13_categorical_accuracy: 0.7560 - 14_categorical_accuracy: 0.7755 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9443 - 44_categorical_accuracy: 0.7341 - 53_categorical_accuracy: 0.9444 - 54_categorical_accuracy: 0.9600 - reward_categorical_accuracy: 0.7165 - val_loss: 9.3393 - val_03_loss: 0.9607 - val_04_loss: 0.2830 - val_13_loss: 1.1488 - val_14_loss: 1.0352 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4677 - val_44_loss: 2.2022 - val_53_loss: 0.4794 - val_54_loss: 0.8407 - val_reward_loss: 1.9216 - val_03_categorical_accuracy: 0.6181 - val_04_categorical_accuracy: 0.9525 - val_13_categorical_accuracy: 0.5725 - val_14_categorical_accuracy: 0.6004 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8874 - val_44_categorical_accuracy: 0.4531 - val_53_categorical_accuracy: 0.8865 - val_54_categorical_accuracy: 0.8751 - val_reward_categorical_accuracy: 0.4803\n",
      "Epoch 47/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 2.9530 - 03_loss: 0.3933 - 04_loss: 0.0642 - 13_loss: 0.5104 - 14_loss: 0.4403 - 23_loss: 5.0373e-10 - 24_loss: 6.3016e-10 - 33_loss: 2.8030e-10 - 34_loss: 7.2649e-10 - 43_loss: 0.1412 - 44_loss: 0.5876 - 53_loss: 0.1412 - 54_loss: 0.0826 - reward_loss: 0.5922 - 03_categorical_accuracy: 0.8046 - 04_categorical_accuracy: 0.9765 - 13_categorical_accuracy: 0.7590 - 14_categorical_accuracy: 0.7775 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9450 - 44_categorical_accuracy: 0.7362 - 53_categorical_accuracy: 0.9440 - 54_categorical_accuracy: 0.9596 - reward_categorical_accuracy: 0.7194 - val_loss: 9.3010 - val_03_loss: 0.9611 - val_04_loss: 0.2835 - val_13_loss: 1.1512 - val_14_loss: 1.0308 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4642 - val_44_loss: 2.1673 - val_53_loss: 0.4811 - val_54_loss: 0.8468 - val_reward_loss: 1.9149 - val_03_categorical_accuracy: 0.6235 - val_04_categorical_accuracy: 0.9521 - val_13_categorical_accuracy: 0.5735 - val_14_categorical_accuracy: 0.6023 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8880 - val_44_categorical_accuracy: 0.4466 - val_53_categorical_accuracy: 0.8878 - val_54_categorical_accuracy: 0.8758 - val_reward_categorical_accuracy: 0.4770\n",
      "Epoch 48/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.9303 - 03_loss: 0.3910 - 04_loss: 0.0639 - 13_loss: 0.5065 - 14_loss: 0.4360 - 23_loss: 1.3112e-10 - 24_loss: 1.3112e-10 - 33_loss: 2.0069e-11 - 34_loss: 1.8865e-10 - 43_loss: 0.1398 - 44_loss: 0.5838 - 53_loss: 0.1394 - 54_loss: 0.0819 - reward_loss: 0.5881 - 03_categorical_accuracy: 0.8061 - 04_categorical_accuracy: 0.9768 - 13_categorical_accuracy: 0.7611 - 14_categorical_accuracy: 0.7804 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9448 - 44_categorical_accuracy: 0.7367 - 53_categorical_accuracy: 0.9448 - 54_categorical_accuracy: 0.9601 - reward_categorical_accuracy: 0.7206 - val_loss: 9.5593 - val_03_loss: 0.9869 - val_04_loss: 0.2832 - val_13_loss: 1.1864 - val_14_loss: 1.0612 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4811 - val_44_loss: 2.2312 - val_53_loss: 0.4941 - val_54_loss: 0.8637 - val_reward_loss: 1.9716 - val_03_categorical_accuracy: 0.6194 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5694 - val_14_categorical_accuracy: 0.5976 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8848 - val_44_categorical_accuracy: 0.4552 - val_53_categorical_accuracy: 0.8890 - val_54_categorical_accuracy: 0.8723 - val_reward_categorical_accuracy: 0.4693\n",
      "Epoch 49/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.9041 - 03_loss: 0.3873 - 04_loss: 0.0639 - 13_loss: 0.4997 - 14_loss: 0.4319 - 23_loss: 1.1305e-10 - 24_loss: 3.0973e-10 - 33_loss: 0.0000e+00 - 34_loss: 2.9568e-10 - 43_loss: 0.1385 - 44_loss: 0.5798 - 53_loss: 0.1389 - 54_loss: 0.0817 - reward_loss: 0.5823 - 03_categorical_accuracy: 0.8082 - 04_categorical_accuracy: 0.9765 - 13_categorical_accuracy: 0.7658 - 14_categorical_accuracy: 0.7823 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9453 - 44_categorical_accuracy: 0.7386 - 53_categorical_accuracy: 0.9446 - 54_categorical_accuracy: 0.9597 - reward_categorical_accuracy: 0.7233 - val_loss: 9.5939 - val_03_loss: 0.9961 - val_04_loss: 0.2812 - val_13_loss: 1.2019 - val_14_loss: 1.0723 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4811 - val_44_loss: 2.2337 - val_53_loss: 0.4930 - val_54_loss: 0.8550 - val_reward_loss: 1.9796 - val_03_categorical_accuracy: 0.6111 - val_04_categorical_accuracy: 0.9517 - val_13_categorical_accuracy: 0.5785 - val_14_categorical_accuracy: 0.6061 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8904 - val_44_categorical_accuracy: 0.4515 - val_53_categorical_accuracy: 0.8855 - val_54_categorical_accuracy: 0.8715 - val_reward_categorical_accuracy: 0.4740\n",
      "Epoch 50/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 2.8811 - 03_loss: 0.3850 - 04_loss: 0.0635 - 13_loss: 0.4951 - 14_loss: 0.4280 - 23_loss: 8.2283e-11 - 24_loss: 6.3552e-11 - 33_loss: 0.0000e+00 - 34_loss: 1.0570e-10 - 43_loss: 0.1376 - 44_loss: 0.5766 - 53_loss: 0.1375 - 54_loss: 0.0809 - reward_loss: 0.5768 - 03_categorical_accuracy: 0.8092 - 04_categorical_accuracy: 0.9768 - 13_categorical_accuracy: 0.7667 - 14_categorical_accuracy: 0.7843 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9455 - 44_categorical_accuracy: 0.7394 - 53_categorical_accuracy: 0.9450 - 54_categorical_accuracy: 0.9597 - reward_categorical_accuracy: 0.7267 - val_loss: 9.6041 - val_03_loss: 0.9971 - val_04_loss: 0.2895 - val_13_loss: 1.2087 - val_14_loss: 1.0747 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4758 - val_44_loss: 2.2191 - val_53_loss: 0.4884 - val_54_loss: 0.8687 - val_reward_loss: 1.9820 - val_03_categorical_accuracy: 0.6086 - val_04_categorical_accuracy: 0.9505 - val_13_categorical_accuracy: 0.5708 - val_14_categorical_accuracy: 0.6056 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8871 - val_44_categorical_accuracy: 0.4495 - val_53_categorical_accuracy: 0.8824 - val_54_categorical_accuracy: 0.8737 - val_reward_categorical_accuracy: 0.4754\n",
      "Epoch 51/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 19s 27ms/step - loss: 2.8597 - 03_loss: 0.3813 - 04_loss: 0.0636 - 13_loss: 0.4917 - 14_loss: 0.4244 - 23_loss: 2.0136e-10 - 24_loss: 2.4216e-10 - 33_loss: 2.0136e-10 - 34_loss: 2.4216e-10 - 43_loss: 0.1360 - 44_loss: 0.5728 - 53_loss: 0.1366 - 54_loss: 0.0807 - reward_loss: 0.5726 - 03_categorical_accuracy: 0.8103 - 04_categorical_accuracy: 0.9766 - 13_categorical_accuracy: 0.7693 - 14_categorical_accuracy: 0.7865 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9457 - 44_categorical_accuracy: 0.7408 - 53_categorical_accuracy: 0.9453 - 54_categorical_accuracy: 0.9599 - reward_categorical_accuracy: 0.7274 - val_loss: 9.7599 - val_03_loss: 1.0130 - val_04_loss: 0.2867 - val_13_loss: 1.2135 - val_14_loss: 1.0787 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4911 - val_44_loss: 2.3116 - val_53_loss: 0.4986 - val_54_loss: 0.8799 - val_reward_loss: 1.9868 - val_03_categorical_accuracy: 0.6127 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5720 - val_14_categorical_accuracy: 0.5990 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8869 - val_44_categorical_accuracy: 0.4498 - val_53_categorical_accuracy: 0.8840 - val_54_categorical_accuracy: 0.8772 - val_reward_categorical_accuracy: 0.4776\n",
      "Epoch 52/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.8384 - 03_loss: 0.3800 - 04_loss: 0.0633 - 13_loss: 0.4868 - 14_loss: 0.4198 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1353 - 44_loss: 0.5708 - 53_loss: 0.1344 - 54_loss: 0.0802 - reward_loss: 0.5678 - 03_categorical_accuracy: 0.8117 - 04_categorical_accuracy: 0.9766 - 13_categorical_accuracy: 0.7719 - 14_categorical_accuracy: 0.7891 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9456 - 44_categorical_accuracy: 0.7422 - 53_categorical_accuracy: 0.9460 - 54_categorical_accuracy: 0.9603 - reward_categorical_accuracy: 0.7314 - val_loss: 9.8693 - val_03_loss: 1.0161 - val_04_loss: 0.2920 - val_13_loss: 1.2318 - val_14_loss: 1.1126 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4903 - val_44_loss: 2.2739 - val_53_loss: 0.5058 - val_54_loss: 0.8998 - val_reward_loss: 2.0470 - val_03_categorical_accuracy: 0.6184 - val_04_categorical_accuracy: 0.9527 - val_13_categorical_accuracy: 0.5702 - val_14_categorical_accuracy: 0.6008 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8849 - val_44_categorical_accuracy: 0.4577 - val_53_categorical_accuracy: 0.8816 - val_54_categorical_accuracy: 0.8743 - val_reward_categorical_accuracy: 0.4744\n",
      "Epoch 53/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.8161 - 03_loss: 0.3765 - 04_loss: 0.0630 - 13_loss: 0.4809 - 14_loss: 0.4176 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1342 - 44_loss: 0.5666 - 53_loss: 0.1341 - 54_loss: 0.0800 - reward_loss: 0.5632 - 03_categorical_accuracy: 0.8125 - 04_categorical_accuracy: 0.9767 - 13_categorical_accuracy: 0.7743 - 14_categorical_accuracy: 0.7901 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9466 - 44_categorical_accuracy: 0.7430 - 53_categorical_accuracy: 0.9460 - 54_categorical_accuracy: 0.9600 - reward_categorical_accuracy: 0.7329 - val_loss: 9.9245 - val_03_loss: 1.0246 - val_04_loss: 0.2931 - val_13_loss: 1.2309 - val_14_loss: 1.1214 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4926 - val_44_loss: 2.2797 - val_53_loss: 0.5055 - val_54_loss: 0.9088 - val_reward_loss: 2.0680 - val_03_categorical_accuracy: 0.6217 - val_04_categorical_accuracy: 0.9536 - val_13_categorical_accuracy: 0.5666 - val_14_categorical_accuracy: 0.5951 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8869 - val_44_categorical_accuracy: 0.4544 - val_53_categorical_accuracy: 0.8841 - val_54_categorical_accuracy: 0.8768 - val_reward_categorical_accuracy: 0.4829\n",
      "Epoch 54/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.7971 - 03_loss: 0.3744 - 04_loss: 0.0629 - 13_loss: 0.4775 - 14_loss: 0.4131 - 23_loss: 0.0000e+00 - 24_loss: 6.0207e-11 - 33_loss: 0.0000e+00 - 34_loss: 6.0207e-11 - 43_loss: 0.1334 - 44_loss: 0.5637 - 53_loss: 0.1325 - 54_loss: 0.0797 - reward_loss: 0.5599 - 03_categorical_accuracy: 0.8145 - 04_categorical_accuracy: 0.9769 - 13_categorical_accuracy: 0.7760 - 14_categorical_accuracy: 0.7923 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9459 - 44_categorical_accuracy: 0.7441 - 53_categorical_accuracy: 0.9463 - 54_categorical_accuracy: 0.9602 - reward_categorical_accuracy: 0.7358 - val_loss: 9.8426 - val_03_loss: 1.0227 - val_04_loss: 0.2912 - val_13_loss: 1.2448 - val_14_loss: 1.1125 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4885 - val_44_loss: 2.2491 - val_53_loss: 0.5074 - val_54_loss: 0.8818 - val_reward_loss: 2.0446 - val_03_categorical_accuracy: 0.6169 - val_04_categorical_accuracy: 0.9544 - val_13_categorical_accuracy: 0.5636 - val_14_categorical_accuracy: 0.5933 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8809 - val_44_categorical_accuracy: 0.4594 - val_53_categorical_accuracy: 0.8847 - val_54_categorical_accuracy: 0.8727 - val_reward_categorical_accuracy: 0.4764\n",
      "Epoch 55/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.7771 - 03_loss: 0.3715 - 04_loss: 0.0628 - 13_loss: 0.4732 - 14_loss: 0.4106 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1312 - 44_loss: 0.5610 - 53_loss: 0.1317 - 54_loss: 0.0795 - reward_loss: 0.5555 - 03_categorical_accuracy: 0.8157 - 04_categorical_accuracy: 0.9766 - 13_categorical_accuracy: 0.7784 - 14_categorical_accuracy: 0.7936 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9468 - 44_categorical_accuracy: 0.7450 - 53_categorical_accuracy: 0.9462 - 54_categorical_accuracy: 0.9599 - reward_categorical_accuracy: 0.7369 - val_loss: 10.0417 - val_03_loss: 1.0417 - val_04_loss: 0.2907 - val_13_loss: 1.2677 - val_14_loss: 1.1364 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4923 - val_44_loss: 2.2948 - val_53_loss: 0.5101 - val_54_loss: 0.9126 - val_reward_loss: 2.0954 - val_03_categorical_accuracy: 0.6123 - val_04_categorical_accuracy: 0.9527 - val_13_categorical_accuracy: 0.5684 - val_14_categorical_accuracy: 0.5936 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8834 - val_44_categorical_accuracy: 0.4532 - val_53_categorical_accuracy: 0.8849 - val_54_categorical_accuracy: 0.8743 - val_reward_categorical_accuracy: 0.4732\n",
      "Epoch 56/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.7561 - 03_loss: 0.3703 - 04_loss: 0.0626 - 13_loss: 0.4691 - 14_loss: 0.4067 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1305 - 44_loss: 0.5569 - 53_loss: 0.1309 - 54_loss: 0.0788 - reward_loss: 0.5505 - 03_categorical_accuracy: 0.8161 - 04_categorical_accuracy: 0.9771 - 13_categorical_accuracy: 0.7799 - 14_categorical_accuracy: 0.7958 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9471 - 44_categorical_accuracy: 0.7479 - 53_categorical_accuracy: 0.9469 - 54_categorical_accuracy: 0.9603 - reward_categorical_accuracy: 0.7400 - val_loss: 10.0780 - val_03_loss: 1.0278 - val_04_loss: 0.2889 - val_13_loss: 1.2741 - val_14_loss: 1.1307 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5014 - val_44_loss: 2.2726 - val_53_loss: 0.5149 - val_54_loss: 0.9401 - val_reward_loss: 2.1277 - val_03_categorical_accuracy: 0.6100 - val_04_categorical_accuracy: 0.9492 - val_13_categorical_accuracy: 0.5698 - val_14_categorical_accuracy: 0.5975 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8919 - val_44_categorical_accuracy: 0.4557 - val_53_categorical_accuracy: 0.8824 - val_54_categorical_accuracy: 0.8774 - val_reward_categorical_accuracy: 0.4704\n",
      "Epoch 57/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.7375 - 03_loss: 0.3668 - 04_loss: 0.0623 - 13_loss: 0.4656 - 14_loss: 0.4039 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1297 - 44_loss: 0.5547 - 53_loss: 0.1299 - 54_loss: 0.0783 - reward_loss: 0.5462 - 03_categorical_accuracy: 0.8174 - 04_categorical_accuracy: 0.9768 - 13_categorical_accuracy: 0.7816 - 14_categorical_accuracy: 0.7975 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9477 - 44_categorical_accuracy: 0.7480 - 53_categorical_accuracy: 0.9472 - 54_categorical_accuracy: 0.9610 - reward_categorical_accuracy: 0.7415 - val_loss: 10.1525 - val_03_loss: 1.0474 - val_04_loss: 0.2962 - val_13_loss: 1.2719 - val_14_loss: 1.1428 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4953 - val_44_loss: 2.3235 - val_53_loss: 0.5186 - val_54_loss: 0.9285 - val_reward_loss: 2.1283 - val_03_categorical_accuracy: 0.6146 - val_04_categorical_accuracy: 0.9504 - val_13_categorical_accuracy: 0.5593 - val_14_categorical_accuracy: 0.5922 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8862 - val_44_categorical_accuracy: 0.4459 - val_53_categorical_accuracy: 0.8832 - val_54_categorical_accuracy: 0.8753 - val_reward_categorical_accuracy: 0.4710\n",
      "Epoch 58/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.7220 - 03_loss: 0.3651 - 04_loss: 0.0626 - 13_loss: 0.4613 - 14_loss: 0.4004 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1297 - 44_loss: 0.5515 - 53_loss: 0.1299 - 54_loss: 0.0785 - reward_loss: 0.5429 - 03_categorical_accuracy: 0.8188 - 04_categorical_accuracy: 0.9766 - 13_categorical_accuracy: 0.7827 - 14_categorical_accuracy: 0.7994 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9468 - 44_categorical_accuracy: 0.7489 - 53_categorical_accuracy: 0.9475 - 54_categorical_accuracy: 0.9603 - reward_categorical_accuracy: 0.7426 - val_loss: 10.1762 - val_03_loss: 1.0384 - val_04_loss: 0.2899 - val_13_loss: 1.2882 - val_14_loss: 1.1535 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4991 - val_44_loss: 2.3119 - val_53_loss: 0.5149 - val_54_loss: 0.9589 - val_reward_loss: 2.1214 - val_03_categorical_accuracy: 0.6151 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5643 - val_14_categorical_accuracy: 0.5944 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8788 - val_44_categorical_accuracy: 0.4507 - val_53_categorical_accuracy: 0.8837 - val_54_categorical_accuracy: 0.8750 - val_reward_categorical_accuracy: 0.4680\n",
      "Epoch 59/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.7029 - 03_loss: 0.3625 - 04_loss: 0.0622 - 13_loss: 0.4577 - 14_loss: 0.3987 - 23_loss: 1.2443e-10 - 24_loss: 2.5019e-10 - 33_loss: 0.0000e+00 - 34_loss: 1.7728e-10 - 43_loss: 0.1276 - 44_loss: 0.5496 - 53_loss: 0.1281 - 54_loss: 0.0780 - reward_loss: 0.5386 - 03_categorical_accuracy: 0.8199 - 04_categorical_accuracy: 0.9768 - 13_categorical_accuracy: 0.7847 - 14_categorical_accuracy: 0.8005 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9480 - 44_categorical_accuracy: 0.7501 - 53_categorical_accuracy: 0.9474 - 54_categorical_accuracy: 0.9603 - reward_categorical_accuracy: 0.7449 - val_loss: 10.2886 - val_03_loss: 1.0477 - val_04_loss: 0.2923 - val_13_loss: 1.3178 - val_14_loss: 1.1684 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5087 - val_44_loss: 2.3542 - val_53_loss: 0.5243 - val_54_loss: 0.9456 - val_reward_loss: 2.1296 - val_03_categorical_accuracy: 0.6103 - val_04_categorical_accuracy: 0.9513 - val_13_categorical_accuracy: 0.5709 - val_14_categorical_accuracy: 0.5917 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8808 - val_44_categorical_accuracy: 0.4501 - val_53_categorical_accuracy: 0.8798 - val_54_categorical_accuracy: 0.8715 - val_reward_categorical_accuracy: 0.4738\n",
      "Epoch 60/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.6879 - 03_loss: 0.3607 - 04_loss: 0.0619 - 13_loss: 0.4555 - 14_loss: 0.3955 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1263 - 44_loss: 0.5474 - 53_loss: 0.1274 - 54_loss: 0.0777 - reward_loss: 0.5355 - 03_categorical_accuracy: 0.8209 - 04_categorical_accuracy: 0.9770 - 13_categorical_accuracy: 0.7856 - 14_categorical_accuracy: 0.8012 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9483 - 44_categorical_accuracy: 0.7500 - 53_categorical_accuracy: 0.9476 - 54_categorical_accuracy: 0.9604 - reward_categorical_accuracy: 0.7457 - val_loss: 10.3245 - val_03_loss: 1.0520 - val_04_loss: 0.3006 - val_13_loss: 1.3221 - val_14_loss: 1.1765 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5045 - val_44_loss: 2.3653 - val_53_loss: 0.5198 - val_54_loss: 0.9480 - val_reward_loss: 2.1355 - val_03_categorical_accuracy: 0.6068 - val_04_categorical_accuracy: 0.9524 - val_13_categorical_accuracy: 0.5691 - val_14_categorical_accuracy: 0.5999 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8807 - val_44_categorical_accuracy: 0.4517 - val_53_categorical_accuracy: 0.8790 - val_54_categorical_accuracy: 0.8733 - val_reward_categorical_accuracy: 0.4715\n",
      "Epoch 61/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 19s 28ms/step - loss: 2.6733 - 03_loss: 0.3597 - 04_loss: 0.0623 - 13_loss: 0.4512 - 14_loss: 0.3928 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1269 - 44_loss: 0.5444 - 53_loss: 0.1272 - 54_loss: 0.0773 - reward_loss: 0.5316 - 03_categorical_accuracy: 0.8209 - 04_categorical_accuracy: 0.9767 - 13_categorical_accuracy: 0.7885 - 14_categorical_accuracy: 0.8037 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9482 - 44_categorical_accuracy: 0.7515 - 53_categorical_accuracy: 0.9478 - 54_categorical_accuracy: 0.9607 - reward_categorical_accuracy: 0.7479 - val_loss: 10.3327 - val_03_loss: 1.0612 - val_04_loss: 0.3106 - val_13_loss: 1.3104 - val_14_loss: 1.1718 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.4990 - val_44_loss: 2.3730 - val_53_loss: 0.5228 - val_54_loss: 0.9294 - val_reward_loss: 2.1545 - val_03_categorical_accuracy: 0.6218 - val_04_categorical_accuracy: 0.9538 - val_13_categorical_accuracy: 0.5617 - val_14_categorical_accuracy: 0.5956 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8801 - val_44_categorical_accuracy: 0.4472 - val_53_categorical_accuracy: 0.8757 - val_54_categorical_accuracy: 0.8738 - val_reward_categorical_accuracy: 0.4574\n",
      "Epoch 62/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 2.6583 - 03_loss: 0.3581 - 04_loss: 0.0619 - 13_loss: 0.4489 - 14_loss: 0.3904 - 23_loss: 1.4517e-10 - 24_loss: 2.2678e-10 - 33_loss: 8.7634e-11 - 34_loss: 3.2311e-10 - 43_loss: 0.1260 - 44_loss: 0.5418 - 53_loss: 0.1263 - 54_loss: 0.0770 - reward_loss: 0.5278 - 03_categorical_accuracy: 0.8214 - 04_categorical_accuracy: 0.9769 - 13_categorical_accuracy: 0.7889 - 14_categorical_accuracy: 0.8048 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9477 - 44_categorical_accuracy: 0.7516 - 53_categorical_accuracy: 0.9478 - 54_categorical_accuracy: 0.9607 - reward_categorical_accuracy: 0.7501 - val_loss: 10.3662 - val_03_loss: 1.0682 - val_04_loss: 0.2956 - val_13_loss: 1.3239 - val_14_loss: 1.1885 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5094 - val_44_loss: 2.3461 - val_53_loss: 0.5278 - val_54_loss: 0.9596 - val_reward_loss: 2.1471 - val_03_categorical_accuracy: 0.6120 - val_04_categorical_accuracy: 0.9530 - val_13_categorical_accuracy: 0.5651 - val_14_categorical_accuracy: 0.5932 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8874 - val_44_categorical_accuracy: 0.4492 - val_53_categorical_accuracy: 0.8844 - val_54_categorical_accuracy: 0.8749 - val_reward_categorical_accuracy: 0.4653\n",
      "Epoch 63/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.6410 - 03_loss: 0.3555 - 04_loss: 0.0618 - 13_loss: 0.4450 - 14_loss: 0.3875 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1250 - 44_loss: 0.5401 - 53_loss: 0.1250 - 54_loss: 0.0767 - reward_loss: 0.5245 - 03_categorical_accuracy: 0.8231 - 04_categorical_accuracy: 0.9771 - 13_categorical_accuracy: 0.7912 - 14_categorical_accuracy: 0.8061 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9483 - 44_categorical_accuracy: 0.7524 - 53_categorical_accuracy: 0.9484 - 54_categorical_accuracy: 0.9608 - reward_categorical_accuracy: 0.7511 - val_loss: 10.4669 - val_03_loss: 1.0677 - val_04_loss: 0.2949 - val_13_loss: 1.3305 - val_14_loss: 1.1904 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5125 - val_44_loss: 2.3880 - val_53_loss: 0.5214 - val_54_loss: 0.9713 - val_reward_loss: 2.1902 - val_03_categorical_accuracy: 0.6043 - val_04_categorical_accuracy: 0.9522 - val_13_categorical_accuracy: 0.5655 - val_14_categorical_accuracy: 0.5974 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8831 - val_44_categorical_accuracy: 0.4520 - val_53_categorical_accuracy: 0.8780 - val_54_categorical_accuracy: 0.8726 - val_reward_categorical_accuracy: 0.4673\n",
      "Epoch 64/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 2.6272 - 03_loss: 0.3533 - 04_loss: 0.0617 - 13_loss: 0.4424 - 14_loss: 0.3852 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1248 - 44_loss: 0.5383 - 53_loss: 0.1245 - 54_loss: 0.0764 - reward_loss: 0.5205 - 03_categorical_accuracy: 0.8234 - 04_categorical_accuracy: 0.9768 - 13_categorical_accuracy: 0.7923 - 14_categorical_accuracy: 0.8074 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9482 - 44_categorical_accuracy: 0.7529 - 53_categorical_accuracy: 0.9483 - 54_categorical_accuracy: 0.9609 - reward_categorical_accuracy: 0.7529 - val_loss: 10.5086 - val_03_loss: 1.0798 - val_04_loss: 0.2961 - val_13_loss: 1.3366 - val_14_loss: 1.1924 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5124 - val_44_loss: 2.3904 - val_53_loss: 0.5263 - val_54_loss: 0.9786 - val_reward_loss: 2.1960 - val_03_categorical_accuracy: 0.6164 - val_04_categorical_accuracy: 0.9525 - val_13_categorical_accuracy: 0.5629 - val_14_categorical_accuracy: 0.5916 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8832 - val_44_categorical_accuracy: 0.4558 - val_53_categorical_accuracy: 0.8816 - val_54_categorical_accuracy: 0.8724 - val_reward_categorical_accuracy: 0.4606\n",
      "Epoch 65/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.6131 - 03_loss: 0.3515 - 04_loss: 0.0613 - 13_loss: 0.4405 - 14_loss: 0.3828 - 23_loss: 1.1707e-10 - 24_loss: 1.3848e-10 - 33_loss: 3.9469e-11 - 34_loss: 1.6925e-10 - 43_loss: 0.1229 - 44_loss: 0.5356 - 53_loss: 0.1244 - 54_loss: 0.0762 - reward_loss: 0.5179 - 03_categorical_accuracy: 0.8248 - 04_categorical_accuracy: 0.9769 - 13_categorical_accuracy: 0.7929 - 14_categorical_accuracy: 0.8086 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9488 - 44_categorical_accuracy: 0.7552 - 53_categorical_accuracy: 0.9481 - 54_categorical_accuracy: 0.9610 - reward_categorical_accuracy: 0.7543 - val_loss: 10.5730 - val_03_loss: 1.0823 - val_04_loss: 0.2970 - val_13_loss: 1.3432 - val_14_loss: 1.1983 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5148 - val_44_loss: 2.4140 - val_53_loss: 0.5278 - val_54_loss: 0.9766 - val_reward_loss: 2.2189 - val_03_categorical_accuracy: 0.6139 - val_04_categorical_accuracy: 0.9510 - val_13_categorical_accuracy: 0.5594 - val_14_categorical_accuracy: 0.5903 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8815 - val_44_categorical_accuracy: 0.4492 - val_53_categorical_accuracy: 0.8832 - val_54_categorical_accuracy: 0.8736 - val_reward_categorical_accuracy: 0.4644\n",
      "Epoch 66/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 2.5985 - 03_loss: 0.3492 - 04_loss: 0.0614 - 13_loss: 0.4372 - 14_loss: 0.3802 - 23_loss: 1.4650e-10 - 24_loss: 2.2678e-10 - 33_loss: 0.0000e+00 - 34_loss: 2.8498e-10 - 43_loss: 0.1230 - 44_loss: 0.5342 - 53_loss: 0.1231 - 54_loss: 0.0761 - reward_loss: 0.5141 - 03_categorical_accuracy: 0.8261 - 04_categorical_accuracy: 0.9769 - 13_categorical_accuracy: 0.7953 - 14_categorical_accuracy: 0.8094 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9487 - 44_categorical_accuracy: 0.7546 - 53_categorical_accuracy: 0.9487 - 54_categorical_accuracy: 0.9606 - reward_categorical_accuracy: 0.7552 - val_loss: 10.6164 - val_03_loss: 1.0959 - val_04_loss: 0.3048 - val_13_loss: 1.3623 - val_14_loss: 1.2213 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5148 - val_44_loss: 2.4109 - val_53_loss: 0.5281 - val_54_loss: 0.9672 - val_reward_loss: 2.2112 - val_03_categorical_accuracy: 0.6118 - val_04_categorical_accuracy: 0.9534 - val_13_categorical_accuracy: 0.5672 - val_14_categorical_accuracy: 0.6002 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8760 - val_44_categorical_accuracy: 0.4510 - val_53_categorical_accuracy: 0.8792 - val_54_categorical_accuracy: 0.8745 - val_reward_categorical_accuracy: 0.4686\n",
      "Epoch 67/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.5870 - 03_loss: 0.3485 - 04_loss: 0.0611 - 13_loss: 0.4353 - 14_loss: 0.3791 - 23_loss: 0.0000e+00 - 24_loss: 6.7565e-11 - 33_loss: 0.0000e+00 - 34_loss: 6.7565e-11 - 43_loss: 0.1224 - 44_loss: 0.5309 - 53_loss: 0.1227 - 54_loss: 0.0759 - reward_loss: 0.5110 - 03_categorical_accuracy: 0.8259 - 04_categorical_accuracy: 0.9772 - 13_categorical_accuracy: 0.7943 - 14_categorical_accuracy: 0.8097 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9489 - 44_categorical_accuracy: 0.7558 - 53_categorical_accuracy: 0.9489 - 54_categorical_accuracy: 0.9609 - reward_categorical_accuracy: 0.7577 - val_loss: 10.5820 - val_03_loss: 1.0700 - val_04_loss: 0.3058 - val_13_loss: 1.3507 - val_14_loss: 1.2074 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5161 - val_44_loss: 2.3823 - val_53_loss: 0.5266 - val_54_loss: 0.9904 - val_reward_loss: 2.2328 - val_03_categorical_accuracy: 0.6172 - val_04_categorical_accuracy: 0.9538 - val_13_categorical_accuracy: 0.5704 - val_14_categorical_accuracy: 0.5958 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8801 - val_44_categorical_accuracy: 0.4521 - val_53_categorical_accuracy: 0.8826 - val_54_categorical_accuracy: 0.8735 - val_reward_categorical_accuracy: 0.4622\n",
      "Epoch 68/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.5720 - 03_loss: 0.3467 - 04_loss: 0.0611 - 13_loss: 0.4311 - 14_loss: 0.3765 - 23_loss: 1.3312e-10 - 24_loss: 1.5185e-10 - 33_loss: 0.0000e+00 - 34_loss: 1.1372e-10 - 43_loss: 0.1219 - 44_loss: 0.5290 - 53_loss: 0.1218 - 54_loss: 0.0757 - reward_loss: 0.5081 - 03_categorical_accuracy: 0.8268 - 04_categorical_accuracy: 0.9769 - 13_categorical_accuracy: 0.7972 - 14_categorical_accuracy: 0.8104 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9495 - 44_categorical_accuracy: 0.7562 - 53_categorical_accuracy: 0.9494 - 54_categorical_accuracy: 0.9608 - reward_categorical_accuracy: 0.7591 - val_loss: 10.6157 - val_03_loss: 1.0824 - val_04_loss: 0.3107 - val_13_loss: 1.3639 - val_14_loss: 1.2176 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5159 - val_44_loss: 2.3919 - val_53_loss: 0.5304 - val_54_loss: 0.9783 - val_reward_loss: 2.2245 - val_03_categorical_accuracy: 0.6069 - val_04_categorical_accuracy: 0.9532 - val_13_categorical_accuracy: 0.5655 - val_14_categorical_accuracy: 0.5993 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8821 - val_44_categorical_accuracy: 0.4541 - val_53_categorical_accuracy: 0.8799 - val_54_categorical_accuracy: 0.8737 - val_reward_categorical_accuracy: 0.4683\n",
      "Epoch 69/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.5626 - 03_loss: 0.3466 - 04_loss: 0.0612 - 13_loss: 0.4295 - 14_loss: 0.3739 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1214 - 44_loss: 0.5278 - 53_loss: 0.1215 - 54_loss: 0.0751 - reward_loss: 0.5056 - 03_categorical_accuracy: 0.8268 - 04_categorical_accuracy: 0.9770 - 13_categorical_accuracy: 0.7980 - 14_categorical_accuracy: 0.8129 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9489 - 44_categorical_accuracy: 0.7568 - 53_categorical_accuracy: 0.9490 - 54_categorical_accuracy: 0.9614 - reward_categorical_accuracy: 0.7601 - val_loss: 10.6098 - val_03_loss: 1.0888 - val_04_loss: 0.3061 - val_13_loss: 1.3769 - val_14_loss: 1.2170 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5179 - val_44_loss: 2.3848 - val_53_loss: 0.5387 - val_54_loss: 0.9764 - val_reward_loss: 2.2032 - val_03_categorical_accuracy: 0.6120 - val_04_categorical_accuracy: 0.9537 - val_13_categorical_accuracy: 0.5644 - val_14_categorical_accuracy: 0.5937 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8827 - val_44_categorical_accuracy: 0.4478 - val_53_categorical_accuracy: 0.8802 - val_54_categorical_accuracy: 0.8768 - val_reward_categorical_accuracy: 0.4675\n",
      "Epoch 70/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.5509 - 03_loss: 0.3443 - 04_loss: 0.0611 - 13_loss: 0.4275 - 14_loss: 0.3724 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 3.8131e-11 - 43_loss: 0.1209 - 44_loss: 0.5255 - 53_loss: 0.1212 - 54_loss: 0.0750 - reward_loss: 0.5029 - 03_categorical_accuracy: 0.8276 - 04_categorical_accuracy: 0.9770 - 13_categorical_accuracy: 0.7990 - 14_categorical_accuracy: 0.8130 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9497 - 44_categorical_accuracy: 0.7574 - 53_categorical_accuracy: 0.9491 - 54_categorical_accuracy: 0.9610 - reward_categorical_accuracy: 0.7607 - val_loss: 10.7874 - val_03_loss: 1.0926 - val_04_loss: 0.3019 - val_13_loss: 1.3863 - val_14_loss: 1.2212 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5207 - val_44_loss: 2.4316 - val_53_loss: 0.5410 - val_54_loss: 1.0089 - val_reward_loss: 2.2832 - val_03_categorical_accuracy: 0.6071 - val_04_categorical_accuracy: 0.9522 - val_13_categorical_accuracy: 0.5649 - val_14_categorical_accuracy: 0.5935 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8829 - val_44_categorical_accuracy: 0.4507 - val_53_categorical_accuracy: 0.8799 - val_54_categorical_accuracy: 0.8727 - val_reward_categorical_accuracy: 0.4675\n",
      "Epoch 71/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 19s 27ms/step - loss: 2.5384 - 03_loss: 0.3434 - 04_loss: 0.0608 - 13_loss: 0.4243 - 14_loss: 0.3705 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1201 - 44_loss: 0.5231 - 53_loss: 0.1207 - 54_loss: 0.0749 - reward_loss: 0.5007 - 03_categorical_accuracy: 0.8276 - 04_categorical_accuracy: 0.9774 - 13_categorical_accuracy: 0.7997 - 14_categorical_accuracy: 0.8143 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9497 - 44_categorical_accuracy: 0.7582 - 53_categorical_accuracy: 0.9493 - 54_categorical_accuracy: 0.9610 - reward_categorical_accuracy: 0.7628 - val_loss: 10.8641 - val_03_loss: 1.0986 - val_04_loss: 0.3118 - val_13_loss: 1.3995 - val_14_loss: 1.2391 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5234 - val_44_loss: 2.4181 - val_53_loss: 0.5328 - val_54_loss: 1.0350 - val_reward_loss: 2.3058 - val_03_categorical_accuracy: 0.6101 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5660 - val_14_categorical_accuracy: 0.5995 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8756 - val_44_categorical_accuracy: 0.4507 - val_53_categorical_accuracy: 0.8752 - val_54_categorical_accuracy: 0.8739 - val_reward_categorical_accuracy: 0.4670\n",
      "Epoch 72/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.5263 - 03_loss: 0.3409 - 04_loss: 0.0609 - 13_loss: 0.4222 - 14_loss: 0.3684 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1197 - 44_loss: 0.5221 - 53_loss: 0.1195 - 54_loss: 0.0751 - reward_loss: 0.4974 - 03_categorical_accuracy: 0.8290 - 04_categorical_accuracy: 0.9772 - 13_categorical_accuracy: 0.8013 - 14_categorical_accuracy: 0.8160 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9499 - 44_categorical_accuracy: 0.7583 - 53_categorical_accuracy: 0.9495 - 54_categorical_accuracy: 0.9612 - reward_categorical_accuracy: 0.7626 - val_loss: 10.7836 - val_03_loss: 1.1052 - val_04_loss: 0.3106 - val_13_loss: 1.3937 - val_14_loss: 1.2310 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5239 - val_44_loss: 2.4193 - val_53_loss: 0.5363 - val_54_loss: 1.0051 - val_reward_loss: 2.2586 - val_03_categorical_accuracy: 0.6113 - val_04_categorical_accuracy: 0.9520 - val_13_categorical_accuracy: 0.5607 - val_14_categorical_accuracy: 0.5900 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8757 - val_44_categorical_accuracy: 0.4517 - val_53_categorical_accuracy: 0.8782 - val_54_categorical_accuracy: 0.8737 - val_reward_categorical_accuracy: 0.4584\n",
      "Epoch 73/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.5164 - 03_loss: 0.3407 - 04_loss: 0.0606 - 13_loss: 0.4208 - 14_loss: 0.3660 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1196 - 44_loss: 0.5200 - 53_loss: 0.1195 - 54_loss: 0.0746 - reward_loss: 0.4946 - 03_categorical_accuracy: 0.8287 - 04_categorical_accuracy: 0.9773 - 13_categorical_accuracy: 0.8010 - 14_categorical_accuracy: 0.8171 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9498 - 44_categorical_accuracy: 0.7601 - 53_categorical_accuracy: 0.9495 - 54_categorical_accuracy: 0.9614 - reward_categorical_accuracy: 0.7645 - val_loss: 10.7621 - val_03_loss: 1.0992 - val_04_loss: 0.3078 - val_13_loss: 1.3949 - val_14_loss: 1.2371 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5160 - val_44_loss: 2.4233 - val_53_loss: 0.5380 - val_54_loss: 1.0049 - val_reward_loss: 2.2409 - val_03_categorical_accuracy: 0.6128 - val_04_categorical_accuracy: 0.9523 - val_13_categorical_accuracy: 0.5646 - val_14_categorical_accuracy: 0.5934 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8779 - val_44_categorical_accuracy: 0.4471 - val_53_categorical_accuracy: 0.8874 - val_54_categorical_accuracy: 0.8746 - val_reward_categorical_accuracy: 0.4633\n",
      "Epoch 74/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 2.5063 - 03_loss: 0.3392 - 04_loss: 0.0604 - 13_loss: 0.4185 - 14_loss: 0.3649 - 23_loss: 9.7000e-11 - 24_loss: 9.7000e-11 - 33_loss: 0.0000e+00 - 34_loss: 9.7000e-11 - 43_loss: 0.1188 - 44_loss: 0.5187 - 53_loss: 0.1200 - 54_loss: 0.0738 - reward_loss: 0.4919 - 03_categorical_accuracy: 0.8294 - 04_categorical_accuracy: 0.9773 - 13_categorical_accuracy: 0.8024 - 14_categorical_accuracy: 0.8163 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9497 - 44_categorical_accuracy: 0.7592 - 53_categorical_accuracy: 0.9493 - 54_categorical_accuracy: 0.9618 - reward_categorical_accuracy: 0.7660 - val_loss: 10.8129 - val_03_loss: 1.1004 - val_04_loss: 0.2978 - val_13_loss: 1.3909 - val_14_loss: 1.2487 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5264 - val_44_loss: 2.4376 - val_53_loss: 0.5307 - val_54_loss: 1.0181 - val_reward_loss: 2.2622 - val_03_categorical_accuracy: 0.6067 - val_04_categorical_accuracy: 0.9492 - val_13_categorical_accuracy: 0.5618 - val_14_categorical_accuracy: 0.5910 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8838 - val_44_categorical_accuracy: 0.4479 - val_53_categorical_accuracy: 0.8769 - val_54_categorical_accuracy: 0.8716 - val_reward_categorical_accuracy: 0.4694\n",
      "Epoch 75/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.4993 - 03_loss: 0.3382 - 04_loss: 0.0607 - 13_loss: 0.4164 - 14_loss: 0.3640 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1188 - 44_loss: 0.5173 - 53_loss: 0.1190 - 54_loss: 0.0741 - reward_loss: 0.4906 - 03_categorical_accuracy: 0.8305 - 04_categorical_accuracy: 0.9772 - 13_categorical_accuracy: 0.8034 - 14_categorical_accuracy: 0.8167 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9494 - 44_categorical_accuracy: 0.7588 - 53_categorical_accuracy: 0.9498 - 54_categorical_accuracy: 0.9617 - reward_categorical_accuracy: 0.7655 - val_loss: 10.8729 - val_03_loss: 1.1067 - val_04_loss: 0.2960 - val_13_loss: 1.4078 - val_14_loss: 1.2526 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5274 - val_44_loss: 2.4761 - val_53_loss: 0.5377 - val_54_loss: 0.9999 - val_reward_loss: 2.2687 - val_03_categorical_accuracy: 0.6092 - val_04_categorical_accuracy: 0.9511 - val_13_categorical_accuracy: 0.5643 - val_14_categorical_accuracy: 0.5881 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8738 - val_44_categorical_accuracy: 0.4463 - val_53_categorical_accuracy: 0.8809 - val_54_categorical_accuracy: 0.8730 - val_reward_categorical_accuracy: 0.4722\n",
      "Epoch 76/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 2.4862 - 03_loss: 0.3370 - 04_loss: 0.0606 - 13_loss: 0.4137 - 14_loss: 0.3608 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1182 - 44_loss: 0.5164 - 53_loss: 0.1184 - 54_loss: 0.0738 - reward_loss: 0.4874 - 03_categorical_accuracy: 0.8302 - 04_categorical_accuracy: 0.9770 - 13_categorical_accuracy: 0.8040 - 14_categorical_accuracy: 0.8182 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9499 - 44_categorical_accuracy: 0.7606 - 53_categorical_accuracy: 0.9495 - 54_categorical_accuracy: 0.9617 - reward_categorical_accuracy: 0.7685 - val_loss: 10.9734 - val_03_loss: 1.1175 - val_04_loss: 0.3079 - val_13_loss: 1.4047 - val_14_loss: 1.2575 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5247 - val_44_loss: 2.4302 - val_53_loss: 0.5461 - val_54_loss: 1.0605 - val_reward_loss: 2.3241 - val_03_categorical_accuracy: 0.6160 - val_04_categorical_accuracy: 0.9525 - val_13_categorical_accuracy: 0.5622 - val_14_categorical_accuracy: 0.5857 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8802 - val_44_categorical_accuracy: 0.4513 - val_53_categorical_accuracy: 0.8814 - val_54_categorical_accuracy: 0.8733 - val_reward_categorical_accuracy: 0.4670\n",
      "Epoch 77/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.4766 - 03_loss: 0.3354 - 04_loss: 0.0602 - 13_loss: 0.4117 - 14_loss: 0.3600 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1178 - 44_loss: 0.5145 - 53_loss: 0.1178 - 54_loss: 0.0735 - reward_loss: 0.4857 - 03_categorical_accuracy: 0.8309 - 04_categorical_accuracy: 0.9774 - 13_categorical_accuracy: 0.8050 - 14_categorical_accuracy: 0.8197 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9500 - 44_categorical_accuracy: 0.7604 - 53_categorical_accuracy: 0.9503 - 54_categorical_accuracy: 0.9619 - reward_categorical_accuracy: 0.7679 - val_loss: 10.9734 - val_03_loss: 1.1240 - val_04_loss: 0.3102 - val_13_loss: 1.4218 - val_14_loss: 1.2532 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5268 - val_44_loss: 2.4335 - val_53_loss: 0.5423 - val_54_loss: 1.0542 - val_reward_loss: 2.3075 - val_03_categorical_accuracy: 0.6107 - val_04_categorical_accuracy: 0.9502 - val_13_categorical_accuracy: 0.5618 - val_14_categorical_accuracy: 0.5911 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8787 - val_44_categorical_accuracy: 0.4474 - val_53_categorical_accuracy: 0.8741 - val_54_categorical_accuracy: 0.8785 - val_reward_categorical_accuracy: 0.4718\n",
      "Epoch 78/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 2.4681 - 03_loss: 0.3344 - 04_loss: 0.0602 - 13_loss: 0.4099 - 14_loss: 0.3585 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1173 - 44_loss: 0.5125 - 53_loss: 0.1175 - 54_loss: 0.0735 - reward_loss: 0.4843 - 03_categorical_accuracy: 0.8321 - 04_categorical_accuracy: 0.9775 - 13_categorical_accuracy: 0.8058 - 14_categorical_accuracy: 0.8202 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9501 - 44_categorical_accuracy: 0.7624 - 53_categorical_accuracy: 0.9500 - 54_categorical_accuracy: 0.9615 - reward_categorical_accuracy: 0.7686 - val_loss: 11.0687 - val_03_loss: 1.1158 - val_04_loss: 0.3056 - val_13_loss: 1.4337 - val_14_loss: 1.2778 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5239 - val_44_loss: 2.4515 - val_53_loss: 0.5380 - val_54_loss: 1.0841 - val_reward_loss: 2.3382 - val_03_categorical_accuracy: 0.6093 - val_04_categorical_accuracy: 0.9510 - val_13_categorical_accuracy: 0.5609 - val_14_categorical_accuracy: 0.5921 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8764 - val_44_categorical_accuracy: 0.4475 - val_53_categorical_accuracy: 0.8783 - val_54_categorical_accuracy: 0.8759 - val_reward_categorical_accuracy: 0.4604\n",
      "Epoch 79/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.4584 - 03_loss: 0.3328 - 04_loss: 0.0601 - 13_loss: 0.4088 - 14_loss: 0.3561 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1166 - 44_loss: 0.5105 - 53_loss: 0.1167 - 54_loss: 0.0736 - reward_loss: 0.4833 - 03_categorical_accuracy: 0.8325 - 04_categorical_accuracy: 0.9773 - 13_categorical_accuracy: 0.8061 - 14_categorical_accuracy: 0.8213 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9503 - 44_categorical_accuracy: 0.7624 - 53_categorical_accuracy: 0.9500 - 54_categorical_accuracy: 0.9614 - reward_categorical_accuracy: 0.7686 - val_loss: 11.0911 - val_03_loss: 1.1261 - val_04_loss: 0.3085 - val_13_loss: 1.4305 - val_14_loss: 1.2677 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5269 - val_44_loss: 2.4777 - val_53_loss: 0.5474 - val_54_loss: 1.0746 - val_reward_loss: 2.3316 - val_03_categorical_accuracy: 0.6122 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5667 - val_14_categorical_accuracy: 0.5915 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8831 - val_44_categorical_accuracy: 0.4492 - val_53_categorical_accuracy: 0.8783 - val_54_categorical_accuracy: 0.8744 - val_reward_categorical_accuracy: 0.4603\n",
      "Epoch 80/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 2.4467 - 03_loss: 0.3314 - 04_loss: 0.0602 - 13_loss: 0.4054 - 14_loss: 0.3545 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1171 - 44_loss: 0.5097 - 53_loss: 0.1164 - 54_loss: 0.0731 - reward_loss: 0.4788 - 03_categorical_accuracy: 0.8333 - 04_categorical_accuracy: 0.9772 - 13_categorical_accuracy: 0.8075 - 14_categorical_accuracy: 0.8213 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9502 - 44_categorical_accuracy: 0.7626 - 53_categorical_accuracy: 0.9501 - 54_categorical_accuracy: 0.9616 - reward_categorical_accuracy: 0.7715 - val_loss: 11.2000 - val_03_loss: 1.1373 - val_04_loss: 0.3099 - val_13_loss: 1.4460 - val_14_loss: 1.2857 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5313 - val_44_loss: 2.4853 - val_53_loss: 0.5431 - val_54_loss: 1.1092 - val_reward_loss: 2.3523 - val_03_categorical_accuracy: 0.6056 - val_04_categorical_accuracy: 0.9527 - val_13_categorical_accuracy: 0.5617 - val_14_categorical_accuracy: 0.5967 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8796 - val_44_categorical_accuracy: 0.4474 - val_53_categorical_accuracy: 0.8761 - val_54_categorical_accuracy: 0.8758 - val_reward_categorical_accuracy: 0.4658\n",
      "Epoch 81/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 19s 28ms/step - loss: 2.4420 - 03_loss: 0.3320 - 04_loss: 0.0600 - 13_loss: 0.4055 - 14_loss: 0.3543 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 7.6262e-11 - 43_loss: 0.1167 - 44_loss: 0.5080 - 53_loss: 0.1157 - 54_loss: 0.0729 - reward_loss: 0.4769 - 03_categorical_accuracy: 0.8317 - 04_categorical_accuracy: 0.9774 - 13_categorical_accuracy: 0.8072 - 14_categorical_accuracy: 0.8216 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9502 - 44_categorical_accuracy: 0.7626 - 53_categorical_accuracy: 0.9506 - 54_categorical_accuracy: 0.9618 - reward_categorical_accuracy: 0.7716 - val_loss: 11.1354 - val_03_loss: 1.1174 - val_04_loss: 0.3062 - val_13_loss: 1.4391 - val_14_loss: 1.2741 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5282 - val_44_loss: 2.4789 - val_53_loss: 0.5485 - val_54_loss: 1.0885 - val_reward_loss: 2.3546 - val_03_categorical_accuracy: 0.6041 - val_04_categorical_accuracy: 0.9510 - val_13_categorical_accuracy: 0.5644 - val_14_categorical_accuracy: 0.5926 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8817 - val_44_categorical_accuracy: 0.4515 - val_53_categorical_accuracy: 0.8796 - val_54_categorical_accuracy: 0.8724 - val_reward_categorical_accuracy: 0.4666\n",
      "Epoch 82/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.4356 - 03_loss: 0.3302 - 04_loss: 0.0600 - 13_loss: 0.4044 - 14_loss: 0.3530 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1156 - 44_loss: 0.5084 - 53_loss: 0.1159 - 54_loss: 0.0730 - reward_loss: 0.4751 - 03_categorical_accuracy: 0.8330 - 04_categorical_accuracy: 0.9771 - 13_categorical_accuracy: 0.8073 - 14_categorical_accuracy: 0.8221 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9505 - 44_categorical_accuracy: 0.7622 - 53_categorical_accuracy: 0.9507 - 54_categorical_accuracy: 0.9615 - reward_categorical_accuracy: 0.7728 - val_loss: 11.1248 - val_03_loss: 1.1277 - val_04_loss: 0.3107 - val_13_loss: 1.4464 - val_14_loss: 1.2740 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5339 - val_44_loss: 2.4552 - val_53_loss: 0.5509 - val_54_loss: 1.0769 - val_reward_loss: 2.3492 - val_03_categorical_accuracy: 0.6027 - val_04_categorical_accuracy: 0.9513 - val_13_categorical_accuracy: 0.5603 - val_14_categorical_accuracy: 0.5928 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8775 - val_44_categorical_accuracy: 0.4494 - val_53_categorical_accuracy: 0.8802 - val_54_categorical_accuracy: 0.8767 - val_reward_categorical_accuracy: 0.4666\n",
      "Epoch 83/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.4265 - 03_loss: 0.3297 - 04_loss: 0.0599 - 13_loss: 0.4016 - 14_loss: 0.3518 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1153 - 44_loss: 0.5060 - 53_loss: 0.1156 - 54_loss: 0.0727 - reward_loss: 0.4740 - 03_categorical_accuracy: 0.8331 - 04_categorical_accuracy: 0.9773 - 13_categorical_accuracy: 0.8090 - 14_categorical_accuracy: 0.8223 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9508 - 44_categorical_accuracy: 0.7634 - 53_categorical_accuracy: 0.9504 - 54_categorical_accuracy: 0.9619 - reward_categorical_accuracy: 0.7724 - val_loss: 11.1849 - val_03_loss: 1.1368 - val_04_loss: 0.3188 - val_13_loss: 1.4554 - val_14_loss: 1.2775 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5350 - val_44_loss: 2.4757 - val_53_loss: 0.5482 - val_54_loss: 1.0914 - val_reward_loss: 2.3461 - val_03_categorical_accuracy: 0.6126 - val_04_categorical_accuracy: 0.9521 - val_13_categorical_accuracy: 0.5603 - val_14_categorical_accuracy: 0.5932 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8824 - val_44_categorical_accuracy: 0.4507 - val_53_categorical_accuracy: 0.8826 - val_54_categorical_accuracy: 0.8753 - val_reward_categorical_accuracy: 0.4631\n",
      "Epoch 84/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.4179 - 03_loss: 0.3283 - 04_loss: 0.0598 - 13_loss: 0.4005 - 14_loss: 0.3504 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1155 - 44_loss: 0.5042 - 53_loss: 0.1150 - 54_loss: 0.0726 - reward_loss: 0.4715 - 03_categorical_accuracy: 0.8332 - 04_categorical_accuracy: 0.9774 - 13_categorical_accuracy: 0.8092 - 14_categorical_accuracy: 0.8231 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9505 - 44_categorical_accuracy: 0.7640 - 53_categorical_accuracy: 0.9507 - 54_categorical_accuracy: 0.9618 - reward_categorical_accuracy: 0.7733 - val_loss: 11.2751 - val_03_loss: 1.1392 - val_04_loss: 0.3179 - val_13_loss: 1.4616 - val_14_loss: 1.2962 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5321 - val_44_loss: 2.5096 - val_53_loss: 0.5525 - val_54_loss: 1.0962 - val_reward_loss: 2.3698 - val_03_categorical_accuracy: 0.6055 - val_04_categorical_accuracy: 0.9524 - val_13_categorical_accuracy: 0.5621 - val_14_categorical_accuracy: 0.5965 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8717 - val_44_categorical_accuracy: 0.4506 - val_53_categorical_accuracy: 0.8761 - val_54_categorical_accuracy: 0.8732 - val_reward_categorical_accuracy: 0.4650\n",
      "Epoch 85/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.4058 - 03_loss: 0.3268 - 04_loss: 0.0598 - 13_loss: 0.3987 - 14_loss: 0.3483 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1142 - 44_loss: 0.5028 - 53_loss: 0.1147 - 54_loss: 0.0725 - reward_loss: 0.4680 - 03_categorical_accuracy: 0.8346 - 04_categorical_accuracy: 0.9775 - 13_categorical_accuracy: 0.8101 - 14_categorical_accuracy: 0.8237 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9514 - 44_categorical_accuracy: 0.7642 - 53_categorical_accuracy: 0.9507 - 54_categorical_accuracy: 0.9620 - reward_categorical_accuracy: 0.7745 - val_loss: 11.2592 - val_03_loss: 1.1351 - val_04_loss: 0.3118 - val_13_loss: 1.4517 - val_14_loss: 1.3054 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5374 - val_44_loss: 2.4818 - val_53_loss: 0.5584 - val_54_loss: 1.1056 - val_reward_loss: 2.3721 - val_03_categorical_accuracy: 0.6128 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5592 - val_14_categorical_accuracy: 0.5934 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8864 - val_44_categorical_accuracy: 0.4465 - val_53_categorical_accuracy: 0.8861 - val_54_categorical_accuracy: 0.8743 - val_reward_categorical_accuracy: 0.4599\n",
      "Epoch 86/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.4009 - 03_loss: 0.3261 - 04_loss: 0.0597 - 13_loss: 0.3967 - 14_loss: 0.3471 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1140 - 44_loss: 0.5026 - 53_loss: 0.1147 - 54_loss: 0.0723 - reward_loss: 0.4678 - 03_categorical_accuracy: 0.8342 - 04_categorical_accuracy: 0.9775 - 13_categorical_accuracy: 0.8101 - 14_categorical_accuracy: 0.8245 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9508 - 44_categorical_accuracy: 0.7645 - 53_categorical_accuracy: 0.9505 - 54_categorical_accuracy: 0.9618 - reward_categorical_accuracy: 0.7753 - val_loss: 11.3782 - val_03_loss: 1.1341 - val_04_loss: 0.3172 - val_13_loss: 1.4695 - val_14_loss: 1.3076 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5318 - val_44_loss: 2.5114 - val_53_loss: 0.5452 - val_54_loss: 1.1396 - val_reward_loss: 2.4218 - val_03_categorical_accuracy: 0.6087 - val_04_categorical_accuracy: 0.9529 - val_13_categorical_accuracy: 0.5631 - val_14_categorical_accuracy: 0.5927 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8749 - val_44_categorical_accuracy: 0.4523 - val_53_categorical_accuracy: 0.8788 - val_54_categorical_accuracy: 0.8752 - val_reward_categorical_accuracy: 0.4587\n",
      "Epoch 87/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.3968 - 03_loss: 0.3254 - 04_loss: 0.0596 - 13_loss: 0.3963 - 14_loss: 0.3468 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1140 - 44_loss: 0.5009 - 53_loss: 0.1145 - 54_loss: 0.0721 - reward_loss: 0.4674 - 03_categorical_accuracy: 0.8351 - 04_categorical_accuracy: 0.9773 - 13_categorical_accuracy: 0.8110 - 14_categorical_accuracy: 0.8238 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9512 - 44_categorical_accuracy: 0.7652 - 53_categorical_accuracy: 0.9506 - 54_categorical_accuracy: 0.9620 - reward_categorical_accuracy: 0.7754 - val_loss: 11.2570 - val_03_loss: 1.1307 - val_04_loss: 0.3161 - val_13_loss: 1.4598 - val_14_loss: 1.2964 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5299 - val_44_loss: 2.5022 - val_53_loss: 0.5461 - val_54_loss: 1.0911 - val_reward_loss: 2.3848 - val_03_categorical_accuracy: 0.6121 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5558 - val_14_categorical_accuracy: 0.5875 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8840 - val_44_categorical_accuracy: 0.4555 - val_53_categorical_accuracy: 0.8787 - val_54_categorical_accuracy: 0.8756 - val_reward_categorical_accuracy: 0.4658\n",
      "Epoch 88/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.3881 - 03_loss: 0.3242 - 04_loss: 0.0595 - 13_loss: 0.3944 - 14_loss: 0.3452 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1140 - 44_loss: 0.5006 - 53_loss: 0.1136 - 54_loss: 0.0721 - reward_loss: 0.4646 - 03_categorical_accuracy: 0.8357 - 04_categorical_accuracy: 0.9774 - 13_categorical_accuracy: 0.8116 - 14_categorical_accuracy: 0.8246 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9514 - 44_categorical_accuracy: 0.7650 - 53_categorical_accuracy: 0.9511 - 54_categorical_accuracy: 0.9620 - reward_categorical_accuracy: 0.7760 - val_loss: 11.3682 - val_03_loss: 1.1436 - val_04_loss: 0.3202 - val_13_loss: 1.4592 - val_14_loss: 1.3102 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5331 - val_44_loss: 2.5220 - val_53_loss: 0.5610 - val_54_loss: 1.1204 - val_reward_loss: 2.3984 - val_03_categorical_accuracy: 0.6096 - val_04_categorical_accuracy: 0.9511 - val_13_categorical_accuracy: 0.5570 - val_14_categorical_accuracy: 0.5918 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8831 - val_44_categorical_accuracy: 0.4526 - val_53_categorical_accuracy: 0.8823 - val_54_categorical_accuracy: 0.8732 - val_reward_categorical_accuracy: 0.4630\n",
      "Epoch 89/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.3845 - 03_loss: 0.3240 - 04_loss: 0.0595 - 13_loss: 0.3937 - 14_loss: 0.3446 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1135 - 44_loss: 0.4996 - 53_loss: 0.1144 - 54_loss: 0.0719 - reward_loss: 0.4632 - 03_categorical_accuracy: 0.8354 - 04_categorical_accuracy: 0.9775 - 13_categorical_accuracy: 0.8115 - 14_categorical_accuracy: 0.8257 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9511 - 44_categorical_accuracy: 0.7653 - 53_categorical_accuracy: 0.9505 - 54_categorical_accuracy: 0.9617 - reward_categorical_accuracy: 0.7765 - val_loss: 11.2561 - val_03_loss: 1.1403 - val_04_loss: 0.3186 - val_13_loss: 1.4699 - val_14_loss: 1.2969 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5296 - val_44_loss: 2.4601 - val_53_loss: 0.5505 - val_54_loss: 1.1158 - val_reward_loss: 2.3744 - val_03_categorical_accuracy: 0.6066 - val_04_categorical_accuracy: 0.9526 - val_13_categorical_accuracy: 0.5635 - val_14_categorical_accuracy: 0.5963 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8781 - val_44_categorical_accuracy: 0.4529 - val_53_categorical_accuracy: 0.8804 - val_54_categorical_accuracy: 0.8730 - val_reward_categorical_accuracy: 0.4676\n",
      "Epoch 90/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.3773 - 03_loss: 0.3240 - 04_loss: 0.0594 - 13_loss: 0.3915 - 14_loss: 0.3434 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1133 - 44_loss: 0.4984 - 53_loss: 0.1128 - 54_loss: 0.0715 - reward_loss: 0.4629 - 03_categorical_accuracy: 0.8359 - 04_categorical_accuracy: 0.9775 - 13_categorical_accuracy: 0.8120 - 14_categorical_accuracy: 0.8257 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9508 - 44_categorical_accuracy: 0.7656 - 53_categorical_accuracy: 0.9514 - 54_categorical_accuracy: 0.9622 - reward_categorical_accuracy: 0.7770 - val_loss: 11.3861 - val_03_loss: 1.1557 - val_04_loss: 0.3202 - val_13_loss: 1.4883 - val_14_loss: 1.3159 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5389 - val_44_loss: 2.4953 - val_53_loss: 0.5518 - val_54_loss: 1.1188 - val_reward_loss: 2.4012 - val_03_categorical_accuracy: 0.6083 - val_04_categorical_accuracy: 0.9532 - val_13_categorical_accuracy: 0.5620 - val_14_categorical_accuracy: 0.5884 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8817 - val_44_categorical_accuracy: 0.4517 - val_53_categorical_accuracy: 0.8792 - val_54_categorical_accuracy: 0.8749 - val_reward_categorical_accuracy: 0.4648\n",
      "Epoch 91/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 18s 26ms/step - loss: 2.3684 - 03_loss: 0.3222 - 04_loss: 0.0594 - 13_loss: 0.3907 - 14_loss: 0.3417 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1128 - 44_loss: 0.4962 - 53_loss: 0.1128 - 54_loss: 0.0718 - reward_loss: 0.4608 - 03_categorical_accuracy: 0.8357 - 04_categorical_accuracy: 0.9774 - 13_categorical_accuracy: 0.8125 - 14_categorical_accuracy: 0.8256 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9510 - 44_categorical_accuracy: 0.7665 - 53_categorical_accuracy: 0.9512 - 54_categorical_accuracy: 0.9621 - reward_categorical_accuracy: 0.7782 - val_loss: 11.4022 - val_03_loss: 1.1492 - val_04_loss: 0.3198 - val_13_loss: 1.4753 - val_14_loss: 1.3061 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5389 - val_44_loss: 2.5419 - val_53_loss: 0.5537 - val_54_loss: 1.1122 - val_reward_loss: 2.4051 - val_03_categorical_accuracy: 0.6064 - val_04_categorical_accuracy: 0.9508 - val_13_categorical_accuracy: 0.5585 - val_14_categorical_accuracy: 0.5927 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8814 - val_44_categorical_accuracy: 0.4512 - val_53_categorical_accuracy: 0.8766 - val_54_categorical_accuracy: 0.8729 - val_reward_categorical_accuracy: 0.4645\n",
      "Epoch 92/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.3628 - 03_loss: 0.3222 - 04_loss: 0.0592 - 13_loss: 0.3889 - 14_loss: 0.3418 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1128 - 44_loss: 0.4955 - 53_loss: 0.1126 - 54_loss: 0.0714 - reward_loss: 0.4585 - 03_categorical_accuracy: 0.8362 - 04_categorical_accuracy: 0.9775 - 13_categorical_accuracy: 0.8134 - 14_categorical_accuracy: 0.8255 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9508 - 44_categorical_accuracy: 0.7662 - 53_categorical_accuracy: 0.9512 - 54_categorical_accuracy: 0.9623 - reward_categorical_accuracy: 0.7780 - val_loss: 11.3583 - val_03_loss: 1.1502 - val_04_loss: 0.3213 - val_13_loss: 1.4711 - val_14_loss: 1.3100 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5320 - val_44_loss: 2.5145 - val_53_loss: 0.5536 - val_54_loss: 1.1026 - val_reward_loss: 2.4031 - val_03_categorical_accuracy: 0.6154 - val_04_categorical_accuracy: 0.9523 - val_13_categorical_accuracy: 0.5577 - val_14_categorical_accuracy: 0.5870 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8771 - val_44_categorical_accuracy: 0.4500 - val_53_categorical_accuracy: 0.8773 - val_54_categorical_accuracy: 0.8712 - val_reward_categorical_accuracy: 0.4639\n",
      "Epoch 93/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 2.3582 - 03_loss: 0.3209 - 04_loss: 0.0593 - 13_loss: 0.3883 - 14_loss: 0.3403 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1122 - 44_loss: 0.4943 - 53_loss: 0.1130 - 54_loss: 0.0713 - reward_loss: 0.4585 - 03_categorical_accuracy: 0.8363 - 04_categorical_accuracy: 0.9775 - 13_categorical_accuracy: 0.8134 - 14_categorical_accuracy: 0.8265 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9514 - 44_categorical_accuracy: 0.7677 - 53_categorical_accuracy: 0.9508 - 54_categorical_accuracy: 0.9625 - reward_categorical_accuracy: 0.7780 - val_loss: 11.4316 - val_03_loss: 1.1386 - val_04_loss: 0.3229 - val_13_loss: 1.4774 - val_14_loss: 1.3043 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5398 - val_44_loss: 2.5316 - val_53_loss: 0.5554 - val_54_loss: 1.1426 - val_reward_loss: 2.4189 - val_03_categorical_accuracy: 0.6111 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5620 - val_14_categorical_accuracy: 0.5925 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8765 - val_44_categorical_accuracy: 0.4531 - val_53_categorical_accuracy: 0.8758 - val_54_categorical_accuracy: 0.8725 - val_reward_categorical_accuracy: 0.4604\n",
      "Epoch 94/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.3519 - 03_loss: 0.3203 - 04_loss: 0.0592 - 13_loss: 0.3865 - 14_loss: 0.3394 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1119 - 44_loss: 0.4948 - 53_loss: 0.1122 - 54_loss: 0.0710 - reward_loss: 0.4565 - 03_categorical_accuracy: 0.8366 - 04_categorical_accuracy: 0.9776 - 13_categorical_accuracy: 0.8137 - 14_categorical_accuracy: 0.8267 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9514 - 44_categorical_accuracy: 0.7667 - 53_categorical_accuracy: 0.9509 - 54_categorical_accuracy: 0.9623 - reward_categorical_accuracy: 0.7799 - val_loss: 11.6342 - val_03_loss: 1.1609 - val_04_loss: 0.3204 - val_13_loss: 1.5177 - val_14_loss: 1.3306 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5404 - val_44_loss: 2.5612 - val_53_loss: 0.5579 - val_54_loss: 1.1771 - val_reward_loss: 2.4680 - val_03_categorical_accuracy: 0.6047 - val_04_categorical_accuracy: 0.9511 - val_13_categorical_accuracy: 0.5588 - val_14_categorical_accuracy: 0.5912 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8775 - val_44_categorical_accuracy: 0.4510 - val_53_categorical_accuracy: 0.8783 - val_54_categorical_accuracy: 0.8742 - val_reward_categorical_accuracy: 0.4603\n",
      "Epoch 95/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 2.3458 - 03_loss: 0.3196 - 04_loss: 0.0590 - 13_loss: 0.3865 - 14_loss: 0.3382 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1120 - 44_loss: 0.4926 - 53_loss: 0.1120 - 54_loss: 0.0711 - reward_loss: 0.4548 - 03_categorical_accuracy: 0.8366 - 04_categorical_accuracy: 0.9775 - 13_categorical_accuracy: 0.8135 - 14_categorical_accuracy: 0.8272 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9513 - 44_categorical_accuracy: 0.7674 - 53_categorical_accuracy: 0.9513 - 54_categorical_accuracy: 0.9624 - reward_categorical_accuracy: 0.7796 - val_loss: 11.4537 - val_03_loss: 1.1454 - val_04_loss: 0.3209 - val_13_loss: 1.4890 - val_14_loss: 1.3149 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5387 - val_44_loss: 2.5024 - val_53_loss: 0.5536 - val_54_loss: 1.1559 - val_reward_loss: 2.4328 - val_03_categorical_accuracy: 0.6086 - val_04_categorical_accuracy: 0.9511 - val_13_categorical_accuracy: 0.5549 - val_14_categorical_accuracy: 0.5861 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8779 - val_44_categorical_accuracy: 0.4507 - val_53_categorical_accuracy: 0.8775 - val_54_categorical_accuracy: 0.8717 - val_reward_categorical_accuracy: 0.4634\n",
      "Epoch 96/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.3396 - 03_loss: 0.3184 - 04_loss: 0.0592 - 13_loss: 0.3843 - 14_loss: 0.3373 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1111 - 44_loss: 0.4919 - 53_loss: 0.1120 - 54_loss: 0.0712 - reward_loss: 0.4542 - 03_categorical_accuracy: 0.8375 - 04_categorical_accuracy: 0.9775 - 13_categorical_accuracy: 0.8149 - 14_categorical_accuracy: 0.8287 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9516 - 44_categorical_accuracy: 0.7677 - 53_categorical_accuracy: 0.9512 - 54_categorical_accuracy: 0.9618 - reward_categorical_accuracy: 0.7798 - val_loss: 11.3395 - val_03_loss: 1.1351 - val_04_loss: 0.3191 - val_13_loss: 1.4846 - val_14_loss: 1.3103 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5353 - val_44_loss: 2.4990 - val_53_loss: 0.5489 - val_54_loss: 1.1077 - val_reward_loss: 2.3995 - val_03_categorical_accuracy: 0.6108 - val_04_categorical_accuracy: 0.9517 - val_13_categorical_accuracy: 0.5600 - val_14_categorical_accuracy: 0.5918 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8783 - val_44_categorical_accuracy: 0.4460 - val_53_categorical_accuracy: 0.8789 - val_54_categorical_accuracy: 0.8743 - val_reward_categorical_accuracy: 0.4559\n",
      "Epoch 97/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.3327 - 03_loss: 0.3178 - 04_loss: 0.0590 - 13_loss: 0.3839 - 14_loss: 0.3360 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1113 - 44_loss: 0.4905 - 53_loss: 0.1117 - 54_loss: 0.0706 - reward_loss: 0.4519 - 03_categorical_accuracy: 0.8375 - 04_categorical_accuracy: 0.9776 - 13_categorical_accuracy: 0.8152 - 14_categorical_accuracy: 0.8283 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9515 - 44_categorical_accuracy: 0.7683 - 53_categorical_accuracy: 0.9516 - 54_categorical_accuracy: 0.9623 - reward_categorical_accuracy: 0.7805 - val_loss: 11.5382 - val_03_loss: 1.1493 - val_04_loss: 0.3263 - val_13_loss: 1.4903 - val_14_loss: 1.3194 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5460 - val_44_loss: 2.5049 - val_53_loss: 0.5514 - val_54_loss: 1.1833 - val_reward_loss: 2.4673 - val_03_categorical_accuracy: 0.6116 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5683 - val_14_categorical_accuracy: 0.5986 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8826 - val_44_categorical_accuracy: 0.4472 - val_53_categorical_accuracy: 0.8743 - val_54_categorical_accuracy: 0.8752 - val_reward_categorical_accuracy: 0.4595\n",
      "Epoch 98/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.3287 - 03_loss: 0.3173 - 04_loss: 0.0590 - 13_loss: 0.3823 - 14_loss: 0.3353 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1116 - 44_loss: 0.4901 - 53_loss: 0.1113 - 54_loss: 0.0706 - reward_loss: 0.4513 - 03_categorical_accuracy: 0.8376 - 04_categorical_accuracy: 0.9774 - 13_categorical_accuracy: 0.8152 - 14_categorical_accuracy: 0.8285 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9511 - 44_categorical_accuracy: 0.7688 - 53_categorical_accuracy: 0.9515 - 54_categorical_accuracy: 0.9622 - reward_categorical_accuracy: 0.7807 - val_loss: 11.6467 - val_03_loss: 1.1579 - val_04_loss: 0.3379 - val_13_loss: 1.5087 - val_14_loss: 1.3250 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5487 - val_44_loss: 2.5619 - val_53_loss: 0.5597 - val_54_loss: 1.1827 - val_reward_loss: 2.4643 - val_03_categorical_accuracy: 0.6054 - val_04_categorical_accuracy: 0.9524 - val_13_categorical_accuracy: 0.5638 - val_14_categorical_accuracy: 0.5896 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8739 - val_44_categorical_accuracy: 0.4509 - val_53_categorical_accuracy: 0.8782 - val_54_categorical_accuracy: 0.8718 - val_reward_categorical_accuracy: 0.4671\n",
      "Epoch 99/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.3225 - 03_loss: 0.3163 - 04_loss: 0.0588 - 13_loss: 0.3824 - 14_loss: 0.3339 - 23_loss: 1.1239e-10 - 24_loss: 1.1239e-10 - 33_loss: 5.1510e-11 - 34_loss: 1.2911e-10 - 43_loss: 0.1106 - 44_loss: 0.4898 - 53_loss: 0.1111 - 54_loss: 0.0704 - reward_loss: 0.4492 - 03_categorical_accuracy: 0.8372 - 04_categorical_accuracy: 0.9777 - 13_categorical_accuracy: 0.8152 - 14_categorical_accuracy: 0.8289 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9514 - 44_categorical_accuracy: 0.7673 - 53_categorical_accuracy: 0.9511 - 54_categorical_accuracy: 0.9627 - reward_categorical_accuracy: 0.7816 - val_loss: 11.5028 - val_03_loss: 1.1623 - val_04_loss: 0.3220 - val_13_loss: 1.4952 - val_14_loss: 1.3249 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5395 - val_44_loss: 2.5202 - val_53_loss: 0.5533 - val_54_loss: 1.1608 - val_reward_loss: 2.4245 - val_03_categorical_accuracy: 0.6134 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5488 - val_14_categorical_accuracy: 0.5857 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8782 - val_44_categorical_accuracy: 0.4476 - val_53_categorical_accuracy: 0.8771 - val_54_categorical_accuracy: 0.8727 - val_reward_categorical_accuracy: 0.4630\n",
      "Epoch 100/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.3193 - 03_loss: 0.3164 - 04_loss: 0.0591 - 13_loss: 0.3822 - 14_loss: 0.3339 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1100 - 44_loss: 0.4876 - 53_loss: 0.1107 - 54_loss: 0.0705 - reward_loss: 0.4490 - 03_categorical_accuracy: 0.8378 - 04_categorical_accuracy: 0.9775 - 13_categorical_accuracy: 0.8149 - 14_categorical_accuracy: 0.8287 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9520 - 44_categorical_accuracy: 0.7685 - 53_categorical_accuracy: 0.9509 - 54_categorical_accuracy: 0.9628 - reward_categorical_accuracy: 0.7815 - val_loss: 11.6463 - val_03_loss: 1.1681 - val_04_loss: 0.3241 - val_13_loss: 1.5038 - val_14_loss: 1.3296 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5409 - val_44_loss: 2.5794 - val_53_loss: 0.5658 - val_54_loss: 1.1868 - val_reward_loss: 2.4477 - val_03_categorical_accuracy: 0.6151 - val_04_categorical_accuracy: 0.9524 - val_13_categorical_accuracy: 0.5607 - val_14_categorical_accuracy: 0.5884 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8765 - val_44_categorical_accuracy: 0.4504 - val_53_categorical_accuracy: 0.8763 - val_54_categorical_accuracy: 0.8727 - val_reward_categorical_accuracy: 0.4642\n",
      "Epoch 101/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 19s 27ms/step - loss: 2.3113 - 03_loss: 0.3149 - 04_loss: 0.0588 - 13_loss: 0.3793 - 14_loss: 0.3320 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1104 - 44_loss: 0.4879 - 53_loss: 0.1106 - 54_loss: 0.0703 - reward_loss: 0.4471 - 03_categorical_accuracy: 0.8381 - 04_categorical_accuracy: 0.9776 - 13_categorical_accuracy: 0.8161 - 14_categorical_accuracy: 0.8301 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9515 - 44_categorical_accuracy: 0.7677 - 53_categorical_accuracy: 0.9519 - 54_categorical_accuracy: 0.9628 - reward_categorical_accuracy: 0.7824 - val_loss: 11.6170 - val_03_loss: 1.1565 - val_04_loss: 0.3252 - val_13_loss: 1.4921 - val_14_loss: 1.3487 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5501 - val_44_loss: 2.5750 - val_53_loss: 0.5569 - val_54_loss: 1.1547 - val_reward_loss: 2.4579 - val_03_categorical_accuracy: 0.6084 - val_04_categorical_accuracy: 0.9529 - val_13_categorical_accuracy: 0.5589 - val_14_categorical_accuracy: 0.5944 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8874 - val_44_categorical_accuracy: 0.4569 - val_53_categorical_accuracy: 0.8813 - val_54_categorical_accuracy: 0.8727 - val_reward_categorical_accuracy: 0.4631\n",
      "Epoch 102/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.3085 - 03_loss: 0.3148 - 04_loss: 0.0588 - 13_loss: 0.3789 - 14_loss: 0.3317 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1105 - 44_loss: 0.4873 - 53_loss: 0.1103 - 54_loss: 0.0701 - reward_loss: 0.4462 - 03_categorical_accuracy: 0.8380 - 04_categorical_accuracy: 0.9777 - 13_categorical_accuracy: 0.8156 - 14_categorical_accuracy: 0.8292 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9515 - 44_categorical_accuracy: 0.7691 - 53_categorical_accuracy: 0.9520 - 54_categorical_accuracy: 0.9629 - reward_categorical_accuracy: 0.7820 - val_loss: 11.7091 - val_03_loss: 1.1623 - val_04_loss: 0.3367 - val_13_loss: 1.5022 - val_14_loss: 1.3471 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5421 - val_44_loss: 2.5931 - val_53_loss: 0.5577 - val_54_loss: 1.1923 - val_reward_loss: 2.4756 - val_03_categorical_accuracy: 0.6104 - val_04_categorical_accuracy: 0.9538 - val_13_categorical_accuracy: 0.5541 - val_14_categorical_accuracy: 0.5922 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8797 - val_44_categorical_accuracy: 0.4543 - val_53_categorical_accuracy: 0.8791 - val_54_categorical_accuracy: 0.8727 - val_reward_categorical_accuracy: 0.4611\n",
      "Epoch 103/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.3030 - 03_loss: 0.3140 - 04_loss: 0.0587 - 13_loss: 0.3785 - 14_loss: 0.3303 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1101 - 44_loss: 0.4862 - 53_loss: 0.1098 - 54_loss: 0.0700 - reward_loss: 0.4454 - 03_categorical_accuracy: 0.8389 - 04_categorical_accuracy: 0.9776 - 13_categorical_accuracy: 0.8170 - 14_categorical_accuracy: 0.8303 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9517 - 44_categorical_accuracy: 0.7688 - 53_categorical_accuracy: 0.9519 - 54_categorical_accuracy: 0.9627 - reward_categorical_accuracy: 0.7832 - val_loss: 11.7394 - val_03_loss: 1.1668 - val_04_loss: 0.3278 - val_13_loss: 1.5038 - val_14_loss: 1.3421 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5399 - val_44_loss: 2.5638 - val_53_loss: 0.5591 - val_54_loss: 1.2478 - val_reward_loss: 2.4883 - val_03_categorical_accuracy: 0.6055 - val_04_categorical_accuracy: 0.9527 - val_13_categorical_accuracy: 0.5604 - val_14_categorical_accuracy: 0.5862 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8777 - val_44_categorical_accuracy: 0.4492 - val_53_categorical_accuracy: 0.8787 - val_54_categorical_accuracy: 0.8726 - val_reward_categorical_accuracy: 0.4672\n",
      "Epoch 104/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.2983 - 03_loss: 0.3130 - 04_loss: 0.0585 - 13_loss: 0.3774 - 14_loss: 0.3304 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1099 - 44_loss: 0.4855 - 53_loss: 0.1100 - 54_loss: 0.0700 - reward_loss: 0.4437 - 03_categorical_accuracy: 0.8383 - 04_categorical_accuracy: 0.9778 - 13_categorical_accuracy: 0.8166 - 14_categorical_accuracy: 0.8304 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9523 - 44_categorical_accuracy: 0.7690 - 53_categorical_accuracy: 0.9518 - 54_categorical_accuracy: 0.9626 - reward_categorical_accuracy: 0.7835 - val_loss: 11.7985 - val_03_loss: 1.1787 - val_04_loss: 0.3308 - val_13_loss: 1.5357 - val_14_loss: 1.3556 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5521 - val_44_loss: 2.5509 - val_53_loss: 0.5573 - val_54_loss: 1.2358 - val_reward_loss: 2.5016 - val_03_categorical_accuracy: 0.6021 - val_04_categorical_accuracy: 0.9524 - val_13_categorical_accuracy: 0.5635 - val_14_categorical_accuracy: 0.5884 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8859 - val_44_categorical_accuracy: 0.4485 - val_53_categorical_accuracy: 0.8763 - val_54_categorical_accuracy: 0.8725 - val_reward_categorical_accuracy: 0.4568\n",
      "Epoch 105/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.2937 - 03_loss: 0.3131 - 04_loss: 0.0585 - 13_loss: 0.3757 - 14_loss: 0.3293 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1097 - 44_loss: 0.4846 - 53_loss: 0.1103 - 54_loss: 0.0701 - reward_loss: 0.4424 - 03_categorical_accuracy: 0.8387 - 04_categorical_accuracy: 0.9777 - 13_categorical_accuracy: 0.8168 - 14_categorical_accuracy: 0.8302 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9520 - 44_categorical_accuracy: 0.7698 - 53_categorical_accuracy: 0.9514 - 54_categorical_accuracy: 0.9625 - reward_categorical_accuracy: 0.7842 - val_loss: 11.6937 - val_03_loss: 1.1597 - val_04_loss: 0.3266 - val_13_loss: 1.5134 - val_14_loss: 1.3409 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5428 - val_44_loss: 2.5694 - val_53_loss: 0.5592 - val_54_loss: 1.2059 - val_reward_loss: 2.4759 - val_03_categorical_accuracy: 0.6120 - val_04_categorical_accuracy: 0.9529 - val_13_categorical_accuracy: 0.5611 - val_14_categorical_accuracy: 0.5887 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8788 - val_44_categorical_accuracy: 0.4485 - val_53_categorical_accuracy: 0.8742 - val_54_categorical_accuracy: 0.8729 - val_reward_categorical_accuracy: 0.4645\n",
      "Epoch 106/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.2886 - 03_loss: 0.3116 - 04_loss: 0.0586 - 13_loss: 0.3755 - 14_loss: 0.3287 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1094 - 44_loss: 0.4835 - 53_loss: 0.1100 - 54_loss: 0.0697 - reward_loss: 0.4416 - 03_categorical_accuracy: 0.8392 - 04_categorical_accuracy: 0.9777 - 13_categorical_accuracy: 0.8169 - 14_categorical_accuracy: 0.8305 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9516 - 44_categorical_accuracy: 0.7685 - 53_categorical_accuracy: 0.9515 - 54_categorical_accuracy: 0.9628 - reward_categorical_accuracy: 0.7838 - val_loss: 11.7272 - val_03_loss: 1.1693 - val_04_loss: 0.3281 - val_13_loss: 1.5061 - val_14_loss: 1.3385 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5397 - val_44_loss: 2.5630 - val_53_loss: 0.5633 - val_54_loss: 1.2203 - val_reward_loss: 2.4990 - val_03_categorical_accuracy: 0.6105 - val_04_categorical_accuracy: 0.9523 - val_13_categorical_accuracy: 0.5546 - val_14_categorical_accuracy: 0.5854 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8812 - val_44_categorical_accuracy: 0.4526 - val_53_categorical_accuracy: 0.8781 - val_54_categorical_accuracy: 0.8746 - val_reward_categorical_accuracy: 0.4620\n",
      "Epoch 107/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.2825 - 03_loss: 0.3111 - 04_loss: 0.0584 - 13_loss: 0.3737 - 14_loss: 0.3280 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1091 - 44_loss: 0.4829 - 53_loss: 0.1093 - 54_loss: 0.0694 - reward_loss: 0.4405 - 03_categorical_accuracy: 0.8396 - 04_categorical_accuracy: 0.9780 - 13_categorical_accuracy: 0.8175 - 14_categorical_accuracy: 0.8306 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9516 - 44_categorical_accuracy: 0.7690 - 53_categorical_accuracy: 0.9516 - 54_categorical_accuracy: 0.9631 - reward_categorical_accuracy: 0.7846 - val_loss: 11.7434 - val_03_loss: 1.1624 - val_04_loss: 0.3323 - val_13_loss: 1.5131 - val_14_loss: 1.3388 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5444 - val_44_loss: 2.5952 - val_53_loss: 0.5595 - val_54_loss: 1.2204 - val_reward_loss: 2.4773 - val_03_categorical_accuracy: 0.6063 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5593 - val_14_categorical_accuracy: 0.5915 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8765 - val_44_categorical_accuracy: 0.4569 - val_53_categorical_accuracy: 0.8771 - val_54_categorical_accuracy: 0.8739 - val_reward_categorical_accuracy: 0.4590\n",
      "Epoch 108/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.2789 - 03_loss: 0.3112 - 04_loss: 0.0584 - 13_loss: 0.3735 - 14_loss: 0.3273 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1089 - 44_loss: 0.4824 - 53_loss: 0.1090 - 54_loss: 0.0696 - reward_loss: 0.4387 - 03_categorical_accuracy: 0.8402 - 04_categorical_accuracy: 0.9774 - 13_categorical_accuracy: 0.8178 - 14_categorical_accuracy: 0.8308 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9518 - 44_categorical_accuracy: 0.7695 - 53_categorical_accuracy: 0.9522 - 54_categorical_accuracy: 0.9629 - reward_categorical_accuracy: 0.7854 - val_loss: 11.8847 - val_03_loss: 1.1785 - val_04_loss: 0.3360 - val_13_loss: 1.5242 - val_14_loss: 1.3558 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5460 - val_44_loss: 2.5783 - val_53_loss: 0.5645 - val_54_loss: 1.2806 - val_reward_loss: 2.5208 - val_03_categorical_accuracy: 0.6105 - val_04_categorical_accuracy: 0.9520 - val_13_categorical_accuracy: 0.5549 - val_14_categorical_accuracy: 0.5900 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8811 - val_44_categorical_accuracy: 0.4499 - val_53_categorical_accuracy: 0.8809 - val_54_categorical_accuracy: 0.8742 - val_reward_categorical_accuracy: 0.4573\n",
      "Epoch 109/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.2761 - 03_loss: 0.3110 - 04_loss: 0.0584 - 13_loss: 0.3728 - 14_loss: 0.3270 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1090 - 44_loss: 0.4811 - 53_loss: 0.1091 - 54_loss: 0.0694 - reward_loss: 0.4384 - 03_categorical_accuracy: 0.8387 - 04_categorical_accuracy: 0.9776 - 13_categorical_accuracy: 0.8179 - 14_categorical_accuracy: 0.8308 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9520 - 44_categorical_accuracy: 0.7699 - 53_categorical_accuracy: 0.9519 - 54_categorical_accuracy: 0.9632 - reward_categorical_accuracy: 0.7859 - val_loss: 11.9019 - val_03_loss: 1.1777 - val_04_loss: 0.3298 - val_13_loss: 1.5229 - val_14_loss: 1.3548 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5416 - val_44_loss: 2.6120 - val_53_loss: 0.5630 - val_54_loss: 1.2762 - val_reward_loss: 2.5239 - val_03_categorical_accuracy: 0.6123 - val_04_categorical_accuracy: 0.9522 - val_13_categorical_accuracy: 0.5583 - val_14_categorical_accuracy: 0.5894 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8785 - val_44_categorical_accuracy: 0.4511 - val_53_categorical_accuracy: 0.8774 - val_54_categorical_accuracy: 0.8736 - val_reward_categorical_accuracy: 0.4591\n",
      "Epoch 110/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 2.2700 - 03_loss: 0.3103 - 04_loss: 0.0585 - 13_loss: 0.3713 - 14_loss: 0.3258 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1084 - 44_loss: 0.4804 - 53_loss: 0.1086 - 54_loss: 0.0696 - reward_loss: 0.4370 - 03_categorical_accuracy: 0.8393 - 04_categorical_accuracy: 0.9777 - 13_categorical_accuracy: 0.8188 - 14_categorical_accuracy: 0.8312 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9521 - 44_categorical_accuracy: 0.7700 - 53_categorical_accuracy: 0.9519 - 54_categorical_accuracy: 0.9628 - reward_categorical_accuracy: 0.7864 - val_loss: 11.8452 - val_03_loss: 1.1805 - val_04_loss: 0.3353 - val_13_loss: 1.5337 - val_14_loss: 1.3661 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5511 - val_44_loss: 2.5768 - val_53_loss: 0.5614 - val_54_loss: 1.2464 - val_reward_loss: 2.4939 - val_03_categorical_accuracy: 0.6015 - val_04_categorical_accuracy: 0.9510 - val_13_categorical_accuracy: 0.5615 - val_14_categorical_accuracy: 0.5919 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8728 - val_44_categorical_accuracy: 0.4541 - val_53_categorical_accuracy: 0.8720 - val_54_categorical_accuracy: 0.8743 - val_reward_categorical_accuracy: 0.4609\n",
      "Epoch 111/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 19s 27ms/step - loss: 2.2665 - 03_loss: 0.3091 - 04_loss: 0.0585 - 13_loss: 0.3715 - 14_loss: 0.3251 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1087 - 44_loss: 0.4793 - 53_loss: 0.1081 - 54_loss: 0.0693 - reward_loss: 0.4368 - 03_categorical_accuracy: 0.8402 - 04_categorical_accuracy: 0.9778 - 13_categorical_accuracy: 0.8185 - 14_categorical_accuracy: 0.8322 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9518 - 44_categorical_accuracy: 0.7707 - 53_categorical_accuracy: 0.9520 - 54_categorical_accuracy: 0.9627 - reward_categorical_accuracy: 0.7860 - val_loss: 11.8985 - val_03_loss: 1.1859 - val_04_loss: 0.3352 - val_13_loss: 1.5402 - val_14_loss: 1.3571 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5451 - val_44_loss: 2.6105 - val_53_loss: 0.5619 - val_54_loss: 1.2467 - val_reward_loss: 2.5159 - val_03_categorical_accuracy: 0.6049 - val_04_categorical_accuracy: 0.9525 - val_13_categorical_accuracy: 0.5633 - val_14_categorical_accuracy: 0.5921 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8791 - val_44_categorical_accuracy: 0.4512 - val_53_categorical_accuracy: 0.8738 - val_54_categorical_accuracy: 0.8729 - val_reward_categorical_accuracy: 0.4577\n",
      "Epoch 112/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 2.2628 - 03_loss: 0.3091 - 04_loss: 0.0583 - 13_loss: 0.3704 - 14_loss: 0.3241 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1089 - 44_loss: 0.4790 - 53_loss: 0.1084 - 54_loss: 0.0692 - reward_loss: 0.4355 - 03_categorical_accuracy: 0.8398 - 04_categorical_accuracy: 0.9779 - 13_categorical_accuracy: 0.8189 - 14_categorical_accuracy: 0.8321 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9519 - 44_categorical_accuracy: 0.7708 - 53_categorical_accuracy: 0.9524 - 54_categorical_accuracy: 0.9625 - reward_categorical_accuracy: 0.7859 - val_loss: 12.0068 - val_03_loss: 1.1907 - val_04_loss: 0.3355 - val_13_loss: 1.5333 - val_14_loss: 1.3724 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5536 - val_44_loss: 2.6286 - val_53_loss: 0.5722 - val_54_loss: 1.2696 - val_reward_loss: 2.5509 - val_03_categorical_accuracy: 0.6111 - val_04_categorical_accuracy: 0.9512 - val_13_categorical_accuracy: 0.5568 - val_14_categorical_accuracy: 0.5929 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8803 - val_44_categorical_accuracy: 0.4482 - val_53_categorical_accuracy: 0.8818 - val_54_categorical_accuracy: 0.8748 - val_reward_categorical_accuracy: 0.4610\n",
      "Epoch 113/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.2578 - 03_loss: 0.3079 - 04_loss: 0.0582 - 13_loss: 0.3683 - 14_loss: 0.3239 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1083 - 44_loss: 0.4785 - 53_loss: 0.1081 - 54_loss: 0.0689 - reward_loss: 0.4357 - 03_categorical_accuracy: 0.8400 - 04_categorical_accuracy: 0.9779 - 13_categorical_accuracy: 0.8200 - 14_categorical_accuracy: 0.8318 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9518 - 44_categorical_accuracy: 0.7705 - 53_categorical_accuracy: 0.9522 - 54_categorical_accuracy: 0.9632 - reward_categorical_accuracy: 0.7850 - val_loss: 11.8900 - val_03_loss: 1.1787 - val_04_loss: 0.3357 - val_13_loss: 1.5262 - val_14_loss: 1.3641 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5461 - val_44_loss: 2.6103 - val_53_loss: 0.5580 - val_54_loss: 1.2620 - val_reward_loss: 2.5090 - val_03_categorical_accuracy: 0.6136 - val_04_categorical_accuracy: 0.9523 - val_13_categorical_accuracy: 0.5610 - val_14_categorical_accuracy: 0.5937 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8772 - val_44_categorical_accuracy: 0.4525 - val_53_categorical_accuracy: 0.8709 - val_54_categorical_accuracy: 0.8744 - val_reward_categorical_accuracy: 0.4632\n",
      "Epoch 114/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.2533 - 03_loss: 0.3076 - 04_loss: 0.0582 - 13_loss: 0.3674 - 14_loss: 0.3232 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1082 - 44_loss: 0.4774 - 53_loss: 0.1081 - 54_loss: 0.0688 - reward_loss: 0.4343 - 03_categorical_accuracy: 0.8397 - 04_categorical_accuracy: 0.9777 - 13_categorical_accuracy: 0.8189 - 14_categorical_accuracy: 0.8314 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9517 - 44_categorical_accuracy: 0.7715 - 53_categorical_accuracy: 0.9519 - 54_categorical_accuracy: 0.9632 - reward_categorical_accuracy: 0.7859 - val_loss: 11.9230 - val_03_loss: 1.1895 - val_04_loss: 0.3359 - val_13_loss: 1.5389 - val_14_loss: 1.3793 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5479 - val_44_loss: 2.5792 - val_53_loss: 0.5592 - val_54_loss: 1.2953 - val_reward_loss: 2.4978 - val_03_categorical_accuracy: 0.6105 - val_04_categorical_accuracy: 0.9506 - val_13_categorical_accuracy: 0.5608 - val_14_categorical_accuracy: 0.5861 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8797 - val_44_categorical_accuracy: 0.4518 - val_53_categorical_accuracy: 0.8714 - val_54_categorical_accuracy: 0.8727 - val_reward_categorical_accuracy: 0.4596\n",
      "Epoch 115/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.2523 - 03_loss: 0.3082 - 04_loss: 0.0579 - 13_loss: 0.3680 - 14_loss: 0.3229 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1075 - 44_loss: 0.4775 - 53_loss: 0.1076 - 54_loss: 0.0688 - reward_loss: 0.4338 - 03_categorical_accuracy: 0.8402 - 04_categorical_accuracy: 0.9781 - 13_categorical_accuracy: 0.8196 - 14_categorical_accuracy: 0.8323 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9524 - 44_categorical_accuracy: 0.7712 - 53_categorical_accuracy: 0.9522 - 54_categorical_accuracy: 0.9626 - reward_categorical_accuracy: 0.7855 - val_loss: 11.9064 - val_03_loss: 1.1662 - val_04_loss: 0.3489 - val_13_loss: 1.5287 - val_14_loss: 1.3521 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5482 - val_44_loss: 2.5686 - val_53_loss: 0.5597 - val_54_loss: 1.2915 - val_reward_loss: 2.5425 - val_03_categorical_accuracy: 0.6075 - val_04_categorical_accuracy: 0.9527 - val_13_categorical_accuracy: 0.5625 - val_14_categorical_accuracy: 0.5915 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8759 - val_44_categorical_accuracy: 0.4459 - val_53_categorical_accuracy: 0.8740 - val_54_categorical_accuracy: 0.8724 - val_reward_categorical_accuracy: 0.4602\n",
      "Epoch 116/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 2.2456 - 03_loss: 0.3068 - 04_loss: 0.0579 - 13_loss: 0.3668 - 14_loss: 0.3221 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1066 - 44_loss: 0.4761 - 53_loss: 0.1072 - 54_loss: 0.0688 - reward_loss: 0.4333 - 03_categorical_accuracy: 0.8406 - 04_categorical_accuracy: 0.9779 - 13_categorical_accuracy: 0.8200 - 14_categorical_accuracy: 0.8330 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9524 - 44_categorical_accuracy: 0.7714 - 53_categorical_accuracy: 0.9526 - 54_categorical_accuracy: 0.9634 - reward_categorical_accuracy: 0.7864 - val_loss: 11.9506 - val_03_loss: 1.1880 - val_04_loss: 0.3492 - val_13_loss: 1.5691 - val_14_loss: 1.3688 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5474 - val_44_loss: 2.5866 - val_53_loss: 0.5684 - val_54_loss: 1.2504 - val_reward_loss: 2.5227 - val_03_categorical_accuracy: 0.6053 - val_04_categorical_accuracy: 0.9530 - val_13_categorical_accuracy: 0.5555 - val_14_categorical_accuracy: 0.5928 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8809 - val_44_categorical_accuracy: 0.4514 - val_53_categorical_accuracy: 0.8761 - val_54_categorical_accuracy: 0.8749 - val_reward_categorical_accuracy: 0.4647\n",
      "Epoch 117/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.2448 - 03_loss: 0.3068 - 04_loss: 0.0580 - 13_loss: 0.3662 - 14_loss: 0.3219 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1077 - 44_loss: 0.4761 - 53_loss: 0.1075 - 54_loss: 0.0688 - reward_loss: 0.4318 - 03_categorical_accuracy: 0.8402 - 04_categorical_accuracy: 0.9779 - 13_categorical_accuracy: 0.8196 - 14_categorical_accuracy: 0.8323 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9519 - 44_categorical_accuracy: 0.7710 - 53_categorical_accuracy: 0.9519 - 54_categorical_accuracy: 0.9632 - reward_categorical_accuracy: 0.7868 - val_loss: 12.0063 - val_03_loss: 1.1887 - val_04_loss: 0.3440 - val_13_loss: 1.5452 - val_14_loss: 1.3642 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5545 - val_44_loss: 2.5910 - val_53_loss: 0.5598 - val_54_loss: 1.3165 - val_reward_loss: 2.5424 - val_03_categorical_accuracy: 0.6054 - val_04_categorical_accuracy: 0.9522 - val_13_categorical_accuracy: 0.5548 - val_14_categorical_accuracy: 0.5869 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8748 - val_44_categorical_accuracy: 0.4497 - val_53_categorical_accuracy: 0.8716 - val_54_categorical_accuracy: 0.8737 - val_reward_categorical_accuracy: 0.4617\n",
      "Epoch 118/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.2392 - 03_loss: 0.3062 - 04_loss: 0.0580 - 13_loss: 0.3659 - 14_loss: 0.3215 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1069 - 44_loss: 0.4747 - 53_loss: 0.1071 - 54_loss: 0.0685 - reward_loss: 0.4304 - 03_categorical_accuracy: 0.8411 - 04_categorical_accuracy: 0.9779 - 13_categorical_accuracy: 0.8191 - 14_categorical_accuracy: 0.8320 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9525 - 44_categorical_accuracy: 0.7706 - 53_categorical_accuracy: 0.9524 - 54_categorical_accuracy: 0.9632 - reward_categorical_accuracy: 0.7867 - val_loss: 11.9330 - val_03_loss: 1.1828 - val_04_loss: 0.3416 - val_13_loss: 1.5411 - val_14_loss: 1.3630 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5498 - val_44_loss: 2.6397 - val_53_loss: 0.5653 - val_54_loss: 1.2463 - val_reward_loss: 2.5034 - val_03_categorical_accuracy: 0.6058 - val_04_categorical_accuracy: 0.9525 - val_13_categorical_accuracy: 0.5621 - val_14_categorical_accuracy: 0.5965 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8806 - val_44_categorical_accuracy: 0.4462 - val_53_categorical_accuracy: 0.8817 - val_54_categorical_accuracy: 0.8733 - val_reward_categorical_accuracy: 0.4588\n",
      "Epoch 119/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.2352 - 03_loss: 0.3060 - 04_loss: 0.0580 - 13_loss: 0.3645 - 14_loss: 0.3201 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1069 - 44_loss: 0.4745 - 53_loss: 0.1067 - 54_loss: 0.0685 - reward_loss: 0.4299 - 03_categorical_accuracy: 0.8413 - 04_categorical_accuracy: 0.9779 - 13_categorical_accuracy: 0.8204 - 14_categorical_accuracy: 0.8335 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9521 - 44_categorical_accuracy: 0.7722 - 53_categorical_accuracy: 0.9526 - 54_categorical_accuracy: 0.9632 - reward_categorical_accuracy: 0.7875 - val_loss: 11.9383 - val_03_loss: 1.1699 - val_04_loss: 0.3417 - val_13_loss: 1.5290 - val_14_loss: 1.3698 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5522 - val_44_loss: 2.5926 - val_53_loss: 0.5526 - val_54_loss: 1.2956 - val_reward_loss: 2.5350 - val_03_categorical_accuracy: 0.6036 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5653 - val_14_categorical_accuracy: 0.5960 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8797 - val_44_categorical_accuracy: 0.4496 - val_53_categorical_accuracy: 0.8740 - val_54_categorical_accuracy: 0.8736 - val_reward_categorical_accuracy: 0.4633\n",
      "Epoch 120/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.2348 - 03_loss: 0.3057 - 04_loss: 0.0579 - 13_loss: 0.3651 - 14_loss: 0.3206 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1072 - 44_loss: 0.4737 - 53_loss: 0.1073 - 54_loss: 0.0684 - reward_loss: 0.4289 - 03_categorical_accuracy: 0.8408 - 04_categorical_accuracy: 0.9779 - 13_categorical_accuracy: 0.8198 - 14_categorical_accuracy: 0.8325 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9526 - 44_categorical_accuracy: 0.7718 - 53_categorical_accuracy: 0.9519 - 54_categorical_accuracy: 0.9630 - reward_categorical_accuracy: 0.7883 - val_loss: 12.0499 - val_03_loss: 1.1988 - val_04_loss: 0.3506 - val_13_loss: 1.5441 - val_14_loss: 1.3861 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5510 - val_44_loss: 2.6208 - val_53_loss: 0.5607 - val_54_loss: 1.3140 - val_reward_loss: 2.5237 - val_03_categorical_accuracy: 0.6091 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5585 - val_14_categorical_accuracy: 0.5891 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8805 - val_44_categorical_accuracy: 0.4450 - val_53_categorical_accuracy: 0.8769 - val_54_categorical_accuracy: 0.8736 - val_reward_categorical_accuracy: 0.4562\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 19s 27ms/step - loss: 2.2280 - 03_loss: 0.3042 - 04_loss: 0.0579 - 13_loss: 0.3627 - 14_loss: 0.3195 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1071 - 44_loss: 0.4730 - 53_loss: 0.1064 - 54_loss: 0.0685 - reward_loss: 0.4287 - 03_categorical_accuracy: 0.8416 - 04_categorical_accuracy: 0.9778 - 13_categorical_accuracy: 0.8211 - 14_categorical_accuracy: 0.8328 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9525 - 44_categorical_accuracy: 0.7720 - 53_categorical_accuracy: 0.9527 - 54_categorical_accuracy: 0.9633 - reward_categorical_accuracy: 0.7877 - val_loss: 11.9933 - val_03_loss: 1.1831 - val_04_loss: 0.3429 - val_13_loss: 1.5298 - val_14_loss: 1.3605 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5432 - val_44_loss: 2.5982 - val_53_loss: 0.5590 - val_54_loss: 1.3487 - val_reward_loss: 2.5280 - val_03_categorical_accuracy: 0.6103 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5571 - val_14_categorical_accuracy: 0.5888 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8781 - val_44_categorical_accuracy: 0.4519 - val_53_categorical_accuracy: 0.8737 - val_54_categorical_accuracy: 0.8754 - val_reward_categorical_accuracy: 0.4594\n",
      "Epoch 122/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.2253 - 03_loss: 0.3045 - 04_loss: 0.0578 - 13_loss: 0.3629 - 14_loss: 0.3186 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1061 - 44_loss: 0.4729 - 53_loss: 0.1068 - 54_loss: 0.0683 - reward_loss: 0.4274 - 03_categorical_accuracy: 0.8413 - 04_categorical_accuracy: 0.9780 - 13_categorical_accuracy: 0.8205 - 14_categorical_accuracy: 0.8333 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9523 - 44_categorical_accuracy: 0.7719 - 53_categorical_accuracy: 0.9524 - 54_categorical_accuracy: 0.9633 - reward_categorical_accuracy: 0.7877 - val_loss: 12.1000 - val_03_loss: 1.1808 - val_04_loss: 0.3451 - val_13_loss: 1.5443 - val_14_loss: 1.3742 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5423 - val_44_loss: 2.6230 - val_53_loss: 0.5653 - val_54_loss: 1.3428 - val_reward_loss: 2.5822 - val_03_categorical_accuracy: 0.6073 - val_04_categorical_accuracy: 0.9525 - val_13_categorical_accuracy: 0.5669 - val_14_categorical_accuracy: 0.5880 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8754 - val_44_categorical_accuracy: 0.4502 - val_53_categorical_accuracy: 0.8782 - val_54_categorical_accuracy: 0.8737 - val_reward_categorical_accuracy: 0.4567\n",
      "Epoch 123/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.2242 - 03_loss: 0.3037 - 04_loss: 0.0578 - 13_loss: 0.3624 - 14_loss: 0.3184 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1068 - 44_loss: 0.4718 - 53_loss: 0.1064 - 54_loss: 0.0681 - reward_loss: 0.4289 - 03_categorical_accuracy: 0.8410 - 04_categorical_accuracy: 0.9780 - 13_categorical_accuracy: 0.8206 - 14_categorical_accuracy: 0.8337 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9522 - 44_categorical_accuracy: 0.7729 - 53_categorical_accuracy: 0.9527 - 54_categorical_accuracy: 0.9632 - reward_categorical_accuracy: 0.7875 - val_loss: 12.0768 - val_03_loss: 1.1822 - val_04_loss: 0.3366 - val_13_loss: 1.5468 - val_14_loss: 1.3880 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5525 - val_44_loss: 2.6313 - val_53_loss: 0.5673 - val_54_loss: 1.3425 - val_reward_loss: 2.5297 - val_03_categorical_accuracy: 0.6048 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5630 - val_14_categorical_accuracy: 0.5899 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8796 - val_44_categorical_accuracy: 0.4525 - val_53_categorical_accuracy: 0.8765 - val_54_categorical_accuracy: 0.8727 - val_reward_categorical_accuracy: 0.4658\n",
      "Epoch 124/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.2209 - 03_loss: 0.3035 - 04_loss: 0.0577 - 13_loss: 0.3616 - 14_loss: 0.3181 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1065 - 44_loss: 0.4722 - 53_loss: 0.1065 - 54_loss: 0.0684 - reward_loss: 0.4266 - 03_categorical_accuracy: 0.8405 - 04_categorical_accuracy: 0.9780 - 13_categorical_accuracy: 0.8204 - 14_categorical_accuracy: 0.8333 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9523 - 44_categorical_accuracy: 0.7721 - 53_categorical_accuracy: 0.9523 - 54_categorical_accuracy: 0.9632 - reward_categorical_accuracy: 0.7880 - val_loss: 12.0259 - val_03_loss: 1.1900 - val_04_loss: 0.3397 - val_13_loss: 1.5582 - val_14_loss: 1.3901 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5474 - val_44_loss: 2.6148 - val_53_loss: 0.5633 - val_54_loss: 1.2888 - val_reward_loss: 2.5336 - val_03_categorical_accuracy: 0.6105 - val_04_categorical_accuracy: 0.9520 - val_13_categorical_accuracy: 0.5563 - val_14_categorical_accuracy: 0.5859 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8760 - val_44_categorical_accuracy: 0.4495 - val_53_categorical_accuracy: 0.8753 - val_54_categorical_accuracy: 0.8735 - val_reward_categorical_accuracy: 0.4605\n",
      "Epoch 125/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.2137 - 03_loss: 0.3030 - 04_loss: 0.0577 - 13_loss: 0.3613 - 14_loss: 0.3170 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1065 - 44_loss: 0.4703 - 53_loss: 0.1054 - 54_loss: 0.0678 - reward_loss: 0.4247 - 03_categorical_accuracy: 0.8416 - 04_categorical_accuracy: 0.9781 - 13_categorical_accuracy: 0.8211 - 14_categorical_accuracy: 0.8340 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9525 - 44_categorical_accuracy: 0.7725 - 53_categorical_accuracy: 0.9527 - 54_categorical_accuracy: 0.9637 - reward_categorical_accuracy: 0.7882 - val_loss: 12.1904 - val_03_loss: 1.1941 - val_04_loss: 0.3497 - val_13_loss: 1.5620 - val_14_loss: 1.3823 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5570 - val_44_loss: 2.6710 - val_53_loss: 0.5639 - val_54_loss: 1.3433 - val_reward_loss: 2.5671 - val_03_categorical_accuracy: 0.6078 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5588 - val_14_categorical_accuracy: 0.5886 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8836 - val_44_categorical_accuracy: 0.4478 - val_53_categorical_accuracy: 0.8736 - val_54_categorical_accuracy: 0.8747 - val_reward_categorical_accuracy: 0.4628\n",
      "Epoch 126/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.2104 - 03_loss: 0.3017 - 04_loss: 0.0578 - 13_loss: 0.3600 - 14_loss: 0.3158 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1060 - 44_loss: 0.4708 - 53_loss: 0.1058 - 54_loss: 0.0678 - reward_loss: 0.4246 - 03_categorical_accuracy: 0.8422 - 04_categorical_accuracy: 0.9780 - 13_categorical_accuracy: 0.8211 - 14_categorical_accuracy: 0.8347 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9528 - 44_categorical_accuracy: 0.7720 - 53_categorical_accuracy: 0.9525 - 54_categorical_accuracy: 0.9637 - reward_categorical_accuracy: 0.7888 - val_loss: 12.0560 - val_03_loss: 1.1799 - val_04_loss: 0.3538 - val_13_loss: 1.5450 - val_14_loss: 1.3753 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5504 - val_44_loss: 2.6237 - val_53_loss: 0.5649 - val_54_loss: 1.3083 - val_reward_loss: 2.5547 - val_03_categorical_accuracy: 0.6100 - val_04_categorical_accuracy: 0.9535 - val_13_categorical_accuracy: 0.5562 - val_14_categorical_accuracy: 0.5847 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8764 - val_44_categorical_accuracy: 0.4503 - val_53_categorical_accuracy: 0.8777 - val_54_categorical_accuracy: 0.8725 - val_reward_categorical_accuracy: 0.4635\n",
      "Epoch 127/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.2102 - 03_loss: 0.3019 - 04_loss: 0.0577 - 13_loss: 0.3597 - 14_loss: 0.3160 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1061 - 44_loss: 0.4707 - 53_loss: 0.1057 - 54_loss: 0.0677 - reward_loss: 0.4246 - 03_categorical_accuracy: 0.8420 - 04_categorical_accuracy: 0.9782 - 13_categorical_accuracy: 0.8215 - 14_categorical_accuracy: 0.8337 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9523 - 44_categorical_accuracy: 0.7728 - 53_categorical_accuracy: 0.9524 - 54_categorical_accuracy: 0.9634 - reward_categorical_accuracy: 0.7887 - val_loss: 12.2274 - val_03_loss: 1.1929 - val_04_loss: 0.3499 - val_13_loss: 1.5630 - val_14_loss: 1.3954 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5543 - val_44_loss: 2.6576 - val_53_loss: 0.5693 - val_54_loss: 1.3692 - val_reward_loss: 2.5758 - val_03_categorical_accuracy: 0.6160 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5567 - val_14_categorical_accuracy: 0.5911 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8723 - val_44_categorical_accuracy: 0.4523 - val_53_categorical_accuracy: 0.8787 - val_54_categorical_accuracy: 0.8732 - val_reward_categorical_accuracy: 0.4635\n",
      "Epoch 128/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.2054 - 03_loss: 0.3014 - 04_loss: 0.0578 - 13_loss: 0.3587 - 14_loss: 0.3149 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1055 - 44_loss: 0.4703 - 53_loss: 0.1059 - 54_loss: 0.0676 - reward_loss: 0.4233 - 03_categorical_accuracy: 0.8419 - 04_categorical_accuracy: 0.9783 - 13_categorical_accuracy: 0.8216 - 14_categorical_accuracy: 0.8350 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9524 - 44_categorical_accuracy: 0.7720 - 53_categorical_accuracy: 0.9525 - 54_categorical_accuracy: 0.9638 - reward_categorical_accuracy: 0.7893 - val_loss: 12.0596 - val_03_loss: 1.1825 - val_04_loss: 0.3445 - val_13_loss: 1.5519 - val_14_loss: 1.3748 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5516 - val_44_loss: 2.6216 - val_53_loss: 0.5665 - val_54_loss: 1.3207 - val_reward_loss: 2.5454 - val_03_categorical_accuracy: 0.6071 - val_04_categorical_accuracy: 0.9520 - val_13_categorical_accuracy: 0.5539 - val_14_categorical_accuracy: 0.5907 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8763 - val_44_categorical_accuracy: 0.4523 - val_53_categorical_accuracy: 0.8766 - val_54_categorical_accuracy: 0.8724 - val_reward_categorical_accuracy: 0.4664\n",
      "Epoch 129/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.2060 - 03_loss: 0.3008 - 04_loss: 0.0577 - 13_loss: 0.3595 - 14_loss: 0.3162 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1054 - 44_loss: 0.4687 - 53_loss: 0.1059 - 54_loss: 0.0677 - reward_loss: 0.4242 - 03_categorical_accuracy: 0.8426 - 04_categorical_accuracy: 0.9779 - 13_categorical_accuracy: 0.8213 - 14_categorical_accuracy: 0.8341 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9526 - 44_categorical_accuracy: 0.7732 - 53_categorical_accuracy: 0.9524 - 54_categorical_accuracy: 0.9636 - reward_categorical_accuracy: 0.7890 - val_loss: 12.1925 - val_03_loss: 1.1857 - val_04_loss: 0.3542 - val_13_loss: 1.5482 - val_14_loss: 1.3694 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5550 - val_44_loss: 2.6547 - val_53_loss: 0.5675 - val_54_loss: 1.3887 - val_reward_loss: 2.5690 - val_03_categorical_accuracy: 0.6049 - val_04_categorical_accuracy: 0.9520 - val_13_categorical_accuracy: 0.5627 - val_14_categorical_accuracy: 0.5875 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8752 - val_44_categorical_accuracy: 0.4466 - val_53_categorical_accuracy: 0.8795 - val_54_categorical_accuracy: 0.8743 - val_reward_categorical_accuracy: 0.4672\n",
      "Epoch 130/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.2007 - 03_loss: 0.3014 - 04_loss: 0.0576 - 13_loss: 0.3579 - 14_loss: 0.3152 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1060 - 44_loss: 0.4680 - 53_loss: 0.1052 - 54_loss: 0.0675 - reward_loss: 0.4219 - 03_categorical_accuracy: 0.8418 - 04_categorical_accuracy: 0.9781 - 13_categorical_accuracy: 0.8213 - 14_categorical_accuracy: 0.8336 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9527 - 44_categorical_accuracy: 0.7729 - 53_categorical_accuracy: 0.9525 - 54_categorical_accuracy: 0.9634 - reward_categorical_accuracy: 0.7903 - val_loss: 12.2299 - val_03_loss: 1.1984 - val_04_loss: 0.3511 - val_13_loss: 1.5720 - val_14_loss: 1.4042 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5530 - val_44_loss: 2.6697 - val_53_loss: 0.5620 - val_54_loss: 1.3433 - val_reward_loss: 2.5762 - val_03_categorical_accuracy: 0.6135 - val_04_categorical_accuracy: 0.9522 - val_13_categorical_accuracy: 0.5567 - val_14_categorical_accuracy: 0.5868 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8748 - val_44_categorical_accuracy: 0.4508 - val_53_categorical_accuracy: 0.8737 - val_54_categorical_accuracy: 0.8747 - val_reward_categorical_accuracy: 0.4596\n",
      "Epoch 131/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 19s 27ms/step - loss: 2.1960 - 03_loss: 0.2993 - 04_loss: 0.0575 - 13_loss: 0.3574 - 14_loss: 0.3138 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1052 - 44_loss: 0.4688 - 53_loss: 0.1053 - 54_loss: 0.0675 - reward_loss: 0.4211 - 03_categorical_accuracy: 0.8427 - 04_categorical_accuracy: 0.9781 - 13_categorical_accuracy: 0.8220 - 14_categorical_accuracy: 0.8348 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9528 - 44_categorical_accuracy: 0.7723 - 53_categorical_accuracy: 0.9524 - 54_categorical_accuracy: 0.9639 - reward_categorical_accuracy: 0.7901 - val_loss: 12.1761 - val_03_loss: 1.1944 - val_04_loss: 0.3515 - val_13_loss: 1.5669 - val_14_loss: 1.3973 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5492 - val_44_loss: 2.6447 - val_53_loss: 0.5620 - val_54_loss: 1.3438 - val_reward_loss: 2.5664 - val_03_categorical_accuracy: 0.6130 - val_04_categorical_accuracy: 0.9522 - val_13_categorical_accuracy: 0.5596 - val_14_categorical_accuracy: 0.5905 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8823 - val_44_categorical_accuracy: 0.4547 - val_53_categorical_accuracy: 0.8763 - val_54_categorical_accuracy: 0.8743 - val_reward_categorical_accuracy: 0.4574\n",
      "Epoch 132/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.1956 - 03_loss: 0.3001 - 04_loss: 0.0576 - 13_loss: 0.3571 - 14_loss: 0.3144 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1047 - 44_loss: 0.4684 - 53_loss: 0.1049 - 54_loss: 0.0674 - reward_loss: 0.4210 - 03_categorical_accuracy: 0.8427 - 04_categorical_accuracy: 0.9782 - 13_categorical_accuracy: 0.8220 - 14_categorical_accuracy: 0.8347 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9528 - 44_categorical_accuracy: 0.7732 - 53_categorical_accuracy: 0.9524 - 54_categorical_accuracy: 0.9638 - reward_categorical_accuracy: 0.7901 - val_loss: 12.1905 - val_03_loss: 1.1901 - val_04_loss: 0.3539 - val_13_loss: 1.5756 - val_14_loss: 1.3868 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5538 - val_44_loss: 2.6288 - val_53_loss: 0.5693 - val_54_loss: 1.3624 - val_reward_loss: 2.5699 - val_03_categorical_accuracy: 0.6061 - val_04_categorical_accuracy: 0.9533 - val_13_categorical_accuracy: 0.5568 - val_14_categorical_accuracy: 0.5935 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8780 - val_44_categorical_accuracy: 0.4472 - val_53_categorical_accuracy: 0.8787 - val_54_categorical_accuracy: 0.8733 - val_reward_categorical_accuracy: 0.4593\n",
      "Epoch 133/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.1913 - 03_loss: 0.3001 - 04_loss: 0.0577 - 13_loss: 0.3557 - 14_loss: 0.3129 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1054 - 44_loss: 0.4669 - 53_loss: 0.1054 - 54_loss: 0.0673 - reward_loss: 0.4199 - 03_categorical_accuracy: 0.8422 - 04_categorical_accuracy: 0.9780 - 13_categorical_accuracy: 0.8226 - 14_categorical_accuracy: 0.8358 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9522 - 44_categorical_accuracy: 0.7725 - 53_categorical_accuracy: 0.9526 - 54_categorical_accuracy: 0.9638 - reward_categorical_accuracy: 0.7887 - val_loss: 12.3649 - val_03_loss: 1.2088 - val_04_loss: 0.3547 - val_13_loss: 1.5720 - val_14_loss: 1.4003 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5607 - val_44_loss: 2.6702 - val_53_loss: 0.5708 - val_54_loss: 1.4113 - val_reward_loss: 2.6161 - val_03_categorical_accuracy: 0.6056 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5581 - val_14_categorical_accuracy: 0.5923 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8789 - val_44_categorical_accuracy: 0.4495 - val_53_categorical_accuracy: 0.8765 - val_54_categorical_accuracy: 0.8741 - val_reward_categorical_accuracy: 0.4661\n",
      "Epoch 134/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.1885 - 03_loss: 0.3000 - 04_loss: 0.0575 - 13_loss: 0.3556 - 14_loss: 0.3126 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1049 - 44_loss: 0.4667 - 53_loss: 0.1050 - 54_loss: 0.0670 - reward_loss: 0.4191 - 03_categorical_accuracy: 0.8423 - 04_categorical_accuracy: 0.9781 - 13_categorical_accuracy: 0.8224 - 14_categorical_accuracy: 0.8347 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9526 - 44_categorical_accuracy: 0.7729 - 53_categorical_accuracy: 0.9527 - 54_categorical_accuracy: 0.9638 - reward_categorical_accuracy: 0.7905 - val_loss: 12.2453 - val_03_loss: 1.1876 - val_04_loss: 0.3434 - val_13_loss: 1.5792 - val_14_loss: 1.4055 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5490 - val_44_loss: 2.6563 - val_53_loss: 0.5626 - val_54_loss: 1.3761 - val_reward_loss: 2.5856 - val_03_categorical_accuracy: 0.6056 - val_04_categorical_accuracy: 0.9512 - val_13_categorical_accuracy: 0.5631 - val_14_categorical_accuracy: 0.5865 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8744 - val_44_categorical_accuracy: 0.4525 - val_53_categorical_accuracy: 0.8789 - val_54_categorical_accuracy: 0.8752 - val_reward_categorical_accuracy: 0.4576\n",
      "Epoch 135/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.1848 - 03_loss: 0.2988 - 04_loss: 0.0574 - 13_loss: 0.3550 - 14_loss: 0.3120 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1048 - 44_loss: 0.4657 - 53_loss: 0.1049 - 54_loss: 0.0672 - reward_loss: 0.4191 - 03_categorical_accuracy: 0.8426 - 04_categorical_accuracy: 0.9783 - 13_categorical_accuracy: 0.8220 - 14_categorical_accuracy: 0.8343 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9527 - 44_categorical_accuracy: 0.7736 - 53_categorical_accuracy: 0.9525 - 54_categorical_accuracy: 0.9639 - reward_categorical_accuracy: 0.7901 - val_loss: 12.2060 - val_03_loss: 1.1954 - val_04_loss: 0.3560 - val_13_loss: 1.5677 - val_14_loss: 1.3948 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5569 - val_44_loss: 2.6573 - val_53_loss: 0.5614 - val_54_loss: 1.3418 - val_reward_loss: 2.5749 - val_03_categorical_accuracy: 0.6039 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5630 - val_14_categorical_accuracy: 0.5948 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8852 - val_44_categorical_accuracy: 0.4535 - val_53_categorical_accuracy: 0.8726 - val_54_categorical_accuracy: 0.8735 - val_reward_categorical_accuracy: 0.4569\n",
      "Epoch 136/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.1825 - 03_loss: 0.2988 - 04_loss: 0.0575 - 13_loss: 0.3540 - 14_loss: 0.3113 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1049 - 44_loss: 0.4655 - 53_loss: 0.1049 - 54_loss: 0.0670 - reward_loss: 0.4186 - 03_categorical_accuracy: 0.8421 - 04_categorical_accuracy: 0.9781 - 13_categorical_accuracy: 0.8228 - 14_categorical_accuracy: 0.8354 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9529 - 44_categorical_accuracy: 0.7738 - 53_categorical_accuracy: 0.9524 - 54_categorical_accuracy: 0.9639 - reward_categorical_accuracy: 0.7901 - val_loss: 12.2528 - val_03_loss: 1.2060 - val_04_loss: 0.3529 - val_13_loss: 1.5656 - val_14_loss: 1.4079 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5596 - val_44_loss: 2.6778 - val_53_loss: 0.5628 - val_54_loss: 1.3662 - val_reward_loss: 2.5539 - val_03_categorical_accuracy: 0.6034 - val_04_categorical_accuracy: 0.9511 - val_13_categorical_accuracy: 0.5606 - val_14_categorical_accuracy: 0.5905 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8782 - val_44_categorical_accuracy: 0.4533 - val_53_categorical_accuracy: 0.8731 - val_54_categorical_accuracy: 0.8729 - val_reward_categorical_accuracy: 0.4640\n",
      "Epoch 137/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.1796 - 03_loss: 0.2980 - 04_loss: 0.0572 - 13_loss: 0.3548 - 14_loss: 0.3115 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1043 - 44_loss: 0.4655 - 53_loss: 0.1045 - 54_loss: 0.0669 - reward_loss: 0.4168 - 03_categorical_accuracy: 0.8430 - 04_categorical_accuracy: 0.9783 - 13_categorical_accuracy: 0.8225 - 14_categorical_accuracy: 0.8351 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9527 - 44_categorical_accuracy: 0.7735 - 53_categorical_accuracy: 0.9524 - 54_categorical_accuracy: 0.9639 - reward_categorical_accuracy: 0.7909 - val_loss: 12.3109 - val_03_loss: 1.2028 - val_04_loss: 0.3597 - val_13_loss: 1.5587 - val_14_loss: 1.3978 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5549 - val_44_loss: 2.6482 - val_53_loss: 0.5699 - val_54_loss: 1.4107 - val_reward_loss: 2.6083 - val_03_categorical_accuracy: 0.6076 - val_04_categorical_accuracy: 0.9521 - val_13_categorical_accuracy: 0.5628 - val_14_categorical_accuracy: 0.5914 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8797 - val_44_categorical_accuracy: 0.4510 - val_53_categorical_accuracy: 0.8769 - val_54_categorical_accuracy: 0.8748 - val_reward_categorical_accuracy: 0.4621\n",
      "Epoch 138/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.1773 - 03_loss: 0.2978 - 04_loss: 0.0573 - 13_loss: 0.3540 - 14_loss: 0.3107 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1047 - 44_loss: 0.4648 - 53_loss: 0.1043 - 54_loss: 0.0668 - reward_loss: 0.4169 - 03_categorical_accuracy: 0.8432 - 04_categorical_accuracy: 0.9781 - 13_categorical_accuracy: 0.8224 - 14_categorical_accuracy: 0.8356 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9530 - 44_categorical_accuracy: 0.7731 - 53_categorical_accuracy: 0.9529 - 54_categorical_accuracy: 0.9643 - reward_categorical_accuracy: 0.7910 - val_loss: 12.4304 - val_03_loss: 1.2124 - val_04_loss: 0.3617 - val_13_loss: 1.5897 - val_14_loss: 1.4100 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5628 - val_44_loss: 2.6540 - val_53_loss: 0.5759 - val_54_loss: 1.4443 - val_reward_loss: 2.6195 - val_03_categorical_accuracy: 0.6075 - val_04_categorical_accuracy: 0.9521 - val_13_categorical_accuracy: 0.5619 - val_14_categorical_accuracy: 0.5933 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8787 - val_44_categorical_accuracy: 0.4495 - val_53_categorical_accuracy: 0.8725 - val_54_categorical_accuracy: 0.8734 - val_reward_categorical_accuracy: 0.4577\n",
      "Epoch 139/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.1733 - 03_loss: 0.2975 - 04_loss: 0.0573 - 13_loss: 0.3526 - 14_loss: 0.3103 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1042 - 44_loss: 0.4638 - 53_loss: 0.1042 - 54_loss: 0.0668 - reward_loss: 0.4166 - 03_categorical_accuracy: 0.8430 - 04_categorical_accuracy: 0.9781 - 13_categorical_accuracy: 0.8230 - 14_categorical_accuracy: 0.8356 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9531 - 44_categorical_accuracy: 0.7734 - 53_categorical_accuracy: 0.9529 - 54_categorical_accuracy: 0.9643 - reward_categorical_accuracy: 0.7907 - val_loss: 12.3723 - val_03_loss: 1.2159 - val_04_loss: 0.3644 - val_13_loss: 1.5877 - val_14_loss: 1.4095 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5616 - val_44_loss: 2.6958 - val_53_loss: 0.5660 - val_54_loss: 1.4153 - val_reward_loss: 2.5561 - val_03_categorical_accuracy: 0.6031 - val_04_categorical_accuracy: 0.9529 - val_13_categorical_accuracy: 0.5591 - val_14_categorical_accuracy: 0.5905 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8762 - val_44_categorical_accuracy: 0.4509 - val_53_categorical_accuracy: 0.8709 - val_54_categorical_accuracy: 0.8744 - val_reward_categorical_accuracy: 0.4608\n",
      "Epoch 140/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.1707 - 03_loss: 0.2974 - 04_loss: 0.0572 - 13_loss: 0.3522 - 14_loss: 0.3097 - 23_loss: 1.2643e-10 - 24_loss: 1.8999e-10 - 33_loss: 7.2917e-11 - 34_loss: 2.0403e-10 - 43_loss: 0.1043 - 44_loss: 0.4635 - 53_loss: 0.1041 - 54_loss: 0.0667 - reward_loss: 0.4156 - 03_categorical_accuracy: 0.8427 - 04_categorical_accuracy: 0.9783 - 13_categorical_accuracy: 0.8234 - 14_categorical_accuracy: 0.8355 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9527 - 44_categorical_accuracy: 0.7733 - 53_categorical_accuracy: 0.9524 - 54_categorical_accuracy: 0.9641 - reward_categorical_accuracy: 0.7910 - val_loss: 12.4165 - val_03_loss: 1.2097 - val_04_loss: 0.3665 - val_13_loss: 1.5779 - val_14_loss: 1.4349 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5597 - val_44_loss: 2.6831 - val_53_loss: 0.5696 - val_54_loss: 1.4096 - val_reward_loss: 2.6055 - val_03_categorical_accuracy: 0.6109 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5570 - val_14_categorical_accuracy: 0.5827 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8790 - val_44_categorical_accuracy: 0.4519 - val_53_categorical_accuracy: 0.8737 - val_54_categorical_accuracy: 0.8741 - val_reward_categorical_accuracy: 0.4588\n",
      "Epoch 141/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 19s 27ms/step - loss: 2.1693 - 03_loss: 0.2972 - 04_loss: 0.0573 - 13_loss: 0.3522 - 14_loss: 0.3100 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1037 - 44_loss: 0.4636 - 53_loss: 0.1036 - 54_loss: 0.0668 - reward_loss: 0.4150 - 03_categorical_accuracy: 0.8429 - 04_categorical_accuracy: 0.9780 - 13_categorical_accuracy: 0.8227 - 14_categorical_accuracy: 0.8353 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9526 - 44_categorical_accuracy: 0.7737 - 53_categorical_accuracy: 0.9532 - 54_categorical_accuracy: 0.9642 - reward_categorical_accuracy: 0.7914 - val_loss: 12.4115 - val_03_loss: 1.2017 - val_04_loss: 0.3594 - val_13_loss: 1.5890 - val_14_loss: 1.4238 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5603 - val_44_loss: 2.6816 - val_53_loss: 0.5737 - val_54_loss: 1.4356 - val_reward_loss: 2.5864 - val_03_categorical_accuracy: 0.6044 - val_04_categorical_accuracy: 0.9520 - val_13_categorical_accuracy: 0.5588 - val_14_categorical_accuracy: 0.5934 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8793 - val_44_categorical_accuracy: 0.4534 - val_53_categorical_accuracy: 0.8794 - val_54_categorical_accuracy: 0.8741 - val_reward_categorical_accuracy: 0.4609\n",
      "Epoch 142/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.1681 - 03_loss: 0.2971 - 04_loss: 0.0572 - 13_loss: 0.3515 - 14_loss: 0.3093 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1040 - 44_loss: 0.4629 - 53_loss: 0.1044 - 54_loss: 0.0667 - reward_loss: 0.4149 - 03_categorical_accuracy: 0.8431 - 04_categorical_accuracy: 0.9781 - 13_categorical_accuracy: 0.8231 - 14_categorical_accuracy: 0.8362 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9531 - 44_categorical_accuracy: 0.7737 - 53_categorical_accuracy: 0.9523 - 54_categorical_accuracy: 0.9642 - reward_categorical_accuracy: 0.7915 - val_loss: 12.5047 - val_03_loss: 1.1979 - val_04_loss: 0.3593 - val_13_loss: 1.5875 - val_14_loss: 1.4154 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5583 - val_44_loss: 2.6883 - val_53_loss: 0.5745 - val_54_loss: 1.4768 - val_reward_loss: 2.6468 - val_03_categorical_accuracy: 0.6025 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5647 - val_14_categorical_accuracy: 0.5924 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8803 - val_44_categorical_accuracy: 0.4458 - val_53_categorical_accuracy: 0.8760 - val_54_categorical_accuracy: 0.8747 - val_reward_categorical_accuracy: 0.4573\n",
      "Epoch 143/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.1616 - 03_loss: 0.2959 - 04_loss: 0.0571 - 13_loss: 0.3513 - 14_loss: 0.3085 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1036 - 44_loss: 0.4621 - 53_loss: 0.1038 - 54_loss: 0.0665 - reward_loss: 0.4131 - 03_categorical_accuracy: 0.8433 - 04_categorical_accuracy: 0.9783 - 13_categorical_accuracy: 0.8235 - 14_categorical_accuracy: 0.8363 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9531 - 44_categorical_accuracy: 0.7746 - 53_categorical_accuracy: 0.9529 - 54_categorical_accuracy: 0.9642 - reward_categorical_accuracy: 0.7922 - val_loss: 12.5319 - val_03_loss: 1.2039 - val_04_loss: 0.3593 - val_13_loss: 1.5899 - val_14_loss: 1.4325 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5575 - val_44_loss: 2.7019 - val_53_loss: 0.5771 - val_54_loss: 1.4797 - val_reward_loss: 2.6301 - val_03_categorical_accuracy: 0.6048 - val_04_categorical_accuracy: 0.9514 - val_13_categorical_accuracy: 0.5553 - val_14_categorical_accuracy: 0.5870 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8799 - val_44_categorical_accuracy: 0.4512 - val_53_categorical_accuracy: 0.8790 - val_54_categorical_accuracy: 0.8740 - val_reward_categorical_accuracy: 0.4678\n",
      "Epoch 144/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.1635 - 03_loss: 0.2965 - 04_loss: 0.0571 - 13_loss: 0.3504 - 14_loss: 0.3088 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1038 - 44_loss: 0.4620 - 53_loss: 0.1037 - 54_loss: 0.0668 - reward_loss: 0.4144 - 03_categorical_accuracy: 0.8433 - 04_categorical_accuracy: 0.9782 - 13_categorical_accuracy: 0.8235 - 14_categorical_accuracy: 0.8357 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9529 - 44_categorical_accuracy: 0.7740 - 53_categorical_accuracy: 0.9525 - 54_categorical_accuracy: 0.9641 - reward_categorical_accuracy: 0.7910 - val_loss: 12.4512 - val_03_loss: 1.2071 - val_04_loss: 0.3658 - val_13_loss: 1.5664 - val_14_loss: 1.4019 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5536 - val_44_loss: 2.7045 - val_53_loss: 0.5602 - val_54_loss: 1.4658 - val_reward_loss: 2.6260 - val_03_categorical_accuracy: 0.6113 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5526 - val_14_categorical_accuracy: 0.5822 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8766 - val_44_categorical_accuracy: 0.4479 - val_53_categorical_accuracy: 0.8734 - val_54_categorical_accuracy: 0.8729 - val_reward_categorical_accuracy: 0.4649\n",
      "Epoch 145/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.1598 - 03_loss: 0.2955 - 04_loss: 0.0570 - 13_loss: 0.3504 - 14_loss: 0.3075 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1036 - 44_loss: 0.4618 - 53_loss: 0.1038 - 54_loss: 0.0665 - reward_loss: 0.4137 - 03_categorical_accuracy: 0.8428 - 04_categorical_accuracy: 0.9782 - 13_categorical_accuracy: 0.8229 - 14_categorical_accuracy: 0.8361 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9527 - 44_categorical_accuracy: 0.7743 - 53_categorical_accuracy: 0.9529 - 54_categorical_accuracy: 0.9637 - reward_categorical_accuracy: 0.7909 - val_loss: 12.4717 - val_03_loss: 1.2017 - val_04_loss: 0.3700 - val_13_loss: 1.5740 - val_14_loss: 1.4269 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5588 - val_44_loss: 2.6713 - val_53_loss: 0.5599 - val_54_loss: 1.4977 - val_reward_loss: 2.6113 - val_03_categorical_accuracy: 0.6059 - val_04_categorical_accuracy: 0.9521 - val_13_categorical_accuracy: 0.5613 - val_14_categorical_accuracy: 0.5894 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8775 - val_44_categorical_accuracy: 0.4509 - val_53_categorical_accuracy: 0.8765 - val_54_categorical_accuracy: 0.8729 - val_reward_categorical_accuracy: 0.4570\n",
      "Epoch 146/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.1554 - 03_loss: 0.2953 - 04_loss: 0.0570 - 13_loss: 0.3492 - 14_loss: 0.3081 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1036 - 44_loss: 0.4611 - 53_loss: 0.1034 - 54_loss: 0.0662 - reward_loss: 0.4115 - 03_categorical_accuracy: 0.8432 - 04_categorical_accuracy: 0.9782 - 13_categorical_accuracy: 0.8246 - 14_categorical_accuracy: 0.8354 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9528 - 44_categorical_accuracy: 0.7738 - 53_categorical_accuracy: 0.9526 - 54_categorical_accuracy: 0.9643 - reward_categorical_accuracy: 0.7907 - val_loss: 12.4662 - val_03_loss: 1.2094 - val_04_loss: 0.3593 - val_13_loss: 1.5821 - val_14_loss: 1.4122 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5537 - val_44_loss: 2.6682 - val_53_loss: 0.5694 - val_54_loss: 1.4872 - val_reward_loss: 2.6248 - val_03_categorical_accuracy: 0.6039 - val_04_categorical_accuracy: 0.9514 - val_13_categorical_accuracy: 0.5599 - val_14_categorical_accuracy: 0.5898 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8754 - val_44_categorical_accuracy: 0.4548 - val_53_categorical_accuracy: 0.8793 - val_54_categorical_accuracy: 0.8743 - val_reward_categorical_accuracy: 0.4681\n",
      "Epoch 147/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.1534 - 03_loss: 0.2948 - 04_loss: 0.0570 - 13_loss: 0.3488 - 14_loss: 0.3070 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1033 - 44_loss: 0.4607 - 53_loss: 0.1032 - 54_loss: 0.0664 - reward_loss: 0.4123 - 03_categorical_accuracy: 0.8435 - 04_categorical_accuracy: 0.9783 - 13_categorical_accuracy: 0.8236 - 14_categorical_accuracy: 0.8362 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9529 - 44_categorical_accuracy: 0.7741 - 53_categorical_accuracy: 0.9531 - 54_categorical_accuracy: 0.9642 - reward_categorical_accuracy: 0.7908 - val_loss: 12.4740 - val_03_loss: 1.2038 - val_04_loss: 0.3670 - val_13_loss: 1.5785 - val_14_loss: 1.4218 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5568 - val_44_loss: 2.6796 - val_53_loss: 0.5696 - val_54_loss: 1.4712 - val_reward_loss: 2.6257 - val_03_categorical_accuracy: 0.6039 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5616 - val_14_categorical_accuracy: 0.5921 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8764 - val_44_categorical_accuracy: 0.4465 - val_53_categorical_accuracy: 0.8758 - val_54_categorical_accuracy: 0.8738 - val_reward_categorical_accuracy: 0.4606\n",
      "Epoch 148/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.1520 - 03_loss: 0.2948 - 04_loss: 0.0570 - 13_loss: 0.3484 - 14_loss: 0.3069 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1033 - 44_loss: 0.4598 - 53_loss: 0.1033 - 54_loss: 0.0662 - reward_loss: 0.4123 - 03_categorical_accuracy: 0.8445 - 04_categorical_accuracy: 0.9782 - 13_categorical_accuracy: 0.8239 - 14_categorical_accuracy: 0.8366 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9527 - 44_categorical_accuracy: 0.7738 - 53_categorical_accuracy: 0.9529 - 54_categorical_accuracy: 0.9642 - reward_categorical_accuracy: 0.7905 - val_loss: 12.5542 - val_03_loss: 1.2086 - val_04_loss: 0.3643 - val_13_loss: 1.5748 - val_14_loss: 1.4155 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5542 - val_44_loss: 2.6808 - val_53_loss: 0.5735 - val_54_loss: 1.5256 - val_reward_loss: 2.6569 - val_03_categorical_accuracy: 0.5984 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5568 - val_14_categorical_accuracy: 0.5918 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8774 - val_44_categorical_accuracy: 0.4508 - val_53_categorical_accuracy: 0.8813 - val_54_categorical_accuracy: 0.8744 - val_reward_categorical_accuracy: 0.4650\n",
      "Epoch 149/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.1483 - 03_loss: 0.2945 - 04_loss: 0.0570 - 13_loss: 0.3483 - 14_loss: 0.3063 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1033 - 44_loss: 0.4595 - 53_loss: 0.1030 - 54_loss: 0.0664 - reward_loss: 0.4100 - 03_categorical_accuracy: 0.8432 - 04_categorical_accuracy: 0.9783 - 13_categorical_accuracy: 0.8234 - 14_categorical_accuracy: 0.8362 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9528 - 44_categorical_accuracy: 0.7745 - 53_categorical_accuracy: 0.9529 - 54_categorical_accuracy: 0.9645 - reward_categorical_accuracy: 0.7924 - val_loss: 12.6638 - val_03_loss: 1.2198 - val_04_loss: 0.3794 - val_13_loss: 1.6010 - val_14_loss: 1.4312 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5625 - val_44_loss: 2.7309 - val_53_loss: 0.5730 - val_54_loss: 1.5041 - val_reward_loss: 2.6620 - val_03_categorical_accuracy: 0.6071 - val_04_categorical_accuracy: 0.9523 - val_13_categorical_accuracy: 0.5558 - val_14_categorical_accuracy: 0.5889 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8724 - val_44_categorical_accuracy: 0.4524 - val_53_categorical_accuracy: 0.8754 - val_54_categorical_accuracy: 0.8734 - val_reward_categorical_accuracy: 0.4610\n",
      "Epoch 150/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.1476 - 03_loss: 0.2940 - 04_loss: 0.0569 - 13_loss: 0.3473 - 14_loss: 0.3062 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1025 - 44_loss: 0.4607 - 53_loss: 0.1032 - 54_loss: 0.0660 - reward_loss: 0.4107 - 03_categorical_accuracy: 0.8430 - 04_categorical_accuracy: 0.9785 - 13_categorical_accuracy: 0.8242 - 14_categorical_accuracy: 0.8359 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9532 - 44_categorical_accuracy: 0.7738 - 53_categorical_accuracy: 0.9527 - 54_categorical_accuracy: 0.9644 - reward_categorical_accuracy: 0.7917 - val_loss: 12.5927 - val_03_loss: 1.2225 - val_04_loss: 0.3779 - val_13_loss: 1.5938 - val_14_loss: 1.4300 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5632 - val_44_loss: 2.6821 - val_53_loss: 0.5727 - val_54_loss: 1.5024 - val_reward_loss: 2.6481 - val_03_categorical_accuracy: 0.6091 - val_04_categorical_accuracy: 0.9520 - val_13_categorical_accuracy: 0.5539 - val_14_categorical_accuracy: 0.5896 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8814 - val_44_categorical_accuracy: 0.4468 - val_53_categorical_accuracy: 0.8755 - val_54_categorical_accuracy: 0.8740 - val_reward_categorical_accuracy: 0.4581\n",
      "Epoch 151/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 19s 27ms/step - loss: 2.1424 - 03_loss: 0.2933 - 04_loss: 0.0569 - 13_loss: 0.3468 - 14_loss: 0.3056 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1027 - 44_loss: 0.4585 - 53_loss: 0.1027 - 54_loss: 0.0660 - reward_loss: 0.4098 - 03_categorical_accuracy: 0.8435 - 04_categorical_accuracy: 0.9783 - 13_categorical_accuracy: 0.8240 - 14_categorical_accuracy: 0.8366 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9534 - 44_categorical_accuracy: 0.7743 - 53_categorical_accuracy: 0.9530 - 54_categorical_accuracy: 0.9643 - reward_categorical_accuracy: 0.7919 - val_loss: 12.7025 - val_03_loss: 1.2369 - val_04_loss: 0.3705 - val_13_loss: 1.6205 - val_14_loss: 1.4565 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5640 - val_44_loss: 2.7059 - val_53_loss: 0.5750 - val_54_loss: 1.5018 - val_reward_loss: 2.6715 - val_03_categorical_accuracy: 0.6034 - val_04_categorical_accuracy: 0.9512 - val_13_categorical_accuracy: 0.5627 - val_14_categorical_accuracy: 0.5900 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8757 - val_44_categorical_accuracy: 0.4509 - val_53_categorical_accuracy: 0.8728 - val_54_categorical_accuracy: 0.8727 - val_reward_categorical_accuracy: 0.4599\n",
      "Epoch 152/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.1427 - 03_loss: 0.2939 - 04_loss: 0.0570 - 13_loss: 0.3473 - 14_loss: 0.3055 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1030 - 44_loss: 0.4585 - 53_loss: 0.1027 - 54_loss: 0.0659 - reward_loss: 0.4090 - 03_categorical_accuracy: 0.8432 - 04_categorical_accuracy: 0.9782 - 13_categorical_accuracy: 0.8238 - 14_categorical_accuracy: 0.8365 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9529 - 44_categorical_accuracy: 0.7752 - 53_categorical_accuracy: 0.9529 - 54_categorical_accuracy: 0.9646 - reward_categorical_accuracy: 0.7921 - val_loss: 12.6529 - val_03_loss: 1.2223 - val_04_loss: 0.3739 - val_13_loss: 1.6031 - val_14_loss: 1.4397 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5581 - val_44_loss: 2.7242 - val_53_loss: 0.5658 - val_54_loss: 1.4956 - val_reward_loss: 2.6702 - val_03_categorical_accuracy: 0.6037 - val_04_categorical_accuracy: 0.9520 - val_13_categorical_accuracy: 0.5603 - val_14_categorical_accuracy: 0.5895 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8766 - val_44_categorical_accuracy: 0.4484 - val_53_categorical_accuracy: 0.8766 - val_54_categorical_accuracy: 0.8735 - val_reward_categorical_accuracy: 0.4666\n",
      "Epoch 153/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.1398 - 03_loss: 0.2931 - 04_loss: 0.0569 - 13_loss: 0.3461 - 14_loss: 0.3049 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1023 - 44_loss: 0.4583 - 53_loss: 0.1022 - 54_loss: 0.0657 - reward_loss: 0.4103 - 03_categorical_accuracy: 0.8440 - 04_categorical_accuracy: 0.9783 - 13_categorical_accuracy: 0.8244 - 14_categorical_accuracy: 0.8370 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9531 - 44_categorical_accuracy: 0.7745 - 53_categorical_accuracy: 0.9534 - 54_categorical_accuracy: 0.9643 - reward_categorical_accuracy: 0.7915 - val_loss: 12.7738 - val_03_loss: 1.2166 - val_04_loss: 0.3792 - val_13_loss: 1.6072 - val_14_loss: 1.4495 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5659 - val_44_loss: 2.7120 - val_53_loss: 0.5807 - val_54_loss: 1.5853 - val_reward_loss: 2.6774 - val_03_categorical_accuracy: 0.6115 - val_04_categorical_accuracy: 0.9524 - val_13_categorical_accuracy: 0.5586 - val_14_categorical_accuracy: 0.5879 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8770 - val_44_categorical_accuracy: 0.4529 - val_53_categorical_accuracy: 0.8786 - val_54_categorical_accuracy: 0.8747 - val_reward_categorical_accuracy: 0.4589\n",
      "Epoch 154/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.1364 - 03_loss: 0.2924 - 04_loss: 0.0568 - 13_loss: 0.3452 - 14_loss: 0.3044 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1026 - 44_loss: 0.4588 - 53_loss: 0.1024 - 54_loss: 0.0657 - reward_loss: 0.4081 - 03_categorical_accuracy: 0.8444 - 04_categorical_accuracy: 0.9783 - 13_categorical_accuracy: 0.8247 - 14_categorical_accuracy: 0.8374 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9531 - 44_categorical_accuracy: 0.7743 - 53_categorical_accuracy: 0.9531 - 54_categorical_accuracy: 0.9643 - reward_categorical_accuracy: 0.7920 - val_loss: 12.5739 - val_03_loss: 1.2229 - val_04_loss: 0.3737 - val_13_loss: 1.5870 - val_14_loss: 1.4270 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5555 - val_44_loss: 2.7150 - val_53_loss: 0.5710 - val_54_loss: 1.5062 - val_reward_loss: 2.6156 - val_03_categorical_accuracy: 0.6036 - val_04_categorical_accuracy: 0.9523 - val_13_categorical_accuracy: 0.5551 - val_14_categorical_accuracy: 0.5808 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8778 - val_44_categorical_accuracy: 0.4503 - val_53_categorical_accuracy: 0.8805 - val_54_categorical_accuracy: 0.8724 - val_reward_categorical_accuracy: 0.4640\n",
      "Epoch 155/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.1370 - 03_loss: 0.2928 - 04_loss: 0.0569 - 13_loss: 0.3464 - 14_loss: 0.3045 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1021 - 44_loss: 0.4573 - 53_loss: 0.1020 - 54_loss: 0.0658 - reward_loss: 0.4091 - 03_categorical_accuracy: 0.8435 - 04_categorical_accuracy: 0.9783 - 13_categorical_accuracy: 0.8241 - 14_categorical_accuracy: 0.8371 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9531 - 44_categorical_accuracy: 0.7746 - 53_categorical_accuracy: 0.9531 - 54_categorical_accuracy: 0.9641 - reward_categorical_accuracy: 0.7915 - val_loss: 12.7177 - val_03_loss: 1.2206 - val_04_loss: 0.3793 - val_13_loss: 1.6048 - val_14_loss: 1.4432 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5641 - val_44_loss: 2.7477 - val_53_loss: 0.5770 - val_54_loss: 1.5378 - val_reward_loss: 2.6432 - val_03_categorical_accuracy: 0.6082 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5639 - val_14_categorical_accuracy: 0.5919 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8814 - val_44_categorical_accuracy: 0.4493 - val_53_categorical_accuracy: 0.8799 - val_54_categorical_accuracy: 0.8742 - val_reward_categorical_accuracy: 0.4587\n",
      "Epoch 156/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.1322 - 03_loss: 0.2918 - 04_loss: 0.0568 - 13_loss: 0.3446 - 14_loss: 0.3042 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1026 - 44_loss: 0.4565 - 53_loss: 0.1018 - 54_loss: 0.0661 - reward_loss: 0.4079 - 03_categorical_accuracy: 0.8443 - 04_categorical_accuracy: 0.9785 - 13_categorical_accuracy: 0.8246 - 14_categorical_accuracy: 0.8374 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9531 - 44_categorical_accuracy: 0.7757 - 53_categorical_accuracy: 0.9534 - 54_categorical_accuracy: 0.9647 - reward_categorical_accuracy: 0.7923 - val_loss: 12.8494 - val_03_loss: 1.2448 - val_04_loss: 0.3863 - val_13_loss: 1.6250 - val_14_loss: 1.4545 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5677 - val_44_loss: 2.7468 - val_53_loss: 0.5810 - val_54_loss: 1.5545 - val_reward_loss: 2.6888 - val_03_categorical_accuracy: 0.6019 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5582 - val_14_categorical_accuracy: 0.5844 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8797 - val_44_categorical_accuracy: 0.4530 - val_53_categorical_accuracy: 0.8709 - val_54_categorical_accuracy: 0.8746 - val_reward_categorical_accuracy: 0.4643\n",
      "Epoch 157/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.1278 - 03_loss: 0.2917 - 04_loss: 0.0568 - 13_loss: 0.3437 - 14_loss: 0.3026 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1026 - 44_loss: 0.4562 - 53_loss: 0.1022 - 54_loss: 0.0655 - reward_loss: 0.4064 - 03_categorical_accuracy: 0.8441 - 04_categorical_accuracy: 0.9785 - 13_categorical_accuracy: 0.8251 - 14_categorical_accuracy: 0.8373 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9528 - 44_categorical_accuracy: 0.7752 - 53_categorical_accuracy: 0.9534 - 54_categorical_accuracy: 0.9645 - reward_categorical_accuracy: 0.7931 - val_loss: 12.9016 - val_03_loss: 1.2324 - val_04_loss: 0.3814 - val_13_loss: 1.6288 - val_14_loss: 1.4657 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5669 - val_44_loss: 2.7960 - val_53_loss: 0.5752 - val_54_loss: 1.5553 - val_reward_loss: 2.6999 - val_03_categorical_accuracy: 0.6106 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5540 - val_14_categorical_accuracy: 0.5885 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8717 - val_44_categorical_accuracy: 0.4535 - val_53_categorical_accuracy: 0.8774 - val_54_categorical_accuracy: 0.8743 - val_reward_categorical_accuracy: 0.4621\n",
      "Epoch 158/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.1298 - 03_loss: 0.2917 - 04_loss: 0.0569 - 13_loss: 0.3443 - 14_loss: 0.3036 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1020 - 44_loss: 0.4569 - 53_loss: 0.1018 - 54_loss: 0.0659 - reward_loss: 0.4068 - 03_categorical_accuracy: 0.8441 - 04_categorical_accuracy: 0.9783 - 13_categorical_accuracy: 0.8246 - 14_categorical_accuracy: 0.8380 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9533 - 44_categorical_accuracy: 0.7748 - 53_categorical_accuracy: 0.9533 - 54_categorical_accuracy: 0.9645 - reward_categorical_accuracy: 0.7923 - val_loss: 12.7236 - val_03_loss: 1.2257 - val_04_loss: 0.3803 - val_13_loss: 1.5970 - val_14_loss: 1.4472 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5655 - val_44_loss: 2.7144 - val_53_loss: 0.5777 - val_54_loss: 1.5457 - val_reward_loss: 2.6699 - val_03_categorical_accuracy: 0.6058 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5569 - val_14_categorical_accuracy: 0.5833 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8766 - val_44_categorical_accuracy: 0.4484 - val_53_categorical_accuracy: 0.8755 - val_54_categorical_accuracy: 0.8733 - val_reward_categorical_accuracy: 0.4617\n",
      "Epoch 159/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.1242 - 03_loss: 0.2913 - 04_loss: 0.0568 - 13_loss: 0.3432 - 14_loss: 0.3023 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1017 - 44_loss: 0.4560 - 53_loss: 0.1016 - 54_loss: 0.0653 - reward_loss: 0.4061 - 03_categorical_accuracy: 0.8438 - 04_categorical_accuracy: 0.9785 - 13_categorical_accuracy: 0.8256 - 14_categorical_accuracy: 0.8380 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9531 - 44_categorical_accuracy: 0.7744 - 53_categorical_accuracy: 0.9531 - 54_categorical_accuracy: 0.9646 - reward_categorical_accuracy: 0.7926 - val_loss: 12.7142 - val_03_loss: 1.2268 - val_04_loss: 0.3746 - val_13_loss: 1.6066 - val_14_loss: 1.4517 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5608 - val_44_loss: 2.7102 - val_53_loss: 0.5792 - val_54_loss: 1.5590 - val_reward_loss: 2.6453 - val_03_categorical_accuracy: 0.6109 - val_04_categorical_accuracy: 0.9517 - val_13_categorical_accuracy: 0.5558 - val_14_categorical_accuracy: 0.5895 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8811 - val_44_categorical_accuracy: 0.4462 - val_53_categorical_accuracy: 0.8821 - val_54_categorical_accuracy: 0.8742 - val_reward_categorical_accuracy: 0.4591\n",
      "Epoch 160/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.1232 - 03_loss: 0.2909 - 04_loss: 0.0565 - 13_loss: 0.3431 - 14_loss: 0.3024 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1019 - 44_loss: 0.4551 - 53_loss: 0.1021 - 54_loss: 0.0656 - reward_loss: 0.4055 - 03_categorical_accuracy: 0.8440 - 04_categorical_accuracy: 0.9785 - 13_categorical_accuracy: 0.8252 - 14_categorical_accuracy: 0.8373 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9537 - 44_categorical_accuracy: 0.7755 - 53_categorical_accuracy: 0.9530 - 54_categorical_accuracy: 0.9643 - reward_categorical_accuracy: 0.7929 - val_loss: 12.8305 - val_03_loss: 1.2306 - val_04_loss: 0.3798 - val_13_loss: 1.6170 - val_14_loss: 1.4559 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5729 - val_44_loss: 2.7347 - val_53_loss: 0.5769 - val_54_loss: 1.5855 - val_reward_loss: 2.6771 - val_03_categorical_accuracy: 0.6138 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5546 - val_14_categorical_accuracy: 0.5797 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8764 - val_44_categorical_accuracy: 0.4515 - val_53_categorical_accuracy: 0.8744 - val_54_categorical_accuracy: 0.8729 - val_reward_categorical_accuracy: 0.4672\n",
      "Epoch 161/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 19s 28ms/step - loss: 2.1223 - 03_loss: 0.2911 - 04_loss: 0.0567 - 13_loss: 0.3425 - 14_loss: 0.3023 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1017 - 44_loss: 0.4554 - 53_loss: 0.1020 - 54_loss: 0.0655 - reward_loss: 0.4051 - 03_categorical_accuracy: 0.8441 - 04_categorical_accuracy: 0.9784 - 13_categorical_accuracy: 0.8258 - 14_categorical_accuracy: 0.8377 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9534 - 44_categorical_accuracy: 0.7752 - 53_categorical_accuracy: 0.9527 - 54_categorical_accuracy: 0.9647 - reward_categorical_accuracy: 0.7923 - val_loss: 12.7302 - val_03_loss: 1.2254 - val_04_loss: 0.3824 - val_13_loss: 1.6034 - val_14_loss: 1.4394 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5667 - val_44_loss: 2.7149 - val_53_loss: 0.5726 - val_54_loss: 1.5715 - val_reward_loss: 2.6541 - val_03_categorical_accuracy: 0.6149 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5571 - val_14_categorical_accuracy: 0.5841 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8828 - val_44_categorical_accuracy: 0.4518 - val_53_categorical_accuracy: 0.8727 - val_54_categorical_accuracy: 0.8736 - val_reward_categorical_accuracy: 0.4587\n",
      "Epoch 162/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.1210 - 03_loss: 0.2909 - 04_loss: 0.0568 - 13_loss: 0.3424 - 14_loss: 0.3019 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1019 - 44_loss: 0.4553 - 53_loss: 0.1017 - 54_loss: 0.0655 - reward_loss: 0.4045 - 03_categorical_accuracy: 0.8443 - 04_categorical_accuracy: 0.9785 - 13_categorical_accuracy: 0.8247 - 14_categorical_accuracy: 0.8374 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9534 - 44_categorical_accuracy: 0.7751 - 53_categorical_accuracy: 0.9534 - 54_categorical_accuracy: 0.9646 - reward_categorical_accuracy: 0.7936 - val_loss: 12.8358 - val_03_loss: 1.2322 - val_04_loss: 0.3855 - val_13_loss: 1.6165 - val_14_loss: 1.4518 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5625 - val_44_loss: 2.7544 - val_53_loss: 0.5706 - val_54_loss: 1.5562 - val_reward_loss: 2.7062 - val_03_categorical_accuracy: 0.6005 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5600 - val_14_categorical_accuracy: 0.5886 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8789 - val_44_categorical_accuracy: 0.4529 - val_53_categorical_accuracy: 0.8750 - val_54_categorical_accuracy: 0.8748 - val_reward_categorical_accuracy: 0.4704\n",
      "Epoch 163/1000\n",
      "697/697 [==============================] - 20s 28ms/step - loss: 2.1181 - 03_loss: 0.2907 - 04_loss: 0.0566 - 13_loss: 0.3422 - 14_loss: 0.3015 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1018 - 44_loss: 0.4544 - 53_loss: 0.1014 - 54_loss: 0.0651 - reward_loss: 0.4044 - 03_categorical_accuracy: 0.8444 - 04_categorical_accuracy: 0.9786 - 13_categorical_accuracy: 0.8253 - 14_categorical_accuracy: 0.8379 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9533 - 44_categorical_accuracy: 0.7762 - 53_categorical_accuracy: 0.9534 - 54_categorical_accuracy: 0.9648 - reward_categorical_accuracy: 0.7930 - val_loss: 12.7358 - val_03_loss: 1.2285 - val_04_loss: 0.3756 - val_13_loss: 1.6212 - val_14_loss: 1.4715 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5653 - val_44_loss: 2.7179 - val_53_loss: 0.5777 - val_54_loss: 1.5271 - val_reward_loss: 2.6511 - val_03_categorical_accuracy: 0.6092 - val_04_categorical_accuracy: 0.9524 - val_13_categorical_accuracy: 0.5595 - val_14_categorical_accuracy: 0.5882 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8747 - val_44_categorical_accuracy: 0.4492 - val_53_categorical_accuracy: 0.8772 - val_54_categorical_accuracy: 0.8740 - val_reward_categorical_accuracy: 0.4616\n",
      "Epoch 164/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.1160 - 03_loss: 0.2902 - 04_loss: 0.0566 - 13_loss: 0.3416 - 14_loss: 0.3012 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1016 - 44_loss: 0.4550 - 53_loss: 0.1011 - 54_loss: 0.0652 - reward_loss: 0.4033 - 03_categorical_accuracy: 0.8445 - 04_categorical_accuracy: 0.9785 - 13_categorical_accuracy: 0.8255 - 14_categorical_accuracy: 0.8378 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9535 - 44_categorical_accuracy: 0.7753 - 53_categorical_accuracy: 0.9534 - 54_categorical_accuracy: 0.9646 - reward_categorical_accuracy: 0.7936 - val_loss: 12.9323 - val_03_loss: 1.2219 - val_04_loss: 0.3843 - val_13_loss: 1.6160 - val_14_loss: 1.4451 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5698 - val_44_loss: 2.7669 - val_53_loss: 0.5826 - val_54_loss: 1.6352 - val_reward_loss: 2.7104 - val_03_categorical_accuracy: 0.6026 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5579 - val_14_categorical_accuracy: 0.5926 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8787 - val_44_categorical_accuracy: 0.4541 - val_53_categorical_accuracy: 0.8747 - val_54_categorical_accuracy: 0.8755 - val_reward_categorical_accuracy: 0.4650\n",
      "Epoch 165/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.1140 - 03_loss: 0.2905 - 04_loss: 0.0568 - 13_loss: 0.3410 - 14_loss: 0.3004 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1014 - 44_loss: 0.4537 - 53_loss: 0.1014 - 54_loss: 0.0654 - reward_loss: 0.4035 - 03_categorical_accuracy: 0.8441 - 04_categorical_accuracy: 0.9785 - 13_categorical_accuracy: 0.8259 - 14_categorical_accuracy: 0.8378 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9532 - 44_categorical_accuracy: 0.7760 - 53_categorical_accuracy: 0.9533 - 54_categorical_accuracy: 0.9643 - reward_categorical_accuracy: 0.7932 - val_loss: 12.8671 - val_03_loss: 1.2206 - val_04_loss: 0.3915 - val_13_loss: 1.6264 - val_14_loss: 1.4609 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5683 - val_44_loss: 2.7265 - val_53_loss: 0.5791 - val_54_loss: 1.6028 - val_reward_loss: 2.6911 - val_03_categorical_accuracy: 0.6068 - val_04_categorical_accuracy: 0.9522 - val_13_categorical_accuracy: 0.5640 - val_14_categorical_accuracy: 0.5889 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8809 - val_44_categorical_accuracy: 0.4480 - val_53_categorical_accuracy: 0.8756 - val_54_categorical_accuracy: 0.8734 - val_reward_categorical_accuracy: 0.4594\n",
      "Epoch 166/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.1121 - 03_loss: 0.2896 - 04_loss: 0.0566 - 13_loss: 0.3409 - 14_loss: 0.3005 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1011 - 44_loss: 0.4537 - 53_loss: 0.1014 - 54_loss: 0.0653 - reward_loss: 0.4030 - 03_categorical_accuracy: 0.8443 - 04_categorical_accuracy: 0.9784 - 13_categorical_accuracy: 0.8261 - 14_categorical_accuracy: 0.8382 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9537 - 44_categorical_accuracy: 0.7749 - 53_categorical_accuracy: 0.9528 - 54_categorical_accuracy: 0.9649 - reward_categorical_accuracy: 0.7933 - val_loss: 12.8030 - val_03_loss: 1.2245 - val_04_loss: 0.3805 - val_13_loss: 1.6041 - val_14_loss: 1.4626 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5659 - val_44_loss: 2.7379 - val_53_loss: 0.5655 - val_54_loss: 1.5614 - val_reward_loss: 2.7007 - val_03_categorical_accuracy: 0.6092 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5574 - val_14_categorical_accuracy: 0.5899 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8816 - val_44_categorical_accuracy: 0.4501 - val_53_categorical_accuracy: 0.8707 - val_54_categorical_accuracy: 0.8732 - val_reward_categorical_accuracy: 0.4567\n",
      "Epoch 167/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.1113 - 03_loss: 0.2892 - 04_loss: 0.0566 - 13_loss: 0.3402 - 14_loss: 0.3008 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1012 - 44_loss: 0.4538 - 53_loss: 0.1014 - 54_loss: 0.0652 - reward_loss: 0.4029 - 03_categorical_accuracy: 0.8446 - 04_categorical_accuracy: 0.9785 - 13_categorical_accuracy: 0.8257 - 14_categorical_accuracy: 0.8372 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9534 - 44_categorical_accuracy: 0.7754 - 53_categorical_accuracy: 0.9531 - 54_categorical_accuracy: 0.9647 - reward_categorical_accuracy: 0.7925 - val_loss: 12.8239 - val_03_loss: 1.2276 - val_04_loss: 0.3791 - val_13_loss: 1.6206 - val_14_loss: 1.4539 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5699 - val_44_loss: 2.7459 - val_53_loss: 0.5816 - val_54_loss: 1.5734 - val_reward_loss: 2.6720 - val_03_categorical_accuracy: 0.6110 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5569 - val_14_categorical_accuracy: 0.5849 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8726 - val_44_categorical_accuracy: 0.4516 - val_53_categorical_accuracy: 0.8785 - val_54_categorical_accuracy: 0.8737 - val_reward_categorical_accuracy: 0.4661\n",
      "Epoch 168/1000\n",
      "697/697 [==============================] - 20s 28ms/step - loss: 2.1070 - 03_loss: 0.2895 - 04_loss: 0.0565 - 13_loss: 0.3404 - 14_loss: 0.2996 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1010 - 44_loss: 0.4524 - 53_loss: 0.1009 - 54_loss: 0.0650 - reward_loss: 0.4017 - 03_categorical_accuracy: 0.8446 - 04_categorical_accuracy: 0.9784 - 13_categorical_accuracy: 0.8251 - 14_categorical_accuracy: 0.8381 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9532 - 44_categorical_accuracy: 0.7760 - 53_categorical_accuracy: 0.9538 - 54_categorical_accuracy: 0.9647 - reward_categorical_accuracy: 0.7940 - val_loss: 12.9954 - val_03_loss: 1.2373 - val_04_loss: 0.3918 - val_13_loss: 1.6313 - val_14_loss: 1.4767 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5724 - val_44_loss: 2.8123 - val_53_loss: 0.5849 - val_54_loss: 1.5859 - val_reward_loss: 2.7028 - val_03_categorical_accuracy: 0.6068 - val_04_categorical_accuracy: 0.9520 - val_13_categorical_accuracy: 0.5534 - val_14_categorical_accuracy: 0.5866 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8819 - val_44_categorical_accuracy: 0.4530 - val_53_categorical_accuracy: 0.8751 - val_54_categorical_accuracy: 0.8735 - val_reward_categorical_accuracy: 0.4650\n",
      "Epoch 169/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 2.1061 - 03_loss: 0.2884 - 04_loss: 0.0564 - 13_loss: 0.3394 - 14_loss: 0.2993 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1007 - 44_loss: 0.4531 - 53_loss: 0.1009 - 54_loss: 0.0651 - reward_loss: 0.4027 - 03_categorical_accuracy: 0.8446 - 04_categorical_accuracy: 0.9785 - 13_categorical_accuracy: 0.8265 - 14_categorical_accuracy: 0.8383 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9532 - 44_categorical_accuracy: 0.7754 - 53_categorical_accuracy: 0.9534 - 54_categorical_accuracy: 0.9647 - reward_categorical_accuracy: 0.7931 - val_loss: 12.9244 - val_03_loss: 1.2471 - val_04_loss: 0.3831 - val_13_loss: 1.6219 - val_14_loss: 1.4606 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5681 - val_44_loss: 2.7544 - val_53_loss: 0.5783 - val_54_loss: 1.6049 - val_reward_loss: 2.7060 - val_03_categorical_accuracy: 0.6069 - val_04_categorical_accuracy: 0.9523 - val_13_categorical_accuracy: 0.5595 - val_14_categorical_accuracy: 0.5906 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8777 - val_44_categorical_accuracy: 0.4552 - val_53_categorical_accuracy: 0.8819 - val_54_categorical_accuracy: 0.8736 - val_reward_categorical_accuracy: 0.4646\n",
      "Epoch 170/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.1044 - 03_loss: 0.2888 - 04_loss: 0.0564 - 13_loss: 0.3388 - 14_loss: 0.2992 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1007 - 44_loss: 0.4527 - 53_loss: 0.1007 - 54_loss: 0.0654 - reward_loss: 0.4016 - 03_categorical_accuracy: 0.8456 - 04_categorical_accuracy: 0.9786 - 13_categorical_accuracy: 0.8253 - 14_categorical_accuracy: 0.8384 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9534 - 44_categorical_accuracy: 0.7749 - 53_categorical_accuracy: 0.9538 - 54_categorical_accuracy: 0.9645 - reward_categorical_accuracy: 0.7938 - val_loss: 12.7927 - val_03_loss: 1.2230 - val_04_loss: 0.3927 - val_13_loss: 1.6250 - val_14_loss: 1.4559 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5681 - val_44_loss: 2.7258 - val_53_loss: 0.5733 - val_54_loss: 1.5631 - val_reward_loss: 2.6658 - val_03_categorical_accuracy: 0.6057 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5543 - val_14_categorical_accuracy: 0.5908 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8770 - val_44_categorical_accuracy: 0.4453 - val_53_categorical_accuracy: 0.8757 - val_54_categorical_accuracy: 0.8737 - val_reward_categorical_accuracy: 0.4649\n",
      "Epoch 171/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 19s 27ms/step - loss: 2.1002 - 03_loss: 0.2879 - 04_loss: 0.0564 - 13_loss: 0.3381 - 14_loss: 0.2990 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1011 - 44_loss: 0.4513 - 53_loss: 0.1009 - 54_loss: 0.0649 - reward_loss: 0.4007 - 03_categorical_accuracy: 0.8452 - 04_categorical_accuracy: 0.9787 - 13_categorical_accuracy: 0.8269 - 14_categorical_accuracy: 0.8377 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9534 - 44_categorical_accuracy: 0.7761 - 53_categorical_accuracy: 0.9533 - 54_categorical_accuracy: 0.9650 - reward_categorical_accuracy: 0.7938 - val_loss: 13.0029 - val_03_loss: 1.2455 - val_04_loss: 0.3978 - val_13_loss: 1.6446 - val_14_loss: 1.4729 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5750 - val_44_loss: 2.7729 - val_53_loss: 0.5790 - val_54_loss: 1.6145 - val_reward_loss: 2.7008 - val_03_categorical_accuracy: 0.6072 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5601 - val_14_categorical_accuracy: 0.5952 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8761 - val_44_categorical_accuracy: 0.4461 - val_53_categorical_accuracy: 0.8754 - val_54_categorical_accuracy: 0.8737 - val_reward_categorical_accuracy: 0.4588\n",
      "Epoch 172/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0981 - 03_loss: 0.2880 - 04_loss: 0.0563 - 13_loss: 0.3381 - 14_loss: 0.2984 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1009 - 44_loss: 0.4506 - 53_loss: 0.1007 - 54_loss: 0.0647 - reward_loss: 0.4003 - 03_categorical_accuracy: 0.8449 - 04_categorical_accuracy: 0.9787 - 13_categorical_accuracy: 0.8257 - 14_categorical_accuracy: 0.8380 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9535 - 44_categorical_accuracy: 0.7769 - 53_categorical_accuracy: 0.9532 - 54_categorical_accuracy: 0.9650 - reward_categorical_accuracy: 0.7938 - val_loss: 12.7951 - val_03_loss: 1.2298 - val_04_loss: 0.3821 - val_13_loss: 1.6058 - val_14_loss: 1.4487 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5685 - val_44_loss: 2.7480 - val_53_loss: 0.5737 - val_54_loss: 1.5788 - val_reward_loss: 2.6597 - val_03_categorical_accuracy: 0.6140 - val_04_categorical_accuracy: 0.9520 - val_13_categorical_accuracy: 0.5527 - val_14_categorical_accuracy: 0.5848 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8803 - val_44_categorical_accuracy: 0.4527 - val_53_categorical_accuracy: 0.8756 - val_54_categorical_accuracy: 0.8742 - val_reward_categorical_accuracy: 0.4586\n",
      "Epoch 173/1000\n",
      "697/697 [==============================] - 20s 28ms/step - loss: 2.0967 - 03_loss: 0.2875 - 04_loss: 0.0563 - 13_loss: 0.3378 - 14_loss: 0.2982 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1009 - 44_loss: 0.4508 - 53_loss: 0.1008 - 54_loss: 0.0647 - reward_loss: 0.3996 - 03_categorical_accuracy: 0.8454 - 04_categorical_accuracy: 0.9787 - 13_categorical_accuracy: 0.8265 - 14_categorical_accuracy: 0.8389 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9534 - 44_categorical_accuracy: 0.7772 - 53_categorical_accuracy: 0.9536 - 54_categorical_accuracy: 0.9647 - reward_categorical_accuracy: 0.7944 - val_loss: 13.0479 - val_03_loss: 1.2359 - val_04_loss: 0.3940 - val_13_loss: 1.6420 - val_14_loss: 1.4823 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5675 - val_44_loss: 2.7819 - val_53_loss: 0.5785 - val_54_loss: 1.6481 - val_reward_loss: 2.7177 - val_03_categorical_accuracy: 0.6054 - val_04_categorical_accuracy: 0.9520 - val_13_categorical_accuracy: 0.5632 - val_14_categorical_accuracy: 0.5958 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8790 - val_44_categorical_accuracy: 0.4509 - val_53_categorical_accuracy: 0.8790 - val_54_categorical_accuracy: 0.8739 - val_reward_categorical_accuracy: 0.4573\n",
      "Epoch 174/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0962 - 03_loss: 0.2880 - 04_loss: 0.0564 - 13_loss: 0.3381 - 14_loss: 0.2975 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1004 - 44_loss: 0.4506 - 53_loss: 0.1005 - 54_loss: 0.0649 - reward_loss: 0.4000 - 03_categorical_accuracy: 0.8453 - 04_categorical_accuracy: 0.9786 - 13_categorical_accuracy: 0.8259 - 14_categorical_accuracy: 0.8392 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9538 - 44_categorical_accuracy: 0.7763 - 53_categorical_accuracy: 0.9530 - 54_categorical_accuracy: 0.9651 - reward_categorical_accuracy: 0.7942 - val_loss: 13.0825 - val_03_loss: 1.2494 - val_04_loss: 0.3803 - val_13_loss: 1.6528 - val_14_loss: 1.4873 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5773 - val_44_loss: 2.8067 - val_53_loss: 0.5787 - val_54_loss: 1.6510 - val_reward_loss: 2.6991 - val_03_categorical_accuracy: 0.6069 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5523 - val_14_categorical_accuracy: 0.5888 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8782 - val_44_categorical_accuracy: 0.4469 - val_53_categorical_accuracy: 0.8737 - val_54_categorical_accuracy: 0.8747 - val_reward_categorical_accuracy: 0.4650\n",
      "Epoch 175/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.0931 - 03_loss: 0.2869 - 04_loss: 0.0565 - 13_loss: 0.3369 - 14_loss: 0.2969 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1008 - 44_loss: 0.4505 - 53_loss: 0.1003 - 54_loss: 0.0649 - reward_loss: 0.3994 - 03_categorical_accuracy: 0.8458 - 04_categorical_accuracy: 0.9785 - 13_categorical_accuracy: 0.8268 - 14_categorical_accuracy: 0.8396 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9536 - 44_categorical_accuracy: 0.7759 - 53_categorical_accuracy: 0.9533 - 54_categorical_accuracy: 0.9648 - reward_categorical_accuracy: 0.7942 - val_loss: 13.1738 - val_03_loss: 1.2554 - val_04_loss: 0.3894 - val_13_loss: 1.6705 - val_14_loss: 1.5118 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5718 - val_44_loss: 2.7782 - val_53_loss: 0.5809 - val_54_loss: 1.6652 - val_reward_loss: 2.7505 - val_03_categorical_accuracy: 0.6047 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5640 - val_14_categorical_accuracy: 0.5903 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8743 - val_44_categorical_accuracy: 0.4531 - val_53_categorical_accuracy: 0.8763 - val_54_categorical_accuracy: 0.8724 - val_reward_categorical_accuracy: 0.4603\n",
      "Epoch 176/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0924 - 03_loss: 0.2868 - 04_loss: 0.0564 - 13_loss: 0.3362 - 14_loss: 0.2971 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1005 - 44_loss: 0.4506 - 53_loss: 0.1004 - 54_loss: 0.0648 - reward_loss: 0.3995 - 03_categorical_accuracy: 0.8451 - 04_categorical_accuracy: 0.9787 - 13_categorical_accuracy: 0.8269 - 14_categorical_accuracy: 0.8383 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9540 - 44_categorical_accuracy: 0.7761 - 53_categorical_accuracy: 0.9535 - 54_categorical_accuracy: 0.9652 - reward_categorical_accuracy: 0.7935 - val_loss: 13.1560 - val_03_loss: 1.2480 - val_04_loss: 0.3951 - val_13_loss: 1.6547 - val_14_loss: 1.4966 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5739 - val_44_loss: 2.7837 - val_53_loss: 0.5808 - val_54_loss: 1.6677 - val_reward_loss: 2.7555 - val_03_categorical_accuracy: 0.6025 - val_04_categorical_accuracy: 0.9523 - val_13_categorical_accuracy: 0.5551 - val_14_categorical_accuracy: 0.5894 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8763 - val_44_categorical_accuracy: 0.4470 - val_53_categorical_accuracy: 0.8780 - val_54_categorical_accuracy: 0.8736 - val_reward_categorical_accuracy: 0.4577\n",
      "Epoch 177/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.0905 - 03_loss: 0.2868 - 04_loss: 0.0563 - 13_loss: 0.3369 - 14_loss: 0.2968 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1004 - 44_loss: 0.4507 - 53_loss: 0.1001 - 54_loss: 0.0647 - reward_loss: 0.3979 - 03_categorical_accuracy: 0.8451 - 04_categorical_accuracy: 0.9787 - 13_categorical_accuracy: 0.8263 - 14_categorical_accuracy: 0.8387 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9535 - 44_categorical_accuracy: 0.7752 - 53_categorical_accuracy: 0.9536 - 54_categorical_accuracy: 0.9653 - reward_categorical_accuracy: 0.7949 - val_loss: 13.0850 - val_03_loss: 1.2493 - val_04_loss: 0.3924 - val_13_loss: 1.6535 - val_14_loss: 1.4854 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5749 - val_44_loss: 2.7632 - val_53_loss: 0.5789 - val_54_loss: 1.6433 - val_reward_loss: 2.7442 - val_03_categorical_accuracy: 0.6072 - val_04_categorical_accuracy: 0.9524 - val_13_categorical_accuracy: 0.5608 - val_14_categorical_accuracy: 0.5881 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8737 - val_44_categorical_accuracy: 0.4474 - val_53_categorical_accuracy: 0.8773 - val_54_categorical_accuracy: 0.8743 - val_reward_categorical_accuracy: 0.4647\n",
      "Epoch 178/1000\n",
      "697/697 [==============================] - 20s 28ms/step - loss: 2.0871 - 03_loss: 0.2860 - 04_loss: 0.0563 - 13_loss: 0.3361 - 14_loss: 0.2966 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0998 - 44_loss: 0.4495 - 53_loss: 0.0999 - 54_loss: 0.0646 - reward_loss: 0.3984 - 03_categorical_accuracy: 0.8463 - 04_categorical_accuracy: 0.9786 - 13_categorical_accuracy: 0.8270 - 14_categorical_accuracy: 0.8384 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9538 - 44_categorical_accuracy: 0.7762 - 53_categorical_accuracy: 0.9538 - 54_categorical_accuracy: 0.9649 - reward_categorical_accuracy: 0.7935 - val_loss: 13.0757 - val_03_loss: 1.2261 - val_04_loss: 0.3920 - val_13_loss: 1.6202 - val_14_loss: 1.4750 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5702 - val_44_loss: 2.7631 - val_53_loss: 0.5788 - val_54_loss: 1.7040 - val_reward_loss: 2.7463 - val_03_categorical_accuracy: 0.6091 - val_04_categorical_accuracy: 0.9523 - val_13_categorical_accuracy: 0.5591 - val_14_categorical_accuracy: 0.5873 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8750 - val_44_categorical_accuracy: 0.4483 - val_53_categorical_accuracy: 0.8801 - val_54_categorical_accuracy: 0.8725 - val_reward_categorical_accuracy: 0.4662\n",
      "Epoch 179/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0871 - 03_loss: 0.2868 - 04_loss: 0.0563 - 13_loss: 0.3360 - 14_loss: 0.2966 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1001 - 44_loss: 0.4488 - 53_loss: 0.1004 - 54_loss: 0.0649 - reward_loss: 0.3973 - 03_categorical_accuracy: 0.8441 - 04_categorical_accuracy: 0.9787 - 13_categorical_accuracy: 0.8266 - 14_categorical_accuracy: 0.8387 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9532 - 44_categorical_accuracy: 0.7766 - 53_categorical_accuracy: 0.9534 - 54_categorical_accuracy: 0.9650 - reward_categorical_accuracy: 0.7943 - val_loss: 13.0818 - val_03_loss: 1.2413 - val_04_loss: 0.3944 - val_13_loss: 1.6369 - val_14_loss: 1.4745 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5762 - val_44_loss: 2.7537 - val_53_loss: 0.5825 - val_54_loss: 1.6849 - val_reward_loss: 2.7373 - val_03_categorical_accuracy: 0.6027 - val_04_categorical_accuracy: 0.9522 - val_13_categorical_accuracy: 0.5636 - val_14_categorical_accuracy: 0.5902 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8775 - val_44_categorical_accuracy: 0.4513 - val_53_categorical_accuracy: 0.8791 - val_54_categorical_accuracy: 0.8745 - val_reward_categorical_accuracy: 0.4648\n",
      "Epoch 180/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.0854 - 03_loss: 0.2860 - 04_loss: 0.0562 - 13_loss: 0.3350 - 14_loss: 0.2964 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1005 - 44_loss: 0.4491 - 53_loss: 0.0999 - 54_loss: 0.0645 - reward_loss: 0.3977 - 03_categorical_accuracy: 0.8455 - 04_categorical_accuracy: 0.9786 - 13_categorical_accuracy: 0.8272 - 14_categorical_accuracy: 0.8391 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9536 - 44_categorical_accuracy: 0.7769 - 53_categorical_accuracy: 0.9540 - 54_categorical_accuracy: 0.9652 - reward_categorical_accuracy: 0.7940 - val_loss: 13.0550 - val_03_loss: 1.2436 - val_04_loss: 0.3991 - val_13_loss: 1.6319 - val_14_loss: 1.4753 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5733 - val_44_loss: 2.8057 - val_53_loss: 0.5756 - val_54_loss: 1.6501 - val_reward_loss: 2.7004 - val_03_categorical_accuracy: 0.6082 - val_04_categorical_accuracy: 0.9521 - val_13_categorical_accuracy: 0.5603 - val_14_categorical_accuracy: 0.5907 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8767 - val_44_categorical_accuracy: 0.4502 - val_53_categorical_accuracy: 0.8770 - val_54_categorical_accuracy: 0.8732 - val_reward_categorical_accuracy: 0.4586\n",
      "Epoch 181/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0830 - 03_loss: 0.2856 - 04_loss: 0.0563 - 13_loss: 0.3355 - 14_loss: 0.2961 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0998 - 44_loss: 0.4481 - 53_loss: 0.1001 - 54_loss: 0.0645 - reward_loss: 0.3971 - 03_categorical_accuracy: 0.8459 - 04_categorical_accuracy: 0.9787 - 13_categorical_accuracy: 0.8260 - 14_categorical_accuracy: 0.8388 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9536 - 44_categorical_accuracy: 0.7756 - 53_categorical_accuracy: 0.9535 - 54_categorical_accuracy: 0.9651 - reward_categorical_accuracy: 0.7937 - val_loss: 13.0710 - val_03_loss: 1.2377 - val_04_loss: 0.3991 - val_13_loss: 1.6506 - val_14_loss: 1.4846 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5671 - val_44_loss: 2.7616 - val_53_loss: 0.5772 - val_54_loss: 1.6674 - val_reward_loss: 2.7257 - val_03_categorical_accuracy: 0.6076 - val_04_categorical_accuracy: 0.9517 - val_13_categorical_accuracy: 0.5580 - val_14_categorical_accuracy: 0.5876 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8820 - val_44_categorical_accuracy: 0.4520 - val_53_categorical_accuracy: 0.8807 - val_54_categorical_accuracy: 0.8751 - val_reward_categorical_accuracy: 0.4615\n",
      "Epoch 182/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.0789 - 03_loss: 0.2854 - 04_loss: 0.0562 - 13_loss: 0.3345 - 14_loss: 0.2953 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0995 - 44_loss: 0.4478 - 53_loss: 0.1000 - 54_loss: 0.0645 - reward_loss: 0.3957 - 03_categorical_accuracy: 0.8447 - 04_categorical_accuracy: 0.9787 - 13_categorical_accuracy: 0.8268 - 14_categorical_accuracy: 0.8390 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9539 - 44_categorical_accuracy: 0.7767 - 53_categorical_accuracy: 0.9537 - 54_categorical_accuracy: 0.9647 - reward_categorical_accuracy: 0.7946 - val_loss: 13.1515 - val_03_loss: 1.2446 - val_04_loss: 0.3976 - val_13_loss: 1.6482 - val_14_loss: 1.4863 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5775 - val_44_loss: 2.7996 - val_53_loss: 0.5775 - val_54_loss: 1.7061 - val_reward_loss: 2.7142 - val_03_categorical_accuracy: 0.6084 - val_04_categorical_accuracy: 0.9520 - val_13_categorical_accuracy: 0.5555 - val_14_categorical_accuracy: 0.5877 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8792 - val_44_categorical_accuracy: 0.4504 - val_53_categorical_accuracy: 0.8772 - val_54_categorical_accuracy: 0.8737 - val_reward_categorical_accuracy: 0.4608\n",
      "Epoch 183/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.0799 - 03_loss: 0.2847 - 04_loss: 0.0561 - 13_loss: 0.3346 - 14_loss: 0.2958 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.1001 - 44_loss: 0.4481 - 53_loss: 0.0998 - 54_loss: 0.0647 - reward_loss: 0.3961 - 03_categorical_accuracy: 0.8455 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8267 - 14_categorical_accuracy: 0.8391 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9537 - 44_categorical_accuracy: 0.7770 - 53_categorical_accuracy: 0.9534 - 54_categorical_accuracy: 0.9649 - reward_categorical_accuracy: 0.7943 - val_loss: 13.2399 - val_03_loss: 1.2577 - val_04_loss: 0.3980 - val_13_loss: 1.6632 - val_14_loss: 1.5069 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5751 - val_44_loss: 2.7906 - val_53_loss: 0.5875 - val_54_loss: 1.6865 - val_reward_loss: 2.7744 - val_03_categorical_accuracy: 0.6118 - val_04_categorical_accuracy: 0.9521 - val_13_categorical_accuracy: 0.5561 - val_14_categorical_accuracy: 0.5868 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8788 - val_44_categorical_accuracy: 0.4520 - val_53_categorical_accuracy: 0.8783 - val_54_categorical_accuracy: 0.8724 - val_reward_categorical_accuracy: 0.4602\n",
      "Epoch 184/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.0777 - 03_loss: 0.2847 - 04_loss: 0.0562 - 13_loss: 0.3344 - 14_loss: 0.2946 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0997 - 44_loss: 0.4479 - 53_loss: 0.0995 - 54_loss: 0.0643 - reward_loss: 0.3964 - 03_categorical_accuracy: 0.8462 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8273 - 14_categorical_accuracy: 0.8396 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9535 - 44_categorical_accuracy: 0.7772 - 53_categorical_accuracy: 0.9535 - 54_categorical_accuracy: 0.9651 - reward_categorical_accuracy: 0.7941 - val_loss: 13.2445 - val_03_loss: 1.2539 - val_04_loss: 0.4100 - val_13_loss: 1.6474 - val_14_loss: 1.5136 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5841 - val_44_loss: 2.7932 - val_53_loss: 0.5853 - val_54_loss: 1.6962 - val_reward_loss: 2.7607 - val_03_categorical_accuracy: 0.6069 - val_04_categorical_accuracy: 0.9521 - val_13_categorical_accuracy: 0.5560 - val_14_categorical_accuracy: 0.5877 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8755 - val_44_categorical_accuracy: 0.4492 - val_53_categorical_accuracy: 0.8747 - val_54_categorical_accuracy: 0.8728 - val_reward_categorical_accuracy: 0.4626\n",
      "Epoch 185/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0770 - 03_loss: 0.2850 - 04_loss: 0.0561 - 13_loss: 0.3346 - 14_loss: 0.2945 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0995 - 44_loss: 0.4473 - 53_loss: 0.0996 - 54_loss: 0.0647 - reward_loss: 0.3957 - 03_categorical_accuracy: 0.8455 - 04_categorical_accuracy: 0.9787 - 13_categorical_accuracy: 0.8271 - 14_categorical_accuracy: 0.8400 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9536 - 44_categorical_accuracy: 0.7764 - 53_categorical_accuracy: 0.9538 - 54_categorical_accuracy: 0.9651 - reward_categorical_accuracy: 0.7943 - val_loss: 13.1381 - val_03_loss: 1.2405 - val_04_loss: 0.3983 - val_13_loss: 1.6491 - val_14_loss: 1.4868 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5689 - val_44_loss: 2.8079 - val_53_loss: 0.5725 - val_54_loss: 1.6870 - val_reward_loss: 2.7272 - val_03_categorical_accuracy: 0.6034 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5598 - val_14_categorical_accuracy: 0.5844 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8768 - val_44_categorical_accuracy: 0.4511 - val_53_categorical_accuracy: 0.8754 - val_54_categorical_accuracy: 0.8736 - val_reward_categorical_accuracy: 0.4639\n",
      "Epoch 186/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0741 - 03_loss: 0.2846 - 04_loss: 0.0562 - 13_loss: 0.3332 - 14_loss: 0.2946 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0994 - 44_loss: 0.4471 - 53_loss: 0.0996 - 54_loss: 0.0644 - reward_loss: 0.3951 - 03_categorical_accuracy: 0.8454 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8277 - 14_categorical_accuracy: 0.8396 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9540 - 44_categorical_accuracy: 0.7765 - 53_categorical_accuracy: 0.9532 - 54_categorical_accuracy: 0.9653 - reward_categorical_accuracy: 0.7948 - val_loss: 13.1241 - val_03_loss: 1.2565 - val_04_loss: 0.3980 - val_13_loss: 1.6359 - val_14_loss: 1.4891 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5736 - val_44_loss: 2.7803 - val_53_loss: 0.5848 - val_54_loss: 1.6622 - val_reward_loss: 2.7437 - val_03_categorical_accuracy: 0.6127 - val_04_categorical_accuracy: 0.9513 - val_13_categorical_accuracy: 0.5551 - val_14_categorical_accuracy: 0.5896 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8757 - val_44_categorical_accuracy: 0.4478 - val_53_categorical_accuracy: 0.8764 - val_54_categorical_accuracy: 0.8740 - val_reward_categorical_accuracy: 0.4576\n",
      "Epoch 187/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0730 - 03_loss: 0.2842 - 04_loss: 0.0561 - 13_loss: 0.3329 - 14_loss: 0.2942 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0992 - 44_loss: 0.4468 - 53_loss: 0.0995 - 54_loss: 0.0646 - reward_loss: 0.3955 - 03_categorical_accuracy: 0.8453 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8275 - 14_categorical_accuracy: 0.8396 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9540 - 44_categorical_accuracy: 0.7767 - 53_categorical_accuracy: 0.9538 - 54_categorical_accuracy: 0.9649 - reward_categorical_accuracy: 0.7945 - val_loss: 13.2242 - val_03_loss: 1.2583 - val_04_loss: 0.4020 - val_13_loss: 1.6706 - val_14_loss: 1.5011 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5797 - val_44_loss: 2.7862 - val_53_loss: 0.5854 - val_54_loss: 1.6621 - val_reward_loss: 2.7787 - val_03_categorical_accuracy: 0.6079 - val_04_categorical_accuracy: 0.9520 - val_13_categorical_accuracy: 0.5579 - val_14_categorical_accuracy: 0.5866 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8745 - val_44_categorical_accuracy: 0.4518 - val_53_categorical_accuracy: 0.8803 - val_54_categorical_accuracy: 0.8732 - val_reward_categorical_accuracy: 0.4607\n",
      "Epoch 188/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0690 - 03_loss: 0.2837 - 04_loss: 0.0561 - 13_loss: 0.3322 - 14_loss: 0.2940 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0992 - 44_loss: 0.4455 - 53_loss: 0.0994 - 54_loss: 0.0644 - reward_loss: 0.3945 - 03_categorical_accuracy: 0.8458 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8273 - 14_categorical_accuracy: 0.8394 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9535 - 44_categorical_accuracy: 0.7776 - 53_categorical_accuracy: 0.9533 - 54_categorical_accuracy: 0.9655 - reward_categorical_accuracy: 0.7946 - val_loss: 13.4688 - val_03_loss: 1.2506 - val_04_loss: 0.4190 - val_13_loss: 1.6653 - val_14_loss: 1.5082 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5871 - val_44_loss: 2.8368 - val_53_loss: 0.5905 - val_54_loss: 1.7790 - val_reward_loss: 2.8323 - val_03_categorical_accuracy: 0.6085 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5559 - val_14_categorical_accuracy: 0.5837 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8810 - val_44_categorical_accuracy: 0.4469 - val_53_categorical_accuracy: 0.8770 - val_54_categorical_accuracy: 0.8739 - val_reward_categorical_accuracy: 0.4622\n",
      "Epoch 189/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 2.0693 - 03_loss: 0.2834 - 04_loss: 0.0561 - 13_loss: 0.3326 - 14_loss: 0.2931 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0995 - 44_loss: 0.4460 - 53_loss: 0.0993 - 54_loss: 0.0645 - reward_loss: 0.3949 - 03_categorical_accuracy: 0.8465 - 04_categorical_accuracy: 0.9787 - 13_categorical_accuracy: 0.8272 - 14_categorical_accuracy: 0.8400 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9532 - 44_categorical_accuracy: 0.7769 - 53_categorical_accuracy: 0.9535 - 54_categorical_accuracy: 0.9648 - reward_categorical_accuracy: 0.7943 - val_loss: 13.3342 - val_03_loss: 1.2553 - val_04_loss: 0.4025 - val_13_loss: 1.6715 - val_14_loss: 1.5141 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5810 - val_44_loss: 2.8336 - val_53_loss: 0.5879 - val_54_loss: 1.7063 - val_reward_loss: 2.7820 - val_03_categorical_accuracy: 0.6042 - val_04_categorical_accuracy: 0.9513 - val_13_categorical_accuracy: 0.5595 - val_14_categorical_accuracy: 0.5909 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8754 - val_44_categorical_accuracy: 0.4525 - val_53_categorical_accuracy: 0.8737 - val_54_categorical_accuracy: 0.8730 - val_reward_categorical_accuracy: 0.4621\n",
      "Epoch 190/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 2.0666 - 03_loss: 0.2835 - 04_loss: 0.0562 - 13_loss: 0.3319 - 14_loss: 0.2930 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0992 - 44_loss: 0.4447 - 53_loss: 0.0990 - 54_loss: 0.0642 - reward_loss: 0.3948 - 03_categorical_accuracy: 0.8457 - 04_categorical_accuracy: 0.9786 - 13_categorical_accuracy: 0.8272 - 14_categorical_accuracy: 0.8399 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9540 - 44_categorical_accuracy: 0.7773 - 53_categorical_accuracy: 0.9539 - 54_categorical_accuracy: 0.9653 - reward_categorical_accuracy: 0.7951 - val_loss: 13.4027 - val_03_loss: 1.2595 - val_04_loss: 0.4092 - val_13_loss: 1.6628 - val_14_loss: 1.5244 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5828 - val_44_loss: 2.8262 - val_53_loss: 0.5920 - val_54_loss: 1.7516 - val_reward_loss: 2.7943 - val_03_categorical_accuracy: 0.6042 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5518 - val_14_categorical_accuracy: 0.5859 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8794 - val_44_categorical_accuracy: 0.4504 - val_53_categorical_accuracy: 0.8768 - val_54_categorical_accuracy: 0.8729 - val_reward_categorical_accuracy: 0.4616\n",
      "Epoch 191/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0659 - 03_loss: 0.2827 - 04_loss: 0.0563 - 13_loss: 0.3317 - 14_loss: 0.2927 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0993 - 44_loss: 0.4456 - 53_loss: 0.0992 - 54_loss: 0.0643 - reward_loss: 0.3940 - 03_categorical_accuracy: 0.8461 - 04_categorical_accuracy: 0.9786 - 13_categorical_accuracy: 0.8275 - 14_categorical_accuracy: 0.8403 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9537 - 44_categorical_accuracy: 0.7764 - 53_categorical_accuracy: 0.9541 - 54_categorical_accuracy: 0.9650 - reward_categorical_accuracy: 0.7940 - val_loss: 13.1717 - val_03_loss: 1.2444 - val_04_loss: 0.3996 - val_13_loss: 1.6444 - val_14_loss: 1.4956 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5720 - val_44_loss: 2.8274 - val_53_loss: 0.5802 - val_54_loss: 1.6788 - val_reward_loss: 2.7292 - val_03_categorical_accuracy: 0.6031 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5616 - val_14_categorical_accuracy: 0.5965 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8786 - val_44_categorical_accuracy: 0.4483 - val_53_categorical_accuracy: 0.8776 - val_54_categorical_accuracy: 0.8736 - val_reward_categorical_accuracy: 0.4608\n",
      "Epoch 192/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.0645 - 03_loss: 0.2833 - 04_loss: 0.0561 - 13_loss: 0.3313 - 14_loss: 0.2933 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0989 - 44_loss: 0.4457 - 53_loss: 0.0991 - 54_loss: 0.0643 - reward_loss: 0.3927 - 03_categorical_accuracy: 0.8460 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8278 - 14_categorical_accuracy: 0.8393 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9538 - 44_categorical_accuracy: 0.7772 - 53_categorical_accuracy: 0.9535 - 54_categorical_accuracy: 0.9651 - reward_categorical_accuracy: 0.7953 - val_loss: 13.3946 - val_03_loss: 1.2496 - val_04_loss: 0.4005 - val_13_loss: 1.6779 - val_14_loss: 1.5152 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5829 - val_44_loss: 2.8535 - val_53_loss: 0.5863 - val_54_loss: 1.7429 - val_reward_loss: 2.7857 - val_03_categorical_accuracy: 0.6039 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5572 - val_14_categorical_accuracy: 0.5916 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8781 - val_44_categorical_accuracy: 0.4477 - val_53_categorical_accuracy: 0.8694 - val_54_categorical_accuracy: 0.8738 - val_reward_categorical_accuracy: 0.4624\n",
      "Epoch 193/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 2.0633 - 03_loss: 0.2827 - 04_loss: 0.0561 - 13_loss: 0.3317 - 14_loss: 0.2922 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0993 - 44_loss: 0.4457 - 53_loss: 0.0987 - 54_loss: 0.0641 - reward_loss: 0.3928 - 03_categorical_accuracy: 0.8465 - 04_categorical_accuracy: 0.9787 - 13_categorical_accuracy: 0.8275 - 14_categorical_accuracy: 0.8409 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9535 - 44_categorical_accuracy: 0.7771 - 53_categorical_accuracy: 0.9536 - 54_categorical_accuracy: 0.9652 - reward_categorical_accuracy: 0.7956 - val_loss: 13.2077 - val_03_loss: 1.2520 - val_04_loss: 0.4037 - val_13_loss: 1.6705 - val_14_loss: 1.5208 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5760 - val_44_loss: 2.8179 - val_53_loss: 0.5765 - val_54_loss: 1.6569 - val_reward_loss: 2.7334 - val_03_categorical_accuracy: 0.6064 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5607 - val_14_categorical_accuracy: 0.5893 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8769 - val_44_categorical_accuracy: 0.4523 - val_53_categorical_accuracy: 0.8741 - val_54_categorical_accuracy: 0.8737 - val_reward_categorical_accuracy: 0.4548\n",
      "Epoch 194/1000\n",
      "697/697 [==============================] - 18s 26ms/step - loss: 2.0600 - 03_loss: 0.2826 - 04_loss: 0.0560 - 13_loss: 0.3306 - 14_loss: 0.2918 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0990 - 44_loss: 0.4448 - 53_loss: 0.0990 - 54_loss: 0.0642 - reward_loss: 0.3920 - 03_categorical_accuracy: 0.8464 - 04_categorical_accuracy: 0.9787 - 13_categorical_accuracy: 0.8282 - 14_categorical_accuracy: 0.8409 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9540 - 44_categorical_accuracy: 0.7778 - 53_categorical_accuracy: 0.9538 - 54_categorical_accuracy: 0.9655 - reward_categorical_accuracy: 0.7953 - val_loss: 13.5140 - val_03_loss: 1.2702 - val_04_loss: 0.4212 - val_13_loss: 1.6805 - val_14_loss: 1.5521 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5888 - val_44_loss: 2.8377 - val_53_loss: 0.5906 - val_54_loss: 1.7631 - val_reward_loss: 2.8096 - val_03_categorical_accuracy: 0.6040 - val_04_categorical_accuracy: 0.9514 - val_13_categorical_accuracy: 0.5577 - val_14_categorical_accuracy: 0.5907 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8722 - val_44_categorical_accuracy: 0.4503 - val_53_categorical_accuracy: 0.8761 - val_54_categorical_accuracy: 0.8732 - val_reward_categorical_accuracy: 0.4645\n",
      "Epoch 195/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.0591 - 03_loss: 0.2823 - 04_loss: 0.0559 - 13_loss: 0.3310 - 14_loss: 0.2921 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0983 - 44_loss: 0.4442 - 53_loss: 0.0993 - 54_loss: 0.0640 - reward_loss: 0.3920 - 03_categorical_accuracy: 0.8465 - 04_categorical_accuracy: 0.9786 - 13_categorical_accuracy: 0.8279 - 14_categorical_accuracy: 0.8400 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9539 - 44_categorical_accuracy: 0.7761 - 53_categorical_accuracy: 0.9531 - 54_categorical_accuracy: 0.9653 - reward_categorical_accuracy: 0.7948 - val_loss: 13.4548 - val_03_loss: 1.2565 - val_04_loss: 0.4128 - val_13_loss: 1.6773 - val_14_loss: 1.5205 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5782 - val_44_loss: 2.8254 - val_53_loss: 0.5798 - val_54_loss: 1.8043 - val_reward_loss: 2.8000 - val_03_categorical_accuracy: 0.6066 - val_04_categorical_accuracy: 0.9517 - val_13_categorical_accuracy: 0.5574 - val_14_categorical_accuracy: 0.5906 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8768 - val_44_categorical_accuracy: 0.4491 - val_53_categorical_accuracy: 0.8734 - val_54_categorical_accuracy: 0.8734 - val_reward_categorical_accuracy: 0.4580\n",
      "Epoch 196/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0558 - 03_loss: 0.2824 - 04_loss: 0.0558 - 13_loss: 0.3295 - 14_loss: 0.2920 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0984 - 44_loss: 0.4438 - 53_loss: 0.0984 - 54_loss: 0.0642 - reward_loss: 0.3913 - 03_categorical_accuracy: 0.8455 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8283 - 14_categorical_accuracy: 0.8400 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9542 - 44_categorical_accuracy: 0.7782 - 53_categorical_accuracy: 0.9540 - 54_categorical_accuracy: 0.9654 - reward_categorical_accuracy: 0.7957 - val_loss: 13.3594 - val_03_loss: 1.2539 - val_04_loss: 0.4197 - val_13_loss: 1.6822 - val_14_loss: 1.5243 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5775 - val_44_loss: 2.8263 - val_53_loss: 0.5930 - val_54_loss: 1.7070 - val_reward_loss: 2.7755 - val_03_categorical_accuracy: 0.6038 - val_04_categorical_accuracy: 0.9517 - val_13_categorical_accuracy: 0.5632 - val_14_categorical_accuracy: 0.5969 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8793 - val_44_categorical_accuracy: 0.4512 - val_53_categorical_accuracy: 0.8782 - val_54_categorical_accuracy: 0.8739 - val_reward_categorical_accuracy: 0.4612\n",
      "Epoch 197/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0593 - 03_loss: 0.2822 - 04_loss: 0.0559 - 13_loss: 0.3305 - 14_loss: 0.2921 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0987 - 44_loss: 0.4449 - 53_loss: 0.0986 - 54_loss: 0.0640 - reward_loss: 0.3923 - 03_categorical_accuracy: 0.8458 - 04_categorical_accuracy: 0.9789 - 13_categorical_accuracy: 0.8285 - 14_categorical_accuracy: 0.8393 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9537 - 44_categorical_accuracy: 0.7769 - 53_categorical_accuracy: 0.9539 - 54_categorical_accuracy: 0.9656 - reward_categorical_accuracy: 0.7953 - val_loss: 13.6173 - val_03_loss: 1.2673 - val_04_loss: 0.4193 - val_13_loss: 1.6860 - val_14_loss: 1.5247 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5847 - val_44_loss: 2.8595 - val_53_loss: 0.5995 - val_54_loss: 1.8350 - val_reward_loss: 2.8413 - val_03_categorical_accuracy: 0.6103 - val_04_categorical_accuracy: 0.9524 - val_13_categorical_accuracy: 0.5606 - val_14_categorical_accuracy: 0.5929 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8768 - val_44_categorical_accuracy: 0.4521 - val_53_categorical_accuracy: 0.8771 - val_54_categorical_accuracy: 0.8736 - val_reward_categorical_accuracy: 0.4608\n",
      "Epoch 198/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0547 - 03_loss: 0.2812 - 04_loss: 0.0559 - 13_loss: 0.3295 - 14_loss: 0.2910 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0985 - 44_loss: 0.4438 - 53_loss: 0.0987 - 54_loss: 0.0642 - reward_loss: 0.3920 - 03_categorical_accuracy: 0.8471 - 04_categorical_accuracy: 0.9789 - 13_categorical_accuracy: 0.8286 - 14_categorical_accuracy: 0.8407 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9536 - 44_categorical_accuracy: 0.7771 - 53_categorical_accuracy: 0.9540 - 54_categorical_accuracy: 0.9652 - reward_categorical_accuracy: 0.7948 - val_loss: 13.4081 - val_03_loss: 1.2596 - val_04_loss: 0.4154 - val_13_loss: 1.6609 - val_14_loss: 1.5221 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5807 - val_44_loss: 2.8456 - val_53_loss: 0.5835 - val_54_loss: 1.7410 - val_reward_loss: 2.7994 - val_03_categorical_accuracy: 0.6033 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5551 - val_14_categorical_accuracy: 0.5884 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8814 - val_44_categorical_accuracy: 0.4513 - val_53_categorical_accuracy: 0.8756 - val_54_categorical_accuracy: 0.8743 - val_reward_categorical_accuracy: 0.4604\n",
      "Epoch 199/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.0566 - 03_loss: 0.2833 - 04_loss: 0.0565 - 13_loss: 0.3293 - 14_loss: 0.2916 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0984 - 44_loss: 0.4435 - 53_loss: 0.0986 - 54_loss: 0.0640 - reward_loss: 0.3913 - 03_categorical_accuracy: 0.8462 - 04_categorical_accuracy: 0.9787 - 13_categorical_accuracy: 0.8287 - 14_categorical_accuracy: 0.8410 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9539 - 44_categorical_accuracy: 0.7775 - 53_categorical_accuracy: 0.9540 - 54_categorical_accuracy: 0.9655 - reward_categorical_accuracy: 0.7962 - val_loss: 13.6032 - val_03_loss: 1.2773 - val_04_loss: 0.4244 - val_13_loss: 1.6905 - val_14_loss: 1.5405 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5871 - val_44_loss: 2.8546 - val_53_loss: 0.5941 - val_54_loss: 1.8035 - val_reward_loss: 2.8312 - val_03_categorical_accuracy: 0.6051 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5539 - val_14_categorical_accuracy: 0.5880 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8764 - val_44_categorical_accuracy: 0.4534 - val_53_categorical_accuracy: 0.8724 - val_54_categorical_accuracy: 0.8739 - val_reward_categorical_accuracy: 0.4634\n",
      "Epoch 200/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0509 - 03_loss: 0.2814 - 04_loss: 0.0563 - 13_loss: 0.3290 - 14_loss: 0.2905 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0985 - 44_loss: 0.4428 - 53_loss: 0.0986 - 54_loss: 0.0639 - reward_loss: 0.3899 - 03_categorical_accuracy: 0.8470 - 04_categorical_accuracy: 0.9789 - 13_categorical_accuracy: 0.8284 - 14_categorical_accuracy: 0.8403 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9536 - 44_categorical_accuracy: 0.7782 - 53_categorical_accuracy: 0.9540 - 54_categorical_accuracy: 0.9656 - reward_categorical_accuracy: 0.7958 - val_loss: 13.1772 - val_03_loss: 1.2437 - val_04_loss: 0.4013 - val_13_loss: 1.6425 - val_14_loss: 1.4895 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5663 - val_44_loss: 2.8101 - val_53_loss: 0.5779 - val_54_loss: 1.7104 - val_reward_loss: 2.7355 - val_03_categorical_accuracy: 0.6108 - val_04_categorical_accuracy: 0.9523 - val_13_categorical_accuracy: 0.5578 - val_14_categorical_accuracy: 0.5847 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8762 - val_44_categorical_accuracy: 0.4514 - val_53_categorical_accuracy: 0.8825 - val_54_categorical_accuracy: 0.8736 - val_reward_categorical_accuracy: 0.4591\n",
      "Epoch 201/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0511 - 03_loss: 0.2814 - 04_loss: 0.0561 - 13_loss: 0.3289 - 14_loss: 0.2904 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0987 - 44_loss: 0.4434 - 53_loss: 0.0980 - 54_loss: 0.0642 - reward_loss: 0.3900 - 03_categorical_accuracy: 0.8460 - 04_categorical_accuracy: 0.9787 - 13_categorical_accuracy: 0.8282 - 14_categorical_accuracy: 0.8404 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9539 - 44_categorical_accuracy: 0.7771 - 53_categorical_accuracy: 0.9542 - 54_categorical_accuracy: 0.9657 - reward_categorical_accuracy: 0.7961 - val_loss: 13.2664 - val_03_loss: 1.2426 - val_04_loss: 0.4103 - val_13_loss: 1.6279 - val_14_loss: 1.4851 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5726 - val_44_loss: 2.8354 - val_53_loss: 0.5788 - val_54_loss: 1.7727 - val_reward_loss: 2.7411 - val_03_categorical_accuracy: 0.6086 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5560 - val_14_categorical_accuracy: 0.5866 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8760 - val_44_categorical_accuracy: 0.4471 - val_53_categorical_accuracy: 0.8776 - val_54_categorical_accuracy: 0.8738 - val_reward_categorical_accuracy: 0.4647\n",
      "Epoch 202/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.0491 - 03_loss: 0.2810 - 04_loss: 0.0560 - 13_loss: 0.3291 - 14_loss: 0.2903 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0985 - 44_loss: 0.4423 - 53_loss: 0.0982 - 54_loss: 0.0639 - reward_loss: 0.3898 - 03_categorical_accuracy: 0.8463 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8282 - 14_categorical_accuracy: 0.8402 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9538 - 44_categorical_accuracy: 0.7780 - 53_categorical_accuracy: 0.9537 - 54_categorical_accuracy: 0.9651 - reward_categorical_accuracy: 0.7960 - val_loss: 13.6475 - val_03_loss: 1.2736 - val_04_loss: 0.4225 - val_13_loss: 1.6977 - val_14_loss: 1.5342 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5897 - val_44_loss: 2.8906 - val_53_loss: 0.5935 - val_54_loss: 1.8149 - val_reward_loss: 2.8309 - val_03_categorical_accuracy: 0.6044 - val_04_categorical_accuracy: 0.9520 - val_13_categorical_accuracy: 0.5576 - val_14_categorical_accuracy: 0.5913 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8767 - val_44_categorical_accuracy: 0.4535 - val_53_categorical_accuracy: 0.8768 - val_54_categorical_accuracy: 0.8737 - val_reward_categorical_accuracy: 0.4631\n",
      "Epoch 203/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0455 - 03_loss: 0.2812 - 04_loss: 0.0560 - 13_loss: 0.3278 - 14_loss: 0.2892 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0981 - 44_loss: 0.4422 - 53_loss: 0.0983 - 54_loss: 0.0636 - reward_loss: 0.3892 - 03_categorical_accuracy: 0.8468 - 04_categorical_accuracy: 0.9787 - 13_categorical_accuracy: 0.8285 - 14_categorical_accuracy: 0.8410 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9540 - 44_categorical_accuracy: 0.7779 - 53_categorical_accuracy: 0.9538 - 54_categorical_accuracy: 0.9653 - reward_categorical_accuracy: 0.7962 - val_loss: 13.4287 - val_03_loss: 1.2582 - val_04_loss: 0.4260 - val_13_loss: 1.6611 - val_14_loss: 1.5182 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5825 - val_44_loss: 2.8452 - val_53_loss: 0.5900 - val_54_loss: 1.7707 - val_reward_loss: 2.7770 - val_03_categorical_accuracy: 0.6099 - val_04_categorical_accuracy: 0.9521 - val_13_categorical_accuracy: 0.5569 - val_14_categorical_accuracy: 0.5898 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8747 - val_44_categorical_accuracy: 0.4471 - val_53_categorical_accuracy: 0.8776 - val_54_categorical_accuracy: 0.8732 - val_reward_categorical_accuracy: 0.4564\n",
      "Epoch 204/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.0449 - 03_loss: 0.2806 - 04_loss: 0.0561 - 13_loss: 0.3276 - 14_loss: 0.2897 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0982 - 44_loss: 0.4419 - 53_loss: 0.0982 - 54_loss: 0.0635 - reward_loss: 0.3890 - 03_categorical_accuracy: 0.8469 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8290 - 14_categorical_accuracy: 0.8407 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9539 - 44_categorical_accuracy: 0.7776 - 53_categorical_accuracy: 0.9541 - 54_categorical_accuracy: 0.9656 - reward_categorical_accuracy: 0.7959 - val_loss: 13.6910 - val_03_loss: 1.2709 - val_04_loss: 0.4199 - val_13_loss: 1.7056 - val_14_loss: 1.5427 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5766 - val_44_loss: 2.9076 - val_53_loss: 0.5916 - val_54_loss: 1.8338 - val_reward_loss: 2.8420 - val_03_categorical_accuracy: 0.6033 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5568 - val_14_categorical_accuracy: 0.5867 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8769 - val_44_categorical_accuracy: 0.4502 - val_53_categorical_accuracy: 0.8768 - val_54_categorical_accuracy: 0.8737 - val_reward_categorical_accuracy: 0.4609\n",
      "Epoch 205/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0439 - 03_loss: 0.2803 - 04_loss: 0.0558 - 13_loss: 0.3277 - 14_loss: 0.2896 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0982 - 44_loss: 0.4415 - 53_loss: 0.0977 - 54_loss: 0.0639 - reward_loss: 0.3893 - 03_categorical_accuracy: 0.8459 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8283 - 14_categorical_accuracy: 0.8407 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9537 - 44_categorical_accuracy: 0.7788 - 53_categorical_accuracy: 0.9541 - 54_categorical_accuracy: 0.9659 - reward_categorical_accuracy: 0.7953 - val_loss: 13.5347 - val_03_loss: 1.2672 - val_04_loss: 0.4237 - val_13_loss: 1.6923 - val_14_loss: 1.5493 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5843 - val_44_loss: 2.8672 - val_53_loss: 0.5926 - val_54_loss: 1.7535 - val_reward_loss: 2.8047 - val_03_categorical_accuracy: 0.6018 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5597 - val_14_categorical_accuracy: 0.5914 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8803 - val_44_categorical_accuracy: 0.4496 - val_53_categorical_accuracy: 0.8780 - val_54_categorical_accuracy: 0.8741 - val_reward_categorical_accuracy: 0.4643\n",
      "Epoch 206/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.0435 - 03_loss: 0.2802 - 04_loss: 0.0558 - 13_loss: 0.3280 - 14_loss: 0.2893 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0982 - 44_loss: 0.4411 - 53_loss: 0.0982 - 54_loss: 0.0640 - reward_loss: 0.3888 - 03_categorical_accuracy: 0.8468 - 04_categorical_accuracy: 0.9790 - 13_categorical_accuracy: 0.8288 - 14_categorical_accuracy: 0.8409 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9537 - 44_categorical_accuracy: 0.7772 - 53_categorical_accuracy: 0.9541 - 54_categorical_accuracy: 0.9656 - reward_categorical_accuracy: 0.7955 - val_loss: 13.3818 - val_03_loss: 1.2526 - val_04_loss: 0.4216 - val_13_loss: 1.6770 - val_14_loss: 1.5176 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5857 - val_44_loss: 2.8161 - val_53_loss: 0.5887 - val_54_loss: 1.7516 - val_reward_loss: 2.7707 - val_03_categorical_accuracy: 0.6001 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5554 - val_14_categorical_accuracy: 0.5903 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8790 - val_44_categorical_accuracy: 0.4481 - val_53_categorical_accuracy: 0.8761 - val_54_categorical_accuracy: 0.8736 - val_reward_categorical_accuracy: 0.4648\n",
      "Epoch 207/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0441 - 03_loss: 0.2803 - 04_loss: 0.0559 - 13_loss: 0.3274 - 14_loss: 0.2896 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0980 - 44_loss: 0.4422 - 53_loss: 0.0979 - 54_loss: 0.0637 - reward_loss: 0.3892 - 03_categorical_accuracy: 0.8465 - 04_categorical_accuracy: 0.9789 - 13_categorical_accuracy: 0.8290 - 14_categorical_accuracy: 0.8408 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9540 - 44_categorical_accuracy: 0.7769 - 53_categorical_accuracy: 0.9539 - 54_categorical_accuracy: 0.9653 - reward_categorical_accuracy: 0.7954 - val_loss: 13.5079 - val_03_loss: 1.2672 - val_04_loss: 0.4201 - val_13_loss: 1.6719 - val_14_loss: 1.5119 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5835 - val_44_loss: 2.8457 - val_53_loss: 0.5953 - val_54_loss: 1.8078 - val_reward_loss: 2.8045 - val_03_categorical_accuracy: 0.6091 - val_04_categorical_accuracy: 0.9520 - val_13_categorical_accuracy: 0.5560 - val_14_categorical_accuracy: 0.5879 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8800 - val_44_categorical_accuracy: 0.4501 - val_53_categorical_accuracy: 0.8761 - val_54_categorical_accuracy: 0.8740 - val_reward_categorical_accuracy: 0.4608\n",
      "Epoch 208/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.0396 - 03_loss: 0.2803 - 04_loss: 0.0561 - 13_loss: 0.3267 - 14_loss: 0.2879 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0980 - 44_loss: 0.4410 - 53_loss: 0.0980 - 54_loss: 0.0641 - reward_loss: 0.3876 - 03_categorical_accuracy: 0.8466 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8293 - 14_categorical_accuracy: 0.8416 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9537 - 44_categorical_accuracy: 0.7781 - 53_categorical_accuracy: 0.9538 - 54_categorical_accuracy: 0.9656 - reward_categorical_accuracy: 0.7965 - val_loss: 13.5631 - val_03_loss: 1.2632 - val_04_loss: 0.4203 - val_13_loss: 1.6958 - val_14_loss: 1.5353 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5771 - val_44_loss: 2.8647 - val_53_loss: 0.5915 - val_54_loss: 1.7789 - val_reward_loss: 2.8362 - val_03_categorical_accuracy: 0.6093 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5552 - val_14_categorical_accuracy: 0.5853 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8776 - val_44_categorical_accuracy: 0.4555 - val_53_categorical_accuracy: 0.8792 - val_54_categorical_accuracy: 0.8735 - val_reward_categorical_accuracy: 0.4613\n",
      "Epoch 209/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0378 - 03_loss: 0.2797 - 04_loss: 0.0558 - 13_loss: 0.3261 - 14_loss: 0.2886 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0978 - 44_loss: 0.4408 - 53_loss: 0.0974 - 54_loss: 0.0636 - reward_loss: 0.3880 - 03_categorical_accuracy: 0.8470 - 04_categorical_accuracy: 0.9789 - 13_categorical_accuracy: 0.8294 - 14_categorical_accuracy: 0.8412 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9544 - 44_categorical_accuracy: 0.7783 - 53_categorical_accuracy: 0.9541 - 54_categorical_accuracy: 0.9654 - reward_categorical_accuracy: 0.7958 - val_loss: 13.7531 - val_03_loss: 1.2751 - val_04_loss: 0.4313 - val_13_loss: 1.7191 - val_14_loss: 1.5751 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5888 - val_44_loss: 2.8966 - val_53_loss: 0.5950 - val_54_loss: 1.8205 - val_reward_loss: 2.8516 - val_03_categorical_accuracy: 0.6075 - val_04_categorical_accuracy: 0.9521 - val_13_categorical_accuracy: 0.5573 - val_14_categorical_accuracy: 0.5912 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8738 - val_44_categorical_accuracy: 0.4539 - val_53_categorical_accuracy: 0.8792 - val_54_categorical_accuracy: 0.8739 - val_reward_categorical_accuracy: 0.4578\n",
      "Epoch 210/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0382 - 03_loss: 0.2799 - 04_loss: 0.0560 - 13_loss: 0.3261 - 14_loss: 0.2883 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0978 - 44_loss: 0.4409 - 53_loss: 0.0975 - 54_loss: 0.0637 - reward_loss: 0.3880 - 03_categorical_accuracy: 0.8469 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8289 - 14_categorical_accuracy: 0.8412 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9541 - 44_categorical_accuracy: 0.7780 - 53_categorical_accuracy: 0.9541 - 54_categorical_accuracy: 0.9656 - reward_categorical_accuracy: 0.7959 - val_loss: 13.5125 - val_03_loss: 1.2494 - val_04_loss: 0.4154 - val_13_loss: 1.6944 - val_14_loss: 1.5213 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5749 - val_44_loss: 2.8479 - val_53_loss: 0.5946 - val_54_loss: 1.7878 - val_reward_loss: 2.8268 - val_03_categorical_accuracy: 0.6070 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5575 - val_14_categorical_accuracy: 0.5874 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8776 - val_44_categorical_accuracy: 0.4471 - val_53_categorical_accuracy: 0.8781 - val_54_categorical_accuracy: 0.8735 - val_reward_categorical_accuracy: 0.4659\n",
      "Epoch 211/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 19s 28ms/step - loss: 2.0355 - 03_loss: 0.2792 - 04_loss: 0.0556 - 13_loss: 0.3254 - 14_loss: 0.2882 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0977 - 44_loss: 0.4408 - 53_loss: 0.0981 - 54_loss: 0.0634 - reward_loss: 0.3872 - 03_categorical_accuracy: 0.8473 - 04_categorical_accuracy: 0.9790 - 13_categorical_accuracy: 0.8293 - 14_categorical_accuracy: 0.8409 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9539 - 44_categorical_accuracy: 0.7779 - 53_categorical_accuracy: 0.9539 - 54_categorical_accuracy: 0.9655 - reward_categorical_accuracy: 0.7956 - val_loss: 13.7262 - val_03_loss: 1.2666 - val_04_loss: 0.4354 - val_13_loss: 1.6936 - val_14_loss: 1.5473 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5840 - val_44_loss: 2.8833 - val_53_loss: 0.5989 - val_54_loss: 1.8690 - val_reward_loss: 2.8482 - val_03_categorical_accuracy: 0.6083 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5592 - val_14_categorical_accuracy: 0.5916 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8777 - val_44_categorical_accuracy: 0.4545 - val_53_categorical_accuracy: 0.8775 - val_54_categorical_accuracy: 0.8738 - val_reward_categorical_accuracy: 0.4606\n",
      "Epoch 212/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0368 - 03_loss: 0.2795 - 04_loss: 0.0559 - 13_loss: 0.3268 - 14_loss: 0.2883 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0977 - 44_loss: 0.4402 - 53_loss: 0.0978 - 54_loss: 0.0635 - reward_loss: 0.3870 - 03_categorical_accuracy: 0.8469 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8285 - 14_categorical_accuracy: 0.8413 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9540 - 44_categorical_accuracy: 0.7781 - 53_categorical_accuracy: 0.9538 - 54_categorical_accuracy: 0.9655 - reward_categorical_accuracy: 0.7962 - val_loss: 13.4849 - val_03_loss: 1.2610 - val_04_loss: 0.4217 - val_13_loss: 1.6898 - val_14_loss: 1.5360 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5821 - val_44_loss: 2.8382 - val_53_loss: 0.5858 - val_54_loss: 1.7725 - val_reward_loss: 2.7978 - val_03_categorical_accuracy: 0.6036 - val_04_categorical_accuracy: 0.9517 - val_13_categorical_accuracy: 0.5561 - val_14_categorical_accuracy: 0.5880 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8806 - val_44_categorical_accuracy: 0.4497 - val_53_categorical_accuracy: 0.8774 - val_54_categorical_accuracy: 0.8738 - val_reward_categorical_accuracy: 0.4639\n",
      "Epoch 213/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0323 - 03_loss: 0.2788 - 04_loss: 0.0559 - 13_loss: 0.3256 - 14_loss: 0.2877 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0977 - 44_loss: 0.4394 - 53_loss: 0.0975 - 54_loss: 0.0635 - reward_loss: 0.3863 - 03_categorical_accuracy: 0.8471 - 04_categorical_accuracy: 0.9787 - 13_categorical_accuracy: 0.8297 - 14_categorical_accuracy: 0.8414 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9538 - 44_categorical_accuracy: 0.7781 - 53_categorical_accuracy: 0.9538 - 54_categorical_accuracy: 0.9654 - reward_categorical_accuracy: 0.7965 - val_loss: 13.7382 - val_03_loss: 1.2745 - val_04_loss: 0.4276 - val_13_loss: 1.6999 - val_14_loss: 1.5478 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5822 - val_44_loss: 2.9162 - val_53_loss: 0.5996 - val_54_loss: 1.8254 - val_reward_loss: 2.8649 - val_03_categorical_accuracy: 0.6017 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5625 - val_14_categorical_accuracy: 0.5924 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8764 - val_44_categorical_accuracy: 0.4493 - val_53_categorical_accuracy: 0.8772 - val_54_categorical_accuracy: 0.8742 - val_reward_categorical_accuracy: 0.4638\n",
      "Epoch 214/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.0333 - 03_loss: 0.2788 - 04_loss: 0.0560 - 13_loss: 0.3257 - 14_loss: 0.2877 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0977 - 44_loss: 0.4399 - 53_loss: 0.0974 - 54_loss: 0.0638 - reward_loss: 0.3863 - 03_categorical_accuracy: 0.8465 - 04_categorical_accuracy: 0.9787 - 13_categorical_accuracy: 0.8295 - 14_categorical_accuracy: 0.8414 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9539 - 44_categorical_accuracy: 0.7784 - 53_categorical_accuracy: 0.9541 - 54_categorical_accuracy: 0.9657 - reward_categorical_accuracy: 0.7963 - val_loss: 13.5788 - val_03_loss: 1.2558 - val_04_loss: 0.4223 - val_13_loss: 1.6853 - val_14_loss: 1.5244 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5855 - val_44_loss: 2.8954 - val_53_loss: 0.5866 - val_54_loss: 1.8042 - val_reward_loss: 2.8192 - val_03_categorical_accuracy: 0.6077 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5573 - val_14_categorical_accuracy: 0.5842 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8792 - val_44_categorical_accuracy: 0.4516 - val_53_categorical_accuracy: 0.8745 - val_54_categorical_accuracy: 0.8739 - val_reward_categorical_accuracy: 0.4627\n",
      "Epoch 215/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0301 - 03_loss: 0.2788 - 04_loss: 0.0557 - 13_loss: 0.3251 - 14_loss: 0.2873 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0973 - 44_loss: 0.4395 - 53_loss: 0.0974 - 54_loss: 0.0633 - reward_loss: 0.3856 - 03_categorical_accuracy: 0.8474 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8298 - 14_categorical_accuracy: 0.8403 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9540 - 44_categorical_accuracy: 0.7785 - 53_categorical_accuracy: 0.9540 - 54_categorical_accuracy: 0.9660 - reward_categorical_accuracy: 0.7962 - val_loss: 13.7678 - val_03_loss: 1.2838 - val_04_loss: 0.4352 - val_13_loss: 1.7021 - val_14_loss: 1.5471 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5913 - val_44_loss: 2.9153 - val_53_loss: 0.5960 - val_54_loss: 1.8365 - val_reward_loss: 2.8606 - val_03_categorical_accuracy: 0.6051 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5572 - val_14_categorical_accuracy: 0.5879 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8806 - val_44_categorical_accuracy: 0.4503 - val_53_categorical_accuracy: 0.8762 - val_54_categorical_accuracy: 0.8734 - val_reward_categorical_accuracy: 0.4672\n",
      "Epoch 216/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.0300 - 03_loss: 0.2784 - 04_loss: 0.0558 - 13_loss: 0.3245 - 14_loss: 0.2870 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0972 - 44_loss: 0.4399 - 53_loss: 0.0975 - 54_loss: 0.0635 - reward_loss: 0.3863 - 03_categorical_accuracy: 0.8475 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8294 - 14_categorical_accuracy: 0.8418 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9542 - 44_categorical_accuracy: 0.7786 - 53_categorical_accuracy: 0.9544 - 54_categorical_accuracy: 0.9657 - reward_categorical_accuracy: 0.7959 - val_loss: 13.7719 - val_03_loss: 1.2753 - val_04_loss: 0.4293 - val_13_loss: 1.7126 - val_14_loss: 1.5533 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5847 - val_44_loss: 2.8672 - val_53_loss: 0.5980 - val_54_loss: 1.8795 - val_reward_loss: 2.8721 - val_03_categorical_accuracy: 0.6071 - val_04_categorical_accuracy: 0.9517 - val_13_categorical_accuracy: 0.5573 - val_14_categorical_accuracy: 0.5870 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8764 - val_44_categorical_accuracy: 0.4485 - val_53_categorical_accuracy: 0.8763 - val_54_categorical_accuracy: 0.8735 - val_reward_categorical_accuracy: 0.4622\n",
      "Epoch 217/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0267 - 03_loss: 0.2779 - 04_loss: 0.0558 - 13_loss: 0.3246 - 14_loss: 0.2865 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0973 - 44_loss: 0.4389 - 53_loss: 0.0971 - 54_loss: 0.0633 - reward_loss: 0.3853 - 03_categorical_accuracy: 0.8473 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8293 - 14_categorical_accuracy: 0.8413 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9540 - 44_categorical_accuracy: 0.7785 - 53_categorical_accuracy: 0.9543 - 54_categorical_accuracy: 0.9657 - reward_categorical_accuracy: 0.7962 - val_loss: 13.8699 - val_03_loss: 1.2897 - val_04_loss: 0.4386 - val_13_loss: 1.7060 - val_14_loss: 1.5589 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5924 - val_44_loss: 2.9337 - val_53_loss: 0.5902 - val_54_loss: 1.9002 - val_reward_loss: 2.8602 - val_03_categorical_accuracy: 0.6077 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5567 - val_14_categorical_accuracy: 0.5885 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8784 - val_44_categorical_accuracy: 0.4481 - val_53_categorical_accuracy: 0.8724 - val_54_categorical_accuracy: 0.8735 - val_reward_categorical_accuracy: 0.4646\n",
      "Epoch 218/1000\n",
      "697/697 [==============================] - 20s 28ms/step - loss: 2.0266 - 03_loss: 0.2787 - 04_loss: 0.0559 - 13_loss: 0.3247 - 14_loss: 0.2863 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0974 - 44_loss: 0.4382 - 53_loss: 0.0970 - 54_loss: 0.0633 - reward_loss: 0.3853 - 03_categorical_accuracy: 0.8471 - 04_categorical_accuracy: 0.9790 - 13_categorical_accuracy: 0.8289 - 14_categorical_accuracy: 0.8422 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9539 - 44_categorical_accuracy: 0.7791 - 53_categorical_accuracy: 0.9542 - 54_categorical_accuracy: 0.9660 - reward_categorical_accuracy: 0.7965 - val_loss: 13.9651 - val_03_loss: 1.2911 - val_04_loss: 0.4370 - val_13_loss: 1.7341 - val_14_loss: 1.5799 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5929 - val_44_loss: 2.9395 - val_53_loss: 0.5999 - val_54_loss: 1.8862 - val_reward_loss: 2.9045 - val_03_categorical_accuracy: 0.6079 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5615 - val_14_categorical_accuracy: 0.5891 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8768 - val_44_categorical_accuracy: 0.4532 - val_53_categorical_accuracy: 0.8756 - val_54_categorical_accuracy: 0.8733 - val_reward_categorical_accuracy: 0.4575\n",
      "Epoch 219/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0263 - 03_loss: 0.2782 - 04_loss: 0.0558 - 13_loss: 0.3243 - 14_loss: 0.2866 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0973 - 44_loss: 0.4389 - 53_loss: 0.0970 - 54_loss: 0.0634 - reward_loss: 0.3849 - 03_categorical_accuracy: 0.8473 - 04_categorical_accuracy: 0.9790 - 13_categorical_accuracy: 0.8292 - 14_categorical_accuracy: 0.8414 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9539 - 44_categorical_accuracy: 0.7776 - 53_categorical_accuracy: 0.9543 - 54_categorical_accuracy: 0.9658 - reward_categorical_accuracy: 0.7979 - val_loss: 13.9047 - val_03_loss: 1.2913 - val_04_loss: 0.4381 - val_13_loss: 1.7358 - val_14_loss: 1.5624 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5870 - val_44_loss: 2.9652 - val_53_loss: 0.5986 - val_54_loss: 1.8677 - val_reward_loss: 2.8587 - val_03_categorical_accuracy: 0.6066 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5565 - val_14_categorical_accuracy: 0.5852 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8782 - val_44_categorical_accuracy: 0.4451 - val_53_categorical_accuracy: 0.8757 - val_54_categorical_accuracy: 0.8734 - val_reward_categorical_accuracy: 0.4651\n",
      "Epoch 220/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.0240 - 03_loss: 0.2780 - 04_loss: 0.0557 - 13_loss: 0.3238 - 14_loss: 0.2861 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0971 - 44_loss: 0.4380 - 53_loss: 0.0970 - 54_loss: 0.0633 - reward_loss: 0.3850 - 03_categorical_accuracy: 0.8472 - 04_categorical_accuracy: 0.9789 - 13_categorical_accuracy: 0.8294 - 14_categorical_accuracy: 0.8413 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9542 - 44_categorical_accuracy: 0.7785 - 53_categorical_accuracy: 0.9543 - 54_categorical_accuracy: 0.9656 - reward_categorical_accuracy: 0.7961 - val_loss: 14.0115 - val_03_loss: 1.2992 - val_04_loss: 0.4415 - val_13_loss: 1.7216 - val_14_loss: 1.5666 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5914 - val_44_loss: 2.9586 - val_53_loss: 0.6052 - val_54_loss: 1.9347 - val_reward_loss: 2.8927 - val_03_categorical_accuracy: 0.6068 - val_04_categorical_accuracy: 0.9512 - val_13_categorical_accuracy: 0.5576 - val_14_categorical_accuracy: 0.5899 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8728 - val_44_categorical_accuracy: 0.4509 - val_53_categorical_accuracy: 0.8783 - val_54_categorical_accuracy: 0.8747 - val_reward_categorical_accuracy: 0.4614\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 19s 28ms/step - loss: 2.0199 - 03_loss: 0.2772 - 04_loss: 0.0558 - 13_loss: 0.3231 - 14_loss: 0.2857 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0966 - 44_loss: 0.4369 - 53_loss: 0.0969 - 54_loss: 0.0633 - reward_loss: 0.3844 - 03_categorical_accuracy: 0.8474 - 04_categorical_accuracy: 0.9790 - 13_categorical_accuracy: 0.8303 - 14_categorical_accuracy: 0.8413 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9544 - 44_categorical_accuracy: 0.7786 - 53_categorical_accuracy: 0.9545 - 54_categorical_accuracy: 0.9657 - reward_categorical_accuracy: 0.7968 - val_loss: 13.7408 - val_03_loss: 1.2717 - val_04_loss: 0.4385 - val_13_loss: 1.7032 - val_14_loss: 1.5610 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5849 - val_44_loss: 2.9357 - val_53_loss: 0.5920 - val_54_loss: 1.8595 - val_reward_loss: 2.7943 - val_03_categorical_accuracy: 0.6096 - val_04_categorical_accuracy: 0.9522 - val_13_categorical_accuracy: 0.5553 - val_14_categorical_accuracy: 0.5873 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8815 - val_44_categorical_accuracy: 0.4491 - val_53_categorical_accuracy: 0.8757 - val_54_categorical_accuracy: 0.8738 - val_reward_categorical_accuracy: 0.4598\n",
      "Epoch 222/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0216 - 03_loss: 0.2773 - 04_loss: 0.0557 - 13_loss: 0.3229 - 14_loss: 0.2848 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0972 - 44_loss: 0.4383 - 53_loss: 0.0971 - 54_loss: 0.0632 - reward_loss: 0.3850 - 03_categorical_accuracy: 0.8468 - 04_categorical_accuracy: 0.9790 - 13_categorical_accuracy: 0.8301 - 14_categorical_accuracy: 0.8425 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9540 - 44_categorical_accuracy: 0.7787 - 53_categorical_accuracy: 0.9544 - 54_categorical_accuracy: 0.9658 - reward_categorical_accuracy: 0.7959 - val_loss: 13.8166 - val_03_loss: 1.2895 - val_04_loss: 0.4364 - val_13_loss: 1.7219 - val_14_loss: 1.5669 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5840 - val_44_loss: 2.8920 - val_53_loss: 0.5972 - val_54_loss: 1.8809 - val_reward_loss: 2.8479 - val_03_categorical_accuracy: 0.5992 - val_04_categorical_accuracy: 0.9520 - val_13_categorical_accuracy: 0.5577 - val_14_categorical_accuracy: 0.5908 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8776 - val_44_categorical_accuracy: 0.4478 - val_53_categorical_accuracy: 0.8774 - val_54_categorical_accuracy: 0.8735 - val_reward_categorical_accuracy: 0.4645\n",
      "Epoch 223/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.0205 - 03_loss: 0.2770 - 04_loss: 0.0557 - 13_loss: 0.3233 - 14_loss: 0.2856 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0972 - 44_loss: 0.4377 - 53_loss: 0.0971 - 54_loss: 0.0632 - reward_loss: 0.3838 - 03_categorical_accuracy: 0.8481 - 04_categorical_accuracy: 0.9790 - 13_categorical_accuracy: 0.8306 - 14_categorical_accuracy: 0.8420 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9542 - 44_categorical_accuracy: 0.7787 - 53_categorical_accuracy: 0.9539 - 54_categorical_accuracy: 0.9657 - reward_categorical_accuracy: 0.7974 - val_loss: 13.7996 - val_03_loss: 1.2848 - val_04_loss: 0.4311 - val_13_loss: 1.7241 - val_14_loss: 1.5645 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5908 - val_44_loss: 2.9134 - val_53_loss: 0.5928 - val_54_loss: 1.8686 - val_reward_loss: 2.8295 - val_03_categorical_accuracy: 0.6028 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5595 - val_14_categorical_accuracy: 0.5847 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8761 - val_44_categorical_accuracy: 0.4524 - val_53_categorical_accuracy: 0.8716 - val_54_categorical_accuracy: 0.8735 - val_reward_categorical_accuracy: 0.4663\n",
      "Epoch 224/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0196 - 03_loss: 0.2768 - 04_loss: 0.0559 - 13_loss: 0.3227 - 14_loss: 0.2855 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0969 - 44_loss: 0.4378 - 53_loss: 0.0969 - 54_loss: 0.0630 - reward_loss: 0.3841 - 03_categorical_accuracy: 0.8477 - 04_categorical_accuracy: 0.9791 - 13_categorical_accuracy: 0.8298 - 14_categorical_accuracy: 0.8414 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9545 - 44_categorical_accuracy: 0.7787 - 53_categorical_accuracy: 0.9542 - 54_categorical_accuracy: 0.9659 - reward_categorical_accuracy: 0.7961 - val_loss: 14.0202 - val_03_loss: 1.2928 - val_04_loss: 0.4297 - val_13_loss: 1.7272 - val_14_loss: 1.5772 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5895 - val_44_loss: 2.9620 - val_53_loss: 0.5983 - val_54_loss: 1.9404 - val_reward_loss: 2.9033 - val_03_categorical_accuracy: 0.6004 - val_04_categorical_accuracy: 0.9515 - val_13_categorical_accuracy: 0.5555 - val_14_categorical_accuracy: 0.5880 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8822 - val_44_categorical_accuracy: 0.4520 - val_53_categorical_accuracy: 0.8718 - val_54_categorical_accuracy: 0.8733 - val_reward_categorical_accuracy: 0.4622\n",
      "Epoch 225/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.0174 - 03_loss: 0.2769 - 04_loss: 0.0556 - 13_loss: 0.3227 - 14_loss: 0.2849 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0967 - 44_loss: 0.4374 - 53_loss: 0.0970 - 54_loss: 0.0631 - reward_loss: 0.3831 - 03_categorical_accuracy: 0.8481 - 04_categorical_accuracy: 0.9790 - 13_categorical_accuracy: 0.8300 - 14_categorical_accuracy: 0.8419 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9544 - 44_categorical_accuracy: 0.7785 - 53_categorical_accuracy: 0.9543 - 54_categorical_accuracy: 0.9659 - reward_categorical_accuracy: 0.7974 - val_loss: 13.9370 - val_03_loss: 1.2962 - val_04_loss: 0.4327 - val_13_loss: 1.7194 - val_14_loss: 1.5752 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5832 - val_44_loss: 2.9488 - val_53_loss: 0.5958 - val_54_loss: 1.9087 - val_reward_loss: 2.8768 - val_03_categorical_accuracy: 0.6073 - val_04_categorical_accuracy: 0.9523 - val_13_categorical_accuracy: 0.5560 - val_14_categorical_accuracy: 0.5844 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8775 - val_44_categorical_accuracy: 0.4538 - val_53_categorical_accuracy: 0.8767 - val_54_categorical_accuracy: 0.8733 - val_reward_categorical_accuracy: 0.4641\n",
      "Epoch 226/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0156 - 03_loss: 0.2770 - 04_loss: 0.0556 - 13_loss: 0.3223 - 14_loss: 0.2847 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0966 - 44_loss: 0.4368 - 53_loss: 0.0968 - 54_loss: 0.0631 - reward_loss: 0.3826 - 03_categorical_accuracy: 0.8468 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8298 - 14_categorical_accuracy: 0.8425 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9542 - 44_categorical_accuracy: 0.7793 - 53_categorical_accuracy: 0.9542 - 54_categorical_accuracy: 0.9660 - reward_categorical_accuracy: 0.7970 - val_loss: 14.1501 - val_03_loss: 1.3061 - val_04_loss: 0.4498 - val_13_loss: 1.7455 - val_14_loss: 1.5882 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5973 - val_44_loss: 2.9948 - val_53_loss: 0.6025 - val_54_loss: 1.9600 - val_reward_loss: 2.9059 - val_03_categorical_accuracy: 0.6060 - val_04_categorical_accuracy: 0.9521 - val_13_categorical_accuracy: 0.5549 - val_14_categorical_accuracy: 0.5861 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8704 - val_44_categorical_accuracy: 0.4454 - val_53_categorical_accuracy: 0.8800 - val_54_categorical_accuracy: 0.8729 - val_reward_categorical_accuracy: 0.4657\n",
      "Epoch 227/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.0162 - 03_loss: 0.2769 - 04_loss: 0.0556 - 13_loss: 0.3214 - 14_loss: 0.2851 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0968 - 44_loss: 0.4363 - 53_loss: 0.0969 - 54_loss: 0.0635 - reward_loss: 0.3836 - 03_categorical_accuracy: 0.8478 - 04_categorical_accuracy: 0.9790 - 13_categorical_accuracy: 0.8307 - 14_categorical_accuracy: 0.8416 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9541 - 44_categorical_accuracy: 0.7792 - 53_categorical_accuracy: 0.9541 - 54_categorical_accuracy: 0.9660 - reward_categorical_accuracy: 0.7975 - val_loss: 13.9877 - val_03_loss: 1.3037 - val_04_loss: 0.4533 - val_13_loss: 1.7532 - val_14_loss: 1.5768 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5907 - val_44_loss: 2.9766 - val_53_loss: 0.5915 - val_54_loss: 1.9150 - val_reward_loss: 2.8269 - val_03_categorical_accuracy: 0.6019 - val_04_categorical_accuracy: 0.9517 - val_13_categorical_accuracy: 0.5622 - val_14_categorical_accuracy: 0.5941 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8765 - val_44_categorical_accuracy: 0.4483 - val_53_categorical_accuracy: 0.8754 - val_54_categorical_accuracy: 0.8733 - val_reward_categorical_accuracy: 0.4617\n",
      "Epoch 228/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0147 - 03_loss: 0.2763 - 04_loss: 0.0556 - 13_loss: 0.3220 - 14_loss: 0.2846 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0967 - 44_loss: 0.4360 - 53_loss: 0.0965 - 54_loss: 0.0633 - reward_loss: 0.3837 - 03_categorical_accuracy: 0.8483 - 04_categorical_accuracy: 0.9790 - 13_categorical_accuracy: 0.8303 - 14_categorical_accuracy: 0.8420 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9543 - 44_categorical_accuracy: 0.7793 - 53_categorical_accuracy: 0.9545 - 54_categorical_accuracy: 0.9660 - reward_categorical_accuracy: 0.7976 - val_loss: 13.8961 - val_03_loss: 1.2895 - val_04_loss: 0.4367 - val_13_loss: 1.7375 - val_14_loss: 1.5583 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5947 - val_44_loss: 2.9497 - val_53_loss: 0.6037 - val_54_loss: 1.8602 - val_reward_loss: 2.8658 - val_03_categorical_accuracy: 0.6062 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5593 - val_14_categorical_accuracy: 0.5903 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8794 - val_44_categorical_accuracy: 0.4476 - val_53_categorical_accuracy: 0.8732 - val_54_categorical_accuracy: 0.8734 - val_reward_categorical_accuracy: 0.4624\n",
      "Epoch 229/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0118 - 03_loss: 0.2758 - 04_loss: 0.0556 - 13_loss: 0.3212 - 14_loss: 0.2841 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0964 - 44_loss: 0.4368 - 53_loss: 0.0967 - 54_loss: 0.0629 - reward_loss: 0.3822 - 03_categorical_accuracy: 0.8477 - 04_categorical_accuracy: 0.9790 - 13_categorical_accuracy: 0.8303 - 14_categorical_accuracy: 0.8424 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9546 - 44_categorical_accuracy: 0.7791 - 53_categorical_accuracy: 0.9545 - 54_categorical_accuracy: 0.9661 - reward_categorical_accuracy: 0.7967 - val_loss: 13.8950 - val_03_loss: 1.2840 - val_04_loss: 0.4296 - val_13_loss: 1.7279 - val_14_loss: 1.5755 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5795 - val_44_loss: 2.9724 - val_53_loss: 0.5952 - val_54_loss: 1.8682 - val_reward_loss: 2.8627 - val_03_categorical_accuracy: 0.6081 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5567 - val_14_categorical_accuracy: 0.5885 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8759 - val_44_categorical_accuracy: 0.4532 - val_53_categorical_accuracy: 0.8752 - val_54_categorical_accuracy: 0.8731 - val_reward_categorical_accuracy: 0.4648\n",
      "Epoch 230/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0102 - 03_loss: 0.2764 - 04_loss: 0.0557 - 13_loss: 0.3206 - 14_loss: 0.2840 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0964 - 44_loss: 0.4356 - 53_loss: 0.0965 - 54_loss: 0.0630 - reward_loss: 0.3820 - 03_categorical_accuracy: 0.8480 - 04_categorical_accuracy: 0.9790 - 13_categorical_accuracy: 0.8304 - 14_categorical_accuracy: 0.8422 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9545 - 44_categorical_accuracy: 0.7793 - 53_categorical_accuracy: 0.9540 - 54_categorical_accuracy: 0.9660 - reward_categorical_accuracy: 0.7980 - val_loss: 13.8690 - val_03_loss: 1.2988 - val_04_loss: 0.4326 - val_13_loss: 1.7425 - val_14_loss: 1.5743 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5894 - val_44_loss: 2.9208 - val_53_loss: 0.5989 - val_54_loss: 1.8493 - val_reward_loss: 2.8623 - val_03_categorical_accuracy: 0.6128 - val_04_categorical_accuracy: 0.9520 - val_13_categorical_accuracy: 0.5572 - val_14_categorical_accuracy: 0.5814 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8775 - val_44_categorical_accuracy: 0.4541 - val_53_categorical_accuracy: 0.8744 - val_54_categorical_accuracy: 0.8741 - val_reward_categorical_accuracy: 0.4655\n",
      "Epoch 231/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0092 - 03_loss: 0.2757 - 04_loss: 0.0556 - 13_loss: 0.3208 - 14_loss: 0.2839 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0961 - 44_loss: 0.4355 - 53_loss: 0.0966 - 54_loss: 0.0631 - reward_loss: 0.3820 - 03_categorical_accuracy: 0.8483 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8300 - 14_categorical_accuracy: 0.8426 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9544 - 44_categorical_accuracy: 0.7792 - 53_categorical_accuracy: 0.9543 - 54_categorical_accuracy: 0.9659 - reward_categorical_accuracy: 0.7969 - val_loss: 13.8567 - val_03_loss: 1.2932 - val_04_loss: 0.4442 - val_13_loss: 1.7580 - val_14_loss: 1.5921 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5979 - val_44_loss: 2.9029 - val_53_loss: 0.5974 - val_54_loss: 1.8259 - val_reward_loss: 2.8451 - val_03_categorical_accuracy: 0.6044 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5569 - val_14_categorical_accuracy: 0.5904 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8794 - val_44_categorical_accuracy: 0.4493 - val_53_categorical_accuracy: 0.8767 - val_54_categorical_accuracy: 0.8733 - val_reward_categorical_accuracy: 0.4615\n",
      "Epoch 232/1000\n",
      "697/697 [==============================] - 20s 28ms/step - loss: 2.0086 - 03_loss: 0.2756 - 04_loss: 0.0556 - 13_loss: 0.3205 - 14_loss: 0.2837 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0962 - 44_loss: 0.4356 - 53_loss: 0.0965 - 54_loss: 0.0633 - reward_loss: 0.3817 - 03_categorical_accuracy: 0.8476 - 04_categorical_accuracy: 0.9789 - 13_categorical_accuracy: 0.8307 - 14_categorical_accuracy: 0.8424 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9545 - 44_categorical_accuracy: 0.7791 - 53_categorical_accuracy: 0.9543 - 54_categorical_accuracy: 0.9660 - reward_categorical_accuracy: 0.7971 - val_loss: 13.9462 - val_03_loss: 1.2946 - val_04_loss: 0.4309 - val_13_loss: 1.7303 - val_14_loss: 1.5795 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5876 - val_44_loss: 2.9539 - val_53_loss: 0.5985 - val_54_loss: 1.8830 - val_reward_loss: 2.8878 - val_03_categorical_accuracy: 0.6033 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5558 - val_14_categorical_accuracy: 0.5884 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8773 - val_44_categorical_accuracy: 0.4531 - val_53_categorical_accuracy: 0.8771 - val_54_categorical_accuracy: 0.8736 - val_reward_categorical_accuracy: 0.4706\n",
      "Epoch 233/1000\n",
      "697/697 [==============================] - 18s 27ms/step - loss: 2.0075 - 03_loss: 0.2755 - 04_loss: 0.0554 - 13_loss: 0.3212 - 14_loss: 0.2831 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0960 - 44_loss: 0.4356 - 53_loss: 0.0963 - 54_loss: 0.0630 - reward_loss: 0.3814 - 03_categorical_accuracy: 0.8481 - 04_categorical_accuracy: 0.9791 - 13_categorical_accuracy: 0.8303 - 14_categorical_accuracy: 0.8429 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9549 - 44_categorical_accuracy: 0.7788 - 53_categorical_accuracy: 0.9544 - 54_categorical_accuracy: 0.9660 - reward_categorical_accuracy: 0.7975 - val_loss: 14.0937 - val_03_loss: 1.2985 - val_04_loss: 0.4526 - val_13_loss: 1.7602 - val_14_loss: 1.5969 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5997 - val_44_loss: 2.9816 - val_53_loss: 0.6031 - val_54_loss: 1.9093 - val_reward_loss: 2.8917 - val_03_categorical_accuracy: 0.6028 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5566 - val_14_categorical_accuracy: 0.5896 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8723 - val_44_categorical_accuracy: 0.4478 - val_53_categorical_accuracy: 0.8764 - val_54_categorical_accuracy: 0.8737 - val_reward_categorical_accuracy: 0.4570\n",
      "Epoch 234/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.0053 - 03_loss: 0.2755 - 04_loss: 0.0556 - 13_loss: 0.3202 - 14_loss: 0.2831 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0964 - 44_loss: 0.4349 - 53_loss: 0.0961 - 54_loss: 0.0629 - reward_loss: 0.3808 - 03_categorical_accuracy: 0.8478 - 04_categorical_accuracy: 0.9791 - 13_categorical_accuracy: 0.8306 - 14_categorical_accuracy: 0.8426 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9543 - 44_categorical_accuracy: 0.7798 - 53_categorical_accuracy: 0.9544 - 54_categorical_accuracy: 0.9664 - reward_categorical_accuracy: 0.7979 - val_loss: 14.1287 - val_03_loss: 1.3004 - val_04_loss: 0.4433 - val_13_loss: 1.7423 - val_14_loss: 1.5957 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5978 - val_44_loss: 2.9824 - val_53_loss: 0.6093 - val_54_loss: 1.9407 - val_reward_loss: 2.9167 - val_03_categorical_accuracy: 0.6031 - val_04_categorical_accuracy: 0.9513 - val_13_categorical_accuracy: 0.5580 - val_14_categorical_accuracy: 0.5881 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8745 - val_44_categorical_accuracy: 0.4483 - val_53_categorical_accuracy: 0.8788 - val_54_categorical_accuracy: 0.8721 - val_reward_categorical_accuracy: 0.4614\n",
      "Epoch 235/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0057 - 03_loss: 0.2754 - 04_loss: 0.0555 - 13_loss: 0.3201 - 14_loss: 0.2831 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0958 - 44_loss: 0.4348 - 53_loss: 0.0964 - 54_loss: 0.0631 - reward_loss: 0.3814 - 03_categorical_accuracy: 0.8484 - 04_categorical_accuracy: 0.9790 - 13_categorical_accuracy: 0.8310 - 14_categorical_accuracy: 0.8426 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9544 - 44_categorical_accuracy: 0.7791 - 53_categorical_accuracy: 0.9546 - 54_categorical_accuracy: 0.9656 - reward_categorical_accuracy: 0.7970 - val_loss: 14.0111 - val_03_loss: 1.2795 - val_04_loss: 0.4428 - val_13_loss: 1.7417 - val_14_loss: 1.5988 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5958 - val_44_loss: 2.9467 - val_53_loss: 0.5928 - val_54_loss: 1.9270 - val_reward_loss: 2.8861 - val_03_categorical_accuracy: 0.6014 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5588 - val_14_categorical_accuracy: 0.5907 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8780 - val_44_categorical_accuracy: 0.4489 - val_53_categorical_accuracy: 0.8739 - val_54_categorical_accuracy: 0.8734 - val_reward_categorical_accuracy: 0.4625\n",
      "Epoch 236/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.0031 - 03_loss: 0.2748 - 04_loss: 0.0555 - 13_loss: 0.3198 - 14_loss: 0.2829 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0963 - 44_loss: 0.4345 - 53_loss: 0.0960 - 54_loss: 0.0630 - reward_loss: 0.3801 - 03_categorical_accuracy: 0.8484 - 04_categorical_accuracy: 0.9791 - 13_categorical_accuracy: 0.8310 - 14_categorical_accuracy: 0.8426 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9545 - 44_categorical_accuracy: 0.7798 - 53_categorical_accuracy: 0.9548 - 54_categorical_accuracy: 0.9659 - reward_categorical_accuracy: 0.7979 - val_loss: 14.0826 - val_03_loss: 1.2955 - val_04_loss: 0.4366 - val_13_loss: 1.7363 - val_14_loss: 1.5880 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5968 - val_44_loss: 2.9544 - val_53_loss: 0.5975 - val_54_loss: 1.9792 - val_reward_loss: 2.8983 - val_03_categorical_accuracy: 0.6085 - val_04_categorical_accuracy: 0.9517 - val_13_categorical_accuracy: 0.5602 - val_14_categorical_accuracy: 0.5894 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8807 - val_44_categorical_accuracy: 0.4523 - val_53_categorical_accuracy: 0.8763 - val_54_categorical_accuracy: 0.8741 - val_reward_categorical_accuracy: 0.4639\n",
      "Epoch 237/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 2.0035 - 03_loss: 0.2750 - 04_loss: 0.0556 - 13_loss: 0.3196 - 14_loss: 0.2824 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0962 - 44_loss: 0.4353 - 53_loss: 0.0960 - 54_loss: 0.0630 - reward_loss: 0.3805 - 03_categorical_accuracy: 0.8485 - 04_categorical_accuracy: 0.9790 - 13_categorical_accuracy: 0.8313 - 14_categorical_accuracy: 0.8432 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9545 - 44_categorical_accuracy: 0.7785 - 53_categorical_accuracy: 0.9542 - 54_categorical_accuracy: 0.9661 - reward_categorical_accuracy: 0.7985 - val_loss: 14.1079 - val_03_loss: 1.2999 - val_04_loss: 0.4370 - val_13_loss: 1.7608 - val_14_loss: 1.5958 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.6005 - val_44_loss: 2.9735 - val_53_loss: 0.5973 - val_54_loss: 1.9487 - val_reward_loss: 2.8944 - val_03_categorical_accuracy: 0.6092 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5554 - val_14_categorical_accuracy: 0.5890 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8806 - val_44_categorical_accuracy: 0.4477 - val_53_categorical_accuracy: 0.8715 - val_54_categorical_accuracy: 0.8734 - val_reward_categorical_accuracy: 0.4636\n",
      "Epoch 238/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0013 - 03_loss: 0.2747 - 04_loss: 0.0554 - 13_loss: 0.3193 - 14_loss: 0.2825 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0956 - 44_loss: 0.4348 - 53_loss: 0.0961 - 54_loss: 0.0629 - reward_loss: 0.3800 - 03_categorical_accuracy: 0.8477 - 04_categorical_accuracy: 0.9789 - 13_categorical_accuracy: 0.8302 - 14_categorical_accuracy: 0.8427 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9544 - 44_categorical_accuracy: 0.7799 - 53_categorical_accuracy: 0.9546 - 54_categorical_accuracy: 0.9656 - reward_categorical_accuracy: 0.7973 - val_loss: 14.0997 - val_03_loss: 1.2961 - val_04_loss: 0.4550 - val_13_loss: 1.7336 - val_14_loss: 1.5765 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5989 - val_44_loss: 2.9737 - val_53_loss: 0.5977 - val_54_loss: 1.9443 - val_reward_loss: 2.9240 - val_03_categorical_accuracy: 0.6084 - val_04_categorical_accuracy: 0.9520 - val_13_categorical_accuracy: 0.5583 - val_14_categorical_accuracy: 0.5869 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8767 - val_44_categorical_accuracy: 0.4513 - val_53_categorical_accuracy: 0.8767 - val_54_categorical_accuracy: 0.8735 - val_reward_categorical_accuracy: 0.4652\n",
      "Epoch 239/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0026 - 03_loss: 0.2750 - 04_loss: 0.0557 - 13_loss: 0.3197 - 14_loss: 0.2823 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0961 - 44_loss: 0.4337 - 53_loss: 0.0963 - 54_loss: 0.0633 - reward_loss: 0.3804 - 03_categorical_accuracy: 0.8486 - 04_categorical_accuracy: 0.9789 - 13_categorical_accuracy: 0.8305 - 14_categorical_accuracy: 0.8433 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9546 - 44_categorical_accuracy: 0.7797 - 53_categorical_accuracy: 0.9544 - 54_categorical_accuracy: 0.9662 - reward_categorical_accuracy: 0.7987 - val_loss: 13.8203 - val_03_loss: 1.2836 - val_04_loss: 0.4524 - val_13_loss: 1.7260 - val_14_loss: 1.5700 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5859 - val_44_loss: 2.9284 - val_53_loss: 0.5898 - val_54_loss: 1.8460 - val_reward_loss: 2.8382 - val_03_categorical_accuracy: 0.6068 - val_04_categorical_accuracy: 0.9517 - val_13_categorical_accuracy: 0.5579 - val_14_categorical_accuracy: 0.5870 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8816 - val_44_categorical_accuracy: 0.4536 - val_53_categorical_accuracy: 0.8760 - val_54_categorical_accuracy: 0.8738 - val_reward_categorical_accuracy: 0.4651\n",
      "Epoch 240/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 2.0001 - 03_loss: 0.2743 - 04_loss: 0.0557 - 13_loss: 0.3187 - 14_loss: 0.2819 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0963 - 44_loss: 0.4340 - 53_loss: 0.0960 - 54_loss: 0.0631 - reward_loss: 0.3801 - 03_categorical_accuracy: 0.8488 - 04_categorical_accuracy: 0.9789 - 13_categorical_accuracy: 0.8316 - 14_categorical_accuracy: 0.8436 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9540 - 44_categorical_accuracy: 0.7794 - 53_categorical_accuracy: 0.9547 - 54_categorical_accuracy: 0.9659 - reward_categorical_accuracy: 0.7973 - val_loss: 14.2038 - val_03_loss: 1.3086 - val_04_loss: 0.4565 - val_13_loss: 1.7478 - val_14_loss: 1.5999 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5948 - val_44_loss: 2.9742 - val_53_loss: 0.6120 - val_54_loss: 1.9857 - val_reward_loss: 2.9243 - val_03_categorical_accuracy: 0.6064 - val_04_categorical_accuracy: 0.9513 - val_13_categorical_accuracy: 0.5592 - val_14_categorical_accuracy: 0.5908 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8766 - val_44_categorical_accuracy: 0.4516 - val_53_categorical_accuracy: 0.8771 - val_54_categorical_accuracy: 0.8737 - val_reward_categorical_accuracy: 0.4576\n",
      "Epoch 241/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 19s 28ms/step - loss: 1.9975 - 03_loss: 0.2740 - 04_loss: 0.0554 - 13_loss: 0.3184 - 14_loss: 0.2819 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0957 - 44_loss: 0.4334 - 53_loss: 0.0960 - 54_loss: 0.0629 - reward_loss: 0.3797 - 03_categorical_accuracy: 0.8487 - 04_categorical_accuracy: 0.9790 - 13_categorical_accuracy: 0.8311 - 14_categorical_accuracy: 0.8426 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9545 - 44_categorical_accuracy: 0.7792 - 53_categorical_accuracy: 0.9546 - 54_categorical_accuracy: 0.9660 - reward_categorical_accuracy: 0.7971 - val_loss: 14.2705 - val_03_loss: 1.3124 - val_04_loss: 0.4528 - val_13_loss: 1.7724 - val_14_loss: 1.6216 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.6113 - val_44_loss: 3.0252 - val_53_loss: 0.6147 - val_54_loss: 1.9316 - val_reward_loss: 2.9284 - val_03_categorical_accuracy: 0.6083 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5509 - val_14_categorical_accuracy: 0.5862 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8768 - val_44_categorical_accuracy: 0.4473 - val_53_categorical_accuracy: 0.8782 - val_54_categorical_accuracy: 0.8731 - val_reward_categorical_accuracy: 0.4612\n",
      "Epoch 242/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 1.9969 - 03_loss: 0.2735 - 04_loss: 0.0555 - 13_loss: 0.3185 - 14_loss: 0.2819 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0956 - 44_loss: 0.4343 - 53_loss: 0.0958 - 54_loss: 0.0629 - reward_loss: 0.3789 - 03_categorical_accuracy: 0.8492 - 04_categorical_accuracy: 0.9790 - 13_categorical_accuracy: 0.8316 - 14_categorical_accuracy: 0.8432 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9546 - 44_categorical_accuracy: 0.7793 - 53_categorical_accuracy: 0.9545 - 54_categorical_accuracy: 0.9661 - reward_categorical_accuracy: 0.7987 - val_loss: 14.2598 - val_03_loss: 1.3043 - val_04_loss: 0.4512 - val_13_loss: 1.7605 - val_14_loss: 1.6059 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.6001 - val_44_loss: 3.0069 - val_53_loss: 0.6078 - val_54_loss: 1.9701 - val_reward_loss: 2.9530 - val_03_categorical_accuracy: 0.6082 - val_04_categorical_accuracy: 0.9517 - val_13_categorical_accuracy: 0.5572 - val_14_categorical_accuracy: 0.5901 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8772 - val_44_categorical_accuracy: 0.4464 - val_53_categorical_accuracy: 0.8777 - val_54_categorical_accuracy: 0.8734 - val_reward_categorical_accuracy: 0.4559\n",
      "Epoch 243/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 1.9947 - 03_loss: 0.2737 - 04_loss: 0.0557 - 13_loss: 0.3180 - 14_loss: 0.2816 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0954 - 44_loss: 0.4329 - 53_loss: 0.0953 - 54_loss: 0.0626 - reward_loss: 0.3796 - 03_categorical_accuracy: 0.8486 - 04_categorical_accuracy: 0.9791 - 13_categorical_accuracy: 0.8309 - 14_categorical_accuracy: 0.8435 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9547 - 44_categorical_accuracy: 0.7799 - 53_categorical_accuracy: 0.9548 - 54_categorical_accuracy: 0.9659 - reward_categorical_accuracy: 0.7977 - val_loss: 14.1781 - val_03_loss: 1.3174 - val_04_loss: 0.4634 - val_13_loss: 1.7648 - val_14_loss: 1.6140 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5973 - val_44_loss: 3.0050 - val_53_loss: 0.6081 - val_54_loss: 1.9376 - val_reward_loss: 2.8705 - val_03_categorical_accuracy: 0.6127 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5579 - val_14_categorical_accuracy: 0.5897 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8788 - val_44_categorical_accuracy: 0.4500 - val_53_categorical_accuracy: 0.8776 - val_54_categorical_accuracy: 0.8734 - val_reward_categorical_accuracy: 0.4572\n",
      "Epoch 244/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 1.9958 - 03_loss: 0.2736 - 04_loss: 0.0559 - 13_loss: 0.3175 - 14_loss: 0.2812 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0955 - 44_loss: 0.4332 - 53_loss: 0.0961 - 54_loss: 0.0632 - reward_loss: 0.3795 - 03_categorical_accuracy: 0.8491 - 04_categorical_accuracy: 0.9790 - 13_categorical_accuracy: 0.8313 - 14_categorical_accuracy: 0.8436 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9547 - 44_categorical_accuracy: 0.7799 - 53_categorical_accuracy: 0.9541 - 54_categorical_accuracy: 0.9662 - reward_categorical_accuracy: 0.7975 - val_loss: 14.1797 - val_03_loss: 1.3146 - val_04_loss: 0.4501 - val_13_loss: 1.7593 - val_14_loss: 1.6203 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5972 - val_44_loss: 2.9923 - val_53_loss: 0.6034 - val_54_loss: 1.9196 - val_reward_loss: 2.9230 - val_03_categorical_accuracy: 0.6107 - val_04_categorical_accuracy: 0.9520 - val_13_categorical_accuracy: 0.5561 - val_14_categorical_accuracy: 0.5890 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8779 - val_44_categorical_accuracy: 0.4477 - val_53_categorical_accuracy: 0.8747 - val_54_categorical_accuracy: 0.8739 - val_reward_categorical_accuracy: 0.4610\n",
      "Epoch 245/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 1.9958 - 03_loss: 0.2736 - 04_loss: 0.0555 - 13_loss: 0.3180 - 14_loss: 0.2814 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0959 - 44_loss: 0.4332 - 53_loss: 0.0958 - 54_loss: 0.0634 - reward_loss: 0.3791 - 03_categorical_accuracy: 0.8482 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8315 - 14_categorical_accuracy: 0.8433 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9545 - 44_categorical_accuracy: 0.7799 - 53_categorical_accuracy: 0.9545 - 54_categorical_accuracy: 0.9660 - reward_categorical_accuracy: 0.7988 - val_loss: 14.0551 - val_03_loss: 1.3134 - val_04_loss: 0.4569 - val_13_loss: 1.7567 - val_14_loss: 1.6048 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5921 - val_44_loss: 2.9382 - val_53_loss: 0.5950 - val_54_loss: 1.9053 - val_reward_loss: 2.8927 - val_03_categorical_accuracy: 0.6059 - val_04_categorical_accuracy: 0.9521 - val_13_categorical_accuracy: 0.5603 - val_14_categorical_accuracy: 0.5907 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8784 - val_44_categorical_accuracy: 0.4544 - val_53_categorical_accuracy: 0.8749 - val_54_categorical_accuracy: 0.8740 - val_reward_categorical_accuracy: 0.4598\n",
      "Epoch 246/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 1.9932 - 03_loss: 0.2734 - 04_loss: 0.0555 - 13_loss: 0.3173 - 14_loss: 0.2811 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0956 - 44_loss: 0.4336 - 53_loss: 0.0955 - 54_loss: 0.0627 - reward_loss: 0.3785 - 03_categorical_accuracy: 0.8479 - 04_categorical_accuracy: 0.9791 - 13_categorical_accuracy: 0.8309 - 14_categorical_accuracy: 0.8434 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9545 - 44_categorical_accuracy: 0.7792 - 53_categorical_accuracy: 0.9546 - 54_categorical_accuracy: 0.9659 - reward_categorical_accuracy: 0.7978 - val_loss: 14.3024 - val_03_loss: 1.3235 - val_04_loss: 0.4517 - val_13_loss: 1.7752 - val_14_loss: 1.6143 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.6035 - val_44_loss: 3.0320 - val_53_loss: 0.6046 - val_54_loss: 1.9619 - val_reward_loss: 2.9357 - val_03_categorical_accuracy: 0.6048 - val_04_categorical_accuracy: 0.9516 - val_13_categorical_accuracy: 0.5609 - val_14_categorical_accuracy: 0.5880 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8803 - val_44_categorical_accuracy: 0.4474 - val_53_categorical_accuracy: 0.8807 - val_54_categorical_accuracy: 0.8742 - val_reward_categorical_accuracy: 0.4657\n",
      "Epoch 247/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 1.9911 - 03_loss: 0.2733 - 04_loss: 0.0555 - 13_loss: 0.3166 - 14_loss: 0.2804 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0954 - 44_loss: 0.4325 - 53_loss: 0.0957 - 54_loss: 0.0630 - reward_loss: 0.3786 - 03_categorical_accuracy: 0.8495 - 04_categorical_accuracy: 0.9792 - 13_categorical_accuracy: 0.8321 - 14_categorical_accuracy: 0.8436 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9546 - 44_categorical_accuracy: 0.7794 - 53_categorical_accuracy: 0.9546 - 54_categorical_accuracy: 0.9659 - reward_categorical_accuracy: 0.7980 - val_loss: 14.4284 - val_03_loss: 1.3133 - val_04_loss: 0.4580 - val_13_loss: 1.8028 - val_14_loss: 1.6591 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.6071 - val_44_loss: 2.9573 - val_53_loss: 0.6117 - val_54_loss: 2.0187 - val_reward_loss: 3.0005 - val_03_categorical_accuracy: 0.6069 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5583 - val_14_categorical_accuracy: 0.5888 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8763 - val_44_categorical_accuracy: 0.4515 - val_53_categorical_accuracy: 0.8760 - val_54_categorical_accuracy: 0.8742 - val_reward_categorical_accuracy: 0.4615\n",
      "Epoch 248/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 1.9905 - 03_loss: 0.2732 - 04_loss: 0.0558 - 13_loss: 0.3173 - 14_loss: 0.2805 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0955 - 44_loss: 0.4320 - 53_loss: 0.0956 - 54_loss: 0.0629 - reward_loss: 0.3777 - 03_categorical_accuracy: 0.8482 - 04_categorical_accuracy: 0.9788 - 13_categorical_accuracy: 0.8318 - 14_categorical_accuracy: 0.8436 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9548 - 44_categorical_accuracy: 0.7799 - 53_categorical_accuracy: 0.9544 - 54_categorical_accuracy: 0.9662 - reward_categorical_accuracy: 0.7981 - val_loss: 14.4705 - val_03_loss: 1.3216 - val_04_loss: 0.4644 - val_13_loss: 1.7969 - val_14_loss: 1.6479 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5983 - val_44_loss: 3.0055 - val_53_loss: 0.6100 - val_54_loss: 2.0313 - val_reward_loss: 2.9946 - val_03_categorical_accuracy: 0.6065 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5586 - val_14_categorical_accuracy: 0.5919 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8791 - val_44_categorical_accuracy: 0.4475 - val_53_categorical_accuracy: 0.8731 - val_54_categorical_accuracy: 0.8736 - val_reward_categorical_accuracy: 0.4576\n",
      "Epoch 249/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 1.9886 - 03_loss: 0.2726 - 04_loss: 0.0554 - 13_loss: 0.3167 - 14_loss: 0.2805 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0954 - 44_loss: 0.4318 - 53_loss: 0.0956 - 54_loss: 0.0630 - reward_loss: 0.3775 - 03_categorical_accuracy: 0.8489 - 04_categorical_accuracy: 0.9792 - 13_categorical_accuracy: 0.8315 - 14_categorical_accuracy: 0.8434 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9547 - 44_categorical_accuracy: 0.7807 - 53_categorical_accuracy: 0.9548 - 54_categorical_accuracy: 0.9658 - reward_categorical_accuracy: 0.7989 - val_loss: 14.2745 - val_03_loss: 1.3194 - val_04_loss: 0.4599 - val_13_loss: 1.8060 - val_14_loss: 1.6206 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.6121 - val_44_loss: 2.9655 - val_53_loss: 0.6059 - val_54_loss: 1.9633 - val_reward_loss: 2.9218 - val_03_categorical_accuracy: 0.5969 - val_04_categorical_accuracy: 0.9518 - val_13_categorical_accuracy: 0.5637 - val_14_categorical_accuracy: 0.5941 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8804 - val_44_categorical_accuracy: 0.4536 - val_53_categorical_accuracy: 0.8747 - val_54_categorical_accuracy: 0.8740 - val_reward_categorical_accuracy: 0.4629\n",
      "Epoch 250/1000\n",
      "697/697 [==============================] - 20s 28ms/step - loss: 1.9889 - 03_loss: 0.2727 - 04_loss: 0.0555 - 13_loss: 0.3166 - 14_loss: 0.2805 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0953 - 44_loss: 0.4324 - 53_loss: 0.0954 - 54_loss: 0.0630 - reward_loss: 0.3774 - 03_categorical_accuracy: 0.8488 - 04_categorical_accuracy: 0.9790 - 13_categorical_accuracy: 0.8320 - 14_categorical_accuracy: 0.8440 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9543 - 44_categorical_accuracy: 0.7798 - 53_categorical_accuracy: 0.9547 - 54_categorical_accuracy: 0.9663 - reward_categorical_accuracy: 0.7985 - val_loss: 14.5256 - val_03_loss: 1.3384 - val_04_loss: 0.4661 - val_13_loss: 1.8183 - val_14_loss: 1.6579 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.6132 - val_44_loss: 3.0951 - val_53_loss: 0.6102 - val_54_loss: 1.9511 - val_reward_loss: 2.9753 - val_03_categorical_accuracy: 0.6023 - val_04_categorical_accuracy: 0.9513 - val_13_categorical_accuracy: 0.5577 - val_14_categorical_accuracy: 0.5884 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8748 - val_44_categorical_accuracy: 0.4515 - val_53_categorical_accuracy: 0.8742 - val_54_categorical_accuracy: 0.8737 - val_reward_categorical_accuracy: 0.4616\n",
      "Epoch 251/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 18s 27ms/step - loss: 1.9871 - 03_loss: 0.2727 - 04_loss: 0.0555 - 13_loss: 0.3162 - 14_loss: 0.2799 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0957 - 44_loss: 0.4321 - 53_loss: 0.0953 - 54_loss: 0.0626 - reward_loss: 0.3771 - 03_categorical_accuracy: 0.8487 - 04_categorical_accuracy: 0.9792 - 13_categorical_accuracy: 0.8319 - 14_categorical_accuracy: 0.8433 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9544 - 44_categorical_accuracy: 0.7809 - 53_categorical_accuracy: 0.9547 - 54_categorical_accuracy: 0.9661 - reward_categorical_accuracy: 0.7984 - val_loss: 14.3372 - val_03_loss: 1.3430 - val_04_loss: 0.4488 - val_13_loss: 1.7952 - val_14_loss: 1.6272 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5954 - val_44_loss: 3.0187 - val_53_loss: 0.6137 - val_54_loss: 1.9456 - val_reward_loss: 2.9497 - val_03_categorical_accuracy: 0.6112 - val_04_categorical_accuracy: 0.9517 - val_13_categorical_accuracy: 0.5545 - val_14_categorical_accuracy: 0.5842 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8784 - val_44_categorical_accuracy: 0.4470 - val_53_categorical_accuracy: 0.8781 - val_54_categorical_accuracy: 0.8740 - val_reward_categorical_accuracy: 0.4599\n",
      "Epoch 252/1000\n",
      "697/697 [==============================] - 19s 27ms/step - loss: 1.9858 - 03_loss: 0.2723 - 04_loss: 0.0555 - 13_loss: 0.3163 - 14_loss: 0.2797 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0957 - 44_loss: 0.4317 - 53_loss: 0.0953 - 54_loss: 0.0626 - reward_loss: 0.3767 - 03_categorical_accuracy: 0.8497 - 04_categorical_accuracy: 0.9791 - 13_categorical_accuracy: 0.8312 - 14_categorical_accuracy: 0.8440 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9545 - 44_categorical_accuracy: 0.7802 - 53_categorical_accuracy: 0.9546 - 54_categorical_accuracy: 0.9664 - reward_categorical_accuracy: 0.7990 - val_loss: 14.3843 - val_03_loss: 1.3223 - val_04_loss: 0.4536 - val_13_loss: 1.7761 - val_14_loss: 1.6257 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.5989 - val_44_loss: 2.9837 - val_53_loss: 0.6068 - val_54_loss: 2.0541 - val_reward_loss: 2.9631 - val_03_categorical_accuracy: 0.6069 - val_04_categorical_accuracy: 0.9519 - val_13_categorical_accuracy: 0.5611 - val_14_categorical_accuracy: 0.5918 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8765 - val_44_categorical_accuracy: 0.4496 - val_53_categorical_accuracy: 0.8789 - val_54_categorical_accuracy: 0.8739 - val_reward_categorical_accuracy: 0.4580\n",
      "Epoch 253/1000\n",
      "697/697 [==============================] - 19s 28ms/step - loss: 1.9852 - 03_loss: 0.2729 - 04_loss: 0.0554 - 13_loss: 0.3159 - 14_loss: 0.2795 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0954 - 44_loss: 0.4313 - 53_loss: 0.0953 - 54_loss: 0.0628 - reward_loss: 0.3767 - 03_categorical_accuracy: 0.8487 - 04_categorical_accuracy: 0.9792 - 13_categorical_accuracy: 0.8322 - 14_categorical_accuracy: 0.8433 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9546 - 44_categorical_accuracy: 0.7801 - 53_categorical_accuracy: 0.9549 - 54_categorical_accuracy: 0.9660 - reward_categorical_accuracy: 0.7990 - val_loss: 14.6120 - val_03_loss: 1.3196 - val_04_loss: 0.4685 - val_13_loss: 1.8096 - val_14_loss: 1.6528 - val_23_loss: 0.0000e+00 - val_24_loss: 0.0000e+00 - val_33_loss: 0.0000e+00 - val_34_loss: 0.0000e+00 - val_43_loss: 0.6080 - val_44_loss: 3.0746 - val_53_loss: 0.6127 - val_54_loss: 2.0659 - val_reward_loss: 3.0003 - val_03_categorical_accuracy: 0.6052 - val_04_categorical_accuracy: 0.9517 - val_13_categorical_accuracy: 0.5583 - val_14_categorical_accuracy: 0.5925 - val_23_categorical_accuracy: 1.0000 - val_24_categorical_accuracy: 1.0000 - val_33_categorical_accuracy: 1.0000 - val_34_categorical_accuracy: 1.0000 - val_43_categorical_accuracy: 0.8763 - val_44_categorical_accuracy: 0.4483 - val_53_categorical_accuracy: 0.8770 - val_54_categorical_accuracy: 0.8741 - val_reward_categorical_accuracy: 0.4627\n",
      "Epoch 254/1000\n",
      "576/697 [=======================>......] - ETA: 3s - loss: 1.9620 - 03_loss: 0.2689 - 04_loss: 0.0549 - 13_loss: 0.3129 - 14_loss: 0.2764 - 23_loss: 0.0000e+00 - 24_loss: 0.0000e+00 - 33_loss: 0.0000e+00 - 34_loss: 0.0000e+00 - 43_loss: 0.0936 - 44_loss: 0.4275 - 53_loss: 0.0937 - 54_loss: 0.0625 - reward_loss: 0.3716 - 03_categorical_accuracy: 0.8512 - 04_categorical_accuracy: 0.9794 - 13_categorical_accuracy: 0.8333 - 14_categorical_accuracy: 0.8459 - 23_categorical_accuracy: 1.0000 - 24_categorical_accuracy: 1.0000 - 33_categorical_accuracy: 1.0000 - 34_categorical_accuracy: 1.0000 - 43_categorical_accuracy: 0.9557 - 44_categorical_accuracy: 0.7828 - 53_categorical_accuracy: 0.9553 - 54_categorical_accuracy: 0.9663 - reward_categorical_accuracy: 0.8016"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 47\u001b[0m\n\u001b[1;32m     43\u001b[0m K\u001b[38;5;241m.\u001b[39mset_value(model\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mlearning_rate, \u001b[38;5;241m0.0005\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#model.fit(train_dataset,epochs=250, verbose=1, callbacks=[callback])\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates_actions_seq_10\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM, Input, GRU\n",
    "from keras.layers import Bidirectional\n",
    "from keras.models import Model\n",
    "\n",
    "NUM_NODES = 6\n",
    "NODE_CLASSES = [3, 4]\n",
    "\n",
    "data_map = {}\n",
    "losses = []\n",
    "index = 0\n",
    "for i in range(NUM_NODES):\n",
    "    for n in NODE_CLASSES:\n",
    "        data_map[str(i)+str(n)] = next_states[:,index:index+n]\n",
    "        losses.append(tf.keras.losses.CategoricalCrossentropy())\n",
    "        index += n\n",
    "data_map['reward'] = reward_encoding\n",
    "losses.append(tf.keras.losses.CategoricalCrossentropy())\n",
    "        \n",
    "input_ = Input(shape=(10,42+20,))\n",
    "#x = Bidirectional(LSTM(64, activation='relu', return_sequences=True))(input_)\n",
    "#x = Bidirectional(GRU(64))(input_)\n",
    "x = Bidirectional(LSTM(256))(input_)\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "\n",
    "outs = []\n",
    "for i in range(NUM_NODES):\n",
    "    for n in NODE_CLASSES:\n",
    "        x_ = Dense(256, activation='relu')(x)\n",
    "        outs.append(Dense(n, activation='softmax', name=str(i)+str(n))(x_))\n",
    "        \n",
    "x_ = Dense(256, activation='relu')(x)\n",
    "outs.append(Dense(6, activation='softmax', name='reward')(x_))\n",
    "\n",
    "model = Model(input_, outs)\n",
    "model.compile(optimizer='adam', loss=losses, metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=7)\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_value(model.optimizer.learning_rate, 0.0005)\n",
    "\n",
    "#model.fit(train_dataset,epochs=250, verbose=1, callbacks=[callback])\n",
    "\n",
    "model.fit(states_actions_seq_10, data_map, epochs=1000, validation_split=0.1, verbose=1, callbacks=[callback], batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = model.predict(states_actions[0:1])\n",
    "\n",
    "state = np.zeros(42)\n",
    "index_state = 0\n",
    "index = 0\n",
    "for i in range(NUM_NODES):\n",
    "    for n in NODE_CLASSES:\n",
    "        state[index_state+np.random.choice(np.arange(n), p=probs[index][0])] = 1\n",
    "        index_state += n\n",
    "        index += 1\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "[array([[9.9999988e-01, 2.8316990e-10, 6.2747894e-08]], dtype=float32), array([[1.4892132e-35, 9.9999988e-01, 3.8243346e-08, 1.2682605e-07]],\n",
      "      dtype=float32), array([[2.6334348e-08, 6.1443985e-02, 9.3855602e-01]], dtype=float32), array([[0.00808789, 0.7319339 , 0.02746691, 0.23251131]], dtype=float32), array([[1.3898515e-15, 1.0057768e-15, 1.0000000e+00]], dtype=float32), array([[4.0497008e-16, 5.7430210e-16, 4.9967082e-16, 1.0000000e+00]],\n",
      "      dtype=float32), array([[4.0957807e-16, 3.2186437e-16, 1.0000000e+00]], dtype=float32), array([[7.2782153e-16, 8.9383671e-16, 1.0721520e-15, 1.0000000e+00]],\n",
      "      dtype=float32), array([[3.632320e-08, 2.473178e-02, 9.752681e-01]], dtype=float32), array([[1.01864416e-07, 3.16646350e-07, 3.63653725e-12, 9.99999523e-01]],\n",
      "      dtype=float32), array([[2.7840000e-10, 4.2507645e-02, 9.5749241e-01]], dtype=float32), array([[3.4164978e-09, 2.7237392e-13, 1.2582257e-14, 1.0000000e+00]],\n",
      "      dtype=float32)]\n",
      "68\n",
      "[1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 1]\n",
      "18\n",
      "[1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 1]\n",
      "5\n",
      "[1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 1]\n",
      "3\n",
      "[1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 1]\n",
      "3\n",
      "[1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1\n",
      " 0 0 0 0 1]\n",
      "2\n",
      "[1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1\n",
      " 0 0 0 0 1]\n",
      "1\n",
      "[1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 1]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(np.array([states_actions[50]]))\n",
    "print(prediction)\n",
    "\n",
    "new_state = {}\n",
    "\n",
    "for i in range(100):\n",
    "    state = np.zeros(42, dtype=np.int8)\n",
    "    index_state, index = 0, 0\n",
    "    for i in range(NUM_NODES):\n",
    "        for n in NODE_CLASSES:\n",
    "            state[index_state+np.random.choice(np.arange(n), p=prediction[index][0])] = 1\n",
    "            index_state += n; index += 1\n",
    "    if not state.tobytes() in new_state:\n",
    "        new_state[state.tobytes()] = 1\n",
    "    else:\n",
    "        new_state[state.tobytes()] += 1\n",
    "        \n",
    "ns = {k: v for k, v in sorted(new_state.items(), key=lambda item: item[1], reverse=True)}\n",
    "            \n",
    "for s in ns.keys():\n",
    "    print(ns[s])\n",
    "    print(np.frombuffer(s, dtype=\"int8\"))\n",
    "\n",
    "print(len(new_state.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "[1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 1]\n",
      "19\n",
      "[1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 1]\n",
      "5\n",
      "[1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1\n",
      " 0 0 0 0 1]\n",
      "4\n",
      "[1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 1]\n",
      "4\n",
      "[1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 1]\n",
      "2\n",
      "[1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 1]\n",
      "2\n",
      "[1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 1]\n",
      "1\n",
      "[1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 1]\n",
      "1\n",
      "[1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 1]\n",
      "9\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "target = states_actions[50]\n",
    "new_state = {}\n",
    "\n",
    "for i in range(194040):\n",
    "    if (target==states_actions[i]).all():\n",
    "        state = np.array(next_states[i], dtype=np.int8)\n",
    "        if not state.tobytes() in new_state:\n",
    "            new_state[state.tobytes()] = 1\n",
    "        else:\n",
    "            new_state[state.tobytes()] += 1\n",
    "        \n",
    "ns = {k: v for k, v in sorted(new_state.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "count = 0\n",
    "for s in ns.keys():\n",
    "    print(ns[s])\n",
    "    count+=ns[s]\n",
    "    print(np.frombuffer(s, dtype=\"int8\"))\n",
    "\n",
    "print(len(new_state.keys()))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('Reward_Model_Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0. ,  0. ,  0. , ..., -0.1, -0.1, -0.1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3064    134     94   1402   1232   5192   3798  53061   2784 121865\n",
      "   5374]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: -11.0,\n",
       " 1: -4.099999904632568,\n",
       " 2: -4.0,\n",
       " 3: -3.0999999046325684,\n",
       " 4: -3.0,\n",
       " 5: -2.0999999046325684,\n",
       " 6: -2.0,\n",
       " 7: -1.100000023841858,\n",
       " 8: -1.0,\n",
       " 9: -0.10000000149011612,\n",
       " 10: 0.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(rewards.shape[0]):\n",
    "    if rewards[i] < -10:\n",
    "        rewards[i] = -11\n",
    "\n",
    "labels, encoding, counts = np.unique(rewards, return_inverse=True, return_counts=True)\n",
    "encoding = np.eye(labels.shape[0])[encoding]\n",
    "reward_map = {}\n",
    "for i in range(labels.shape[0]):\n",
    "    reward_map[i] = labels[i]\n",
    "print(counts)\n",
    "reward_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "697/697 [==============================] - 14s 11ms/step - loss: 1.0678 - categorical_accuracy: 0.5428 - val_loss: 1.0416 - val_categorical_accuracy: 0.5509\n",
      "Epoch 2/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 1.0319 - categorical_accuracy: 0.5531 - val_loss: 1.0454 - val_categorical_accuracy: 0.5485\n",
      "Epoch 3/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 1.0206 - categorical_accuracy: 0.5568 - val_loss: 1.0459 - val_categorical_accuracy: 0.5509\n",
      "Epoch 4/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 1.0084 - categorical_accuracy: 0.5609 - val_loss: 1.0433 - val_categorical_accuracy: 0.5513\n",
      "Epoch 5/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.9960 - categorical_accuracy: 0.5638 - val_loss: 1.0597 - val_categorical_accuracy: 0.5516\n",
      "Epoch 6/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.9836 - categorical_accuracy: 0.5674 - val_loss: 1.0781 - val_categorical_accuracy: 0.5491\n",
      "Epoch 7/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.9722 - categorical_accuracy: 0.5720 - val_loss: 1.0748 - val_categorical_accuracy: 0.5482\n",
      "Epoch 8/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.9590 - categorical_accuracy: 0.5752 - val_loss: 1.1170 - val_categorical_accuracy: 0.5449\n",
      "Epoch 9/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.9482 - categorical_accuracy: 0.5788 - val_loss: 1.1207 - val_categorical_accuracy: 0.5427\n",
      "Epoch 10/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.9351 - categorical_accuracy: 0.5829 - val_loss: 1.1288 - val_categorical_accuracy: 0.5422\n",
      "Epoch 11/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.9242 - categorical_accuracy: 0.5865 - val_loss: 1.1417 - val_categorical_accuracy: 0.5447\n",
      "Epoch 12/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.9130 - categorical_accuracy: 0.5907 - val_loss: 1.1720 - val_categorical_accuracy: 0.5399\n",
      "Epoch 13/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.9038 - categorical_accuracy: 0.5939 - val_loss: 1.1643 - val_categorical_accuracy: 0.5396\n",
      "Epoch 14/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.8930 - categorical_accuracy: 0.5968 - val_loss: 1.1910 - val_categorical_accuracy: 0.5394\n",
      "Epoch 15/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.8829 - categorical_accuracy: 0.6002 - val_loss: 1.2274 - val_categorical_accuracy: 0.5399\n",
      "Epoch 16/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.8729 - categorical_accuracy: 0.6041 - val_loss: 1.2358 - val_categorical_accuracy: 0.5311\n",
      "Epoch 17/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.8637 - categorical_accuracy: 0.6067 - val_loss: 1.2470 - val_categorical_accuracy: 0.5315\n",
      "Epoch 18/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.8550 - categorical_accuracy: 0.6093 - val_loss: 1.2512 - val_categorical_accuracy: 0.5352\n",
      "Epoch 19/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.8462 - categorical_accuracy: 0.6126 - val_loss: 1.2817 - val_categorical_accuracy: 0.5309\n",
      "Epoch 20/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.8372 - categorical_accuracy: 0.6156 - val_loss: 1.3084 - val_categorical_accuracy: 0.5255\n",
      "Epoch 21/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.8287 - categorical_accuracy: 0.6196 - val_loss: 1.3449 - val_categorical_accuracy: 0.5217\n",
      "Epoch 22/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.8201 - categorical_accuracy: 0.6224 - val_loss: 1.3446 - val_categorical_accuracy: 0.5267\n",
      "Epoch 23/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.8121 - categorical_accuracy: 0.6255 - val_loss: 1.3479 - val_categorical_accuracy: 0.5258\n",
      "Epoch 24/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.8046 - categorical_accuracy: 0.6285 - val_loss: 1.3822 - val_categorical_accuracy: 0.5221\n",
      "Epoch 25/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.7974 - categorical_accuracy: 0.6311 - val_loss: 1.3780 - val_categorical_accuracy: 0.5181\n",
      "Epoch 26/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.7905 - categorical_accuracy: 0.6345 - val_loss: 1.4072 - val_categorical_accuracy: 0.5195\n",
      "Epoch 27/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.7841 - categorical_accuracy: 0.6375 - val_loss: 1.4372 - val_categorical_accuracy: 0.5239\n",
      "Epoch 28/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.7760 - categorical_accuracy: 0.6399 - val_loss: 1.4600 - val_categorical_accuracy: 0.5199\n",
      "Epoch 29/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.7702 - categorical_accuracy: 0.6413 - val_loss: 1.4957 - val_categorical_accuracy: 0.5204\n",
      "Epoch 30/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.7634 - categorical_accuracy: 0.6446 - val_loss: 1.5009 - val_categorical_accuracy: 0.5235\n",
      "Epoch 31/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.7578 - categorical_accuracy: 0.6466 - val_loss: 1.5105 - val_categorical_accuracy: 0.5179\n",
      "Epoch 32/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.7512 - categorical_accuracy: 0.6492 - val_loss: 1.5152 - val_categorical_accuracy: 0.5159\n",
      "Epoch 33/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.7453 - categorical_accuracy: 0.6520 - val_loss: 1.5736 - val_categorical_accuracy: 0.5157\n",
      "Epoch 34/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.7386 - categorical_accuracy: 0.6536 - val_loss: 1.5739 - val_categorical_accuracy: 0.5127\n",
      "Epoch 35/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.7323 - categorical_accuracy: 0.6571 - val_loss: 1.6031 - val_categorical_accuracy: 0.5155\n",
      "Epoch 36/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.7287 - categorical_accuracy: 0.6584 - val_loss: 1.6322 - val_categorical_accuracy: 0.5118\n",
      "Epoch 37/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.7227 - categorical_accuracy: 0.6612 - val_loss: 1.6172 - val_categorical_accuracy: 0.5082\n",
      "Epoch 38/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.7176 - categorical_accuracy: 0.6628 - val_loss: 1.6292 - val_categorical_accuracy: 0.5117\n",
      "Epoch 39/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.7122 - categorical_accuracy: 0.6661 - val_loss: 1.6707 - val_categorical_accuracy: 0.5143\n",
      "Epoch 40/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.7067 - categorical_accuracy: 0.6683 - val_loss: 1.6807 - val_categorical_accuracy: 0.5088\n",
      "Epoch 41/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.7022 - categorical_accuracy: 0.6693 - val_loss: 1.6852 - val_categorical_accuracy: 0.5057\n",
      "Epoch 42/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.6965 - categorical_accuracy: 0.6720 - val_loss: 1.7143 - val_categorical_accuracy: 0.5042\n",
      "Epoch 43/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.6914 - categorical_accuracy: 0.6746 - val_loss: 1.7253 - val_categorical_accuracy: 0.5018\n",
      "Epoch 44/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.6871 - categorical_accuracy: 0.6759 - val_loss: 1.7612 - val_categorical_accuracy: 0.5022\n",
      "Epoch 45/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.6819 - categorical_accuracy: 0.6787 - val_loss: 1.7809 - val_categorical_accuracy: 0.5045\n",
      "Epoch 46/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.6781 - categorical_accuracy: 0.6803 - val_loss: 1.7583 - val_categorical_accuracy: 0.5043\n",
      "Epoch 47/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.6733 - categorical_accuracy: 0.6826 - val_loss: 1.7709 - val_categorical_accuracy: 0.4988\n",
      "Epoch 48/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.6686 - categorical_accuracy: 0.6848 - val_loss: 1.8167 - val_categorical_accuracy: 0.5055\n",
      "Epoch 49/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.6631 - categorical_accuracy: 0.6868 - val_loss: 1.8204 - val_categorical_accuracy: 0.5014\n",
      "Epoch 50/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.6594 - categorical_accuracy: 0.6880 - val_loss: 1.8533 - val_categorical_accuracy: 0.4931\n",
      "Epoch 51/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.6547 - categorical_accuracy: 0.6905 - val_loss: 1.8596 - val_categorical_accuracy: 0.4990\n",
      "Epoch 52/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.6506 - categorical_accuracy: 0.6923 - val_loss: 1.8683 - val_categorical_accuracy: 0.4994\n",
      "Epoch 53/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.6469 - categorical_accuracy: 0.6940 - val_loss: 1.8924 - val_categorical_accuracy: 0.5022\n",
      "Epoch 54/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.6421 - categorical_accuracy: 0.6966 - val_loss: 1.9196 - val_categorical_accuracy: 0.4967\n",
      "Epoch 55/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.6380 - categorical_accuracy: 0.6984 - val_loss: 1.9394 - val_categorical_accuracy: 0.4917\n",
      "Epoch 56/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.6343 - categorical_accuracy: 0.6992 - val_loss: 1.9602 - val_categorical_accuracy: 0.4911\n",
      "Epoch 57/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.6306 - categorical_accuracy: 0.7026 - val_loss: 1.9507 - val_categorical_accuracy: 0.4972\n",
      "Epoch 58/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.6262 - categorical_accuracy: 0.7040 - val_loss: 1.9903 - val_categorical_accuracy: 0.4909\n",
      "Epoch 59/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.6242 - categorical_accuracy: 0.7043 - val_loss: 1.9918 - val_categorical_accuracy: 0.4887\n",
      "Epoch 60/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.6190 - categorical_accuracy: 0.7075 - val_loss: 1.9771 - val_categorical_accuracy: 0.4909\n",
      "Epoch 61/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.6151 - categorical_accuracy: 0.7092 - val_loss: 1.9700 - val_categorical_accuracy: 0.4891\n",
      "Epoch 62/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.6115 - categorical_accuracy: 0.7106 - val_loss: 2.0173 - val_categorical_accuracy: 0.4907\n",
      "Epoch 63/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.6088 - categorical_accuracy: 0.7120 - val_loss: 2.0190 - val_categorical_accuracy: 0.4835\n",
      "Epoch 64/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.6040 - categorical_accuracy: 0.7139 - val_loss: 2.0930 - val_categorical_accuracy: 0.4911\n",
      "Epoch 65/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.6018 - categorical_accuracy: 0.7146 - val_loss: 2.0481 - val_categorical_accuracy: 0.4891\n",
      "Epoch 66/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.5977 - categorical_accuracy: 0.7173 - val_loss: 2.1086 - val_categorical_accuracy: 0.4861\n",
      "Epoch 67/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.5944 - categorical_accuracy: 0.7181 - val_loss: 2.1104 - val_categorical_accuracy: 0.4760\n",
      "Epoch 68/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5913 - categorical_accuracy: 0.7203 - val_loss: 2.1121 - val_categorical_accuracy: 0.4788\n",
      "Epoch 69/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5882 - categorical_accuracy: 0.7221 - val_loss: 2.1365 - val_categorical_accuracy: 0.4849\n",
      "Epoch 70/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5858 - categorical_accuracy: 0.7233 - val_loss: 2.1464 - val_categorical_accuracy: 0.4828\n",
      "Epoch 71/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5812 - categorical_accuracy: 0.7254 - val_loss: 2.1230 - val_categorical_accuracy: 0.4786\n",
      "Epoch 72/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5785 - categorical_accuracy: 0.7264 - val_loss: 2.2148 - val_categorical_accuracy: 0.4764\n",
      "Epoch 73/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5762 - categorical_accuracy: 0.7281 - val_loss: 2.1604 - val_categorical_accuracy: 0.4759\n",
      "Epoch 74/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.5728 - categorical_accuracy: 0.7300 - val_loss: 2.1879 - val_categorical_accuracy: 0.4792\n",
      "Epoch 75/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.5699 - categorical_accuracy: 0.7304 - val_loss: 2.2007 - val_categorical_accuracy: 0.4813\n",
      "Epoch 76/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.5675 - categorical_accuracy: 0.7313 - val_loss: 2.1891 - val_categorical_accuracy: 0.4761\n",
      "Epoch 77/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5654 - categorical_accuracy: 0.7317 - val_loss: 2.2180 - val_categorical_accuracy: 0.4746\n",
      "Epoch 78/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5620 - categorical_accuracy: 0.7346 - val_loss: 2.2490 - val_categorical_accuracy: 0.4757\n",
      "Epoch 79/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5587 - categorical_accuracy: 0.7357 - val_loss: 2.2510 - val_categorical_accuracy: 0.4784\n",
      "Epoch 80/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5560 - categorical_accuracy: 0.7375 - val_loss: 2.2942 - val_categorical_accuracy: 0.4781\n",
      "Epoch 81/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5537 - categorical_accuracy: 0.7379 - val_loss: 2.2897 - val_categorical_accuracy: 0.4731\n",
      "Epoch 82/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5514 - categorical_accuracy: 0.7397 - val_loss: 2.2894 - val_categorical_accuracy: 0.4689\n",
      "Epoch 83/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.5484 - categorical_accuracy: 0.7400 - val_loss: 2.3062 - val_categorical_accuracy: 0.4751\n",
      "Epoch 84/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.5452 - categorical_accuracy: 0.7413 - val_loss: 2.3511 - val_categorical_accuracy: 0.4745\n",
      "Epoch 85/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.5433 - categorical_accuracy: 0.7427 - val_loss: 2.3285 - val_categorical_accuracy: 0.4742\n",
      "Epoch 86/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5406 - categorical_accuracy: 0.7443 - val_loss: 2.3405 - val_categorical_accuracy: 0.4759\n",
      "Epoch 87/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5388 - categorical_accuracy: 0.7445 - val_loss: 2.3133 - val_categorical_accuracy: 0.4702\n",
      "Epoch 88/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5357 - categorical_accuracy: 0.7455 - val_loss: 2.4282 - val_categorical_accuracy: 0.4679\n",
      "Epoch 89/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5335 - categorical_accuracy: 0.7469 - val_loss: 2.3908 - val_categorical_accuracy: 0.4779\n",
      "Epoch 90/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5317 - categorical_accuracy: 0.7476 - val_loss: 2.4266 - val_categorical_accuracy: 0.4705\n",
      "Epoch 91/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.5301 - categorical_accuracy: 0.7494 - val_loss: 2.3998 - val_categorical_accuracy: 0.4768\n",
      "Epoch 92/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.5287 - categorical_accuracy: 0.7483 - val_loss: 2.4334 - val_categorical_accuracy: 0.4611\n",
      "Epoch 93/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5263 - categorical_accuracy: 0.7505 - val_loss: 2.4178 - val_categorical_accuracy: 0.4712\n",
      "Epoch 94/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5233 - categorical_accuracy: 0.7516 - val_loss: 2.4403 - val_categorical_accuracy: 0.4733\n",
      "Epoch 95/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5207 - categorical_accuracy: 0.7522 - val_loss: 2.4483 - val_categorical_accuracy: 0.4722\n",
      "Epoch 96/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5193 - categorical_accuracy: 0.7540 - val_loss: 2.4374 - val_categorical_accuracy: 0.4674\n",
      "Epoch 97/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5185 - categorical_accuracy: 0.7536 - val_loss: 2.4186 - val_categorical_accuracy: 0.4695\n",
      "Epoch 98/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5151 - categorical_accuracy: 0.7554 - val_loss: 2.4796 - val_categorical_accuracy: 0.4640\n",
      "Epoch 99/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.5136 - categorical_accuracy: 0.7556 - val_loss: 2.4406 - val_categorical_accuracy: 0.4617\n",
      "Epoch 100/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.5122 - categorical_accuracy: 0.7558 - val_loss: 2.4977 - val_categorical_accuracy: 0.4727\n",
      "Epoch 101/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.5103 - categorical_accuracy: 0.7570 - val_loss: 2.4595 - val_categorical_accuracy: 0.4703\n",
      "Epoch 102/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5077 - categorical_accuracy: 0.7587 - val_loss: 2.5412 - val_categorical_accuracy: 0.4758\n",
      "Epoch 103/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5076 - categorical_accuracy: 0.7588 - val_loss: 2.5327 - val_categorical_accuracy: 0.4647\n",
      "Epoch 104/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5040 - categorical_accuracy: 0.7592 - val_loss: 2.5533 - val_categorical_accuracy: 0.4701\n",
      "Epoch 105/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5036 - categorical_accuracy: 0.7592 - val_loss: 2.5485 - val_categorical_accuracy: 0.4716\n",
      "Epoch 106/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.5023 - categorical_accuracy: 0.7610 - val_loss: 2.5175 - val_categorical_accuracy: 0.4709\n",
      "Epoch 107/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4998 - categorical_accuracy: 0.7615 - val_loss: 2.5602 - val_categorical_accuracy: 0.4671\n",
      "Epoch 108/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.4978 - categorical_accuracy: 0.7620 - val_loss: 2.5730 - val_categorical_accuracy: 0.4662\n",
      "Epoch 109/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4964 - categorical_accuracy: 0.7623 - val_loss: 2.6047 - val_categorical_accuracy: 0.4648\n",
      "Epoch 110/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4936 - categorical_accuracy: 0.7639 - val_loss: 2.6373 - val_categorical_accuracy: 0.4687\n",
      "Epoch 111/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4936 - categorical_accuracy: 0.7637 - val_loss: 2.5955 - val_categorical_accuracy: 0.4663\n",
      "Epoch 112/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4924 - categorical_accuracy: 0.7651 - val_loss: 2.6210 - val_categorical_accuracy: 0.4698\n",
      "Epoch 113/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4910 - categorical_accuracy: 0.7646 - val_loss: 2.6446 - val_categorical_accuracy: 0.4638\n",
      "Epoch 114/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4894 - categorical_accuracy: 0.7661 - val_loss: 2.6341 - val_categorical_accuracy: 0.4669\n",
      "Epoch 115/250\n",
      "697/697 [==============================] - 6s 8ms/step - loss: 0.4880 - categorical_accuracy: 0.7665 - val_loss: 2.6339 - val_categorical_accuracy: 0.4595\n",
      "Epoch 116/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4866 - categorical_accuracy: 0.7662 - val_loss: 2.6281 - val_categorical_accuracy: 0.4656\n",
      "Epoch 117/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.4840 - categorical_accuracy: 0.7673 - val_loss: 2.6665 - val_categorical_accuracy: 0.4694\n",
      "Epoch 118/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.4834 - categorical_accuracy: 0.7683 - val_loss: 2.6730 - val_categorical_accuracy: 0.4644\n",
      "Epoch 119/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4824 - categorical_accuracy: 0.7680 - val_loss: 2.6895 - val_categorical_accuracy: 0.4648\n",
      "Epoch 120/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4816 - categorical_accuracy: 0.7683 - val_loss: 2.6995 - val_categorical_accuracy: 0.4696\n",
      "Epoch 121/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4795 - categorical_accuracy: 0.7686 - val_loss: 2.7379 - val_categorical_accuracy: 0.4703\n",
      "Epoch 122/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4787 - categorical_accuracy: 0.7689 - val_loss: 2.6612 - val_categorical_accuracy: 0.4609\n",
      "Epoch 123/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4769 - categorical_accuracy: 0.7708 - val_loss: 2.6897 - val_categorical_accuracy: 0.4611\n",
      "Epoch 124/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.4766 - categorical_accuracy: 0.7709 - val_loss: 2.7252 - val_categorical_accuracy: 0.4711\n",
      "Epoch 125/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.4740 - categorical_accuracy: 0.7713 - val_loss: 2.7493 - val_categorical_accuracy: 0.4656\n",
      "Epoch 126/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4736 - categorical_accuracy: 0.7723 - val_loss: 2.6965 - val_categorical_accuracy: 0.4626\n",
      "Epoch 127/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4734 - categorical_accuracy: 0.7716 - val_loss: 2.7176 - val_categorical_accuracy: 0.4689\n",
      "Epoch 128/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4714 - categorical_accuracy: 0.7730 - val_loss: 2.6908 - val_categorical_accuracy: 0.4619\n",
      "Epoch 129/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4690 - categorical_accuracy: 0.7739 - val_loss: 2.7595 - val_categorical_accuracy: 0.4656\n",
      "Epoch 130/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4696 - categorical_accuracy: 0.7732 - val_loss: 2.6950 - val_categorical_accuracy: 0.4651\n",
      "Epoch 131/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4685 - categorical_accuracy: 0.7732 - val_loss: 2.7695 - val_categorical_accuracy: 0.4655\n",
      "Epoch 132/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.4674 - categorical_accuracy: 0.7741 - val_loss: 2.7158 - val_categorical_accuracy: 0.4659\n",
      "Epoch 133/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.4666 - categorical_accuracy: 0.7739 - val_loss: 2.7456 - val_categorical_accuracy: 0.4606\n",
      "Epoch 134/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.4652 - categorical_accuracy: 0.7750 - val_loss: 2.7570 - val_categorical_accuracy: 0.4647\n",
      "Epoch 135/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4650 - categorical_accuracy: 0.7751 - val_loss: 2.8047 - val_categorical_accuracy: 0.4644\n",
      "Epoch 136/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4633 - categorical_accuracy: 0.7752 - val_loss: 2.7713 - val_categorical_accuracy: 0.4590\n",
      "Epoch 137/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4622 - categorical_accuracy: 0.7766 - val_loss: 2.7432 - val_categorical_accuracy: 0.4639\n",
      "Epoch 138/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4602 - categorical_accuracy: 0.7768 - val_loss: 2.7798 - val_categorical_accuracy: 0.4648\n",
      "Epoch 139/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4606 - categorical_accuracy: 0.7767 - val_loss: 2.8275 - val_categorical_accuracy: 0.4645\n",
      "Epoch 140/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4592 - categorical_accuracy: 0.7778 - val_loss: 2.7970 - val_categorical_accuracy: 0.4606\n",
      "Epoch 141/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.4595 - categorical_accuracy: 0.7769 - val_loss: 2.8533 - val_categorical_accuracy: 0.4687\n",
      "Epoch 142/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4567 - categorical_accuracy: 0.7779 - val_loss: 2.8018 - val_categorical_accuracy: 0.4596\n",
      "Epoch 143/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4556 - categorical_accuracy: 0.7793 - val_loss: 2.8131 - val_categorical_accuracy: 0.4677\n",
      "Epoch 144/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4558 - categorical_accuracy: 0.7786 - val_loss: 2.8060 - val_categorical_accuracy: 0.4598\n",
      "Epoch 145/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4548 - categorical_accuracy: 0.7792 - val_loss: 2.8277 - val_categorical_accuracy: 0.4572\n",
      "Epoch 146/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4546 - categorical_accuracy: 0.7786 - val_loss: 2.8517 - val_categorical_accuracy: 0.4673\n",
      "Epoch 147/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4542 - categorical_accuracy: 0.7789 - val_loss: 2.8762 - val_categorical_accuracy: 0.4662\n",
      "Epoch 148/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4528 - categorical_accuracy: 0.7795 - val_loss: 2.8594 - val_categorical_accuracy: 0.4655\n",
      "Epoch 149/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4495 - categorical_accuracy: 0.7808 - val_loss: 2.8809 - val_categorical_accuracy: 0.4610\n",
      "Epoch 150/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.4525 - categorical_accuracy: 0.7797 - val_loss: 2.8589 - val_categorical_accuracy: 0.4635\n",
      "Epoch 151/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.4506 - categorical_accuracy: 0.7794 - val_loss: 2.9098 - val_categorical_accuracy: 0.4603\n",
      "Epoch 152/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4482 - categorical_accuracy: 0.7817 - val_loss: 2.9592 - val_categorical_accuracy: 0.4649\n",
      "Epoch 153/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4483 - categorical_accuracy: 0.7807 - val_loss: 2.9128 - val_categorical_accuracy: 0.4663\n",
      "Epoch 154/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4472 - categorical_accuracy: 0.7807 - val_loss: 2.8823 - val_categorical_accuracy: 0.4652\n",
      "Epoch 155/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4473 - categorical_accuracy: 0.7813 - val_loss: 2.9790 - val_categorical_accuracy: 0.4680\n",
      "Epoch 156/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4462 - categorical_accuracy: 0.7817 - val_loss: 2.9210 - val_categorical_accuracy: 0.4578\n",
      "Epoch 157/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4460 - categorical_accuracy: 0.7824 - val_loss: 2.9376 - val_categorical_accuracy: 0.4584\n",
      "Epoch 158/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4442 - categorical_accuracy: 0.7827 - val_loss: 2.9291 - val_categorical_accuracy: 0.4618\n",
      "Epoch 159/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.4453 - categorical_accuracy: 0.7816 - val_loss: 2.9818 - val_categorical_accuracy: 0.4634\n",
      "Epoch 160/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.4441 - categorical_accuracy: 0.7818 - val_loss: 2.9146 - val_categorical_accuracy: 0.4648\n",
      "Epoch 161/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4433 - categorical_accuracy: 0.7828 - val_loss: 2.9113 - val_categorical_accuracy: 0.4643\n",
      "Epoch 162/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4414 - categorical_accuracy: 0.7828 - val_loss: 2.9593 - val_categorical_accuracy: 0.4674\n",
      "Epoch 163/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4412 - categorical_accuracy: 0.7827 - val_loss: 2.9280 - val_categorical_accuracy: 0.4608\n",
      "Epoch 164/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4416 - categorical_accuracy: 0.7834 - val_loss: 3.0305 - val_categorical_accuracy: 0.4645\n",
      "Epoch 165/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4402 - categorical_accuracy: 0.7837 - val_loss: 2.9714 - val_categorical_accuracy: 0.4665\n",
      "Epoch 166/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4386 - categorical_accuracy: 0.7839 - val_loss: 2.9477 - val_categorical_accuracy: 0.4633\n",
      "Epoch 167/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.4393 - categorical_accuracy: 0.7834 - val_loss: 2.9702 - val_categorical_accuracy: 0.4628\n",
      "Epoch 168/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.4386 - categorical_accuracy: 0.7837 - val_loss: 2.9384 - val_categorical_accuracy: 0.4583\n",
      "Epoch 169/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4388 - categorical_accuracy: 0.7841 - val_loss: 3.0105 - val_categorical_accuracy: 0.4655\n",
      "Epoch 170/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4377 - categorical_accuracy: 0.7841 - val_loss: 2.9668 - val_categorical_accuracy: 0.4657\n",
      "Epoch 171/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4371 - categorical_accuracy: 0.7837 - val_loss: 3.0029 - val_categorical_accuracy: 0.4689\n",
      "Epoch 172/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4361 - categorical_accuracy: 0.7848 - val_loss: 3.0112 - val_categorical_accuracy: 0.4687\n",
      "Epoch 173/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4355 - categorical_accuracy: 0.7853 - val_loss: 2.9677 - val_categorical_accuracy: 0.4596\n",
      "Epoch 174/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4360 - categorical_accuracy: 0.7842 - val_loss: 3.0216 - val_categorical_accuracy: 0.4548\n",
      "Epoch 175/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.4348 - categorical_accuracy: 0.7845 - val_loss: 3.0188 - val_categorical_accuracy: 0.4632\n",
      "Epoch 176/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.4330 - categorical_accuracy: 0.7857 - val_loss: 2.9594 - val_categorical_accuracy: 0.4621\n",
      "Epoch 177/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4334 - categorical_accuracy: 0.7846 - val_loss: 3.0643 - val_categorical_accuracy: 0.4632\n",
      "Epoch 178/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4324 - categorical_accuracy: 0.7851 - val_loss: 3.0535 - val_categorical_accuracy: 0.4585\n",
      "Epoch 179/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4309 - categorical_accuracy: 0.7862 - val_loss: 3.0272 - val_categorical_accuracy: 0.4605\n",
      "Epoch 180/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4310 - categorical_accuracy: 0.7865 - val_loss: 3.0469 - val_categorical_accuracy: 0.4618\n",
      "Epoch 181/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4311 - categorical_accuracy: 0.7857 - val_loss: 3.0648 - val_categorical_accuracy: 0.4631\n",
      "Epoch 182/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4302 - categorical_accuracy: 0.7863 - val_loss: 3.1287 - val_categorical_accuracy: 0.4612\n",
      "Epoch 183/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4293 - categorical_accuracy: 0.7874 - val_loss: 3.0526 - val_categorical_accuracy: 0.4646\n",
      "Epoch 184/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.4310 - categorical_accuracy: 0.7861 - val_loss: 3.0529 - val_categorical_accuracy: 0.4586\n",
      "Epoch 185/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.4290 - categorical_accuracy: 0.7869 - val_loss: 3.0641 - val_categorical_accuracy: 0.4556\n",
      "Epoch 186/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4297 - categorical_accuracy: 0.7857 - val_loss: 2.9952 - val_categorical_accuracy: 0.4571\n",
      "Epoch 187/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4274 - categorical_accuracy: 0.7873 - val_loss: 3.0740 - val_categorical_accuracy: 0.4623\n",
      "Epoch 188/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4270 - categorical_accuracy: 0.7872 - val_loss: 3.0938 - val_categorical_accuracy: 0.4651\n",
      "Epoch 189/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4269 - categorical_accuracy: 0.7873 - val_loss: 3.0630 - val_categorical_accuracy: 0.4626\n",
      "Epoch 190/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4257 - categorical_accuracy: 0.7869 - val_loss: 3.0890 - val_categorical_accuracy: 0.4673\n",
      "Epoch 191/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4261 - categorical_accuracy: 0.7877 - val_loss: 3.1020 - val_categorical_accuracy: 0.4618\n",
      "Epoch 192/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.4267 - categorical_accuracy: 0.7881 - val_loss: 3.0794 - val_categorical_accuracy: 0.4612\n",
      "Epoch 193/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4249 - categorical_accuracy: 0.7880 - val_loss: 3.1004 - val_categorical_accuracy: 0.4638\n",
      "Epoch 194/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4241 - categorical_accuracy: 0.7888 - val_loss: 3.0625 - val_categorical_accuracy: 0.4619\n",
      "Epoch 195/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4247 - categorical_accuracy: 0.7868 - val_loss: 3.0508 - val_categorical_accuracy: 0.4658\n",
      "Epoch 196/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4236 - categorical_accuracy: 0.7878 - val_loss: 3.1272 - val_categorical_accuracy: 0.4614\n",
      "Epoch 197/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4231 - categorical_accuracy: 0.7888 - val_loss: 3.1508 - val_categorical_accuracy: 0.4579\n",
      "Epoch 198/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4225 - categorical_accuracy: 0.7893 - val_loss: 3.0730 - val_categorical_accuracy: 0.4602\n",
      "Epoch 199/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4230 - categorical_accuracy: 0.7874 - val_loss: 3.1101 - val_categorical_accuracy: 0.4596\n",
      "Epoch 200/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.4224 - categorical_accuracy: 0.7890 - val_loss: 3.0923 - val_categorical_accuracy: 0.4649\n",
      "Epoch 201/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.4214 - categorical_accuracy: 0.7893 - val_loss: 3.1115 - val_categorical_accuracy: 0.4588\n",
      "Epoch 202/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4211 - categorical_accuracy: 0.7891 - val_loss: 3.1974 - val_categorical_accuracy: 0.4584\n",
      "Epoch 203/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4205 - categorical_accuracy: 0.7892 - val_loss: 3.1761 - val_categorical_accuracy: 0.4681\n",
      "Epoch 204/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4208 - categorical_accuracy: 0.7882 - val_loss: 3.0817 - val_categorical_accuracy: 0.4580\n",
      "Epoch 205/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4198 - categorical_accuracy: 0.7897 - val_loss: 3.1999 - val_categorical_accuracy: 0.4576\n",
      "Epoch 206/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4196 - categorical_accuracy: 0.7901 - val_loss: 3.2019 - val_categorical_accuracy: 0.4615\n",
      "Epoch 207/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4192 - categorical_accuracy: 0.7888 - val_loss: 3.1522 - val_categorical_accuracy: 0.4574\n",
      "Epoch 208/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.4188 - categorical_accuracy: 0.7895 - val_loss: 3.2042 - val_categorical_accuracy: 0.4602\n",
      "Epoch 209/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.4184 - categorical_accuracy: 0.7887 - val_loss: 3.1506 - val_categorical_accuracy: 0.4646\n",
      "Epoch 210/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.4188 - categorical_accuracy: 0.7892 - val_loss: 3.2001 - val_categorical_accuracy: 0.4628\n",
      "Epoch 211/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4186 - categorical_accuracy: 0.7894 - val_loss: 3.1604 - val_categorical_accuracy: 0.4622\n",
      "Epoch 212/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4172 - categorical_accuracy: 0.7903 - val_loss: 3.1804 - val_categorical_accuracy: 0.4657\n",
      "Epoch 213/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4177 - categorical_accuracy: 0.7895 - val_loss: 3.1474 - val_categorical_accuracy: 0.4599\n",
      "Epoch 214/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4166 - categorical_accuracy: 0.7900 - val_loss: 3.1552 - val_categorical_accuracy: 0.4657\n",
      "Epoch 215/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4160 - categorical_accuracy: 0.7903 - val_loss: 3.1408 - val_categorical_accuracy: 0.4591\n",
      "Epoch 216/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.4154 - categorical_accuracy: 0.7917 - val_loss: 3.1988 - val_categorical_accuracy: 0.4670\n",
      "Epoch 217/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.4157 - categorical_accuracy: 0.7906 - val_loss: 3.1239 - val_categorical_accuracy: 0.4636\n",
      "Epoch 218/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4160 - categorical_accuracy: 0.7898 - val_loss: 3.2176 - val_categorical_accuracy: 0.4654\n",
      "Epoch 219/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4144 - categorical_accuracy: 0.7912 - val_loss: 3.2039 - val_categorical_accuracy: 0.4621\n",
      "Epoch 220/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4141 - categorical_accuracy: 0.7914 - val_loss: 3.2013 - val_categorical_accuracy: 0.4661\n",
      "Epoch 221/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4136 - categorical_accuracy: 0.7914 - val_loss: 3.2057 - val_categorical_accuracy: 0.4645\n",
      "Epoch 222/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4141 - categorical_accuracy: 0.7907 - val_loss: 3.1584 - val_categorical_accuracy: 0.4656\n",
      "Epoch 223/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4134 - categorical_accuracy: 0.7898 - val_loss: 3.2157 - val_categorical_accuracy: 0.4589\n",
      "Epoch 224/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.4123 - categorical_accuracy: 0.7912 - val_loss: 3.2365 - val_categorical_accuracy: 0.4608\n",
      "Epoch 225/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4128 - categorical_accuracy: 0.7919 - val_loss: 3.3042 - val_categorical_accuracy: 0.4596\n",
      "Epoch 226/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4126 - categorical_accuracy: 0.7918 - val_loss: 3.2450 - val_categorical_accuracy: 0.4615\n",
      "Epoch 227/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4124 - categorical_accuracy: 0.7914 - val_loss: 3.2295 - val_categorical_accuracy: 0.4613\n",
      "Epoch 228/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4108 - categorical_accuracy: 0.7926 - val_loss: 3.2461 - val_categorical_accuracy: 0.4659\n",
      "Epoch 229/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4117 - categorical_accuracy: 0.7914 - val_loss: 3.1749 - val_categorical_accuracy: 0.4631\n",
      "Epoch 230/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.4113 - categorical_accuracy: 0.7914 - val_loss: 3.1912 - val_categorical_accuracy: 0.4628\n",
      "Epoch 231/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4103 - categorical_accuracy: 0.7920 - val_loss: 3.2170 - val_categorical_accuracy: 0.4607\n",
      "Epoch 232/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4102 - categorical_accuracy: 0.7920 - val_loss: 3.2754 - val_categorical_accuracy: 0.4619\n",
      "Epoch 233/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4107 - categorical_accuracy: 0.7918 - val_loss: 3.2508 - val_categorical_accuracy: 0.4599\n",
      "Epoch 234/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4104 - categorical_accuracy: 0.7919 - val_loss: 3.2618 - val_categorical_accuracy: 0.4623\n",
      "Epoch 235/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.4099 - categorical_accuracy: 0.7925 - val_loss: 3.2096 - val_categorical_accuracy: 0.4615\n",
      "Epoch 236/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.4091 - categorical_accuracy: 0.7919 - val_loss: 3.2822 - val_categorical_accuracy: 0.4588\n",
      "Epoch 237/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4094 - categorical_accuracy: 0.7916 - val_loss: 3.2541 - val_categorical_accuracy: 0.4553\n",
      "Epoch 238/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4084 - categorical_accuracy: 0.7921 - val_loss: 3.2309 - val_categorical_accuracy: 0.4655\n",
      "Epoch 239/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4088 - categorical_accuracy: 0.7925 - val_loss: 3.2630 - val_categorical_accuracy: 0.4660\n",
      "Epoch 240/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4077 - categorical_accuracy: 0.7928 - val_loss: 3.3135 - val_categorical_accuracy: 0.4554\n",
      "Epoch 241/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4076 - categorical_accuracy: 0.7927 - val_loss: 3.3320 - val_categorical_accuracy: 0.4583\n",
      "Epoch 242/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4084 - categorical_accuracy: 0.7925 - val_loss: 3.2539 - val_categorical_accuracy: 0.4607\n",
      "Epoch 243/250\n",
      "697/697 [==============================] - 7s 9ms/step - loss: 0.4070 - categorical_accuracy: 0.7922 - val_loss: 3.2637 - val_categorical_accuracy: 0.4619\n",
      "Epoch 244/250\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.4077 - categorical_accuracy: 0.7923 - val_loss: 3.3152 - val_categorical_accuracy: 0.4571\n",
      "Epoch 245/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4066 - categorical_accuracy: 0.7927 - val_loss: 3.2225 - val_categorical_accuracy: 0.4578\n",
      "Epoch 246/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4069 - categorical_accuracy: 0.7925 - val_loss: 3.2073 - val_categorical_accuracy: 0.4636\n",
      "Epoch 247/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4066 - categorical_accuracy: 0.7922 - val_loss: 3.3229 - val_categorical_accuracy: 0.4617\n",
      "Epoch 248/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4048 - categorical_accuracy: 0.7933 - val_loss: 3.2318 - val_categorical_accuracy: 0.4619\n",
      "Epoch 249/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4064 - categorical_accuracy: 0.7930 - val_loss: 3.2737 - val_categorical_accuracy: 0.4675\n",
      "Epoch 250/250\n",
      "697/697 [==============================] - 7s 10ms/step - loss: 0.4058 - categorical_accuracy: 0.7925 - val_loss: 3.2836 - val_categorical_accuracy: 0.4627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1d1f388430>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "input_ = Input(shape=(10,42+20,))\n",
    "#x = Bidirectional(LSTM(64, activation='relu', return_sequences=True))(input_)\n",
    "#x = Bidirectional(GRU(64))(input_)\n",
    "x = Bidirectional(LSTM(128))(input_)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "out = Dense(6, activation='softmax', name='reward')(x)\n",
    "model = Model(input_, out)\n",
    "\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=7)\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_value(model.optimizer.learning_rate, 0.0005)\n",
    "\n",
    "#model.fit(train_dataset,epochs=250, verbose=1, callbacks=[callback])\n",
    "\n",
    "model.fit(states_actions_seq_10, encoding, epochs=250, validation_split=0.1, verbose=1, callbacks=[callback], batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198000, 184)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_concate = np.concatenate([states_t, next_states_t], axis=1)\n",
    "state_concate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_131 (Dense)           (None, 512)               94720     \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 11)                5643      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 625,675\n",
      "Trainable params: 625,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/250\n",
      "2785/2785 [==============================] - 16s 5ms/step - loss: 0.4057 - categorical_accuracy: 0.8597 - val_loss: 0.3373 - val_categorical_accuracy: 0.8796\n",
      "Epoch 2/250\n",
      "2785/2785 [==============================] - 13s 5ms/step - loss: 0.3230 - categorical_accuracy: 0.8848 - val_loss: 0.2984 - val_categorical_accuracy: 0.8947\n",
      "Epoch 3/250\n",
      "2785/2785 [==============================] - 13s 5ms/step - loss: 0.2815 - categorical_accuracy: 0.8977 - val_loss: 0.2569 - val_categorical_accuracy: 0.9081\n",
      "Epoch 4/250\n",
      "2785/2785 [==============================] - 14s 5ms/step - loss: 0.2428 - categorical_accuracy: 0.9092 - val_loss: 0.2299 - val_categorical_accuracy: 0.9139\n",
      "Epoch 5/250\n",
      "2785/2785 [==============================] - 12s 4ms/step - loss: 0.2144 - categorical_accuracy: 0.9187 - val_loss: 0.1924 - val_categorical_accuracy: 0.9281\n",
      "Epoch 6/250\n",
      "2785/2785 [==============================] - 13s 5ms/step - loss: 0.1957 - categorical_accuracy: 0.9243 - val_loss: 0.1818 - val_categorical_accuracy: 0.9301\n",
      "Epoch 7/250\n",
      "2785/2785 [==============================] - 13s 5ms/step - loss: 0.1811 - categorical_accuracy: 0.9284 - val_loss: 0.1720 - val_categorical_accuracy: 0.9338\n",
      "Epoch 8/250\n",
      "2785/2785 [==============================] - 13s 5ms/step - loss: 0.1733 - categorical_accuracy: 0.9316 - val_loss: 0.1656 - val_categorical_accuracy: 0.9329\n",
      "Epoch 9/250\n",
      "2785/2785 [==============================] - 13s 5ms/step - loss: 0.1635 - categorical_accuracy: 0.9343 - val_loss: 0.1519 - val_categorical_accuracy: 0.9393\n",
      "Epoch 10/250\n",
      "2785/2785 [==============================] - 14s 5ms/step - loss: 0.1575 - categorical_accuracy: 0.9360 - val_loss: 0.1484 - val_categorical_accuracy: 0.9393\n",
      "Epoch 11/250\n",
      "2785/2785 [==============================] - 12s 4ms/step - loss: 0.1499 - categorical_accuracy: 0.9393 - val_loss: 0.1524 - val_categorical_accuracy: 0.9357\n",
      "Epoch 12/250\n",
      "2785/2785 [==============================] - 13s 5ms/step - loss: 0.1483 - categorical_accuracy: 0.9392 - val_loss: 0.1386 - val_categorical_accuracy: 0.9414\n",
      "Epoch 13/250\n",
      "2785/2785 [==============================] - 14s 5ms/step - loss: 0.1450 - categorical_accuracy: 0.9407 - val_loss: 0.1369 - val_categorical_accuracy: 0.9426\n",
      "Epoch 14/250\n",
      "2785/2785 [==============================] - 13s 5ms/step - loss: 0.1396 - categorical_accuracy: 0.9421 - val_loss: 0.1339 - val_categorical_accuracy: 0.9439\n",
      "Epoch 15/250\n",
      "2785/2785 [==============================] - 13s 5ms/step - loss: 0.1377 - categorical_accuracy: 0.9428 - val_loss: 0.1300 - val_categorical_accuracy: 0.9455\n",
      "Epoch 16/250\n",
      "2785/2785 [==============================] - 14s 5ms/step - loss: 0.1354 - categorical_accuracy: 0.9441 - val_loss: 0.1313 - val_categorical_accuracy: 0.9462\n",
      "Epoch 17/250\n",
      "2785/2785 [==============================] - 12s 4ms/step - loss: 0.1322 - categorical_accuracy: 0.9446 - val_loss: 0.1342 - val_categorical_accuracy: 0.9446\n",
      "Epoch 18/250\n",
      "2785/2785 [==============================] - 13s 5ms/step - loss: 0.1297 - categorical_accuracy: 0.9450 - val_loss: 0.1467 - val_categorical_accuracy: 0.9401\n",
      "Epoch 19/250\n",
      "2785/2785 [==============================] - 14s 5ms/step - loss: 0.1267 - categorical_accuracy: 0.9464 - val_loss: 0.1221 - val_categorical_accuracy: 0.9485\n",
      "Epoch 20/250\n",
      "2785/2785 [==============================] - 13s 5ms/step - loss: 0.1265 - categorical_accuracy: 0.9466 - val_loss: 0.1227 - val_categorical_accuracy: 0.9481\n",
      "Epoch 21/250\n",
      "2785/2785 [==============================] - 13s 5ms/step - loss: 0.1231 - categorical_accuracy: 0.9475 - val_loss: 0.1254 - val_categorical_accuracy: 0.9473\n",
      "Epoch 22/250\n",
      "2785/2785 [==============================] - 14s 5ms/step - loss: 0.1227 - categorical_accuracy: 0.9485 - val_loss: 0.1205 - val_categorical_accuracy: 0.9475\n",
      "Epoch 23/250\n",
      "2785/2785 [==============================] - 12s 4ms/step - loss: 0.1207 - categorical_accuracy: 0.9487 - val_loss: 0.1206 - val_categorical_accuracy: 0.9494\n",
      "Epoch 24/250\n",
      "2785/2785 [==============================] - 14s 5ms/step - loss: 0.1182 - categorical_accuracy: 0.9497 - val_loss: 0.1167 - val_categorical_accuracy: 0.9499\n",
      "Epoch 25/250\n",
      "2785/2785 [==============================] - 15s 5ms/step - loss: 0.1170 - categorical_accuracy: 0.9501 - val_loss: 0.1100 - val_categorical_accuracy: 0.9524\n",
      "Epoch 26/250\n",
      "2785/2785 [==============================] - 12s 4ms/step - loss: 0.1172 - categorical_accuracy: 0.9496 - val_loss: 0.1088 - val_categorical_accuracy: 0.9539\n",
      "Epoch 27/250\n",
      "2785/2785 [==============================] - 13s 5ms/step - loss: 0.1142 - categorical_accuracy: 0.9513 - val_loss: 0.1071 - val_categorical_accuracy: 0.9554\n",
      "Epoch 28/250\n",
      "2785/2785 [==============================] - 14s 5ms/step - loss: 0.1117 - categorical_accuracy: 0.9519 - val_loss: 0.1077 - val_categorical_accuracy: 0.9533\n",
      "Epoch 29/250\n",
      "2785/2785 [==============================] - 14s 5ms/step - loss: 0.1131 - categorical_accuracy: 0.9519 - val_loss: 0.1044 - val_categorical_accuracy: 0.9544\n",
      "Epoch 30/250\n",
      "2785/2785 [==============================] - 12s 4ms/step - loss: 0.1103 - categorical_accuracy: 0.9525 - val_loss: 0.1067 - val_categorical_accuracy: 0.9544\n",
      "Epoch 31/250\n",
      "2785/2785 [==============================] - 14s 5ms/step - loss: 0.1102 - categorical_accuracy: 0.9530 - val_loss: 0.1029 - val_categorical_accuracy: 0.9552\n",
      "Epoch 32/250\n",
      "2785/2785 [==============================] - 13s 5ms/step - loss: 0.1117 - categorical_accuracy: 0.9525 - val_loss: 0.1111 - val_categorical_accuracy: 0.9526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f61735addc0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM, Input\n",
    "from keras.layers import Bidirectional\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(184,)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(11, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=5)\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_value(model.optimizer.learning_rate, 0.0005)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "#model.fit(train_dataset,epochs=250, verbose=1, callbacks=[callback])\n",
    "\n",
    "model.fit(state_concate, encoding, epochs=250, validation_split=0.1, verbose=1, callbacks=[callback], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('RewardModel')\n",
    "np.save('reward_map.npy', reward_map) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(encoding[0:1000], axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(11, 11), dtype=int32, numpy=\n",
       "array([[  938,     0,     0,     0,    10,     0,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [    0,    24,     0,     3,     0,     0,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [    0,     0,    25,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [    0,     0,     0,   259,     0,     8,     0,     1,     0,\n",
       "            0,     0],\n",
       "       [    1,     0,     2,     0,   345,     0,    19,     0,     2,\n",
       "            0,     0],\n",
       "       [    0,     0,     0,     4,     0,   925,     1,    18,     3,\n",
       "           18,     0],\n",
       "       [    0,     0,     0,     0,     9,     0,  1027,     0,    15,\n",
       "            2,     0],\n",
       "       [    2,     0,     0,     0,     0,     7,     0, 11347,     4,\n",
       "         1568,     2],\n",
       "       [    0,     0,     0,     0,     0,     0,     3,     6,   518,\n",
       "            2,    16],\n",
       "       [    0,     0,     0,     0,     0,     0,     5,   356,     7,\n",
       "        31137,    49],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     7,\n",
       "           76,  1229]], dtype=int32)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model.predict(state_concate[0:50000])\n",
    "confusion = tf.math.confusion_matrix(labels=np.argmax(encoding[0:50000], axis=-1), predictions=np.argmax(y, axis=-1), num_classes=11)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_87 (Dense)            (None, 512)               68608     \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 11)                5643      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 599,563\n",
      "Trainable params: 599,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/250\n",
      "2785/2785 [==============================] - 18s 6ms/step - loss: 0.4729 - categorical_accuracy: 0.8179 - val_loss: 0.3974 - val_categorical_accuracy: 0.8393\n",
      "Epoch 2/250\n",
      "2785/2785 [==============================] - 11s 4ms/step - loss: 0.3829 - categorical_accuracy: 0.8472 - val_loss: 0.3631 - val_categorical_accuracy: 0.8557\n",
      "Epoch 3/250\n",
      "2785/2785 [==============================] - 15s 5ms/step - loss: 0.3464 - categorical_accuracy: 0.8610 - val_loss: 0.3417 - val_categorical_accuracy: 0.8624\n",
      "Epoch 4/250\n",
      "2785/2785 [==============================] - 11s 4ms/step - loss: 0.3192 - categorical_accuracy: 0.8706 - val_loss: 0.3129 - val_categorical_accuracy: 0.8706\n",
      "Epoch 5/250\n",
      "2785/2785 [==============================] - 15s 5ms/step - loss: 0.2994 - categorical_accuracy: 0.8776 - val_loss: 0.2909 - val_categorical_accuracy: 0.8805\n",
      "Epoch 6/250\n",
      "2785/2785 [==============================] - 13s 5ms/step - loss: 0.2854 - categorical_accuracy: 0.8817 - val_loss: 0.2808 - val_categorical_accuracy: 0.8809\n",
      "Epoch 7/250\n",
      "2785/2785 [==============================] - 13s 5ms/step - loss: 0.2727 - categorical_accuracy: 0.8853 - val_loss: 0.2713 - val_categorical_accuracy: 0.8851\n",
      "Epoch 8/250\n",
      "2785/2785 [==============================] - 14s 5ms/step - loss: 0.2653 - categorical_accuracy: 0.8881 - val_loss: 0.2667 - val_categorical_accuracy: 0.8864\n",
      "Epoch 9/250\n",
      "2785/2785 [==============================] - 12s 4ms/step - loss: 0.2563 - categorical_accuracy: 0.8910 - val_loss: 0.2568 - val_categorical_accuracy: 0.8920\n",
      "Epoch 10/250\n",
      "2785/2785 [==============================] - 15s 5ms/step - loss: 0.2499 - categorical_accuracy: 0.8932 - val_loss: 0.2492 - val_categorical_accuracy: 0.8933\n",
      "Epoch 11/250\n",
      "2785/2785 [==============================] - 11s 4ms/step - loss: 0.2432 - categorical_accuracy: 0.8954 - val_loss: 0.2451 - val_categorical_accuracy: 0.8932\n",
      "Epoch 12/250\n",
      "2785/2785 [==============================] - 15s 5ms/step - loss: 0.2384 - categorical_accuracy: 0.8970 - val_loss: 0.2575 - val_categorical_accuracy: 0.8893\n",
      "Epoch 13/250\n",
      "2785/2785 [==============================] - 11s 4ms/step - loss: 0.2348 - categorical_accuracy: 0.8989 - val_loss: 0.2433 - val_categorical_accuracy: 0.8915\n",
      "Epoch 14/250\n",
      "2785/2785 [==============================] - 15s 5ms/step - loss: 0.2286 - categorical_accuracy: 0.9009 - val_loss: 0.2277 - val_categorical_accuracy: 0.9002\n",
      "Epoch 15/250\n",
      "2785/2785 [==============================] - 11s 4ms/step - loss: 0.2265 - categorical_accuracy: 0.9016 - val_loss: 0.2276 - val_categorical_accuracy: 0.8993\n",
      "Epoch 16/250\n",
      "2785/2785 [==============================] - 15s 5ms/step - loss: 0.2211 - categorical_accuracy: 0.9031 - val_loss: 0.2274 - val_categorical_accuracy: 0.8979\n",
      "Epoch 17/250\n",
      "2785/2785 [==============================] - 11s 4ms/step - loss: 0.2189 - categorical_accuracy: 0.9038 - val_loss: 0.2223 - val_categorical_accuracy: 0.9015\n",
      "Epoch 18/250\n",
      "2785/2785 [==============================] - 15s 5ms/step - loss: 0.2157 - categorical_accuracy: 0.9053 - val_loss: 0.2163 - val_categorical_accuracy: 0.9048\n",
      "Epoch 19/250\n",
      "2785/2785 [==============================] - 12s 4ms/step - loss: 0.2139 - categorical_accuracy: 0.9065 - val_loss: 0.2157 - val_categorical_accuracy: 0.9022\n",
      "Epoch 20/250\n",
      "2785/2785 [==============================] - 14s 5ms/step - loss: 0.2100 - categorical_accuracy: 0.9076 - val_loss: 0.2137 - val_categorical_accuracy: 0.9047\n",
      "Epoch 21/250\n",
      "2785/2785 [==============================] - 14s 5ms/step - loss: 0.2079 - categorical_accuracy: 0.9087 - val_loss: 0.2136 - val_categorical_accuracy: 0.9047\n",
      "Epoch 22/250\n",
      "2785/2785 [==============================] - 12s 4ms/step - loss: 0.2048 - categorical_accuracy: 0.9093 - val_loss: 0.2105 - val_categorical_accuracy: 0.9047\n",
      "Epoch 23/250\n",
      "2785/2785 [==============================] - 15s 5ms/step - loss: 0.2030 - categorical_accuracy: 0.9102 - val_loss: 0.2032 - val_categorical_accuracy: 0.9097\n",
      "Epoch 24/250\n",
      "2785/2785 [==============================] - 12s 4ms/step - loss: 0.2024 - categorical_accuracy: 0.9108 - val_loss: 0.2096 - val_categorical_accuracy: 0.9055\n",
      "Epoch 25/250\n",
      "2785/2785 [==============================] - 15s 5ms/step - loss: 0.2002 - categorical_accuracy: 0.9117 - val_loss: 0.2074 - val_categorical_accuracy: 0.9075\n",
      "Epoch 26/250\n",
      "2785/2785 [==============================] - 11s 4ms/step - loss: 0.1981 - categorical_accuracy: 0.9128 - val_loss: 0.1968 - val_categorical_accuracy: 0.9113\n",
      "Epoch 27/250\n",
      "2785/2785 [==============================] - 15s 5ms/step - loss: 0.1953 - categorical_accuracy: 0.9132 - val_loss: 0.2048 - val_categorical_accuracy: 0.9091\n",
      "Epoch 28/250\n",
      "2785/2785 [==============================] - 11s 4ms/step - loss: 0.1956 - categorical_accuracy: 0.9137 - val_loss: 0.1991 - val_categorical_accuracy: 0.9092\n",
      "Epoch 29/250\n",
      "2785/2785 [==============================] - 15s 5ms/step - loss: 0.1931 - categorical_accuracy: 0.9146 - val_loss: 0.1914 - val_categorical_accuracy: 0.9128\n",
      "Epoch 30/250\n",
      "2785/2785 [==============================] - 11s 4ms/step - loss: 0.1909 - categorical_accuracy: 0.9154 - val_loss: 0.1939 - val_categorical_accuracy: 0.9115\n",
      "Epoch 31/250\n",
      "2785/2785 [==============================] - 15s 5ms/step - loss: 0.1908 - categorical_accuracy: 0.9155 - val_loss: 0.1895 - val_categorical_accuracy: 0.9151\n",
      "Epoch 32/250\n",
      "2785/2785 [==============================] - 11s 4ms/step - loss: 0.1863 - categorical_accuracy: 0.9167 - val_loss: 0.1930 - val_categorical_accuracy: 0.9129\n",
      "Epoch 33/250\n",
      "2785/2785 [==============================] - 15s 5ms/step - loss: 0.1896 - categorical_accuracy: 0.9163 - val_loss: 0.1890 - val_categorical_accuracy: 0.9155\n",
      "Epoch 34/250\n",
      "2785/2785 [==============================] - 13s 5ms/step - loss: 0.1862 - categorical_accuracy: 0.9175 - val_loss: 0.1908 - val_categorical_accuracy: 0.9141\n",
      "Epoch 35/250\n",
      "2785/2785 [==============================] - 13s 5ms/step - loss: 0.1842 - categorical_accuracy: 0.9182 - val_loss: 0.1859 - val_categorical_accuracy: 0.9167\n",
      "Epoch 36/250\n",
      "2785/2785 [==============================] - 11s 4ms/step - loss: 0.1835 - categorical_accuracy: 0.9179 - val_loss: 0.1800 - val_categorical_accuracy: 0.9158\n",
      "Epoch 37/250\n",
      "2785/2785 [==============================] - 15s 5ms/step - loss: 0.1844 - categorical_accuracy: 0.9181 - val_loss: 0.1847 - val_categorical_accuracy: 0.9168\n",
      "Epoch 38/250\n",
      "2785/2785 [==============================] - 11s 4ms/step - loss: 0.1810 - categorical_accuracy: 0.9198 - val_loss: 0.1829 - val_categorical_accuracy: 0.9174\n",
      "Epoch 39/250\n",
      "2785/2785 [==============================] - 15s 5ms/step - loss: 0.1797 - categorical_accuracy: 0.9190 - val_loss: 0.1777 - val_categorical_accuracy: 0.9210\n",
      "Epoch 40/250\n",
      "2785/2785 [==============================] - 11s 4ms/step - loss: 0.1815 - categorical_accuracy: 0.9195 - val_loss: 0.1890 - val_categorical_accuracy: 0.9126\n",
      "Epoch 41/250\n",
      "2785/2785 [==============================] - 15s 5ms/step - loss: 0.1771 - categorical_accuracy: 0.9204 - val_loss: 0.1817 - val_categorical_accuracy: 0.9184\n",
      "Epoch 42/250\n",
      "2785/2785 [==============================] - 11s 4ms/step - loss: 0.1786 - categorical_accuracy: 0.9202 - val_loss: 0.1756 - val_categorical_accuracy: 0.9186\n",
      "Epoch 43/250\n",
      " 627/2785 [=====>........................] - ETA: 7s - loss: 0.1861 - categorical_accuracy: 0.9190"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [33], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39msummary())\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#model.fit(train_dataset,epochs=250, verbose=1, callbacks=[callback])\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates_actions_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM, Input\n",
    "from keras.layers import Bidirectional\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(STATE_LEN+1+ACTION_LEN,)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(11, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=7)\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_value(model.optimizer.learning_rate, 0.0005)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "#model.fit(train_dataset,epochs=250, verbose=1, callbacks=[callback])\n",
    "\n",
    "model.fit(states_actions_t, encoding, epochs=250, validation_split=0.1, verbose=1, callbacks=[callback], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11334\n",
      "-1.0\n",
      "528\n",
      "-1.100000023841858\n",
      "43\n",
      "-2.0\n"
     ]
    }
   ],
   "source": [
    "target = states[53]\n",
    "rewards_ = {}\n",
    "\n",
    "for i in range(194040):\n",
    "    if (target==states[i]).all():\n",
    "        reward = rewards[i]\n",
    "        if not reward in rewards_:\n",
    "            rewards_[reward] = 1\n",
    "        else:\n",
    "            rewards_[reward] += 1\n",
    "        \n",
    "ns = {k: v for k, v in sorted(rewards_.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "count = 0\n",
    "for s in ns.keys():\n",
    "    print(ns[s])\n",
    "    count+=ns[s]\n",
    "    print(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "-1.0\n",
      "10\n",
      "0.0\n",
      "6\n",
      "-1.100000023841858\n",
      "5\n",
      "-2.0\n",
      "1\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "target = states_actions[53]\n",
    "rewards_ = {}\n",
    "\n",
    "for i in range(194040):\n",
    "    if (target==states_actions[i]).all():\n",
    "        reward = rewards[i-1]\n",
    "        if not reward in rewards_:\n",
    "            rewards_[reward] = 1\n",
    "        else:\n",
    "            rewards_[reward] += 1\n",
    "        \n",
    "ns = {k: v for k, v in sorted(rewards_.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "count = 0\n",
    "for s in ns.keys():\n",
    "    print(ns[s])\n",
    "    count+=ns[s]\n",
    "    print(s)\n",
    "\n",
    "print(len(new_state.keys()))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
