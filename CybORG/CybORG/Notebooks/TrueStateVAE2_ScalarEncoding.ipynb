{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True State VAE Scalar\n",
    "\n",
    "Trying a version of the VAE where categories ids 1-3 are scaled to (0,1) using (id-0.5)/3\n",
    "Wondering if this may work as the categories are essentially ordinal\n",
    "    (unknown=>known=>scanned)\n",
    "    (no_access=>user=>privileged)\n",
    "This could work better because the VAE is designed for scalar values (images) and I could not get the multi-task cat cross entropy to work in the one hot VAE attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-probability\n",
      "  Downloading tensorflow_probability-0.19.0-py2.py3-none-any.whl (6.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.7 MB 38.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (1.3.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from tensorflow-probability) (1.14.0)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (0.1.8)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (1.23.4)\n",
      "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (0.4.0)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (2.2.1)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (5.1.1)\n",
      "Installing collected packages: tensorflow-probability\n",
      "Successfully installed tensorflow-probability-0.19.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-probability\n",
    "from IPython import display\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import time\n",
    "\n",
    "from ray.rllib.offline.json_reader import JsonReader\n",
    "import numpy_indexed as npi\n",
    "import pandas as pd\n",
    "from true_state_viewer import TrueStateTreeGraphViz, display_tree_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Code from https://www.tensorflow.org/tutorials/generative/cvae\n",
    "class TrueStateVAE(tf.keras.Model):\n",
    "  \"\"\"Convolutional variational autoencoder.\"\"\"\n",
    "\n",
    "  def __init__(self, latent_dim):\n",
    "    super(TrueStateVAE, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(26)),\n",
    "#             tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            # No activation\n",
    "            tf.keras.layers.Dense(latent_dim + latent_dim)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(26)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "  @tf.function\n",
    "  def sample(self, eps=None):\n",
    "    if eps is None:\n",
    "      eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "    return self.decode(eps, apply_sigmoid=True)\n",
    "\n",
    "  def encode(self, x):\n",
    "    mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "    return mean, logvar\n",
    "\n",
    "  def reparameterize(self, mean, logvar):\n",
    "    eps = tf.random.normal(shape=mean.shape)\n",
    "    return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "  def decode(self, z, apply_sigmoid=False):\n",
    "    logits = self.decoder(z)\n",
    "    if apply_sigmoid:\n",
    "      probs = tf.sigmoid(logits)\n",
    "      return probs\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "  log2pi = tf.math.log(2. * np.pi)\n",
    "  return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis)\n",
    "\n",
    "\n",
    "def compute_loss(model, x):\n",
    "  mean, logvar = model.encode(x)\n",
    "  z = model.reparameterize(mean, logvar)\n",
    "  x_logit = model.decode(z)\n",
    "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "  \n",
    "  logpx_z = -tf.reduce_sum(cross_ent, axis=[1])\n",
    "\n",
    "  logpz = log_normal_pdf(z, 0., 0.)\n",
    "  logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "  \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "  This function computes the loss and gradients, and uses the latter to\n",
    "  update the model's parameters.\n",
    "  \"\"\"\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss = compute_loss(model, x)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "latent_dim = 4\n",
    "# latent_dim = 4\n",
    "# num_examples_to_generate = 16\n",
    "\n",
    "# # keeping the random vector constant for generation (prediction) so\n",
    "# # it will be easier to see the improvement.\n",
    "# random_vector_for_generation = tf.random.normal(\n",
    "#     shape=[num_examples_to_generate, latent_dim])\n",
    "true_state_model = TrueStateVAE(latent_dim)\n",
    "\n",
    "# train_size = 4445\n",
    "train_test_split = 0.98\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows = 4445\n",
      "number of rows = 305\n",
      "number of rows = 7972\n",
      "number of rows = 12716\n"
     ]
    }
   ],
   "source": [
    "meander = pd.read_csv('csv_data/TrueStates_200_4000_Meander.csv')\n",
    "bline = pd.read_csv('csv_data/TrueStates_1221_4000_B_Line.csv')\n",
    "badbluemeander = pd.read_csv('csv_data/TrueStates_200_4000_Meander_badblue.csv')\n",
    "\n",
    "dataset = pd.concat([meander, bline, badbluemeander], ignore_index=True)\n",
    "dataset = dataset.drop_duplicates()\n",
    "\n",
    "print(f\"number of rows = {meander.shape[0]}\")\n",
    "print(f\"number of rows = {bline.shape[0]}\")\n",
    "print(f\"number of rows = {badbluemeander.shape[0]}\")\n",
    "print(f\"number of rows = {dataset.shape[0]}\")\n",
    "# dataset=bline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "new_df = pd.DataFrame()\n",
    "for i in range(13):\n",
    "    new_df[f\"{i}_known\"] = (dataset[f\"{i}_unknown\"] + (dataset[f\"{i}_known\"]*2) + (dataset[f\"{i}_scanned\"]*3)-0.5)/3\n",
    "    new_df[f\"{i}_access\"] = (dataset[f\"{i}_none\"] + (dataset[f\"{i}_user\"]*2) + (dataset[f\"{i}_privileged\"]*3)-0.5)/3\n",
    "dataset = new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_known</th>\n",
       "      <th>0_access</th>\n",
       "      <th>1_known</th>\n",
       "      <th>1_access</th>\n",
       "      <th>2_known</th>\n",
       "      <th>2_access</th>\n",
       "      <th>3_known</th>\n",
       "      <th>3_access</th>\n",
       "      <th>4_known</th>\n",
       "      <th>4_access</th>\n",
       "      <th>...</th>\n",
       "      <th>8_known</th>\n",
       "      <th>8_access</th>\n",
       "      <th>9_known</th>\n",
       "      <th>9_access</th>\n",
       "      <th>10_known</th>\n",
       "      <th>10_access</th>\n",
       "      <th>11_known</th>\n",
       "      <th>11_access</th>\n",
       "      <th>12_known</th>\n",
       "      <th>12_access</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0_known  0_access   1_known  1_access   2_known  2_access   3_known  \\\n",
       "0  0.166667  0.166667  0.166667  0.166667  0.166667  0.166667  0.166667   \n",
       "1  0.166667  0.166667  0.166667  0.166667  0.166667  0.166667  0.166667   \n",
       "2  0.166667  0.166667  0.166667  0.166667  0.166667  0.166667  0.166667   \n",
       "3  0.166667  0.166667  0.166667  0.166667  0.166667  0.166667  0.166667   \n",
       "4  0.166667  0.166667  0.166667  0.166667  0.166667  0.166667  0.166667   \n",
       "\n",
       "   3_access   4_known  4_access  ...   8_known  8_access   9_known  9_access  \\\n",
       "0  0.166667  0.166667  0.166667  ...  0.500000  0.833333  0.166667  0.166667   \n",
       "1  0.166667  0.166667  0.166667  ...  0.500000  0.833333  0.500000  0.166667   \n",
       "2  0.166667  0.166667  0.166667  ...  0.500000  0.833333  0.833333  0.166667   \n",
       "3  0.166667  0.166667  0.166667  ...  0.833333  0.833333  0.833333  0.166667   \n",
       "4  0.166667  0.166667  0.166667  ...  0.833333  0.833333  0.833333  0.166667   \n",
       "\n",
       "   10_known  10_access  11_known  11_access  12_known  12_access  \n",
       "0  0.166667   0.166667  0.166667   0.166667  0.166667   0.166667  \n",
       "1  0.500000   0.166667  0.500000   0.166667  0.500000   0.166667  \n",
       "2  0.500000   0.166667  0.500000   0.166667  0.500000   0.166667  \n",
       "3  0.500000   0.166667  0.500000   0.166667  0.500000   0.166667  \n",
       "4  0.500000   0.166667  0.500000   0.166667  0.833333   0.166667  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "train_df=dataset.sample(frac=train_test_split,random_state=200)\n",
    "test_df=dataset.drop(train_df.index)\n",
    "\n",
    "train_size = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (tf.data.Dataset.from_tensor_slices((train_df.iloc[:,:].values)).shuffle(train_size).batch(batch_size))\n",
    "test_dataset = (tf.data.Dataset.from_tensor_slices((test_df.iloc[:,:].values)).shuffle(train_size).batch(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, Test set ELBO: -14.92189884185791, time elapse for current epoch: 0.26542139053344727\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "  start_time = time.time()\n",
    "  for train_x in train_dataset:\n",
    "    train_x = tf.cast(train_x,tf.float32)\n",
    "    train_step(true_state_model, train_x, optimizer)\n",
    "  end_time = time.time()\n",
    "\n",
    "  loss = tf.keras.metrics.Mean()\n",
    "  for test_x in test_dataset:\n",
    "    test_x = tf.cast(test_x,tf.float32)\n",
    "    loss(compute_loss(true_state_model, test_x))\n",
    "  elbo = -loss.result()\n",
    "  display.clear_output(wait=False)\n",
    "  print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "        .format(epoch, elbo, end_time - start_time))\n",
    "#   generate_and_save_images(model, epoch, test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_pred_pair(model, state):\n",
    "  state = tf.cast(state, tf.float32)\n",
    "  mean, logvar = model.encode(state)\n",
    "  z = model.reparameterize(mean, logvar)\n",
    "  predictions = model.sample(z)\n",
    "    \n",
    "  state_scaled = np.rint(((state*3)+0.5).numpy()).reshape(-1).astype(np.int64)-1\n",
    "  predictions_scaled = np.rint(((predictions*3)+0.5).numpy()).reshape(-1).astype(np.int64)-1\n",
    "#   print(state)\n",
    "#   print(state_scaled)\n",
    "  state_oh = np.eye(3)[state_scaled].reshape(-1,2,3)\n",
    "  pred_oh = np.eye(3)[predictions_scaled].reshape(-1,2,3)\n",
    "#   print(state_oh)\n",
    "#   state_oh = tf.reshape(state,(-1,2)) #tf.one_hot(tf.argmax(tf.reshape(state,(-1,3)),axis=1),depth=3)\n",
    "#   pred_oh = tf.one_hot(tf.argmax(tf.nn.softmax(tf.reshape(predictions,(-1,2,3))),axis=2),depth=3)\n",
    "#   print(f\"{state_oh.shape}, {pred_oh.shape}\")\n",
    "  return state_oh, pred_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0/12462 = 0.0, \n",
      "mean of squared diffs = 261250.0/972036=0.268765765876984\n",
      "percentage wrong = (261250.0/2)/(972036/3)=0.40314864881547596\n",
      "12462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ipywidgets/widgets/widget.py:443: DeprecationWarning: Passing unrecognized arguments to super(IntSlider).__init__(name='Index').\n",
      "object.__init__() takes exactly one argument (the instance to initialize)\n",
      "This is deprecated in traitlets 4.2.This error will be raised in a future release of traitlets.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a76bb77a784c4026b344b3b66fadee9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='<<', style=ButtonStyle()), Button(description='>>', style=ButtonStyle()), I…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eebe71a98d824046ba23b0088d3c9ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\xfa\\x00\\x00\\x01[\\x08\\x02\\x00\\x00\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test_dataset = (tf.data.Dataset.from_tensor_slices((dataset.iloc[:200,1:].values)).shuffle(train_size).batch(batch_size))\n",
    "train_dataset2 = (tf.data.Dataset.from_tensor_slices((train_df.iloc[:,:].values)).shuffle(train_size).batch(1))\n",
    "\n",
    "total_matches = 0\n",
    "total = 0\n",
    "nodes = 0\n",
    "sum_diffs_sqrd = 0\n",
    "state_pred_pairs = []\n",
    "state_pred_pair_tree_vis = []\n",
    "for test_x in train_dataset2:\n",
    "    total +=1\n",
    "    state_oh, pred_oh = get_state_pred_pair(true_state_model, test_x)\n",
    "    \n",
    "    state_pred_pairs.append([state_oh, pred_oh])\n",
    "    state_pred_pair_tree_vis.append([TrueStateTreeGraphViz(state_oh), TrueStateTreeGraphViz(pred_oh)])\n",
    "    \n",
    "    diffs = np.rint(state_oh) - np.rint(pred_oh)\n",
    "#     diffs = get_state_diff(true_state_model,test_x)\n",
    "    nodes += len(diffs.flatten())\n",
    "    diffs_sqrd = np.sum(diffs*diffs)\n",
    "    sum_diffs_sqrd += diffs_sqrd\n",
    "    if not diffs_sqrd >0:\n",
    "#       print(diffs)\n",
    "#     else:\n",
    "      total_matches += 1\n",
    "#       print(\"Match\")\n",
    "#       print(diffs)\n",
    "\n",
    "print(f\"accuracy = {total_matches}/{total} = {total_matches/total}, \\nmean of squared diffs = {sum_diffs_sqrd}/{nodes}={sum_diffs_sqrd/nodes}\\npercentage wrong = ({sum_diffs_sqrd}/{2})/({nodes}/{3})={(sum_diffs_sqrd/2)/(nodes/3)}\")\n",
    "display_tree_pairs(state_pred_pair_tree_vis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
