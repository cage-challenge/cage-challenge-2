{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PATH=/home/adamprice/miniconda3/envs/u75a/lib${PATH:+:${PATH}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export LD_LIBRARY_PATH=/home/adamprice/miniconda3/envs/u75a/lib:${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.2.*\n",
      "  Downloading tensorflow-2.2.3-cp38-cp38-manylinux2010_x86_64.whl (516.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m516.5/516.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:05\u001b[0m\n",
      "\u001b[?25hCollecting gast==0.3.3\n",
      "  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/adamprice/.local/lib/python3.8/site-packages (from tensorflow==2.2.*) (1.16.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/adamprice/.local/lib/python3.8/site-packages (from tensorflow==2.2.*) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /home/adamprice/.local/lib/python3.8/site-packages (from tensorflow==2.2.*) (0.2.0)\n",
      "Collecting numpy<1.19.0,>=1.16.0\n",
      "  Using cached numpy-1.18.5-cp38-cp38-manylinux1_x86_64.whl (20.6 MB)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/adamprice/.local/lib/python3.8/site-packages (from tensorflow==2.2.*) (0.37.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /home/adamprice/miniconda3/envs/u75a/lib/python3.8/site-packages (from tensorflow==2.2.*) (3.19.6)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /home/adamprice/.local/lib/python3.8/site-packages (from tensorflow==2.2.*) (1.1.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/adamprice/.local/lib/python3.8/site-packages (from tensorflow==2.2.*) (1.0.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /home/adamprice/.local/lib/python3.8/site-packages (from tensorflow==2.2.*) (1.6.3)\n",
      "Collecting tensorboard<2.3.0,>=2.2.0\n",
      "  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.3.0,>=2.2.0\n",
      "  Downloading tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.6/454.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /home/adamprice/miniconda3/envs/u75a/lib/python3.8/site-packages (from tensorflow==2.2.*) (1.51.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/adamprice/.local/lib/python3.8/site-packages (from tensorflow==2.2.*) (1.1.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /home/adamprice/.local/lib/python3.8/site-packages (from tensorflow==2.2.*) (2.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/adamprice/.local/lib/python3.8/site-packages (from tensorflow==2.2.*) (1.13.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/adamprice/.local/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.*) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/adamprice/.local/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.*) (49.2.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/adamprice/.local/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.*) (2.26.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/adamprice/.local/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.*) (2.0.2)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Using cached google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/adamprice/.local/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.*) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/adamprice/.local/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.*) (1.8.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/adamprice/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.*) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/adamprice/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.*) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/adamprice/miniconda3/envs/u75a/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.*) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/adamprice/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.*) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/adamprice/miniconda3/envs/u75a/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.*) (6.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/adamprice/miniconda3/envs/u75a/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.*) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/adamprice/miniconda3/envs/u75a/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.*) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/adamprice/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.*) (2.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/adamprice/miniconda3/envs/u75a/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.*) (3.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/adamprice/miniconda3/envs/u75a/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.*) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/adamprice/miniconda3/envs/u75a/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.*) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/adamprice/.local/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.*) (3.1.1)\n",
      "Installing collected packages: tensorflow-estimator, numpy, gast, google-auth, tensorboard, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.10.0\n",
      "    Uninstalling tensorflow-estimator-2.10.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.10.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.6\n",
      "    Uninstalling numpy-1.21.6:\n",
      "      Successfully uninstalled numpy-1.21.6\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.2.2\n",
      "    Uninstalling gast-0.2.2:\n",
      "      Successfully uninstalled gast-0.2.2\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 2.16.2\n",
      "    Uninstalling google-auth-2.16.2:\n",
      "      Successfully uninstalled google-auth-2.16.2\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.10.1\n",
      "    Uninstalling tensorboard-2.10.1:\n",
      "      Successfully uninstalled tensorboard-2.10.1\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.10.1\n",
      "    Uninstalling tensorflow-2.10.1:\n",
      "      Successfully uninstalled tensorflow-2.10.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "imageio 2.16.0 requires numpy>=1.20.0, but you have numpy 1.18.5 which is incompatible.\n",
      "gymnasium 0.27.1 requires numpy>=1.21.0, but you have numpy 1.18.5 which is incompatible.\n",
      "google-api-core 2.11.0 requires google-auth<3.0dev,>=2.14.1, but you have google-auth 1.35.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed gast-0.3.3 google-auth-1.35.0 numpy-1.18.5 tensorboard-2.2.2 tensorflow-2.2.3 tensorflow-estimator-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.2.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 12:46:24.889206: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-30 12:46:25.092970: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-30 12:46:25.901276: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/adamprice/miniconda3/envs/u75a/lib/\n",
      "2023-03-30 12:46:25.901384: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/adamprice/miniconda3/envs/u75a/lib/\n",
      "2023-03-30 12:46:25.901397: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import pandas as pd\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM, Input\n",
    "#from ProcessTrueStateActionData import read_df_in_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess the data \n",
    "(produce tf train+test datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = 0.75\n",
    "data_path = '/home/adamprice/u75a-Data-Efficient-Decisions/CybORG/CybORG/Notebooks/logs/PPO/no_decoy_200000'\n",
    "nodes = np.load(data_path + '/data/nodes.npy')\n",
    "actions = np.load(data_path + '/data/actions.npy')\n",
    "node_id = np.load(data_path + '/data/node_id.npy')\n",
    "next_nodes = np.load(data_path + '/data/next_nodes.npy')\n",
    "exploit = np.load(data_path + '/data/exploit.npy')\n",
    "scan = np.load(data_path + '/data/scan.npy')\n",
    "privileged = np.load(data_path + '/data/privileged.npy')\n",
    "user = np.load(data_path + '/data/user.npy')\n",
    "unknown = np.load(data_path + '/data/unknown.npy')\n",
    "no = np.load(data_path + '/data/no.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate([node_id, nodes], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensoRT (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensoRT\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensoRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "STATE_LEN = 91\n",
    "ACTION_LEN = 3\n",
    "    \n",
    "max_train_epochs = 50\n",
    "\n",
    "losses = []\n",
    "input_ = Input(shape=(data.shape[1],))\n",
    "x = Dense(128, activation='relu', name='hidden')(input_)\n",
    "outs = []\n",
    "\n",
    "outs.append(Dense(3, activation='softmax', name='activity')(x))\n",
    "outs.append(Dense(4, activation='softmax', name='compromised')(x))\n",
    "losses.append(tf.keras.losses.CategoricalCrossentropy())\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 2:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.15)\n",
    "\n",
    "base_model = Model(input_, outs)\n",
    "base_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=losses, metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, min_delta=0.0005)\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_map = {}\n",
    "data_map['activity'] = next_nodes[p,:3]\n",
    "data_map['compromised'] = next_nodes[p,3:]\n",
    "with tf.device(\"/device:GPU:1\"):\n",
    "    history = base_model.fit(data[p,:], data_map, epochs=max_train_epochs, validation_split=0.25, \n",
    "                                    verbose=0, callbacks=[es_callback, lr_callback], batch_size=512, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
